/home/e/e1124485/CS5228/trial7/ensemble7.py:75: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  KNN_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:86: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  predict_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:75: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  KNN_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:86: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  predict_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:75: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  KNN_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:86: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  predict_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:75: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  KNN_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:86: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  predict_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:75: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  KNN_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:86: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  predict_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:75: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  KNN_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:86: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  predict_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:75: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  KNN_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:86: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  predict_X['latitude'] *= 2
16
6
16
12
15
6
13
9
6
6
8
8
3
2
5
9
11
6
17
1
15
10
5
5
7
7
5
9
5
7
7
[flaml.automl.logger: 11-01 23:30:05] {1596} WARNING - n_concurrent_trials > 1 is only supported when using Ray or Spark. Ray installed, setting use_ray to True. If you want to use Spark, set use_spark to True.
[flaml.automl.logger: 11-01 23:30:05] {1679} INFO - task = regression
[flaml.automl.logger: 11-01 23:30:05] {1690} INFO - Evaluation method: cv
[flaml.automl.logger: 11-01 23:30:05] {1788} INFO - Minimizing error metric: rmse
[flaml.automl.logger: 11-01 23:30:05] {1900} INFO - List of ML learners in AutoML Run: ['lgbm']
2023-11-01 23:30:05,303	WARNING optuna.py:297 -- You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.
[32m[I 2023-11-01 23:30:05,304][0m A new study created in memory with name: optuna[0m
2023-11-01 23:30:05,334	WARNING function_runner.py:603 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.
[32m[I 2023-11-01 23:30:05,338][0m A new study created in memory with name: optuna[0m
== Status ==
Current time: 2023-11-01 23:30:58 (running for 00:00:03.42)
Memory usage on this node: 20.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 4.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 1/1000000 (1 RUNNING)


== Status ==
Current time: 2023-11-01 23:31:19 (running for 00:00:24.90)
Memory usage on this node: 35.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 40.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 10/1000000 (10 RUNNING)


== Status ==
Current time: 2023-11-01 23:31:26 (running for 00:00:31.52)
Memory usage on this node: 45.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 44.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 11/1000000 (11 RUNNING)


== Status ==
Current time: 2023-11-01 23:31:26 (running for 00:00:31.57)
Memory usage on this node: 44.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 44.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: a79cdf94 with val_loss=588.057257686148 and parameters={'n_estimators': 5, 'num_leaves': 4, 'min_child_samples': 16, 'learning_rate': 0.001439516130279818, 'log_max_bin': 3, 'colsample_bytree': 0.5609665998509923, 'reg_alpha': 0.009543428311289489, 'reg_lambda': 0.18011296997027265, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 12/1000000 (1 PENDING, 11 RUNNING)


== Status ==
Current time: 2023-11-01 23:31:31 (running for 00:00:36.59)
Memory usage on this node: 37.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 108.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: a79cdf93 with val_loss=496.98550924083213 and parameters={'n_estimators': 6, 'num_leaves': 6, 'min_child_samples': 54, 'learning_rate': 0.681085689470444, 'log_max_bin': 3, 'colsample_bytree': 0.9296806900350443, 'reg_alpha': 0.003095681942146277, 'reg_lambda': 125.28594199895093, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 28/1000000 (27 RUNNING, 1 TERMINATED)


== Status ==
Current time: 2023-11-01 23:32:05 (running for 00:01:10.83)
Memory usage on this node: 40.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 104.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: a79cdf93 with val_loss=496.98550924083213 and parameters={'n_estimators': 6, 'num_leaves': 6, 'min_child_samples': 54, 'learning_rate': 0.681085689470444, 'log_max_bin': 3, 'colsample_bytree': 0.9296806900350443, 'reg_alpha': 0.003095681942146277, 'reg_lambda': 125.28594199895093, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 29/1000000 (1 PENDING, 26 RUNNING, 2 TERMINATED)


== Status ==
Current time: 2023-11-01 23:32:10 (running for 00:01:15.87)
Memory usage on this node: 44.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: a79cdf93 with val_loss=496.98550924083213 and parameters={'n_estimators': 6, 'num_leaves': 6, 'min_child_samples': 54, 'learning_rate': 0.681085689470444, 'log_max_bin': 3, 'colsample_bytree': 0.9296806900350443, 'reg_alpha': 0.003095681942146277, 'reg_lambda': 125.28594199895093, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 40/1000000 (31 RUNNING, 9 TERMINATED)


== Status ==
Current time: 2023-11-01 23:32:27 (running for 00:01:33.19)
Memory usage on this node: 27.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: a79cdf93 with val_loss=496.98550924083213 and parameters={'n_estimators': 6, 'num_leaves': 6, 'min_child_samples': 54, 'learning_rate': 0.681085689470444, 'log_max_bin': 3, 'colsample_bytree': 0.9296806900350443, 'reg_alpha': 0.003095681942146277, 'reg_lambda': 125.28594199895093, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 41/1000000 (1 PENDING, 31 RUNNING, 9 TERMINATED)


== Status ==
Current time: 2023-11-01 23:32:32 (running for 00:01:38.24)
Memory usage on this node: 31.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: b98550a4 with val_loss=492.5509594107818 and parameters={'n_estimators': 12, 'num_leaves': 5, 'min_child_samples': 15, 'learning_rate': 1.0, 'log_max_bin': 6, 'colsample_bytree': 0.28928025005570335, 'reg_alpha': 5.876832069419527, 'reg_lambda': 133.48528168261797, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 51/1000000 (32 RUNNING, 19 TERMINATED)


== Status ==
Current time: 2023-11-01 23:32:46 (running for 00:01:51.89)
Memory usage on this node: 38.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: b98550a4 with val_loss=492.5509594107818 and parameters={'n_estimators': 12, 'num_leaves': 5, 'min_child_samples': 15, 'learning_rate': 1.0, 'log_max_bin': 6, 'colsample_bytree': 0.28928025005570335, 'reg_alpha': 5.876832069419527, 'reg_lambda': 133.48528168261797, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 51/1000000 (32 RUNNING, 19 TERMINATED)


== Status ==
Current time: 2023-11-01 23:32:51 (running for 00:01:57.07)
Memory usage on this node: 42.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: ddde77e3 with val_loss=488.02064036886094 and parameters={'n_estimators': 7, 'num_leaves': 21, 'min_child_samples': 11, 'learning_rate': 0.8795579359736123, 'log_max_bin': 8, 'colsample_bytree': 0.37069628172330193, 'reg_alpha': 3.3229447609762377, 'reg_lambda': 250.69871501172477, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 61/1000000 (31 RUNNING, 30 TERMINATED)


== Status ==
Current time: 2023-11-01 23:33:01 (running for 00:02:06.40)
Memory usage on this node: 43.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: ddde77e3 with val_loss=488.02064036886094 and parameters={'n_estimators': 7, 'num_leaves': 21, 'min_child_samples': 11, 'learning_rate': 0.8795579359736123, 'log_max_bin': 8, 'colsample_bytree': 0.37069628172330193, 'reg_alpha': 3.3229447609762377, 'reg_lambda': 250.69871501172477, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 62/1000000 (32 RUNNING, 30 TERMINATED)


== Status ==
Current time: 2023-11-01 23:33:06 (running for 00:02:11.66)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: ddde77e3 with val_loss=488.02064036886094 and parameters={'n_estimators': 7, 'num_leaves': 21, 'min_child_samples': 11, 'learning_rate': 0.8795579359736123, 'log_max_bin': 8, 'colsample_bytree': 0.37069628172330193, 'reg_alpha': 3.3229447609762377, 'reg_lambda': 250.69871501172477, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 65/1000000 (31 RUNNING, 34 TERMINATED)


2023-11-01 23:33:44,315	WARNING util.py:214 -- The `start_trial` operation took 0.532 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-01 23:33:11 (running for 00:02:16.92)
Memory usage on this node: 28.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: e9d0061a with val_loss=483.71066575508394 and parameters={'n_estimators': 22, 'num_leaves': 87, 'min_child_samples': 17, 'learning_rate': 1.0, 'log_max_bin': 5, 'colsample_bytree': 0.30964974714555565, 'reg_alpha': 4.793284507718617, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 78/1000000 (31 RUNNING, 47 TERMINATED)


== Status ==
Current time: 2023-11-01 23:33:42 (running for 00:02:47.94)
Memory usage on this node: 26.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: e9d0061a with val_loss=483.71066575508394 and parameters={'n_estimators': 22, 'num_leaves': 87, 'min_child_samples': 17, 'learning_rate': 1.0, 'log_max_bin': 5, 'colsample_bytree': 0.30964974714555565, 'reg_alpha': 4.793284507718617, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 79/1000000 (1 PENDING, 30 RUNNING, 48 TERMINATED)


== Status ==
Current time: 2023-11-01 23:33:47 (running for 00:02:53.08)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: f5111224 with val_loss=481.0380275872159 and parameters={'n_estimators': 98, 'num_leaves': 48, 'min_child_samples': 63, 'learning_rate': 0.24458931681836676, 'log_max_bin': 4, 'colsample_bytree': 0.7670537428640015, 'reg_alpha': 0.0009765625, 'reg_lambda': 949.7373104155134, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 87/1000000 (31 RUNNING, 56 TERMINATED)


== Status ==
Current time: 2023-11-01 23:34:14 (running for 00:03:19.45)
Memory usage on this node: 41.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: f5111224 with val_loss=481.0380275872159 and parameters={'n_estimators': 98, 'num_leaves': 48, 'min_child_samples': 63, 'learning_rate': 0.24458931681836676, 'log_max_bin': 4, 'colsample_bytree': 0.7670537428640015, 'reg_alpha': 0.0009765625, 'reg_lambda': 949.7373104155134, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 88/1000000 (1 PENDING, 31 RUNNING, 56 TERMINATED)


== Status ==
Current time: 2023-11-01 23:34:19 (running for 00:03:24.49)
Memory usage on this node: 42.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: f5111220 with val_loss=480.9056111690446 and parameters={'n_estimators': 50, 'num_leaves': 137, 'min_child_samples': 34, 'learning_rate': 0.20513373839115787, 'log_max_bin': 5, 'colsample_bytree': 0.7912394336719969, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 95/1000000 (1 PENDING, 31 RUNNING, 63 TERMINATED)


== Status ==
Current time: 2023-11-01 23:34:24 (running for 00:03:29.52)
Memory usage on this node: 44.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: f5111220 with val_loss=480.9056111690446 and parameters={'n_estimators': 50, 'num_leaves': 137, 'min_child_samples': 34, 'learning_rate': 0.20513373839115787, 'log_max_bin': 5, 'colsample_bytree': 0.7912394336719969, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 104/1000000 (31 RUNNING, 73 TERMINATED)


== Status ==
Current time: 2023-11-01 23:35:48 (running for 00:04:53.69)
Memory usage on this node: 44.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 203489ef with val_loss=480.54008880650207 and parameters={'n_estimators': 46, 'num_leaves': 137, 'min_child_samples': 66, 'learning_rate': 0.1937396495348768, 'log_max_bin': 5, 'colsample_bytree': 0.5832358244593082, 'reg_alpha': 0.0012916115224854592, 'reg_lambda': 344.0119756073199, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 105/1000000 (1 PENDING, 31 RUNNING, 73 TERMINATED)


== Status ==
Current time: 2023-11-01 23:35:53 (running for 00:04:58.94)
Memory usage on this node: 48.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 203489ef with val_loss=480.54008880650207 and parameters={'n_estimators': 46, 'num_leaves': 137, 'min_child_samples': 66, 'learning_rate': 0.1937396495348768, 'log_max_bin': 5, 'colsample_bytree': 0.5832358244593082, 'reg_alpha': 0.0012916115224854592, 'reg_lambda': 344.0119756073199, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 112/1000000 (31 RUNNING, 81 TERMINATED)


== Status ==
Current time: 2023-11-01 23:36:02 (running for 00:05:07.39)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 203489ef with val_loss=480.54008880650207 and parameters={'n_estimators': 46, 'num_leaves': 137, 'min_child_samples': 66, 'learning_rate': 0.1937396495348768, 'log_max_bin': 5, 'colsample_bytree': 0.5832358244593082, 'reg_alpha': 0.0012916115224854592, 'reg_lambda': 344.0119756073199, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 123/1000000 (31 RUNNING, 92 TERMINATED)


== Status ==
Current time: 2023-11-01 23:37:26 (running for 00:06:31.84)
Memory usage on this node: 47.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 203489ef with val_loss=480.54008880650207 and parameters={'n_estimators': 46, 'num_leaves': 137, 'min_child_samples': 66, 'learning_rate': 0.1937396495348768, 'log_max_bin': 5, 'colsample_bytree': 0.5832358244593082, 'reg_alpha': 0.0012916115224854592, 'reg_lambda': 344.0119756073199, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 124/1000000 (32 RUNNING, 92 TERMINATED)


== Status ==
Current time: 2023-11-01 23:38:03 (running for 00:07:09.00)
Memory usage on this node: 42.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 203489ef with val_loss=480.54008880650207 and parameters={'n_estimators': 46, 'num_leaves': 137, 'min_child_samples': 66, 'learning_rate': 0.1937396495348768, 'log_max_bin': 5, 'colsample_bytree': 0.5832358244593082, 'reg_alpha': 0.0012916115224854592, 'reg_lambda': 344.0119756073199, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 124/1000000 (32 RUNNING, 92 TERMINATED)


2023-11-01 23:38:14,231	WARNING util.py:214 -- The `start_trial` operation took 0.574 s, which may be a performance bottleneck.
2023-11-01 23:40:28,781	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.692 s, which may be a performance bottleneck.
2023-11-01 23:40:28,781	WARNING util.py:214 -- The `process_trial_result` operation took 0.693 s, which may be a performance bottleneck.
2023-11-01 23:40:28,781	WARNING util.py:214 -- Processing trial results took 0.693 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-01 23:40:28,782	WARNING util.py:214 -- The `process_trial_result` operation took 0.693 s, which may be a performance bottleneck.
2023-11-01 23:40:31,311	WARNING util.py:214 -- The `start_trial` operation took 0.549 s, which may be a performance bottleneck.
2023-11-01 23:40:32,454	WARNING util.py:214 -- The `start_trial` operation took 0.556 s, which may be a performance bottleneck.
2023-11-01 23:40:34,929	WARNING util.py:214 -- The `start_trial` operation took 0.664 s, which may be a performance bottleneck.
2023-11-01 23:43:57,000	WARNING util.py:214 -- The `start_trial` operation took 0.540 s, which may be a performance bottleneck.
2023-11-01 23:46:47,256	WARNING optuna.py:478 -- Received additional result for trial 6ec1641c, but it already finished. Result: {'pred_time': 1.1183677369285114e-05, 'wall_clock_time': 935.8119368553162, 'val_loss': 541.7358916437533, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7f0aadabce80>, 'time_this_iter_s': 118.97803282737732, 'done': False, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 1, 'trial_id': '6ec1641c', 'experiment_id': '48a2963ddbaf41f194246837508a5ebb', 'date': '2023-11-01_23-45-40', 'timestamp': 1698853540, 'time_total_s': 118.97803282737732, 'pid': 493106, 'hostname': 'xcnf29', 'node_ip': '192.168.48.208', 'time_since_restore': 118.97803282737732, 'timesteps_since_restore': 0, 'iterations_since_restore': 1, 'warmup_time': 0.01685929298400879, 'metric_for_logging/pred_time': 1.1183677369285114e-05, 'config/n_estimators': 4, 'config/num_leaves': 2627, 'config/min_child_samples': 4, 'config/learning_rate': 0.08607741746190169, 'config/log_max_bin': 3, 'config/colsample_bytree': 0.42504554192840693, 'config/reg_alpha': 331.03718552740247, 'config/reg_lambda': 0.03774435768979078, 'config/learner': 'lgbm'}
== Status ==
Current time: 2023-11-01 23:38:09 (running for 00:07:14.34)
Memory usage on this node: 49.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 136/1000000 (31 RUNNING, 105 TERMINATED)


== Status ==
Current time: 2023-11-01 23:38:18 (running for 00:07:23.77)
Memory usage on this node: 25.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 146/1000000 (32 RUNNING, 114 TERMINATED)


== Status ==
Current time: 2023-11-01 23:40:29 (running for 00:09:34.62)
Memory usage on this node: 48.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 146/1000000 (32 RUNNING, 114 TERMINATED)


== Status ==
Current time: 2023-11-01 23:40:34 (running for 00:09:40.27)
Memory usage on this node: 52.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 152/1000000 (31 RUNNING, 121 TERMINATED)


== Status ==
Current time: 2023-11-01 23:42:31 (running for 00:11:36.99)
Memory usage on this node: 32.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 153/1000000 (32 RUNNING, 121 TERMINATED)


== Status ==
Current time: 2023-11-01 23:43:40 (running for 00:12:45.51)
Memory usage on this node: 48.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 153/1000000 (31 RUNNING, 122 TERMINATED)


== Status ==
Current time: 2023-11-01 23:43:45 (running for 00:12:50.73)
Memory usage on this node: 52.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 162/1000000 (31 RUNNING, 131 TERMINATED)


== Status ==
Current time: 2023-11-01 23:43:53 (running for 00:12:59.20)
Memory usage on this node: 28.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 168/1000000 (1 PENDING, 31 RUNNING, 136 TERMINATED)


== Status ==
Current time: 2023-11-01 23:43:59 (running for 00:13:04.40)
Memory usage on this node: 32.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 173/1000000 (1 PENDING, 31 RUNNING, 141 TERMINATED)


== Status ==
Current time: 2023-11-01 23:45:31 (running for 00:14:36.57)
Memory usage on this node: 31.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 173/1000000 (32 RUNNING, 141 TERMINATED)


== Status ==
Current time: 2023-11-01 23:46:40 (running for 00:15:46.02)
Memory usage on this node: 48.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 173/1000000 (32 RUNNING, 141 TERMINATED)


== Status ==
Current time: 2023-11-01 23:46:45 (running for 00:15:51.13)
Memory usage on this node: 51.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 180/1000000 (31 RUNNING, 149 TERMINATED)


2023-11-01 23:46:56,518	WARNING util.py:214 -- The `start_trial` operation took 0.553 s, which may be a performance bottleneck.
2023-11-01 23:46:57,061	WARNING optuna.py:478 -- Received additional result for trial 6ec1641c, but it already finished. Result: {'pred_time': 1.1183677369285114e-05, 'wall_clock_time': 935.8119368553162, 'val_loss': 541.7358916437533, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7f0aad0d5810>, 'time_this_iter_s': 66.60368633270264, 'done': False, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 2, 'trial_id': '6ec1641c', 'experiment_id': '48a2963ddbaf41f194246837508a5ebb', 'date': '2023-11-01_23-46-47', 'timestamp': 1698853607, 'time_total_s': 185.58171916007996, 'pid': 493106, 'hostname': 'xcnf29', 'node_ip': '192.168.48.208', 'time_since_restore': 185.58171916007996, 'timesteps_since_restore': 0, 'iterations_since_restore': 2, 'warmup_time': 0.01685929298400879, 'metric_for_logging/pred_time': 1.1183677369285114e-05, 'config/n_estimators': 4, 'config/num_leaves': 2627, 'config/min_child_samples': 4, 'config/learning_rate': 0.08607741746190169, 'config/log_max_bin': 3, 'config/colsample_bytree': 0.42504554192840693, 'config/reg_alpha': 331.03718552740247, 'config/reg_lambda': 0.03774435768979078, 'config/learner': 'lgbm'}
2023-11-01 23:46:59,068	WARNING util.py:214 -- The `start_trial` operation took 0.652 s, which may be a performance bottleneck.
2023-11-01 23:46:59,069	WARNING optuna.py:492 -- Received additional completion for trial 6ec1641c, but it already finished. Result: {'pred_time': 1.1183677369285114e-05, 'wall_clock_time': 935.8119368553162, 'val_loss': 541.7358916437533, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7f0aad0d5810>, 'time_this_iter_s': 66.60368633270264, 'done': True, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 2, 'trial_id': '6ec1641c', 'experiment_id': '48a2963ddbaf41f194246837508a5ebb', 'date': '2023-11-01_23-46-47', 'timestamp': 1698853607, 'time_total_s': 185.58171916007996, 'pid': 493106, 'hostname': 'xcnf29', 'node_ip': '192.168.48.208', 'time_since_restore': 185.58171916007996, 'timesteps_since_restore': 0, 'iterations_since_restore': 2, 'warmup_time': 0.01685929298400879, 'experiment_tag': '155_colsample_bytree=0.4250,learner=lgbm,learning_rate=0.0861,log_max_bin=3,min_child_samples=4,n_estimators=4,num_leaves=2627,reg_alpha=331.0372,reg_lambda=0.0377', 'metric_for_logging/pred_time': 1.1183677369285114e-05, 'config/n_estimators': 4, 'config/num_leaves': 2627, 'config/min_child_samples': 4, 'config/learning_rate': 0.08607741746190169, 'config/log_max_bin': 3, 'config/colsample_bytree': 0.42504554192840693, 'config/reg_alpha': 331.03718552740247, 'config/reg_lambda': 0.03774435768979078, 'config/learner': 'lgbm'}
2023-11-01 23:50:45,181	WARNING util.py:214 -- The `start_trial` operation took 0.547 s, which may be a performance bottleneck.
2023-11-01 23:53:03,333	WARNING util.py:214 -- The `start_trial` operation took 0.556 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-01 23:46:54 (running for 00:15:59.61)
Memory usage on this node: 27.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 185/1000000 (31 RUNNING, 154 TERMINATED)


== Status ==
Current time: 2023-11-01 23:46:59 (running for 00:16:05.28)
Memory usage on this node: 31.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 190/1000000 (1 PENDING, 31 RUNNING, 158 TERMINATED)


== Status ==
Current time: 2023-11-01 23:49:01 (running for 00:18:06.98)
Memory usage on this node: 46.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 190/1000000 (32 RUNNING, 158 TERMINATED)


== Status ==
Current time: 2023-11-01 23:50:42 (running for 00:19:47.50)
Memory usage on this node: 48.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 190/1000000 (32 RUNNING, 158 TERMINATED)


== Status ==
Current time: 2023-11-01 23:50:47 (running for 00:19:52.85)
Memory usage on this node: 52.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 195/1000000 (31 RUNNING, 164 TERMINATED)


== Status ==
Current time: 2023-11-01 23:50:55 (running for 00:20:01.33)
Memory usage on this node: 27.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 201/1000000 (1 PENDING, 31 RUNNING, 169 TERMINATED)


== Status ==
Current time: 2023-11-01 23:53:00 (running for 00:22:05.80)
Memory usage on this node: 42.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 201/1000000 (1 PENDING, 31 RUNNING, 169 TERMINATED)


== Status ==
Current time: 2023-11-01 23:53:05 (running for 00:22:11.03)
Memory usage on this node: 46.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 206/1000000 (31 RUNNING, 175 TERMINATED)


== Status ==
Current time: 2023-11-01 23:55:08 (running for 00:24:13.45)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 207/1000000 (1 PENDING, 31 RUNNING, 175 TERMINATED)


== Status ==
Current time: 2023-11-01 23:55:13 (running for 00:24:18.73)
Memory usage on this node: 32.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 212/1000000 (31 RUNNING, 181 TERMINATED)


== Status ==
Current time: 2023-11-01 23:57:24 (running for 00:26:29.89)
Memory usage on this node: 40.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 213/1000000 (1 PENDING, 31 RUNNING, 181 TERMINATED)


== Status ==
Current time: 2023-11-01 23:57:29 (running for 00:26:35.23)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 217/1000000 (31 RUNNING, 186 TERMINATED)


2023-11-01 23:59:30,506	WARNING util.py:214 -- The `start_trial` operation took 0.504 s, which may be a performance bottleneck.
2023-11-02 00:01:30,368	WARNING util.py:214 -- The `start_trial` operation took 0.783 s, which may be a performance bottleneck.
2023-11-02 00:01:31,178	WARNING util.py:214 -- The `start_trial` operation took 0.584 s, which may be a performance bottleneck.
2023-11-02 00:01:33,978	WARNING util.py:214 -- The `start_trial` operation took 0.637 s, which may be a performance bottleneck.
2023-11-02 00:01:34,786	WARNING util.py:214 -- The `start_trial` operation took 0.668 s, which may be a performance bottleneck.
2023-11-02 00:01:35,973	WARNING util.py:214 -- The `start_trial` operation took 0.712 s, which may be a performance bottleneck.
2023-11-02 00:01:36,862	WARNING util.py:214 -- The `start_trial` operation took 0.861 s, which may be a performance bottleneck.
2023-11-02 00:03:21,556	WARNING util.py:214 -- The `start_trial` operation took 0.526 s, which may be a performance bottleneck.
2023-11-02 00:04:30,558	WARNING util.py:214 -- The `start_trial` operation took 0.742 s, which may be a performance bottleneck.
2023-11-02 00:05:51,105	WARNING util.py:214 -- The `start_trial` operation took 0.879 s, which may be a performance bottleneck.
2023-11-02 00:05:52,146	WARNING util.py:214 -- The `start_trial` operation took 0.516 s, which may be a performance bottleneck.
2023-11-02 00:05:53,255	WARNING util.py:214 -- The `start_trial` operation took 1.046 s, which may be a performance bottleneck.
2023-11-02 00:05:53,962	WARNING util.py:214 -- The `start_trial` operation took 0.620 s, which may be a performance bottleneck.
2023-11-02 00:05:54,922	WARNING util.py:214 -- The `start_trial` operation took 0.588 s, which may be a performance bottleneck.
2023-11-02 00:05:55,940	WARNING util.py:214 -- The `start_trial` operation took 0.805 s, which may be a performance bottleneck.
2023-11-02 00:05:57,562	WARNING util.py:214 -- The `start_trial` operation took 0.965 s, which may be a performance bottleneck.
2023-11-02 00:05:58,350	WARNING util.py:214 -- The `start_trial` operation took 0.709 s, which may be a performance bottleneck.
2023-11-02 00:05:59,292	WARNING util.py:214 -- The `start_trial` operation took 0.724 s, which may be a performance bottleneck.
2023-11-02 00:06:00,294	WARNING util.py:214 -- The `start_trial` operation took 0.535 s, which may be a performance bottleneck.
2023-11-02 00:06:02,187	WARNING util.py:214 -- The `start_trial` operation took 0.734 s, which may be a performance bottleneck.
2023-11-02 00:06:03,085	WARNING util.py:214 -- The `start_trial` operation took 0.747 s, which may be a performance bottleneck.
2023-11-02 00:06:03,944	WARNING util.py:214 -- The `start_trial` operation took 0.663 s, which may be a performance bottleneck.
2023-11-02 00:06:04,958	WARNING util.py:214 -- The `start_trial` operation took 0.641 s, which may be a performance bottleneck.
2023-11-02 00:06:05,726	WARNING util.py:214 -- The `start_trial` operation took 0.625 s, which may be a performance bottleneck.
2023-11-02 00:06:06,519	WARNING util.py:214 -- The `start_trial` operation took 0.784 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-01 23:59:29 (running for 00:28:34.97)
Memory usage on this node: 39.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 218/1000000 (1 PENDING, 31 RUNNING, 186 TERMINATED)


== Status ==
Current time: 2023-11-01 23:59:34 (running for 00:28:40.21)
Memory usage on this node: 42.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 222/1000000 (31 RUNNING, 191 TERMINATED)


== Status ==
Current time: 2023-11-02 00:01:26 (running for 00:30:31.66)
Memory usage on this node: 51.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 223/1000000 (1 PENDING, 31 RUNNING, 191 TERMINATED)


== Status ==
Current time: 2023-11-02 00:01:31 (running for 00:30:36.75)
Memory usage on this node: 40.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 228/1000000 (1 PENDING, 31 RUNNING, 196 TERMINATED)


== Status ==
Current time: 2023-11-02 00:01:36 (running for 00:30:42.20)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 233/1000000 (32 RUNNING, 201 TERMINATED)


== Status ==
Current time: 2023-11-02 00:03:16 (running for 00:32:21.73)
Memory usage on this node: 33.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 233/1000000 (31 RUNNING, 202 TERMINATED)


== Status ==
Current time: 2023-11-02 00:03:21 (running for 00:32:26.90)
Memory usage on this node: 36.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 240/1000000 (32 RUNNING, 208 TERMINATED)


== Status ==
Current time: 2023-11-02 00:04:28 (running for 00:33:33.70)
Memory usage on this node: 50.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 240/1000000 (32 RUNNING, 208 TERMINATED)


== Status ==
Current time: 2023-11-02 00:04:33 (running for 00:33:38.85)
Memory usage on this node: 56.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 246/1000000 (1 PENDING, 31 RUNNING, 214 TERMINATED)


== Status ==
Current time: 2023-11-02 00:05:50 (running for 00:34:55.56)
Memory usage on this node: 44.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 246/1000000 (1 PENDING, 30 RUNNING, 215 TERMINATED)


== Status ==
Current time: 2023-11-02 00:05:55 (running for 00:35:01.28)
Memory usage on this node: 44.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 251/1000000 (31 RUNNING, 220 TERMINATED)


== Status ==
Current time: 2023-11-02 00:06:01 (running for 00:35:06.34)
Memory usage on this node: 49.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 256/1000000 (31 RUNNING, 225 TERMINATED)


2023-11-02 00:08:21,248	WARNING util.py:214 -- The `start_trial` operation took 0.529 s, which may be a performance bottleneck.
2023-11-02 00:08:21,976	WARNING util.py:214 -- The `start_trial` operation took 0.655 s, which may be a performance bottleneck.
2023-11-02 00:08:23,310	WARNING util.py:214 -- The `start_trial` operation took 0.689 s, which may be a performance bottleneck.
2023-11-02 00:08:24,908	WARNING util.py:214 -- The `start_trial` operation took 0.579 s, which may be a performance bottleneck.
2023-11-02 00:08:25,754	WARNING util.py:214 -- The `start_trial` operation took 0.570 s, which may be a performance bottleneck.
2023-11-02 00:08:26,361	WARNING util.py:214 -- The `start_trial` operation took 0.511 s, which may be a performance bottleneck.
2023-11-02 00:08:27,525	WARNING util.py:214 -- The `start_trial` operation took 0.564 s, which may be a performance bottleneck.
2023-11-02 00:08:28,586	WARNING util.py:214 -- The `start_trial` operation took 0.755 s, which may be a performance bottleneck.
2023-11-02 00:08:29,477	WARNING util.py:214 -- The `start_trial` operation took 0.805 s, which may be a performance bottleneck.
2023-11-02 00:10:37,691	WARNING util.py:214 -- The `start_trial` operation took 0.820 s, which may be a performance bottleneck.
2023-11-02 00:10:38,907	WARNING util.py:214 -- The `start_trial` operation took 0.701 s, which may be a performance bottleneck.
2023-11-02 00:10:40,602	WARNING util.py:214 -- The `start_trial` operation took 0.754 s, which may be a performance bottleneck.
2023-11-02 00:10:41,422	WARNING util.py:214 -- The `start_trial` operation took 0.583 s, which may be a performance bottleneck.
2023-11-02 00:10:42,887	WARNING util.py:214 -- The `start_trial` operation took 0.810 s, which may be a performance bottleneck.
2023-11-02 00:10:44,054	WARNING util.py:214 -- The `start_trial` operation took 0.701 s, which may be a performance bottleneck.
2023-11-02 00:10:46,685	WARNING util.py:214 -- The `start_trial` operation took 0.666 s, which may be a performance bottleneck.
2023-11-02 00:10:47,999	WARNING util.py:214 -- The `start_trial` operation took 0.756 s, which may be a performance bottleneck.
2023-11-02 00:10:51,071	WARNING util.py:214 -- The `start_trial` operation took 1.016 s, which may be a performance bottleneck.
2023-11-02 00:10:52,412	WARNING util.py:214 -- The `start_trial` operation took 0.664 s, which may be a performance bottleneck.
2023-11-02 00:10:53,294	WARNING util.py:214 -- The `start_trial` operation took 0.875 s, which may be a performance bottleneck.
2023-11-02 00:10:56,446	WARNING util.py:214 -- The `start_trial` operation took 0.598 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 00:11:50,372 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(505307) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 00:11:52,688 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(505338) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 00:11:56,040 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(505360) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 00:14:36,169	WARNING util.py:214 -- The `start_trial` operation took 0.643 s, which may be a performance bottleneck.
2023-11-02 00:14:37,166	WARNING util.py:214 -- The `start_trial` operation took 0.791 s, which may be a performance bottleneck.
2023-11-02 00:14:38,171	WARNING util.py:214 -- The `start_trial` operation took 0.751 s, which may be a performance bottleneck.
2023-11-02 00:14:39,218	WARNING util.py:214 -- The `start_trial` operation took 0.702 s, which may be a performance bottleneck.
2023-11-02 00:14:40,428	WARNING util.py:214 -- The `start_trial` operation took 0.955 s, which may be a performance bottleneck.
2023-11-02 00:14:41,689	WARNING util.py:214 -- The `start_trial` operation took 1.071 s, which may be a performance bottleneck.
2023-11-02 00:14:42,516	WARNING util.py:214 -- The `start_trial` operation took 0.655 s, which may be a performance bottleneck.
2023-11-02 00:14:43,341	WARNING util.py:214 -- The `start_trial` operation took 0.818 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 00:15:42,927 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(506281) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-02 00:06:06 (running for 00:35:11.86)
Memory usage on this node: 51.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 262/1000000 (32 RUNNING, 230 TERMINATED)


== Status ==
Current time: 2023-11-02 00:08:18 (running for 00:37:24.05)
Memory usage on this node: 47.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 262/1000000 (32 RUNNING, 230 TERMINATED)


== Status ==
Current time: 2023-11-02 00:08:23 (running for 00:37:29.17)
Memory usage on this node: 48.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 267/1000000 (1 PENDING, 30 RUNNING, 236 TERMINATED)


== Status ==
Current time: 2023-11-02 00:08:29 (running for 00:37:34.82)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 273/1000000 (32 RUNNING, 241 TERMINATED)


== Status ==
Current time: 2023-11-02 00:10:33 (running for 00:39:38.64)
Memory usage on this node: 42.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 273/1000000 (32 RUNNING, 241 TERMINATED)


== Status ==
Current time: 2023-11-02 00:10:38 (running for 00:39:44.25)
Memory usage on this node: 45.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 277/1000000 (31 RUNNING, 246 TERMINATED)


== Status ==
Current time: 2023-11-02 00:10:44 (running for 00:39:49.40)
Memory usage on this node: 49.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 281/1000000 (31 RUNNING, 250 TERMINATED)


== Status ==
Current time: 2023-11-02 00:10:49 (running for 00:39:55.21)
Memory usage on this node: 53.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 286/1000000 (1 PENDING, 31 RUNNING, 254 TERMINATED)


== Status ==
Current time: 2023-11-02 00:10:56 (running for 00:40:01.79)
Memory usage on this node: 39.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 289/1000000 (32 RUNNING, 257 TERMINATED)


== Status ==
Current time: 2023-11-02 00:14:32 (running for 00:43:38.09)
Memory usage on this node: 36.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21a431f7 with val_loss=479.82661546222846 and parameters={'n_estimators': 179, 'num_leaves': 89, 'min_child_samples': 67, 'learning_rate': 0.09513986540388727, 'log_max_bin': 5, 'colsample_bytree': 0.7579831075276845, 'reg_alpha': 0.0009765625, 'reg_lambda': 1024.0, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 289/1000000 (32 RUNNING, 257 TERMINATED)


== Status ==
Current time: 2023-11-02 00:14:38 (running for 00:43:43.52)
Memory usage on this node: 40.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: e1df5911 with val_loss=479.37767190926763 and parameters={'n_estimators': 225, 'num_leaves': 41, 'min_child_samples': 86, 'learning_rate': 0.0469587174242431, 'log_max_bin': 6, 'colsample_bytree': 0.5991732770727034, 'reg_alpha': 0.0011708601712099214, 'reg_lambda': 293.92588285976854, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 292/1000000 (31 RUNNING, 261 TERMINATED)


== Status ==
Current time: 2023-11-02 00:14:43 (running for 00:43:48.68)
Memory usage on this node: 44.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: e1df5911 with val_loss=479.37767190926763 and parameters={'n_estimators': 225, 'num_leaves': 41, 'min_child_samples': 86, 'learning_rate': 0.0469587174242431, 'log_max_bin': 6, 'colsample_bytree': 0.5991732770727034, 'reg_alpha': 0.0011708601712099214, 'reg_lambda': 293.92588285976854, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 297/1000000 (32 RUNNING, 265 TERMINATED)


2023-11-02 00:18:22,022	WARNING util.py:214 -- The `start_trial` operation took 0.932 s, which may be a performance bottleneck.
2023-11-02 00:18:23,979	WARNING util.py:214 -- The `start_trial` operation took 0.698 s, which may be a performance bottleneck.
2023-11-02 00:20:08,677	WARNING util.py:214 -- The `start_trial` operation took 0.665 s, which may be a performance bottleneck.
2023-11-02 00:20:10,447	WARNING util.py:214 -- The `start_trial` operation took 0.700 s, which may be a performance bottleneck.
2023-11-02 00:20:11,004	WARNING util.py:214 -- The `start_trial` operation took 0.550 s, which may be a performance bottleneck.
2023-11-02 00:20:12,241	WARNING util.py:214 -- The `start_trial` operation took 0.681 s, which may be a performance bottleneck.
2023-11-02 00:20:13,218	WARNING util.py:214 -- The `start_trial` operation took 0.692 s, which may be a performance bottleneck.
2023-11-02 00:21:53,782	WARNING util.py:214 -- The `start_trial` operation took 0.514 s, which may be a performance bottleneck.
2023-11-02 00:21:54,665	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
2023-11-02 00:21:55,650	WARNING util.py:214 -- The `start_trial` operation took 0.621 s, which may be a performance bottleneck.
2023-11-02 00:21:56,955	WARNING util.py:214 -- The `start_trial` operation took 0.784 s, which may be a performance bottleneck.
2023-11-02 00:21:58,406	WARNING util.py:214 -- The `start_trial` operation took 0.708 s, which may be a performance bottleneck.
2023-11-02 00:21:59,497	WARNING util.py:214 -- The `start_trial` operation took 0.768 s, which may be a performance bottleneck.
2023-11-02 00:22:00,463	WARNING util.py:214 -- The `start_trial` operation took 0.566 s, which may be a performance bottleneck.
2023-11-02 00:22:01,925	WARNING util.py:214 -- The `start_trial` operation took 0.644 s, which may be a performance bottleneck.
2023-11-02 00:22:02,971	WARNING util.py:214 -- The `start_trial` operation took 0.834 s, which may be a performance bottleneck.
2023-11-02 00:24:28,642	WARNING util.py:214 -- The `start_trial` operation took 0.510 s, which may be a performance bottleneck.
2023-11-02 00:24:31,289	WARNING util.py:214 -- The `start_trial` operation took 0.556 s, which may be a performance bottleneck.
2023-11-02 00:26:52,161	WARNING util.py:214 -- The `start_trial` operation took 0.510 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 00:18:18 (running for 00:47:24.24)
Memory usage on this node: 56.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: e1df5911 with val_loss=479.37767190926763 and parameters={'n_estimators': 225, 'num_leaves': 41, 'min_child_samples': 86, 'learning_rate': 0.0469587174242431, 'log_max_bin': 6, 'colsample_bytree': 0.5991732770727034, 'reg_alpha': 0.0011708601712099214, 'reg_lambda': 293.92588285976854, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 297/1000000 (32 RUNNING, 265 TERMINATED)


== Status ==
Current time: 2023-11-02 00:18:23 (running for 00:47:29.32)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: e1df5911 with val_loss=479.37767190926763 and parameters={'n_estimators': 225, 'num_leaves': 41, 'min_child_samples': 86, 'learning_rate': 0.0469587174242431, 'log_max_bin': 6, 'colsample_bytree': 0.5991732770727034, 'reg_alpha': 0.0011708601712099214, 'reg_lambda': 293.92588285976854, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 299/1000000 (31 RUNNING, 268 TERMINATED)


== Status ==
Current time: 2023-11-02 00:20:08 (running for 00:49:13.34)
Memory usage on this node: 32.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: e1df5911 with val_loss=479.37767190926763 and parameters={'n_estimators': 225, 'num_leaves': 41, 'min_child_samples': 86, 'learning_rate': 0.0469587174242431, 'log_max_bin': 6, 'colsample_bytree': 0.5991732770727034, 'reg_alpha': 0.0011708601712099214, 'reg_lambda': 293.92588285976854, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 300/1000000 (1 PENDING, 31 RUNNING, 268 TERMINATED)


== Status ==
Current time: 2023-11-02 00:20:13 (running for 00:49:18.56)
Memory usage on this node: 36.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: e1df5911 with val_loss=479.37767190926763 and parameters={'n_estimators': 225, 'num_leaves': 41, 'min_child_samples': 86, 'learning_rate': 0.0469587174242431, 'log_max_bin': 6, 'colsample_bytree': 0.5991732770727034, 'reg_alpha': 0.0011708601712099214, 'reg_lambda': 293.92588285976854, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 304/1000000 (31 RUNNING, 273 TERMINATED)


== Status ==
Current time: 2023-11-02 00:21:52 (running for 00:50:57.61)
Memory usage on this node: 39.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: e1df5911 with val_loss=479.37767190926763 and parameters={'n_estimators': 225, 'num_leaves': 41, 'min_child_samples': 86, 'learning_rate': 0.0469587174242431, 'log_max_bin': 6, 'colsample_bytree': 0.5991732770727034, 'reg_alpha': 0.0011708601712099214, 'reg_lambda': 293.92588285976854, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 305/1000000 (1 PENDING, 31 RUNNING, 273 TERMINATED)


== Status ==
Current time: 2023-11-02 00:21:57 (running for 00:51:02.90)
Memory usage on this node: 44.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: e1df5911 with val_loss=479.37767190926763 and parameters={'n_estimators': 225, 'num_leaves': 41, 'min_child_samples': 86, 'learning_rate': 0.0469587174242431, 'log_max_bin': 6, 'colsample_bytree': 0.5991732770727034, 'reg_alpha': 0.0011708601712099214, 'reg_lambda': 293.92588285976854, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 310/1000000 (1 PENDING, 30 RUNNING, 279 TERMINATED)


== Status ==
Current time: 2023-11-02 00:22:02 (running for 00:51:08.32)
Memory usage on this node: 46.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: e1df5911 with val_loss=479.37767190926763 and parameters={'n_estimators': 225, 'num_leaves': 41, 'min_child_samples': 86, 'learning_rate': 0.0469587174242431, 'log_max_bin': 6, 'colsample_bytree': 0.5991732770727034, 'reg_alpha': 0.0011708601712099214, 'reg_lambda': 293.92588285976854, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 314/1000000 (32 RUNNING, 282 TERMINATED)


== Status ==
Current time: 2023-11-02 00:24:26 (running for 00:53:31.50)
Memory usage on this node: 45.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: e1df5911 with val_loss=479.37767190926763 and parameters={'n_estimators': 225, 'num_leaves': 41, 'min_child_samples': 86, 'learning_rate': 0.0469587174242431, 'log_max_bin': 6, 'colsample_bytree': 0.5991732770727034, 'reg_alpha': 0.0011708601712099214, 'reg_lambda': 293.92588285976854, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 314/1000000 (31 RUNNING, 283 TERMINATED)


== Status ==
Current time: 2023-11-02 00:24:31 (running for 00:53:36.63)
Memory usage on this node: 48.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: e1df5911 with val_loss=479.37767190926763 and parameters={'n_estimators': 225, 'num_leaves': 41, 'min_child_samples': 86, 'learning_rate': 0.0469587174242431, 'log_max_bin': 6, 'colsample_bytree': 0.5991732770727034, 'reg_alpha': 0.0011708601712099214, 'reg_lambda': 293.92588285976854, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 319/1000000 (31 RUNNING, 288 TERMINATED)


== Status ==
Current time: 2023-11-02 00:26:47 (running for 00:55:52.66)
Memory usage on this node: 41.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: e1df5911 with val_loss=479.37767190926763 and parameters={'n_estimators': 225, 'num_leaves': 41, 'min_child_samples': 86, 'learning_rate': 0.0469587174242431, 'log_max_bin': 6, 'colsample_bytree': 0.5991732770727034, 'reg_alpha': 0.0011708601712099214, 'reg_lambda': 293.92588285976854, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 320/1000000 (1 PENDING, 31 RUNNING, 288 TERMINATED)


== Status ==
Current time: 2023-11-02 00:26:52 (running for 00:55:58.06)
Memory usage on this node: 45.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 875be2ba with val_loss=478.6044412818883 and parameters={'n_estimators': 783, 'num_leaves': 24, 'min_child_samples': 128, 'learning_rate': 0.02866879905783465, 'log_max_bin': 6, 'colsample_bytree': 0.6895126151347971, 'reg_alpha': 0.0009765625, 'reg_lambda': 98.4205398115731, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 327/1000000 (31 RUNNING, 296 TERMINATED)


2023-11-02 00:29:29,437	WARNING util.py:214 -- The `start_trial` operation took 0.608 s, which may be a performance bottleneck.
2023-11-02 00:29:31,406	WARNING util.py:214 -- The `start_trial` operation took 0.845 s, which may be a performance bottleneck.
2023-11-02 00:29:32,150	WARNING util.py:214 -- The `start_trial` operation took 0.638 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 00:30:30,818 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(509667) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 00:30:33,176 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(509683) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 00:33:11,727	WARNING util.py:214 -- The `start_trial` operation took 0.543 s, which may be a performance bottleneck.
2023-11-02 00:33:12,324	WARNING util.py:214 -- The `start_trial` operation took 0.505 s, which may be a performance bottleneck.
2023-11-02 00:35:52,131	WARNING util.py:214 -- The `start_trial` operation took 0.503 s, which may be a performance bottleneck.
2023-11-02 00:35:53,156	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
2023-11-02 00:35:55,531	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
2023-11-02 00:35:56,548	WARNING util.py:214 -- The `start_trial` operation took 0.526 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 00:36:54,544 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(509971) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 00:36:56,303 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(509981) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 00:39:31,016	WARNING util.py:214 -- The `start_trial` operation took 0.531 s, which may be a performance bottleneck.
2023-11-02 00:39:31,775	WARNING util.py:214 -- The `start_trial` operation took 0.552 s, which may be a performance bottleneck.
2023-11-02 00:39:32,518	WARNING util.py:214 -- The `start_trial` operation took 0.554 s, which may be a performance bottleneck.
2023-11-02 00:42:14,520	WARNING util.py:214 -- The `start_trial` operation took 0.566 s, which may be a performance bottleneck.
2023-11-02 00:42:15,096	WARNING util.py:214 -- The `start_trial` operation took 0.570 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 00:43:13,384 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(510457) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 00:43:14,768 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(510461) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-02 00:29:27 (running for 00:58:33.14)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 875be2ba with val_loss=478.6044412818883 and parameters={'n_estimators': 783, 'num_leaves': 24, 'min_child_samples': 128, 'learning_rate': 0.02866879905783465, 'log_max_bin': 6, 'colsample_bytree': 0.6895126151347971, 'reg_alpha': 0.0009765625, 'reg_lambda': 98.4205398115731, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 328/1000000 (1 PENDING, 30 RUNNING, 297 TERMINATED)


== Status ==
Current time: 2023-11-02 00:29:33 (running for 00:58:38.74)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 875be2ba with val_loss=478.6044412818883 and parameters={'n_estimators': 783, 'num_leaves': 24, 'min_child_samples': 128, 'learning_rate': 0.02866879905783465, 'log_max_bin': 6, 'colsample_bytree': 0.6895126151347971, 'reg_alpha': 0.0009765625, 'reg_lambda': 98.4205398115731, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 336/1000000 (32 RUNNING, 304 TERMINATED)


== Status ==
Current time: 2023-11-02 00:33:09 (running for 01:02:15.04)
Memory usage on this node: 25.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 875be2ba with val_loss=478.6044412818883 and parameters={'n_estimators': 783, 'num_leaves': 24, 'min_child_samples': 128, 'learning_rate': 0.02866879905783465, 'log_max_bin': 6, 'colsample_bytree': 0.6895126151347971, 'reg_alpha': 0.0009765625, 'reg_lambda': 98.4205398115731, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 336/1000000 (32 RUNNING, 304 TERMINATED)


== Status ==
Current time: 2023-11-02 00:33:14 (running for 01:02:20.12)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 875be2ba with val_loss=478.6044412818883 and parameters={'n_estimators': 783, 'num_leaves': 24, 'min_child_samples': 128, 'learning_rate': 0.02866879905783465, 'log_max_bin': 6, 'colsample_bytree': 0.6895126151347971, 'reg_alpha': 0.0009765625, 'reg_lambda': 98.4205398115731, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 341/1000000 (31 RUNNING, 310 TERMINATED)


== Status ==
Current time: 2023-11-02 00:35:50 (running for 01:04:56.11)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 875be2ba with val_loss=478.6044412818883 and parameters={'n_estimators': 783, 'num_leaves': 24, 'min_child_samples': 128, 'learning_rate': 0.02866879905783465, 'log_max_bin': 6, 'colsample_bytree': 0.6895126151347971, 'reg_alpha': 0.0009765625, 'reg_lambda': 98.4205398115731, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 342/1000000 (1 PENDING, 31 RUNNING, 310 TERMINATED)


== Status ==
Current time: 2023-11-02 00:35:56 (running for 01:05:01.89)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 875be2ba with val_loss=478.6044412818883 and parameters={'n_estimators': 783, 'num_leaves': 24, 'min_child_samples': 128, 'learning_rate': 0.02866879905783465, 'log_max_bin': 6, 'colsample_bytree': 0.6895126151347971, 'reg_alpha': 0.0009765625, 'reg_lambda': 98.4205398115731, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 348/1000000 (32 RUNNING, 316 TERMINATED)


== Status ==
Current time: 2023-11-02 00:39:28 (running for 01:08:33.74)
Memory usage on this node: 25.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 875be2ba with val_loss=478.6044412818883 and parameters={'n_estimators': 783, 'num_leaves': 24, 'min_child_samples': 128, 'learning_rate': 0.02866879905783465, 'log_max_bin': 6, 'colsample_bytree': 0.6895126151347971, 'reg_alpha': 0.0009765625, 'reg_lambda': 98.4205398115731, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 348/1000000 (32 RUNNING, 316 TERMINATED)


== Status ==
Current time: 2023-11-02 00:39:33 (running for 01:08:38.96)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 76cc9752 with val_loss=478.49770270048066 and parameters={'n_estimators': 1115, 'num_leaves': 20, 'min_child_samples': 128, 'learning_rate': 0.0218921636472883, 'log_max_bin': 6, 'colsample_bytree': 0.5807534254713521, 'reg_alpha': 0.0009765625, 'reg_lambda': 21.814560182447426, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 353/1000000 (32 RUNNING, 321 TERMINATED)


== Status ==
Current time: 2023-11-02 00:42:11 (running for 01:11:16.64)
Memory usage on this node: 25.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 76cc9752 with val_loss=478.49770270048066 and parameters={'n_estimators': 1115, 'num_leaves': 20, 'min_child_samples': 128, 'learning_rate': 0.0218921636472883, 'log_max_bin': 6, 'colsample_bytree': 0.5807534254713521, 'reg_alpha': 0.0009765625, 'reg_lambda': 21.814560182447426, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 353/1000000 (32 RUNNING, 321 TERMINATED)


== Status ==
Current time: 2023-11-02 00:42:16 (running for 01:11:21.68)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 76cc9752 with val_loss=478.49770270048066 and parameters={'n_estimators': 1115, 'num_leaves': 20, 'min_child_samples': 128, 'learning_rate': 0.0218921636472883, 'log_max_bin': 6, 'colsample_bytree': 0.5807534254713521, 'reg_alpha': 0.0009765625, 'reg_lambda': 21.814560182447426, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 358/1000000 (31 RUNNING, 327 TERMINATED)


== Status ==
Current time: 2023-11-02 00:45:57 (running for 01:15:02.86)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 76cc9752 with val_loss=478.49770270048066 and parameters={'n_estimators': 1115, 'num_leaves': 20, 'min_child_samples': 128, 'learning_rate': 0.0218921636472883, 'log_max_bin': 6, 'colsample_bytree': 0.5807534254713521, 'reg_alpha': 0.0009765625, 'reg_lambda': 21.814560182447426, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 359/1000000 (32 RUNNING, 327 TERMINATED)


2023-11-02 00:48:39,161	WARNING util.py:214 -- The `start_trial` operation took 0.526 s, which may be a performance bottleneck.
2023-11-02 00:48:40,460	WARNING util.py:214 -- The `start_trial` operation took 0.510 s, which may be a performance bottleneck.
2023-11-02 00:53:28,042	WARNING util.py:214 -- The `start_trial` operation took 0.552 s, which may be a performance bottleneck.
2023-11-02 00:56:08,818	WARNING util.py:214 -- The `start_trial` operation took 0.517 s, which may be a performance bottleneck.
2023-11-02 00:56:09,865	WARNING util.py:214 -- The `start_trial` operation took 0.678 s, which may be a performance bottleneck.
2023-11-02 00:56:10,655	WARNING util.py:214 -- The `start_trial` operation took 0.573 s, which may be a performance bottleneck.
2023-11-02 00:58:59,253	WARNING util.py:214 -- The `choose_trial_to_run` operation took 1.464 s, which may be a performance bottleneck.
2023-11-02 00:59:08,587	WARNING util.py:214 -- The `start_trial` operation took 9.334 s, which may be a performance bottleneck.
2023-11-02 00:59:10,633	WARNING util.py:214 -- The `start_trial` operation took 0.513 s, which may be a performance bottleneck.
2023-11-02 00:59:11,850	WARNING util.py:214 -- The `start_trial` operation took 0.553 s, which may be a performance bottleneck.
2023-11-02 00:59:12,864	WARNING util.py:214 -- The `start_trial` operation took 0.636 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 01:00:11,577 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(511630) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:00:12,486 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(511635) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 01:03:04,760	WARNING util.py:214 -- The `start_trial` operation took 0.584 s, which may be a performance bottleneck.
2023-11-02 01:03:05,829	WARNING util.py:214 -- The `start_trial` operation took 0.531 s, which may be a performance bottleneck.
2023-11-02 01:03:07,591	WARNING util.py:214 -- The `start_trial` operation took 0.533 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 00:48:35 (running for 01:17:41.12)
Memory usage on this node: 25.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 76cc9752 with val_loss=478.49770270048066 and parameters={'n_estimators': 1115, 'num_leaves': 20, 'min_child_samples': 128, 'learning_rate': 0.0218921636472883, 'log_max_bin': 6, 'colsample_bytree': 0.5807534254713521, 'reg_alpha': 0.0009765625, 'reg_lambda': 21.814560182447426, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 359/1000000 (32 RUNNING, 327 TERMINATED)


== Status ==
Current time: 2023-11-02 00:48:40 (running for 01:17:46.23)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 76cc9752 with val_loss=478.49770270048066 and parameters={'n_estimators': 1115, 'num_leaves': 20, 'min_child_samples': 128, 'learning_rate': 0.0218921636472883, 'log_max_bin': 6, 'colsample_bytree': 0.5807534254713521, 'reg_alpha': 0.0009765625, 'reg_lambda': 21.814560182447426, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 364/1000000 (1 PENDING, 31 RUNNING, 332 TERMINATED)


== Status ==
Current time: 2023-11-02 00:51:03 (running for 01:20:09.17)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 76cc9752 with val_loss=478.49770270048066 and parameters={'n_estimators': 1115, 'num_leaves': 20, 'min_child_samples': 128, 'learning_rate': 0.0218921636472883, 'log_max_bin': 6, 'colsample_bytree': 0.5807534254713521, 'reg_alpha': 0.0009765625, 'reg_lambda': 21.814560182447426, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 364/1000000 (32 RUNNING, 332 TERMINATED)


== Status ==
Current time: 2023-11-02 00:53:23 (running for 01:22:28.88)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 76cc9752 with val_loss=478.49770270048066 and parameters={'n_estimators': 1115, 'num_leaves': 20, 'min_child_samples': 128, 'learning_rate': 0.0218921636472883, 'log_max_bin': 6, 'colsample_bytree': 0.5807534254713521, 'reg_alpha': 0.0009765625, 'reg_lambda': 21.814560182447426, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 364/1000000 (32 RUNNING, 332 TERMINATED)


== Status ==
Current time: 2023-11-02 00:53:29 (running for 01:22:34.34)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 76cc9752 with val_loss=478.49770270048066 and parameters={'n_estimators': 1115, 'num_leaves': 20, 'min_child_samples': 128, 'learning_rate': 0.0218921636472883, 'log_max_bin': 6, 'colsample_bytree': 0.5807534254713521, 'reg_alpha': 0.0009765625, 'reg_lambda': 21.814560182447426, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 370/1000000 (31 RUNNING, 339 TERMINATED)


== Status ==
Current time: 2023-11-02 00:56:05 (running for 01:25:10.82)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 76cc9752 with val_loss=478.49770270048066 and parameters={'n_estimators': 1115, 'num_leaves': 20, 'min_child_samples': 128, 'learning_rate': 0.0218921636472883, 'log_max_bin': 6, 'colsample_bytree': 0.5807534254713521, 'reg_alpha': 0.0009765625, 'reg_lambda': 21.814560182447426, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 371/1000000 (1 PENDING, 31 RUNNING, 339 TERMINATED)


== Status ==
Current time: 2023-11-02 00:56:10 (running for 01:25:16.00)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3c01f1a7 with val_loss=478.4909911620358 and parameters={'n_estimators': 508, 'num_leaves': 55, 'min_child_samples': 128, 'learning_rate': 0.030558551514459124, 'log_max_bin': 6, 'colsample_bytree': 0.41686863826293663, 'reg_alpha': 0.0009765625, 'reg_lambda': 115.9712200416589, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 376/1000000 (31 RUNNING, 345 TERMINATED)


== Status ==
Current time: 2023-11-02 00:58:57 (running for 01:28:03.12)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3c01f1a7 with val_loss=478.4909911620358 and parameters={'n_estimators': 508, 'num_leaves': 55, 'min_child_samples': 128, 'learning_rate': 0.030558551514459124, 'log_max_bin': 6, 'colsample_bytree': 0.41686863826293663, 'reg_alpha': 0.0009765625, 'reg_lambda': 115.9712200416589, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 377/1000000 (1 PENDING, 30 RUNNING, 346 TERMINATED)


== Status ==
Current time: 2023-11-02 00:59:08 (running for 01:28:13.93)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3c01f1a7 with val_loss=478.4909911620358 and parameters={'n_estimators': 508, 'num_leaves': 55, 'min_child_samples': 128, 'learning_rate': 0.030558551514459124, 'log_max_bin': 6, 'colsample_bytree': 0.41686863826293663, 'reg_alpha': 0.0009765625, 'reg_lambda': 115.9712200416589, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 377/1000000 (31 RUNNING, 346 TERMINATED)


== Status ==
Current time: 2023-11-02 00:59:17 (running for 01:28:23.21)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 381/1000000 (32 RUNNING, 349 TERMINATED)


== Status ==
Current time: 2023-11-02 01:03:02 (running for 01:32:07.59)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 381/1000000 (32 RUNNING, 349 TERMINATED)


2023-11-02 01:05:58,991	WARNING util.py:214 -- The `start_trial` operation took 0.518 s, which may be a performance bottleneck.
2023-11-02 01:06:01,130	WARNING util.py:214 -- The `start_trial` operation took 0.507 s, which may be a performance bottleneck.
2023-11-02 01:06:01,762	WARNING util.py:214 -- The `start_trial` operation took 0.540 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 01:06:58,745 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(511931) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:07:58,783 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(511971) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 01:10:20,131	WARNING util.py:214 -- The `start_trial` operation took 0.645 s, which may be a performance bottleneck.
2023-11-02 01:15:09,901	WARNING util.py:214 -- The `start_trial` operation took 0.603 s, which may be a performance bottleneck.
2023-11-02 01:17:50,890	WARNING util.py:214 -- The `start_trial` operation took 0.611 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 01:03:07 (running for 01:32:12.94)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 386/1000000 (31 RUNNING, 355 TERMINATED)


== Status ==
Current time: 2023-11-02 01:05:58 (running for 01:35:03.56)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 387/1000000 (1 PENDING, 31 RUNNING, 355 TERMINATED)


== Status ==
Current time: 2023-11-02 01:06:04 (running for 01:35:10.09)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 391/1000000 (32 RUNNING, 359 TERMINATED)


== Status ==
Current time: 2023-11-02 01:10:17 (running for 01:39:22.67)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 391/1000000 (32 RUNNING, 359 TERMINATED)


== Status ==
Current time: 2023-11-02 01:10:22 (running for 01:39:27.92)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 396/1000000 (31 RUNNING, 365 TERMINATED)


== Status ==
Current time: 2023-11-02 01:12:34 (running for 01:41:39.89)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 397/1000000 (1 PENDING, 31 RUNNING, 365 TERMINATED)


== Status ==
Current time: 2023-11-02 01:12:39 (running for 01:41:45.29)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 404/1000000 (1 PENDING, 30 RUNNING, 373 TERMINATED)


== Status ==
Current time: 2023-11-02 01:15:06 (running for 01:44:11.36)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 404/1000000 (31 RUNNING, 373 TERMINATED)


== Status ==
Current time: 2023-11-02 01:15:11 (running for 01:44:16.73)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 410/1000000 (1 PENDING, 30 RUNNING, 379 TERMINATED)


== Status ==
Current time: 2023-11-02 01:17:48 (running for 01:46:54.17)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 410/1000000 (31 RUNNING, 379 TERMINATED)


== Status ==
Current time: 2023-11-02 01:17:54 (running for 01:47:00.13)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 414/1000000 (1 PENDING, 30 RUNNING, 383 TERMINATED)


2023-11-02 01:20:32,645	WARNING util.py:214 -- The `start_trial` operation took 0.557 s, which may be a performance bottleneck.
2023-11-02 01:20:33,905	WARNING util.py:214 -- The `start_trial` operation took 0.530 s, which may be a performance bottleneck.
2023-11-02 01:20:35,014	WARNING util.py:214 -- The `start_trial` operation took 0.693 s, which may be a performance bottleneck.
2023-11-02 01:23:33,972	WARNING util.py:214 -- The `start_trial` operation took 0.567 s, which may be a performance bottleneck.
2023-11-02 01:23:35,005	WARNING util.py:214 -- The `start_trial` operation took 0.527 s, which may be a performance bottleneck.
2023-11-02 01:23:35,780	WARNING util.py:214 -- The `start_trial` operation took 0.768 s, which may be a performance bottleneck.
2023-11-02 01:26:20,533	WARNING util.py:214 -- The `start_trial` operation took 0.568 s, which may be a performance bottleneck.
2023-11-02 01:26:21,899	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
2023-11-02 01:26:22,851	WARNING util.py:214 -- The `start_trial` operation took 0.605 s, which may be a performance bottleneck.
2023-11-02 01:26:23,529	WARNING util.py:214 -- The `start_trial` operation took 0.660 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 01:27:23,119 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(513150) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:28:23,299 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(513176) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 01:33:52,411	WARNING util.py:214 -- The `start_trial` operation took 0.575 s, which may be a performance bottleneck.
2023-11-02 01:33:54,716	WARNING util.py:214 -- The `start_trial` operation took 0.588 s, which may be a performance bottleneck.
2023-11-02 01:33:55,975	WARNING util.py:214 -- The `start_trial` operation took 0.713 s, which may be a performance bottleneck.
2023-11-02 01:33:58,240	WARNING util.py:214 -- The `start_trial` operation took 0.722 s, which may be a performance bottleneck.
2023-11-02 01:34:00,490	WARNING util.py:214 -- The `start_trial` operation took 0.535 s, which may be a performance bottleneck.
2023-11-02 01:34:01,693	WARNING util.py:214 -- The `start_trial` operation took 0.804 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 01:34:57,908 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(513517) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:35:01,343 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(513527) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:35:03,653 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(513532) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:35:58,091 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(513548) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:36:01,566 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(513551) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-02 01:20:29 (running for 01:49:34.92)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 414/1000000 (31 RUNNING, 383 TERMINATED)


== Status ==
Current time: 2023-11-02 01:20:35 (running for 01:49:40.70)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 418/1000000 (32 RUNNING, 386 TERMINATED)


== Status ==
Current time: 2023-11-02 01:23:30 (running for 01:52:35.57)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 418/1000000 (32 RUNNING, 386 TERMINATED)


== Status ==
Current time: 2023-11-02 01:23:35 (running for 01:52:41.12)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 423/1000000 (32 RUNNING, 391 TERMINATED)


== Status ==
Current time: 2023-11-02 01:26:15 (running for 01:55:21.02)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 423/1000000 (32 RUNNING, 391 TERMINATED)


== Status ==
Current time: 2023-11-02 01:26:20 (running for 01:55:25.94)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 428/1000000 (31 RUNNING, 397 TERMINATED)


== Status ==
Current time: 2023-11-02 01:26:28 (running for 01:55:33.87)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 431/1000000 (32 RUNNING, 399 TERMINATED)


== Status ==
Current time: 2023-11-02 01:31:10 (running for 02:00:15.92)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 431/1000000 (32 RUNNING, 399 TERMINATED)


== Status ==
Current time: 2023-11-02 01:31:15 (running for 02:00:21.09)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 435/1000000 (31 RUNNING, 404 TERMINATED)


== Status ==
Current time: 2023-11-02 01:33:51 (running for 02:02:56.84)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 436/1000000 (1 PENDING, 30 RUNNING, 405 TERMINATED)


== Status ==
Current time: 2023-11-02 01:33:57 (running for 02:03:02.39)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 440/1000000 (1 PENDING, 31 RUNNING, 408 TERMINATED)


2023-11-02 01:38:39,111	WARNING util.py:214 -- The `start_trial` operation took 0.564 s, which may be a performance bottleneck.
2023-11-02 01:38:40,764	WARNING util.py:214 -- The `start_trial` operation took 0.568 s, which may be a performance bottleneck.
2023-11-02 01:38:43,588	WARNING util.py:214 -- The `start_trial` operation took 0.539 s, which may be a performance bottleneck.
2023-11-02 01:41:20,228	WARNING util.py:214 -- The `start_trial` operation took 0.629 s, which may be a performance bottleneck.
2023-11-02 01:41:21,844	WARNING util.py:214 -- The `start_trial` operation took 0.583 s, which may be a performance bottleneck.
2023-11-02 01:41:23,211	WARNING util.py:214 -- The `start_trial` operation took 0.763 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 01:42:19,883 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(513960) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 01:47:17,545	WARNING util.py:214 -- The `start_trial` operation took 0.540 s, which may be a performance bottleneck.
2023-11-02 01:47:22,479	WARNING util.py:214 -- The `on_step_end` operation took 0.584 s, which may be a performance bottleneck.
2023-11-02 01:49:54,778	WARNING util.py:214 -- The `start_trial` operation took 0.534 s, which may be a performance bottleneck.
2023-11-02 01:49:58,629	WARNING util.py:214 -- The `start_trial` operation took 0.560 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 01:34:03 (running for 02:03:09.07)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 443/1000000 (32 RUNNING, 411 TERMINATED)


== Status ==
Current time: 2023-11-02 01:38:34 (running for 02:07:39.38)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 443/1000000 (32 RUNNING, 411 TERMINATED)


== Status ==
Current time: 2023-11-02 01:38:39 (running for 02:07:44.55)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7ff5086b with val_loss=478.4167848367553 and parameters={'n_estimators': 778, 'num_leaves': 20, 'min_child_samples': 115, 'learning_rate': 0.030072461850524812, 'log_max_bin': 7, 'colsample_bytree': 0.5737599099042923, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.9887513528154244, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 446/1000000 (31 RUNNING, 415 TERMINATED)


== Status ==
Current time: 2023-11-02 01:38:44 (running for 02:07:50.26)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 450/1000000 (1 PENDING, 30 RUNNING, 419 TERMINATED)


== Status ==
Current time: 2023-11-02 01:41:17 (running for 02:10:23.01)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 450/1000000 (31 RUNNING, 419 TERMINATED)


== Status ==
Current time: 2023-11-02 01:41:23 (running for 02:10:28.71)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 456/1000000 (32 RUNNING, 424 TERMINATED)


== Status ==
Current time: 2023-11-02 01:44:46 (running for 02:13:51.42)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 456/1000000 (32 RUNNING, 424 TERMINATED)


== Status ==
Current time: 2023-11-02 01:44:51 (running for 02:13:56.73)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 462/1000000 (31 RUNNING, 431 TERMINATED)


== Status ==
Current time: 2023-11-02 01:47:16 (running for 02:16:22.16)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 463/1000000 (1 PENDING, 31 RUNNING, 431 TERMINATED)


== Status ==
Current time: 2023-11-02 01:47:22 (running for 02:16:27.86)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 468/1000000 (1 PENDING, 31 RUNNING, 436 TERMINATED)


== Status ==
Current time: 2023-11-02 01:49:54 (running for 02:18:59.38)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 468/1000000 (1 PENDING, 30 RUNNING, 437 TERMINATED)


2023-11-02 01:50:00,909	WARNING util.py:214 -- The `start_trial` operation took 0.633 s, which may be a performance bottleneck.
2023-11-02 01:50:02,955	WARNING util.py:214 -- The `start_trial` operation took 0.559 s, which may be a performance bottleneck.
2023-11-02 01:50:04,282	WARNING util.py:214 -- The `start_trial` operation took 0.598 s, which may be a performance bottleneck.
2023-11-02 01:50:07,086	WARNING util.py:214 -- The `start_trial` operation took 1.461 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 01:51:00,494 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(514456) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:51:03,955 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(514468) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:51:06,925 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(514473) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:52:00,692 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(514490) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:52:04,129 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(514493) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:52:07,104 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(514495) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:53:00,814 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(514518) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:53:07,256 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(514523) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 01:56:07,828	WARNING util.py:214 -- The `start_trial` operation took 0.575 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 01:57:07,489 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(514796) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:57:10,001 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(514799) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:58:07,622 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(514820) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:58:10,264 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(514823) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 01:59:10,427 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(514843) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 02:01:58,394	WARNING util.py:214 -- The `start_trial` operation took 0.544 s, which may be a performance bottleneck.
2023-11-02 02:02:00,940	WARNING util.py:214 -- The `start_trial` operation took 0.649 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 02:05:59,456 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515195) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:06:59,678 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515224) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 02:09:57,494	WARNING util.py:214 -- The `start_trial` operation took 0.793 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 02:10:57,381 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515438) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 02:13:48,545	WARNING util.py:214 -- The `start_trial` operation took 0.567 s, which may be a performance bottleneck.
2023-11-02 02:13:49,281	WARNING util.py:214 -- The `start_trial` operation took 0.516 s, which may be a performance bottleneck.
2023-11-02 02:13:49,970	WARNING util.py:214 -- The `start_trial` operation took 0.682 s, which may be a performance bottleneck.
2023-11-02 02:13:51,039	WARNING util.py:214 -- The `start_trial` operation took 0.504 s, which may be a performance bottleneck.
2023-11-02 02:13:51,550	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 02:14:49,603 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515544) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:14:51,292 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515620) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:15:49,771 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515643) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:15:51,514 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515648) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:16:49,987 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515663) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:16:51,659 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515668) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:17:50,119 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515682) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:17:51,950 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515690) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:18:50,372 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515709) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:18:52,062 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515718) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:19:52,296 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515800) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 02:22:45,143	WARNING util.py:214 -- The `on_step_end` operation took 0.562 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 01:49:59 (running for 02:19:05.02)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 472/1000000 (31 RUNNING, 441 TERMINATED)


== Status ==
Current time: 2023-11-02 01:50:07 (running for 02:19:12.43)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 476/1000000 (32 RUNNING, 444 TERMINATED)


== Status ==
Current time: 2023-11-02 01:56:05 (running for 02:25:10.66)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 476/1000000 (32 RUNNING, 444 TERMINATED)


== Status ==
Current time: 2023-11-02 01:56:11 (running for 02:25:16.69)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 479/1000000 (32 RUNNING, 447 TERMINATED)


== Status ==
Current time: 2023-11-02 02:01:55 (running for 02:31:00.59)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 479/1000000 (32 RUNNING, 447 TERMINATED)


== Status ==
Current time: 2023-11-02 02:02:01 (running for 02:31:06.50)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 482/1000000 (32 RUNNING, 450 TERMINATED)


== Status ==
Current time: 2023-11-02 02:04:55 (running for 02:34:00.64)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 482/1000000 (32 RUNNING, 450 TERMINATED)


== Status ==
Current time: 2023-11-02 02:05:00 (running for 02:34:06.09)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 486/1000000 (31 RUNNING, 455 TERMINATED)


== Status ==
Current time: 2023-11-02 02:10:01 (running for 02:39:07.18)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 487/1000000 (32 RUNNING, 455 TERMINATED)


== Status ==
Current time: 2023-11-02 02:13:46 (running for 02:42:51.59)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c4e7128f with val_loss=478.2219497729278 and parameters={'n_estimators': 1291, 'num_leaves': 17, 'min_child_samples': 41, 'learning_rate': 0.03519339505786716, 'log_max_bin': 9, 'colsample_bytree': 0.5054287107616271, 'reg_alpha': 0.02263955213457256, 'reg_lambda': 342.17986524170226, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 487/1000000 (32 RUNNING, 455 TERMINATED)


== Status ==
Current time: 2023-11-02 02:13:51 (running for 02:42:56.89)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5b4548a2 with val_loss=477.9994058362007 and parameters={'n_estimators': 2395, 'num_leaves': 24, 'min_child_samples': 24, 'learning_rate': 0.0164909206527046, 'log_max_bin': 9, 'colsample_bytree': 0.38036821621055983, 'reg_alpha': 0.002431712315246282, 'reg_lambda': 181.60009780250218, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 492/1000000 (32 RUNNING, 460 TERMINATED)


2023-11-02 02:22:47,156	WARNING util.py:214 -- The `start_trial` operation took 0.518 s, which may be a performance bottleneck.
2023-11-02 02:22:47,849	WARNING util.py:214 -- The `start_trial` operation took 0.681 s, which may be a performance bottleneck.
2023-11-02 02:22:49,551	WARNING util.py:214 -- The `start_trial` operation took 0.631 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 02:23:47,414 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515933) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:23:49,087 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515939) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:24:47,613 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515961) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:24:49,208 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(515963) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:25:47,807 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516098) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:25:49,416 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516100) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:26:48,024 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516118) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:26:49,590 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516121) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:27:48,280 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516137) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:27:49,746 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516140) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:28:48,448 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516157) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:28:49,958 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516160) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:29:48,652 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516176) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:29:50,069 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516228) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:30:48,831 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516245) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:30:50,278 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516248) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:31:50,452 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516267) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:32:50,592 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516309) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:33:50,670 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516330) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:34:50,865 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516427) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:35:50,966 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516464) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:36:51,201 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516482) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:37:51,403 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516502) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:38:51,561 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516520) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:39:51,670 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516596) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:40:51,902 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516612) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 02:43:42,044	WARNING util.py:214 -- The `start_trial` operation took 0.609 s, which may be a performance bottleneck.
2023-11-02 02:43:44,606	WARNING util.py:214 -- The `start_trial` operation took 0.588 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 02:44:46,205 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516728) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:45:46,427 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516829) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:46:46,642 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516848) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:47:46,835 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516865) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:48:47,163 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516883) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:49:47,319 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516900) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:50:47,544 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(516978) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:51:47,752 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517011) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 02:54:40,861	WARNING util.py:214 -- The `start_trial` operation took 0.571 s, which may be a performance bottleneck.
2023-11-02 02:54:41,643	WARNING util.py:214 -- The `start_trial` operation took 0.624 s, which may be a performance bottleneck.
2023-11-02 02:54:43,608	WARNING util.py:214 -- The `start_trial` operation took 0.623 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 02:55:43,255 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517212) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:56:43,480 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517239) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:57:43,657 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517257) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:58:43,824 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517274) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 02:59:44,053 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517292) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 03:02:48,988	WARNING util.py:214 -- The `start_trial` operation took 0.602 s, which may be a performance bottleneck.
2023-11-02 03:02:51,795	WARNING util.py:214 -- The `start_trial` operation took 0.586 s, which may be a performance bottleneck.
2023-11-02 03:02:53,113	WARNING util.py:214 -- The `start_trial` operation took 0.597 s, which may be a performance bottleneck.
2023-11-02 03:02:54,572	WARNING util.py:214 -- The `start_trial` operation took 0.609 s, which may be a performance bottleneck.
2023-11-02 03:02:55,135	WARNING util.py:214 -- The `start_trial` operation took 0.549 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 03:03:54,802 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517471) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:04:54,979 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517571) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:05:55,193 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517588) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:06:55,390 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517608) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:07:55,696 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517625) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:08:55,872 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517643) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:09:56,033 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517712) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:10:56,245 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517730) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:11:56,414 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517758) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 03:14:59,027	WARNING util.py:214 -- The `start_trial` operation took 0.559 s, which may be a performance bottleneck.
2023-11-02 03:14:59,939	WARNING util.py:214 -- The `start_trial` operation took 0.505 s, which may be a performance bottleneck.
2023-11-02 03:15:01,201	WARNING util.py:214 -- The `start_trial` operation took 0.752 s, which may be a performance bottleneck.
2023-11-02 03:15:02,102	WARNING util.py:214 -- The `start_trial` operation took 0.570 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 03:15:58,705 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517937) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:16:00,755 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(517944) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-02 02:22:45 (running for 02:51:50.54)
Memory usage on this node: 25.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5b4548a2 with val_loss=477.9994058362007 and parameters={'n_estimators': 2395, 'num_leaves': 24, 'min_child_samples': 24, 'learning_rate': 0.0164909206527046, 'log_max_bin': 9, 'colsample_bytree': 0.38036821621055983, 'reg_alpha': 0.002431712315246282, 'reg_lambda': 181.60009780250218, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 492/1000000 (32 RUNNING, 460 TERMINATED)


== Status ==
Current time: 2023-11-02 02:22:54 (running for 02:51:59.90)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5b4548a2 with val_loss=477.9994058362007 and parameters={'n_estimators': 2395, 'num_leaves': 24, 'min_child_samples': 24, 'learning_rate': 0.0164909206527046, 'log_max_bin': 9, 'colsample_bytree': 0.38036821621055983, 'reg_alpha': 0.002431712315246282, 'reg_lambda': 181.60009780250218, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 496/1000000 (32 RUNNING, 464 TERMINATED)


== Status ==
Current time: 2023-11-02 02:43:39 (running for 03:12:44.79)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5b4548a2 with val_loss=477.9994058362007 and parameters={'n_estimators': 2395, 'num_leaves': 24, 'min_child_samples': 24, 'learning_rate': 0.0164909206527046, 'log_max_bin': 9, 'colsample_bytree': 0.38036821621055983, 'reg_alpha': 0.002431712315246282, 'reg_lambda': 181.60009780250218, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 496/1000000 (32 RUNNING, 464 TERMINATED)


== Status ==
Current time: 2023-11-02 02:43:44 (running for 03:12:49.95)
Memory usage on this node: 25.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5b4548a2 with val_loss=477.9994058362007 and parameters={'n_estimators': 2395, 'num_leaves': 24, 'min_child_samples': 24, 'learning_rate': 0.0164909206527046, 'log_max_bin': 9, 'colsample_bytree': 0.38036821621055983, 'reg_alpha': 0.002431712315246282, 'reg_lambda': 181.60009780250218, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 501/1000000 (31 RUNNING, 470 TERMINATED)


== Status ==
Current time: 2023-11-02 02:43:51 (running for 03:12:56.77)
Memory usage on this node: 25.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5b4548a2 with val_loss=477.9994058362007 and parameters={'n_estimators': 2395, 'num_leaves': 24, 'min_child_samples': 24, 'learning_rate': 0.0164909206527046, 'log_max_bin': 9, 'colsample_bytree': 0.38036821621055983, 'reg_alpha': 0.002431712315246282, 'reg_lambda': 181.60009780250218, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 502/1000000 (32 RUNNING, 470 TERMINATED)


== Status ==
Current time: 2023-11-02 02:54:38 (running for 03:23:43.73)
Memory usage on this node: 26.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5b4548a2 with val_loss=477.9994058362007 and parameters={'n_estimators': 2395, 'num_leaves': 24, 'min_child_samples': 24, 'learning_rate': 0.0164909206527046, 'log_max_bin': 9, 'colsample_bytree': 0.38036821621055983, 'reg_alpha': 0.002431712315246282, 'reg_lambda': 181.60009780250218, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 502/1000000 (32 RUNNING, 470 TERMINATED)


== Status ==
Current time: 2023-11-02 02:54:43 (running for 03:23:49.31)
Memory usage on this node: 25.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5b4548a2 with val_loss=477.9994058362007 and parameters={'n_estimators': 2395, 'num_leaves': 24, 'min_child_samples': 24, 'learning_rate': 0.0164909206527046, 'log_max_bin': 9, 'colsample_bytree': 0.38036821621055983, 'reg_alpha': 0.002431712315246282, 'reg_lambda': 181.60009780250218, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 506/1000000 (32 RUNNING, 474 TERMINATED)


== Status ==
Current time: 2023-11-02 03:02:44 (running for 03:31:50.13)
Memory usage on this node: 26.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5b4548a2 with val_loss=477.9994058362007 and parameters={'n_estimators': 2395, 'num_leaves': 24, 'min_child_samples': 24, 'learning_rate': 0.0164909206527046, 'log_max_bin': 9, 'colsample_bytree': 0.38036821621055983, 'reg_alpha': 0.002431712315246282, 'reg_lambda': 181.60009780250218, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 506/1000000 (32 RUNNING, 474 TERMINATED)


== Status ==
Current time: 2023-11-02 03:02:50 (running for 03:31:55.56)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5b4548a2 with val_loss=477.9994058362007 and parameters={'n_estimators': 2395, 'num_leaves': 24, 'min_child_samples': 24, 'learning_rate': 0.0164909206527046, 'log_max_bin': 9, 'colsample_bytree': 0.38036821621055983, 'reg_alpha': 0.002431712315246282, 'reg_lambda': 181.60009780250218, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 509/1000000 (1 PENDING, 31 RUNNING, 477 TERMINATED)


== Status ==
Current time: 2023-11-02 03:03:00 (running for 03:32:05.49)
Memory usage on this node: 26.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5b4548a2 with val_loss=477.9994058362007 and parameters={'n_estimators': 2395, 'num_leaves': 24, 'min_child_samples': 24, 'learning_rate': 0.0164909206527046, 'log_max_bin': 9, 'colsample_bytree': 0.38036821621055983, 'reg_alpha': 0.002431712315246282, 'reg_lambda': 181.60009780250218, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 512/1000000 (32 RUNNING, 480 TERMINATED)


== Status ==
Current time: 2023-11-02 03:14:56 (running for 03:44:02.25)
Memory usage on this node: 26.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5b4548a2 with val_loss=477.9994058362007 and parameters={'n_estimators': 2395, 'num_leaves': 24, 'min_child_samples': 24, 'learning_rate': 0.0164909206527046, 'log_max_bin': 9, 'colsample_bytree': 0.38036821621055983, 'reg_alpha': 0.002431712315246282, 'reg_lambda': 181.60009780250218, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 512/1000000 (32 RUNNING, 480 TERMINATED)


2023-11-02 03:23:56,654	WARNING util.py:214 -- The `start_trial` operation took 0.578 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 03:24:56,832 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518430) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:24:58,674 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518435) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:25:57,084 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518459) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:25:58,911 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518462) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:26:57,240 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518479) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:26:59,104 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518482) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:27:57,471 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518498) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:27:59,305 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518501) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:28:57,641 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518518) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:28:59,485 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518521) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:29:59,700 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518608) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:30:59,861 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518650) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:32:00,060 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518668) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:33:00,168 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518689) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 03:36:09,240	WARNING util.py:214 -- The `on_step_end` operation took 0.513 s, which may be a performance bottleneck.
2023-11-02 03:36:11,838	WARNING util.py:214 -- The `start_trial` operation took 0.581 s, which may be a performance bottleneck.
2023-11-02 03:36:12,430	WARNING util.py:214 -- The `start_trial` operation took 0.584 s, which may be a performance bottleneck.
2023-11-02 03:36:14,401	WARNING util.py:214 -- The `start_trial` operation took 0.521 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 03:37:12,102 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518871) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:38:12,281 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518896) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:39:12,475 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518914) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:40:12,581 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(518985) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:41:12,751 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(519002) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:42:12,979 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(519019) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:43:13,150 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(519036) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:44:13,332 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(519054) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:45:13,544 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(519150) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:46:13,837 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(519723) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:47:14,029 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(519741) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 03:50:02,761	WARNING util.py:214 -- The `start_trial` operation took 0.534 s, which may be a performance bottleneck.
2023-11-02 03:52:54,050	WARNING util.py:214 -- The `start_trial` operation took 0.567 s, which may be a performance bottleneck.
2023-11-02 03:55:44,407	WARNING util.py:214 -- The `on_step_end` operation took 0.535 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 03:15:02 (running for 03:44:07.73)
Memory usage on this node: 25.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 517/1000000 (31 RUNNING, 486 TERMINATED)


== Status ==
Current time: 2023-11-02 03:18:47 (running for 03:47:53.18)
Memory usage on this node: 26.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 518/1000000 (32 RUNNING, 486 TERMINATED)


== Status ==
Current time: 2023-11-02 03:21:07 (running for 03:50:12.59)
Memory usage on this node: 26.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 518/1000000 (32 RUNNING, 486 TERMINATED)


== Status ==
Current time: 2023-11-02 03:21:12 (running for 03:50:17.86)
Memory usage on this node: 25.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 524/1000000 (32 RUNNING, 492 TERMINATED)


== Status ==
Current time: 2023-11-02 03:23:53 (running for 03:52:58.75)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 524/1000000 (32 RUNNING, 492 TERMINATED)


== Status ==
Current time: 2023-11-02 03:23:58 (running for 03:53:04.08)
Memory usage on this node: 25.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 529/1000000 (32 RUNNING, 497 TERMINATED)


== Status ==
Current time: 2023-11-02 03:36:09 (running for 04:05:14.57)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 529/1000000 (32 RUNNING, 497 TERMINATED)


== Status ==
Current time: 2023-11-02 03:36:14 (running for 04:05:20.22)
Memory usage on this node: 25.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 532/1000000 (31 RUNNING, 501 TERMINATED)


== Status ==
Current time: 2023-11-02 03:50:06 (running for 04:19:12.06)
Memory usage on this node: 25.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 533/1000000 (32 RUNNING, 501 TERMINATED)


== Status ==
Current time: 2023-11-02 03:52:49 (running for 04:21:54.99)
Memory usage on this node: 26.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 533/1000000 (32 RUNNING, 501 TERMINATED)


== Status ==
Current time: 2023-11-02 03:52:55 (running for 04:22:00.92)
Memory usage on this node: 25.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 536/1000000 (1 PENDING, 30 RUNNING, 505 TERMINATED)


2023-11-02 03:55:46,624	WARNING util.py:214 -- The `start_trial` operation took 0.506 s, which may be a performance bottleneck.
2023-11-02 03:55:48,353	WARNING util.py:214 -- The `start_trial` operation took 0.573 s, which may be a performance bottleneck.
2023-11-02 03:55:49,605	WARNING util.py:214 -- The `start_trial` operation took 0.704 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 03:56:46,373 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(520152) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:56:49,228 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(520162) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:57:46,617 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(520184) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 03:57:49,431 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(520187) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 04:00:46,546	WARNING util.py:214 -- The `on_step_end` operation took 0.547 s, which may be a performance bottleneck.
2023-11-02 04:00:48,406	WARNING util.py:214 -- The `start_trial` operation took 0.521 s, which may be a performance bottleneck.
2023-11-02 04:00:49,003	WARNING util.py:214 -- The `start_trial` operation took 0.587 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 04:01:48,661 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(520433) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:02:48,864 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(520453) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:03:49,095 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(520471) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 04:06:37,572	WARNING util.py:214 -- The `start_trial` operation took 0.580 s, which may be a performance bottleneck.
2023-11-02 04:09:28,454	WARNING util.py:214 -- The `start_trial` operation took 0.579 s, which may be a performance bottleneck.
2023-11-02 04:09:29,948	WARNING util.py:214 -- The `start_trial` operation took 0.549 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 04:10:28,722 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(520852) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 04:13:30,901	WARNING util.py:214 -- The `start_trial` operation took 0.518 s, which may be a performance bottleneck.
2023-11-02 04:13:32,174	WARNING util.py:214 -- The `start_trial` operation took 0.847 s, which may be a performance bottleneck.
2023-11-02 04:13:35,403	WARNING util.py:214 -- The `on_step_end` operation took 0.638 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 04:14:31,679 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(520985) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:15:31,836 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(521084) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:16:32,006 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(521109) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:17:32,086 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(521129) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 04:20:15,409	WARNING util.py:214 -- The `start_trial` operation took 0.550 s, which may be a performance bottleneck.
2023-11-02 04:20:24,112	WARNING util.py:214 -- The `start_trial` operation took 0.565 s, which may be a performance bottleneck.
2023-11-02 04:20:24,721	WARNING util.py:214 -- The `on_step_end` operation took 0.609 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 04:21:20,430 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(521284) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:21:23,798 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(521296) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-02 03:55:44 (running for 04:24:49.74)
Memory usage on this node: 25.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 536/1000000 (31 RUNNING, 505 TERMINATED)


== Status ==
Current time: 2023-11-02 03:55:49 (running for 04:24:55.18)
Memory usage on this node: 25.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 541/1000000 (32 RUNNING, 509 TERMINATED)


== Status ==
Current time: 2023-11-02 04:00:46 (running for 04:29:51.90)
Memory usage on this node: 26.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 541/1000000 (32 RUNNING, 509 TERMINATED)


== Status ==
Current time: 2023-11-02 04:00:54 (running for 04:29:59.35)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 543/1000000 (32 RUNNING, 511 TERMINATED)


== Status ==
Current time: 2023-11-02 04:06:32 (running for 04:35:38.11)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 543/1000000 (32 RUNNING, 511 TERMINATED)


== Status ==
Current time: 2023-11-02 04:06:38 (running for 04:35:43.50)
Memory usage on this node: 25.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 547/1000000 (31 RUNNING, 516 TERMINATED)


== Status ==
Current time: 2023-11-02 04:09:25 (running for 04:38:30.56)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 548/1000000 (1 PENDING, 31 RUNNING, 516 TERMINATED)


== Status ==
Current time: 2023-11-02 04:09:31 (running for 04:38:36.44)
Memory usage on this node: 25.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 553/1000000 (1 PENDING, 31 RUNNING, 521 TERMINATED)


== Status ==
Current time: 2023-11-02 04:13:29 (running for 04:42:35.09)
Memory usage on this node: 25.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 553/1000000 (1 PENDING, 31 RUNNING, 521 TERMINATED)


== Status ==
Current time: 2023-11-02 04:13:35 (running for 04:42:40.74)
Memory usage on this node: 25.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 556/1000000 (1 PENDING, 30 RUNNING, 525 TERMINATED)


== Status ==
Current time: 2023-11-02 04:20:19 (running for 04:49:24.35)
Memory usage on this node: 26.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 556/1000000 (31 RUNNING, 525 TERMINATED)


2023-11-02 04:24:20,230	WARNING util.py:214 -- The `start_trial` operation took 0.659 s, which may be a performance bottleneck.
2023-11-02 04:24:21,104	WARNING util.py:214 -- The `start_trial` operation took 0.630 s, which may be a performance bottleneck.
2023-11-02 04:24:21,689	WARNING util.py:214 -- The `start_trial` operation took 0.577 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 04:25:18,260 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(521546) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:25:21,387 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(521553) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:26:21,530 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(521588) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 04:29:27,494	WARNING util.py:214 -- The `on_step_end` operation took 0.515 s, which may be a performance bottleneck.
2023-11-02 04:29:32,064	WARNING util.py:214 -- The `start_trial` operation took 0.672 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 04:30:32,316 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(521801) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:31:32,439 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(521824) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:32:32,631 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(521841) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:33:32,769 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(521860) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 04:36:17,307	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.574 s, which may be a performance bottleneck.
2023-11-02 04:36:17,308	WARNING util.py:214 -- The `process_trial_result` operation took 0.574 s, which may be a performance bottleneck.
2023-11-02 04:36:17,308	WARNING util.py:214 -- Processing trial results took 0.574 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-02 04:36:17,308	WARNING util.py:214 -- The `process_trial_result` operation took 0.574 s, which may be a performance bottleneck.
2023-11-02 04:36:19,460	WARNING util.py:214 -- The `start_trial` operation took 0.773 s, which may be a performance bottleneck.
2023-11-02 04:36:21,193	WARNING util.py:214 -- The `start_trial` operation took 0.571 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 04:37:20,935 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(522036) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:38:21,163 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(522066) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:39:21,296 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(522084) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:40:21,483 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(522228) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:41:21,670 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(522246) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 04:44:19,210	WARNING util.py:214 -- The `start_trial` operation took 0.593 s, which may be a performance bottleneck.
2023-11-02 04:44:20,984	WARNING util.py:214 -- The `on_step_end` operation took 0.504 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 04:20:24 (running for 04:49:30.05)
Memory usage on this node: 25.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 559/1000000 (32 RUNNING, 527 TERMINATED)


== Status ==
Current time: 2023-11-02 04:24:16 (running for 04:53:22.13)
Memory usage on this node: 26.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 559/1000000 (32 RUNNING, 527 TERMINATED)


== Status ==
Current time: 2023-11-02 04:24:22 (running for 04:53:27.58)
Memory usage on this node: 25.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 563/1000000 (32 RUNNING, 531 TERMINATED)


== Status ==
Current time: 2023-11-02 04:29:27 (running for 04:58:32.97)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 563/1000000 (32 RUNNING, 531 TERMINATED)


== Status ==
Current time: 2023-11-02 04:29:33 (running for 04:58:38.34)
Memory usage on this node: 25.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 566/1000000 (32 RUNNING, 534 TERMINATED)


== Status ==
Current time: 2023-11-02 04:36:12 (running for 05:05:18.18)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 566/1000000 (32 RUNNING, 534 TERMINATED)


== Status ==
Current time: 2023-11-02 04:36:18 (running for 05:05:23.40)
Memory usage on this node: 25.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 570/1000000 (31 RUNNING, 539 TERMINATED)


== Status ==
Current time: 2023-11-02 04:36:26 (running for 05:05:31.54)
Memory usage on this node: 26.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 574/1000000 (32 RUNNING, 542 TERMINATED)


== Status ==
Current time: 2023-11-02 04:44:14 (running for 05:13:20.14)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 574/1000000 (32 RUNNING, 542 TERMINATED)


== Status ==
Current time: 2023-11-02 04:44:21 (running for 05:13:26.37)
Memory usage on this node: 25.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 579/1000000 (1 PENDING, 31 RUNNING, 547 TERMINATED)


== Status ==
Current time: 2023-11-02 04:47:12 (running for 05:16:17.99)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 579/1000000 (32 RUNNING, 547 TERMINATED)


2023-11-02 04:49:49,177	WARNING util.py:214 -- The `start_trial` operation took 0.518 s, which may be a performance bottleneck.
2023-11-02 04:49:51,549	WARNING util.py:214 -- The `start_trial` operation took 0.771 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 04:50:51,188 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(522681) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:50:52,433 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(522690) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:51:51,411 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(522710) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:51:52,680 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(522712) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:52:51,598 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(522736) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:52:52,887 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(522738) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 04:55:44,978	WARNING util.py:214 -- The `on_step_end` operation took 0.808 s, which may be a performance bottleneck.
2023-11-02 04:55:47,883	WARNING util.py:214 -- The `start_trial` operation took 0.602 s, which may be a performance bottleneck.
2023-11-02 04:55:48,415	WARNING util.py:214 -- The `start_trial` operation took 0.524 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 04:56:48,093 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(522972) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:56:49,647 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(522976) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:57:48,275 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(522998) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 04:57:49,795 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(523001) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 05:00:43,691	WARNING util.py:214 -- The `start_trial` operation took 0.565 s, which may be a performance bottleneck.
2023-11-02 05:00:44,258	WARNING util.py:214 -- The `start_trial` operation took 0.514 s, which may be a performance bottleneck.
2023-11-02 05:00:46,106	WARNING util.py:214 -- The `start_trial` operation took 0.796 s, which may be a performance bottleneck.
2023-11-02 05:00:47,084	WARNING util.py:214 -- The `start_trial` operation took 0.611 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 05:01:45,777 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(523244) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:01:46,721 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(523249) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:02:45,967 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(523269) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:02:46,823 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(523271) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:03:47,103 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(523291) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 05:06:33,522	WARNING util.py:214 -- The `start_trial` operation took 0.634 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 05:07:33,713 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(523507) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 05:10:18,174	WARNING util.py:214 -- The `on_step_end` operation took 0.592 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 04:49:41 (running for 05:18:47.17)
Memory usage on this node: 25.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 579/1000000 (31 RUNNING, 548 TERMINATED)


== Status ==
Current time: 2023-11-02 04:49:47 (running for 05:18:52.62)
Memory usage on this node: 25.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 583/1000000 (1 PENDING, 30 RUNNING, 552 TERMINATED)


== Status ==
Current time: 2023-11-02 04:49:52 (running for 05:18:58.13)
Memory usage on this node: 25.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 588/1000000 (32 RUNNING, 556 TERMINATED)


== Status ==
Current time: 2023-11-02 04:55:44 (running for 05:24:50.31)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 588/1000000 (32 RUNNING, 556 TERMINATED)


== Status ==
Current time: 2023-11-02 04:55:54 (running for 05:25:00.26)
Memory usage on this node: 25.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 592/1000000 (32 RUNNING, 560 TERMINATED)


== Status ==
Current time: 2023-11-02 05:00:38 (running for 05:29:44.10)
Memory usage on this node: 26.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 592/1000000 (32 RUNNING, 560 TERMINATED)


== Status ==
Current time: 2023-11-02 05:00:44 (running for 05:29:49.90)
Memory usage on this node: 26.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 597/1000000 (31 RUNNING, 566 TERMINATED)


== Status ==
Current time: 2023-11-02 05:00:52 (running for 05:29:57.43)
Memory usage on this node: 25.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 599/1000000 (32 RUNNING, 567 TERMINATED)


== Status ==
Current time: 2023-11-02 05:06:28 (running for 05:35:34.07)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 599/1000000 (32 RUNNING, 567 TERMINATED)


== Status ==
Current time: 2023-11-02 05:06:34 (running for 05:35:39.59)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 603/1000000 (32 RUNNING, 571 TERMINATED)


== Status ==
Current time: 2023-11-02 05:10:18 (running for 05:39:23.51)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 603/1000000 (32 RUNNING, 571 TERMINATED)


2023-11-02 05:10:25,557	WARNING util.py:214 -- The `start_trial` operation took 0.520 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 05:11:29,760 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(523716) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:12:29,912 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(523736) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 05:15:22,175	WARNING util.py:214 -- The `start_trial` operation took 0.513 s, which may be a performance bottleneck.
2023-11-02 05:15:24,990	WARNING util.py:214 -- The `on_step_end` operation took 0.716 s, which may be a performance bottleneck.
2023-11-02 05:15:26,260	WARNING util.py:214 -- The `start_trial` operation took 0.699 s, which may be a performance bottleneck.
2023-11-02 05:15:27,882	WARNING util.py:214 -- The `start_trial` operation took 0.562 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 05:16:27,569 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(523987) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:17:27,725 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(524015) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 05:20:23,993	WARNING util.py:214 -- The `start_trial` operation took 0.545 s, which may be a performance bottleneck.
2023-11-02 05:20:26,376	WARNING util.py:214 -- The `start_trial` operation took 0.537 s, which may be a performance bottleneck.
2023-11-02 05:20:26,914	WARNING util.py:214 -- The `on_step_end` operation took 0.537 s, which may be a performance bottleneck.
2023-11-02 05:20:28,148	WARNING util.py:214 -- The `start_trial` operation took 0.604 s, which may be a performance bottleneck.
2023-11-02 05:20:28,941	WARNING util.py:214 -- The `start_trial` operation took 0.567 s, which may be a performance bottleneck.
2023-11-02 05:20:29,945	WARNING util.py:214 -- The `start_trial` operation took 0.646 s, which may be a performance bottleneck.
2023-11-02 05:20:31,442	WARNING util.py:214 -- The `start_trial` operation took 1.489 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 05:21:27,738 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(524178) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:21:30,226 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(524191) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:22:27,962 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(524214) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:22:30,469 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(524216) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:23:30,685 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(524237) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:24:30,859 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(524279) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 05:27:15,201	WARNING util.py:214 -- The `on_step_end` operation took 0.535 s, which may be a performance bottleneck.
2023-11-02 05:27:19,201	WARNING util.py:214 -- The `start_trial` operation took 0.696 s, which may be a performance bottleneck.
2023-11-02 05:27:20,254	WARNING util.py:214 -- The `start_trial` operation took 0.657 s, which may be a performance bottleneck.
2023-11-02 05:29:53,219	WARNING util.py:214 -- The `on_step_end` operation took 0.579 s, which may be a performance bottleneck.
2023-11-02 05:29:56,977	WARNING util.py:214 -- The `start_trial` operation took 0.584 s, which may be a performance bottleneck.
2023-11-02 05:29:57,698	WARNING util.py:214 -- The `start_trial` operation took 0.651 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 05:30:55,033 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(524710) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:31:55,240 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(524747) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:32:55,392 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(524767) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-02 05:10:23 (running for 05:39:28.70)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 608/1000000 (31 RUNNING, 577 TERMINATED)


== Status ==
Current time: 2023-11-02 05:10:29 (running for 05:39:35.15)
Memory usage on this node: 26.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 614/1000000 (32 RUNNING, 582 TERMINATED)


== Status ==
Current time: 2023-11-02 05:15:18 (running for 05:44:24.10)
Memory usage on this node: 26.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 614/1000000 (32 RUNNING, 582 TERMINATED)


== Status ==
Current time: 2023-11-02 05:15:24 (running for 05:44:30.32)
Memory usage on this node: 26.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 618/1000000 (1 PENDING, 31 RUNNING, 586 TERMINATED)


== Status ==
Current time: 2023-11-02 05:15:32 (running for 05:44:38.23)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 621/1000000 (32 RUNNING, 589 TERMINATED)


== Status ==
Current time: 2023-11-02 05:20:20 (running for 05:49:26.28)
Memory usage on this node: 26.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 621/1000000 (32 RUNNING, 589 TERMINATED)


== Status ==
Current time: 2023-11-02 05:20:26 (running for 05:49:32.31)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 624/1000000 (31 RUNNING, 593 TERMINATED)


== Status ==
Current time: 2023-11-02 05:20:36 (running for 05:49:41.79)
Memory usage on this node: 25.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 628/1000000 (32 RUNNING, 596 TERMINATED)


== Status ==
Current time: 2023-11-02 05:27:15 (running for 05:56:20.53)
Memory usage on this node: 26.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 628/1000000 (32 RUNNING, 596 TERMINATED)


== Status ==
Current time: 2023-11-02 05:27:20 (running for 05:56:26.06)
Memory usage on this node: 25.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 631/1000000 (32 RUNNING, 599 TERMINATED)


== Status ==
Current time: 2023-11-02 05:29:53 (running for 05:58:58.55)
Memory usage on this node: 26.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 631/1000000 (32 RUNNING, 599 TERMINATED)


2023-11-02 05:35:46,562	WARNING util.py:214 -- The `on_step_end` operation took 0.557 s, which may be a performance bottleneck.
2023-11-02 05:35:47,832	WARNING util.py:214 -- The `start_trial` operation took 0.710 s, which may be a performance bottleneck.
2023-11-02 05:35:50,703	WARNING util.py:214 -- The `start_trial` operation took 0.521 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 05:36:49,077 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(524881) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:37:49,227 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(524916) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:38:49,395 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(524934) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 05:41:38,910	WARNING util.py:214 -- The `on_step_end` operation took 0.512 s, which may be a performance bottleneck.
2023-11-02 05:41:41,733	WARNING util.py:214 -- The `start_trial` operation took 0.946 s, which may be a performance bottleneck.
2023-11-02 05:41:42,793	WARNING util.py:214 -- The `start_trial` operation took 0.583 s, which may be a performance bottleneck.
2023-11-02 05:41:43,541	WARNING util.py:214 -- The `start_trial` operation took 0.739 s, which may be a performance bottleneck.
2023-11-02 05:41:44,250	WARNING util.py:214 -- The `start_trial` operation took 0.570 s, which may be a performance bottleneck.
2023-11-02 05:44:10,463	WARNING util.py:214 -- The `start_trial` operation took 0.533 s, which may be a performance bottleneck.
2023-11-02 05:46:37,392	WARNING util.py:214 -- The `on_step_end` operation took 0.543 s, which may be a performance bottleneck.
2023-11-02 05:46:41,103	WARNING util.py:214 -- The `start_trial` operation took 0.557 s, which may be a performance bottleneck.
2023-11-02 05:46:43,562	WARNING util.py:214 -- The `on_step_end` operation took 0.698 s, which may be a performance bottleneck.
2023-11-02 05:46:47,732	WARNING util.py:214 -- The `start_trial` operation took 0.504 s, which may be a performance bottleneck.
2023-11-02 05:46:50,511	WARNING util.py:214 -- The `start_trial` operation took 0.680 s, which may be a performance bottleneck.
2023-11-02 05:46:52,543	WARNING util.py:214 -- The `start_trial` operation took 0.511 s, which may be a performance bottleneck.
2023-11-02 05:46:53,864	WARNING util.py:214 -- The `start_trial` operation took 0.640 s, which may be a performance bottleneck.
2023-11-02 05:46:55,835	WARNING util.py:214 -- The `on_step_end` operation took 0.622 s, which may be a performance bottleneck.
2023-11-02 05:49:52,239	WARNING util.py:214 -- The `start_trial` operation took 0.629 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 05:29:58 (running for 05:59:04.04)
Memory usage on this node: 25.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 636/1000000 (31 RUNNING, 605 TERMINATED)


== Status ==
Current time: 2023-11-02 05:35:46 (running for 06:04:52.19)
Memory usage on this node: 25.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 637/1000000 (1 PENDING, 30 RUNNING, 606 TERMINATED)


== Status ==
Current time: 2023-11-02 05:35:52 (running for 06:04:57.52)
Memory usage on this node: 25.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 642/1000000 (1 PENDING, 31 RUNNING, 610 TERMINATED)


== Status ==
Current time: 2023-11-02 05:41:38 (running for 06:10:44.24)
Memory usage on this node: 25.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 642/1000000 (1 PENDING, 31 RUNNING, 610 TERMINATED)


== Status ==
Current time: 2023-11-02 05:41:44 (running for 06:10:50.01)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 646/1000000 (31 RUNNING, 615 TERMINATED)


== Status ==
Current time: 2023-11-02 05:44:15 (running for 06:13:20.45)
Memory usage on this node: 25.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 647/1000000 (32 RUNNING, 615 TERMINATED)


== Status ==
Current time: 2023-11-02 05:46:37 (running for 06:15:42.80)
Memory usage on this node: 25.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 647/1000000 (31 RUNNING, 616 TERMINATED)


== Status ==
Current time: 2023-11-02 05:46:43 (running for 06:15:48.89)
Memory usage on this node: 25.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 651/1000000 (1 PENDING, 31 RUNNING, 619 TERMINATED)


== Status ==
Current time: 2023-11-02 05:46:49 (running for 06:15:54.60)
Memory usage on this node: 25.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 654/1000000 (1 PENDING, 31 RUNNING, 622 TERMINATED)


== Status ==
Current time: 2023-11-02 05:46:55 (running for 06:16:01.22)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 657/1000000 (1 PENDING, 30 RUNNING, 626 TERMINATED)


== Status ==
Current time: 2023-11-02 05:49:48 (running for 06:18:53.64)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 657/1000000 (31 RUNNING, 626 TERMINATED)


2023-11-02 05:52:46,240	WARNING util.py:214 -- The `on_step_end` operation took 0.615 s, which may be a performance bottleneck.
2023-11-02 05:52:49,311	WARNING util.py:214 -- The `start_trial` operation took 0.659 s, which may be a performance bottleneck.
2023-11-02 05:52:52,184	WARNING util.py:214 -- The `start_trial` operation took 0.533 s, which may be a performance bottleneck.
2023-11-02 05:52:52,700	WARNING util.py:214 -- The `on_step_end` operation took 0.516 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 05:53:47,266 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(525833) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:53:51,906 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(525843) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:54:47,454 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(525862) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:54:52,129 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(525884) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:55:47,637 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(525897) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:55:52,306 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(525903) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:56:52,444 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(525923) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 05:57:52,603 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(525969) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 06:00:59,227	WARNING util.py:214 -- The `on_step_end` operation took 0.639 s, which may be a performance bottleneck.
2023-11-02 06:01:04,292	WARNING util.py:214 -- The `start_trial` operation took 0.528 s, which may be a performance bottleneck.
2023-11-02 06:01:08,656	WARNING util.py:214 -- The `start_trial` operation took 0.863 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 06:02:08,189 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(526205) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:03:08,378 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(526226) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:04:08,549 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(526243) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:05:08,724 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(526275) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:06:08,791 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(526292) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:07:08,986 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(526310) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:08:09,184 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(526343) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:09:09,352 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(526362) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 06:11:59,190	WARNING util.py:214 -- The `on_step_end` operation took 0.630 s, which may be a performance bottleneck.
2023-11-02 06:12:05,382	WARNING util.py:214 -- The `on_step_end` operation took 1.038 s, which may be a performance bottleneck.
2023-11-02 06:12:06,413	WARNING util.py:214 -- The `start_trial` operation took 0.826 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 06:13:08,361 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(526610) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:14:08,543 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(526630) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:15:08,702 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(526714) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:16:08,896 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(526731) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:17:09,035 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(526748) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:18:09,185 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(526768) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 06:20:41,643	WARNING util.py:214 -- The `start_trial` operation took 0.685 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 05:49:53 (running for 06:18:59.26)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 660/1000000 (1 PENDING, 31 RUNNING, 628 TERMINATED)


== Status ==
Current time: 2023-11-02 05:52:46 (running for 06:21:51.57)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 660/1000000 (1 PENDING, 31 RUNNING, 628 TERMINATED)


== Status ==
Current time: 2023-11-02 05:52:52 (running for 06:21:58.15)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 663/1000000 (32 RUNNING, 631 TERMINATED)


== Status ==
Current time: 2023-11-02 06:00:59 (running for 06:30:04.56)
Memory usage on this node: 25.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 663/1000000 (32 RUNNING, 631 TERMINATED)


== Status ==
Current time: 2023-11-02 06:01:04 (running for 06:30:09.85)
Memory usage on this node: 25.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 665/1000000 (31 RUNNING, 634 TERMINATED)


== Status ==
Current time: 2023-11-02 06:01:13 (running for 06:30:19.17)
Memory usage on this node: 25.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 667/1000000 (32 RUNNING, 635 TERMINATED)


== Status ==
Current time: 2023-11-02 06:11:53 (running for 06:40:58.34)
Memory usage on this node: 25.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 667/1000000 (32 RUNNING, 635 TERMINATED)


== Status ==
Current time: 2023-11-02 06:11:59 (running for 06:41:04.52)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 671/1000000 (1 PENDING, 31 RUNNING, 639 TERMINATED)


== Status ==
Current time: 2023-11-02 06:12:05 (running for 06:41:10.72)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 674/1000000 (1 PENDING, 30 RUNNING, 643 TERMINATED)


== Status ==
Current time: 2023-11-02 06:12:13 (running for 06:41:18.89)
Memory usage on this node: 25.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 675/1000000 (32 RUNNING, 643 TERMINATED)


== Status ==
Current time: 2023-11-02 06:20:37 (running for 06:49:43.30)
Memory usage on this node: 25.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 675/1000000 (32 RUNNING, 643 TERMINATED)


2023-11-02 06:20:46,843	WARNING util.py:214 -- The `start_trial` operation took 0.663 s, which may be a performance bottleneck.
2023-11-02 06:20:48,459	WARNING util.py:214 -- The `start_trial` operation took 0.607 s, which may be a performance bottleneck.
2023-11-02 06:20:49,985	WARNING util.py:214 -- The `on_step_end` operation took 0.694 s, which may be a performance bottleneck.
2023-11-02 06:23:35,416	WARNING util.py:214 -- The `start_trial` operation took 0.537 s, which may be a performance bottleneck.
2023-11-02 06:23:38,010	WARNING util.py:214 -- The `start_trial` operation took 0.629 s, which may be a performance bottleneck.
2023-11-02 06:23:41,299	WARNING util.py:214 -- The `start_trial` operation took 0.589 s, which may be a performance bottleneck.
2023-11-02 06:23:41,912	WARNING util.py:214 -- The `on_step_end` operation took 0.613 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 06:24:37,598 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(527113) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:24:41,023 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(527121) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:25:37,668 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(527265) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:25:41,172 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(527268) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:26:41,332 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(527320) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 06:29:44,136	WARNING util.py:214 -- The `on_step_end` operation took 0.725 s, which may be a performance bottleneck.
2023-11-02 06:29:49,125	WARNING util.py:214 -- The `start_trial` operation took 0.523 s, which may be a performance bottleneck.
2023-11-02 06:29:49,765	WARNING util.py:214 -- The `start_trial` operation took 0.544 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 06:30:49,410 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(527497) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:31:49,592 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(527521) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:32:49,778 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(527538) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:33:50,004 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(527555) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:34:50,118 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(527572) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:35:50,260 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(527677) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:36:50,473 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(527694) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:37:50,697 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(527711) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:38:50,912 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(527729) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 06:41:44,901	WARNING util.py:214 -- The `on_step_end` operation took 0.562 s, which may be a performance bottleneck.
2023-11-02 06:41:47,105	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.584 s, which may be a performance bottleneck.
2023-11-02 06:41:47,106	WARNING util.py:214 -- The `process_trial_result` operation took 0.585 s, which may be a performance bottleneck.
2023-11-02 06:41:47,106	WARNING util.py:214 -- Processing trial results took 0.585 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-02 06:41:47,106	WARNING util.py:214 -- The `process_trial_result` operation took 0.585 s, which may be a performance bottleneck.
2023-11-02 06:41:47,720	WARNING util.py:214 -- The `start_trial` operation took 0.524 s, which may be a performance bottleneck.
2023-11-02 06:41:48,862	WARNING util.py:214 -- The `start_trial` operation took 0.626 s, which may be a performance bottleneck.
2023-11-02 06:41:50,683	WARNING util.py:214 -- The `on_step_end` operation took 0.701 s, which may be a performance bottleneck.
2023-11-02 06:44:33,144	WARNING util.py:214 -- The `start_trial` operation took 0.780 s, which may be a performance bottleneck.
2023-11-02 06:44:37,300	WARNING util.py:214 -- The `on_step_end` operation took 0.882 s, which may be a performance bottleneck.
2023-11-02 06:47:27,001	WARNING util.py:214 -- The `on_step_end` operation took 0.809 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 06:20:44 (running for 06:49:49.51)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 678/1000000 (1 PENDING, 31 RUNNING, 646 TERMINATED)


== Status ==
Current time: 2023-11-02 06:20:50 (running for 06:49:55.42)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 681/1000000 (1 PENDING, 30 RUNNING, 650 TERMINATED)


== Status ==
Current time: 2023-11-02 06:23:30 (running for 06:52:35.36)
Memory usage on this node: 25.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 681/1000000 (31 RUNNING, 650 TERMINATED)


== Status ==
Current time: 2023-11-02 06:23:35 (running for 06:52:40.94)
Memory usage on this node: 25.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 684/1000000 (31 RUNNING, 653 TERMINATED)


== Status ==
Current time: 2023-11-02 06:23:41 (running for 06:52:47.25)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 687/1000000 (32 RUNNING, 655 TERMINATED)


== Status ==
Current time: 2023-11-02 06:29:44 (running for 06:58:49.57)
Memory usage on this node: 25.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 687/1000000 (32 RUNNING, 655 TERMINATED)


== Status ==
Current time: 2023-11-02 06:29:50 (running for 06:58:55.56)
Memory usage on this node: 25.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 690/1000000 (32 RUNNING, 658 TERMINATED)


== Status ==
Current time: 2023-11-02 06:41:44 (running for 07:10:50.23)
Memory usage on this node: 26.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 690/1000000 (32 RUNNING, 658 TERMINATED)


== Status ==
Current time: 2023-11-02 06:41:50 (running for 07:10:56.02)
Memory usage on this node: 25.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 693/1000000 (1 PENDING, 30 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-02 06:44:31 (running for 07:13:36.38)
Memory usage on this node: 25.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 693/1000000 (31 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-02 06:44:37 (running for 07:13:42.71)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 696/1000000 (1 PENDING, 30 RUNNING, 665 TERMINATED)


2023-11-02 06:47:29,945	WARNING util.py:214 -- The `start_trial` operation took 0.662 s, which may be a performance bottleneck.
2023-11-02 06:47:32,186	WARNING util.py:214 -- The `start_trial` operation took 0.624 s, which may be a performance bottleneck.
2023-11-02 06:47:32,809	WARNING util.py:214 -- The `on_step_end` operation took 0.623 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 06:48:31,840 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528138) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:49:32,033 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528161) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:50:32,153 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528217) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 06:53:36,491	WARNING util.py:214 -- The `on_step_end` operation took 0.779 s, which may be a performance bottleneck.
2023-11-02 06:53:40,677	WARNING util.py:214 -- The `start_trial` operation took 0.672 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 06:54:40,430 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528324) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:54:42,678 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528329) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:55:40,627 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528433) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:55:42,882 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528435) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:56:40,794 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528452) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:56:43,079 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528454) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:57:41,058 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528471) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:58:41,263 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528493) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 06:59:41,469 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528537) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:00:41,562 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528713) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:01:41,708 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528734) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:02:41,973 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528751) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:03:42,211 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528768) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:04:42,362 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528785) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:05:42,586 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528816) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:06:42,803 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528833) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:07:42,935 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528850) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:08:43,142 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528868) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:09:43,305 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(528886) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:10:43,528 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529020) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:11:43,725 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529037) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:12:43,991 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529054) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 07:15:28,081	WARNING util.py:214 -- The `on_step_end` operation took 0.741 s, which may be a performance bottleneck.
2023-11-02 07:15:34,034	WARNING util.py:214 -- The `on_step_end` operation took 0.572 s, which may be a performance bottleneck.
2023-11-02 07:15:35,461	WARNING util.py:214 -- The `start_trial` operation took 0.538 s, which may be a performance bottleneck.
2023-11-02 07:15:36,738	WARNING util.py:214 -- The `start_trial` operation took 0.547 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 07:16:36,507 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529216) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:17:37,006 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529242) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:18:37,286 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529263) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:19:37,460 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529281) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:20:37,715 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529387) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:21:37,872 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529405) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:22:38,073 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529422) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:23:38,309 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529440) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:24:38,488 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529457) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:25:38,690 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529529) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:26:38,835 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529546) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:27:39,012 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529563) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 07:30:28,388	WARNING util.py:214 -- The `on_step_end` operation took 0.675 s, which may be a performance bottleneck.
2023-11-02 07:30:34,278	WARNING util.py:214 -- The `on_step_end` operation took 0.811 s, which may be a performance bottleneck.
2023-11-02 07:30:35,572	WARNING util.py:214 -- The `start_trial` operation took 0.623 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 07:31:39,129 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529755) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:32:39,418 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529775) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 07:35:31,538	WARNING util.py:214 -- The `on_step_end` operation took 0.650 s, which may be a performance bottleneck.
2023-11-02 07:35:34,229	WARNING util.py:214 -- The `start_trial` operation took 0.655 s, which may be a performance bottleneck.
2023-11-02 07:35:36,185	WARNING util.py:214 -- The `start_trial` operation took 0.734 s, which may be a performance bottleneck.
2023-11-02 07:35:38,455	WARNING util.py:214 -- The `on_step_end` operation took 0.739 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 07:36:35,789 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529968) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:37:35,969 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(529991) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:38:36,140 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(530008) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-02 06:47:27 (running for 07:16:32.33)
Memory usage on this node: 25.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 696/1000000 (31 RUNNING, 665 TERMINATED)


== Status ==
Current time: 2023-11-02 06:47:32 (running for 07:16:38.14)
Memory usage on this node: 25.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 698/1000000 (32 RUNNING, 666 TERMINATED)


== Status ==
Current time: 2023-11-02 06:53:36 (running for 07:22:41.82)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 698/1000000 (32 RUNNING, 666 TERMINATED)


== Status ==
Current time: 2023-11-02 06:53:43 (running for 07:22:48.34)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 701/1000000 (32 RUNNING, 669 TERMINATED)


== Status ==
Current time: 2023-11-02 07:15:28 (running for 07:44:33.41)
Memory usage on this node: 25.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 701/1000000 (32 RUNNING, 669 TERMINATED)


== Status ==
Current time: 2023-11-02 07:15:34 (running for 07:44:39.37)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 703/1000000 (31 RUNNING, 672 TERMINATED)


== Status ==
Current time: 2023-11-02 07:15:41 (running for 07:44:47.09)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 706/1000000 (32 RUNNING, 674 TERMINATED)


== Status ==
Current time: 2023-11-02 07:30:28 (running for 07:59:33.79)
Memory usage on this node: 25.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 706/1000000 (32 RUNNING, 674 TERMINATED)


== Status ==
Current time: 2023-11-02 07:30:34 (running for 07:59:39.77)
Memory usage on this node: 25.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 709/1000000 (1 PENDING, 30 RUNNING, 678 TERMINATED)


== Status ==
Current time: 2023-11-02 07:30:44 (running for 07:59:49.54)
Memory usage on this node: 25.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 711/1000000 (32 RUNNING, 679 TERMINATED)


== Status ==
Current time: 2023-11-02 07:35:31 (running for 08:04:36.87)
Memory usage on this node: 26.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 711/1000000 (32 RUNNING, 679 TERMINATED)


2023-11-02 07:41:04,030	WARNING util.py:214 -- The `on_step_end` operation took 0.596 s, which may be a performance bottleneck.
2023-11-02 07:41:08,323	WARNING util.py:214 -- The `start_trial` operation took 0.653 s, which may be a performance bottleneck.
2023-11-02 07:43:43,079	WARNING util.py:214 -- The `on_step_end` operation took 0.579 s, which may be a performance bottleneck.
2023-11-02 07:43:49,157	WARNING util.py:214 -- The `on_step_end` operation took 0.653 s, which may be a performance bottleneck.
2023-11-02 07:46:39,974	WARNING util.py:214 -- The `on_step_end` operation took 0.578 s, which may be a performance bottleneck.
2023-11-02 07:46:44,642	WARNING util.py:214 -- The `start_trial` operation took 0.520 s, which may be a performance bottleneck.
2023-11-02 07:46:46,060	WARNING util.py:214 -- The `start_trial` operation took 0.752 s, which may be a performance bottleneck.
2023-11-02 07:46:46,631	WARNING util.py:214 -- The `on_step_end` operation took 0.571 s, which may be a performance bottleneck.
2023-11-02 07:49:49,411	WARNING util.py:214 -- The `on_step_end` operation took 0.724 s, which may be a performance bottleneck.
2023-11-02 07:49:52,739	WARNING util.py:214 -- The `start_trial` operation took 0.528 s, which may be a performance bottleneck.
2023-11-02 07:49:55,116	WARNING util.py:214 -- The `on_step_end` operation took 0.545 s, which may be a performance bottleneck.
2023-11-02 07:49:56,542	WARNING util.py:214 -- The `start_trial` operation took 0.634 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 07:50:56,238 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(530693) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:50:57,269 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(530695) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:51:56,458 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(530716) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:51:57,511 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(530718) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:52:56,609 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(530746) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:52:57,789 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(530749) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:53:56,784 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(530770) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:53:57,944 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(530771) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:54:58,106 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(530794) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 07:55:58,310 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(530837) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 07:58:45,992	WARNING util.py:214 -- The `on_step_end` operation took 0.674 s, which may be a performance bottleneck.
2023-11-02 07:58:49,610	WARNING util.py:214 -- The `start_trial` operation took 0.883 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 07:35:38 (running for 08:04:43.92)
Memory usage on this node: 25.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 715/1000000 (1 PENDING, 30 RUNNING, 684 TERMINATED)


== Status ==
Current time: 2023-11-02 07:41:04 (running for 08:10:09.52)
Memory usage on this node: 25.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 715/1000000 (31 RUNNING, 684 TERMINATED)


== Status ==
Current time: 2023-11-02 07:41:09 (running for 08:10:15.04)
Memory usage on this node: 25.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 718/1000000 (31 RUNNING, 687 TERMINATED)


== Status ==
Current time: 2023-11-02 07:43:43 (running for 08:12:48.60)
Memory usage on this node: 25.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 719/1000000 (1 PENDING, 31 RUNNING, 687 TERMINATED)


== Status ==
Current time: 2023-11-02 07:43:49 (running for 08:12:54.52)
Memory usage on this node: 25.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 724/1000000 (32 RUNNING, 692 TERMINATED)


== Status ==
Current time: 2023-11-02 07:46:39 (running for 08:15:45.31)
Memory usage on this node: 26.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 724/1000000 (32 RUNNING, 692 TERMINATED)


== Status ==
Current time: 2023-11-02 07:46:46 (running for 08:15:52.21)
Memory usage on this node: 25.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 727/1000000 (32 RUNNING, 695 TERMINATED)


== Status ==
Current time: 2023-11-02 07:49:49 (running for 08:18:54.80)
Memory usage on this node: 26.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 727/1000000 (32 RUNNING, 695 TERMINATED)


== Status ==
Current time: 2023-11-02 07:49:55 (running for 08:19:00.66)
Memory usage on this node: 25.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 729/1000000 (31 RUNNING, 698 TERMINATED)


== Status ==
Current time: 2023-11-02 07:50:00 (running for 08:19:05.74)
Memory usage on this node: 25.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 731/1000000 (32 RUNNING, 699 TERMINATED)


== Status ==
Current time: 2023-11-02 07:58:45 (running for 08:27:51.33)
Memory usage on this node: 26.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 731/1000000 (32 RUNNING, 699 TERMINATED)


2023-11-02 07:58:54,808	WARNING util.py:214 -- The `start_trial` operation took 0.538 s, which may be a performance bottleneck.
2023-11-02 07:58:57,431	WARNING util.py:214 -- The `on_step_end` operation took 0.682 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 07:59:54,444 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(531080) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 08:02:47,711	WARNING util.py:214 -- The `on_step_end` operation took 0.613 s, which may be a performance bottleneck.
2023-11-02 08:02:52,999	WARNING util.py:214 -- The `start_trial` operation took 0.607 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 08:03:50,484 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(531187) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:04:50,757 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(531210) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 08:07:52,514	WARNING util.py:214 -- The `start_trial` operation took 0.603 s, which may be a performance bottleneck.
2023-11-02 08:07:57,407	WARNING util.py:214 -- The `on_step_end` operation took 0.650 s, which may be a performance bottleneck.
2023-11-02 08:10:37,334	WARNING util.py:214 -- The `on_step_end` operation took 0.742 s, which may be a performance bottleneck.
2023-11-02 08:10:41,879	WARNING util.py:214 -- The `start_trial` operation took 0.622 s, which may be a performance bottleneck.
2023-11-02 08:10:43,124	WARNING util.py:214 -- The `on_step_end` operation took 0.769 s, which may be a performance bottleneck.
2023-11-02 08:13:31,267	WARNING util.py:214 -- The `on_step_end` operation took 0.767 s, which may be a performance bottleneck.
2023-11-02 08:13:32,886	WARNING util.py:214 -- The `start_trial` operation took 0.544 s, which may be a performance bottleneck.
2023-11-02 08:13:36,654	WARNING util.py:214 -- The `start_trial` operation took 0.637 s, which may be a performance bottleneck.
2023-11-02 08:13:37,181	WARNING util.py:214 -- The `on_step_end` operation took 0.527 s, which may be a performance bottleneck.
2023-11-02 08:13:39,512	WARNING util.py:214 -- The `start_trial` operation took 0.537 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 08:14:39,208 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(531676) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:14:40,484 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(531681) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:15:39,360 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(531785) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:15:40,668 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(531787) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:16:39,490 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(531804) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:16:40,893 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(531806) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:17:39,673 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(531823) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 08:20:09,994	WARNING util.py:214 -- The `on_step_end` operation took 0.589 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 07:58:51 (running for 08:27:56.87)
Memory usage on this node: 26.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 734/1000000 (1 PENDING, 31 RUNNING, 702 TERMINATED)


== Status ==
Current time: 2023-11-02 07:58:57 (running for 08:28:02.76)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 737/1000000 (1 PENDING, 30 RUNNING, 706 TERMINATED)


== Status ==
Current time: 2023-11-02 08:02:47 (running for 08:31:53.27)
Memory usage on this node: 26.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 737/1000000 (31 RUNNING, 706 TERMINATED)


== Status ==
Current time: 2023-11-02 08:02:53 (running for 08:31:58.74)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 739/1000000 (31 RUNNING, 708 TERMINATED)


== Status ==
Current time: 2023-11-02 08:07:57 (running for 08:37:02.80)
Memory usage on this node: 26.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 740/1000000 (32 RUNNING, 708 TERMINATED)


== Status ==
Current time: 2023-11-02 08:10:37 (running for 08:39:42.68)
Memory usage on this node: 26.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 740/1000000 (32 RUNNING, 708 TERMINATED)


== Status ==
Current time: 2023-11-02 08:10:43 (running for 08:39:48.58)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 743/1000000 (1 PENDING, 31 RUNNING, 711 TERMINATED)


== Status ==
Current time: 2023-11-02 08:13:31 (running for 08:42:36.60)
Memory usage on this node: 26.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 743/1000000 (1 PENDING, 31 RUNNING, 711 TERMINATED)


== Status ==
Current time: 2023-11-02 08:13:37 (running for 08:42:42.51)
Memory usage on this node: 26.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 746/1000000 (31 RUNNING, 715 TERMINATED)


== Status ==
Current time: 2023-11-02 08:13:45 (running for 08:42:51.15)
Memory usage on this node: 26.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 748/1000000 (32 RUNNING, 716 TERMINATED)


== Status ==
Current time: 2023-11-02 08:20:09 (running for 08:49:15.33)
Memory usage on this node: 26.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 748/1000000 (32 RUNNING, 716 TERMINATED)


2023-11-02 08:23:04,239	WARNING util.py:214 -- The `on_step_end` operation took 0.706 s, which may be a performance bottleneck.
2023-11-02 08:23:10,019	WARNING util.py:214 -- The `on_step_end` operation took 0.755 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 08:24:08,151 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532200) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:25:08,350 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532294) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:26:08,549 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532311) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:27:08,764 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532327) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:28:08,956 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532344) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 08:31:12,460	WARNING util.py:214 -- The `on_step_end` operation took 0.806 s, which may be a performance bottleneck.
2023-11-02 08:31:13,928	WARNING util.py:214 -- The `start_trial` operation took 0.535 s, which may be a performance bottleneck.
2023-11-02 08:31:17,078	WARNING util.py:214 -- The `start_trial` operation took 0.588 s, which may be a performance bottleneck.
2023-11-02 08:31:18,037	WARNING util.py:214 -- The `start_trial` operation took 0.570 s, which may be a performance bottleneck.
2023-11-02 08:31:18,545	WARNING util.py:214 -- The `on_step_end` operation took 0.509 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 08:32:13,668 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532508) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:32:16,767 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532513) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:32:17,695 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532515) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:33:13,883 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532531) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:33:17,028 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532534) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:33:17,877 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532536) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:34:14,078 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532552) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:34:17,214 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532556) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:34:18,060 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532558) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:35:14,260 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532643) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:35:17,435 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532646) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:35:18,308 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532648) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:36:14,444 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532664) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:36:17,659 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532667) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:36:18,499 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532669) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:37:14,681 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532685) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:37:17,855 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532688) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:37:18,679 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532690) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:38:14,920 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532706) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:38:18,896 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532711) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:39:15,106 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532744) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:39:19,054 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532756) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:40:15,257 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532831) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:41:15,500 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(532851) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 08:44:35,817	WARNING util.py:214 -- The `on_step_end` operation took 0.791 s, which may be a performance bottleneck.
2023-11-02 08:44:39,502	WARNING util.py:214 -- The `start_trial` operation took 0.528 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 08:45:39,273 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533063) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:45:40,779 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533065) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:46:39,466 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533088) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:46:40,991 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533090) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:47:39,675 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533108) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:47:41,065 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533109) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:48:39,832 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533126) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:48:41,256 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533128) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:49:40,079 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533149) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:49:41,462 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533151) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:50:40,281 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533230) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:50:41,663 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533231) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:51:40,489 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533247) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:51:41,900 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533249) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:52:40,750 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533266) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:52:41,982 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533268) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:53:42,241 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533294) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:54:42,456 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533336) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 08:57:44,810	WARNING util.py:214 -- The `on_step_end` operation took 0.688 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 08:58:48,061 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533516) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 08:59:48,238 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533539) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:00:48,477 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533683) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:01:48,710 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533700) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:02:48,940 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533717) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:03:49,165 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533781) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:04:49,493 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533798) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:05:49,750 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533816) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:06:49,841 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533833) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:07:50,037 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533851) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:08:50,257 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(533886) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 09:12:01,156	WARNING util.py:214 -- The `on_step_end` operation took 0.816 s, which may be a performance bottleneck.
2023-11-02 09:12:03,367	WARNING util.py:214 -- The `start_trial` operation took 0.513 s, which may be a performance bottleneck.
2023-11-02 09:12:04,985	WARNING util.py:214 -- The `start_trial` operation took 0.616 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 09:13:04,671 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534139) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:13:06,407 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534141) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:14:04,827 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534164) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:14:06,581 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534166) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:15:05,034 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534183) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:15:06,813 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534185) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:16:05,234 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534202) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:16:06,970 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534205) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:17:05,426 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534221) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:17:07,185 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534223) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:18:05,593 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534243) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:18:07,450 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534245) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:19:05,791 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534263) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:19:07,603 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534266) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:20:05,969 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534410) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:20:07,802 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534412) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:21:06,126 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534429) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 09:23:55,680	WARNING util.py:214 -- The `on_step_end` operation took 0.696 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 08:20:15 (running for 08:49:20.87)
Memory usage on this node: 26.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 753/1000000 (32 RUNNING, 721 TERMINATED)


== Status ==
Current time: 2023-11-02 08:23:04 (running for 08:52:09.59)
Memory usage on this node: 26.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 753/1000000 (32 RUNNING, 721 TERMINATED)


== Status ==
Current time: 2023-11-02 08:23:10 (running for 08:52:15.43)
Memory usage on this node: 26.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 757/1000000 (1 PENDING, 30 RUNNING, 726 TERMINATED)


== Status ==
Current time: 2023-11-02 08:31:12 (running for 09:00:17.79)
Memory usage on this node: 27.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 757/1000000 (31 RUNNING, 726 TERMINATED)


== Status ==
Current time: 2023-11-02 08:31:18 (running for 09:00:23.88)
Memory usage on this node: 26.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 760/1000000 (32 RUNNING, 728 TERMINATED)


== Status ==
Current time: 2023-11-02 08:44:35 (running for 09:13:41.15)
Memory usage on this node: 28.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 760/1000000 (32 RUNNING, 728 TERMINATED)


== Status ==
Current time: 2023-11-02 08:44:41 (running for 09:13:46.46)
Memory usage on this node: 27.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 764/1000000 (32 RUNNING, 732 TERMINATED)


== Status ==
Current time: 2023-11-02 08:57:44 (running for 09:26:50.31)
Memory usage on this node: 28.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 764/1000000 (32 RUNNING, 732 TERMINATED)


== Status ==
Current time: 2023-11-02 08:57:53 (running for 09:26:58.80)
Memory usage on this node: 28.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 767/1000000 (32 RUNNING, 735 TERMINATED)


== Status ==
Current time: 2023-11-02 09:12:01 (running for 09:41:06.49)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 767/1000000 (32 RUNNING, 735 TERMINATED)


== Status ==
Current time: 2023-11-02 09:12:06 (running for 09:41:12.23)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 771/1000000 (32 RUNNING, 739 TERMINATED)


2023-11-02 09:24:01,486	WARNING util.py:214 -- The `on_step_end` operation took 0.796 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 09:24:59,031 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534568) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:25:59,182 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534600) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:26:59,291 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534633) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:27:59,480 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534650) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 09:30:55,554	WARNING util.py:214 -- The `on_step_end` operation took 0.705 s, which may be a performance bottleneck.
2023-11-02 09:30:56,525	WARNING util.py:214 -- The `start_trial` operation took 0.613 s, which may be a performance bottleneck.
2023-11-02 09:30:58,355	WARNING util.py:214 -- The `start_trial` operation took 0.527 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 09:31:58,924 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534881) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:32:59,135 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534907) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:33:59,386 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534924) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:34:59,529 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534941) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:35:59,752 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534958) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:36:59,966 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534977) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:38:00,208 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(534993) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:39:00,443 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535012) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:40:00,652 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535158) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:41:00,873 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535175) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:42:01,039 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535192) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:43:01,346 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535209) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:44:01,640 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535226) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:45:01,845 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535244) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:46:02,042 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535261) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:47:02,245 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535277) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:48:02,397 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535294) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:49:02,534 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535312) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:50:02,756 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535460) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:51:02,949 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535476) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:52:03,070 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535494) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:53:03,301 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535518) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:54:03,557 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535535) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 09:56:57,537	WARNING util.py:214 -- The `on_step_end` operation took 0.714 s, which may be a performance bottleneck.
2023-11-02 09:57:00,745	WARNING util.py:214 -- The `start_trial` operation took 0.510 s, which may be a performance bottleneck.
2023-11-02 09:57:02,230	WARNING util.py:214 -- The `start_trial` operation took 0.529 s, which may be a performance bottleneck.
2023-11-02 09:57:02,852	WARNING util.py:214 -- The `start_trial` operation took 0.612 s, which may be a performance bottleneck.
2023-11-02 09:57:03,403	WARNING util.py:214 -- The `on_step_end` operation took 0.551 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 09:58:02,483 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535644) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 09:59:02,749 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535675) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:00:03,005 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535820) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:01:03,288 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535837) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:02:03,458 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535854) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:03:03,676 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535871) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:04:03,857 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535889) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:05:04,001 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535908) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:06:04,147 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(535925) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 10:09:05,944	WARNING util.py:214 -- The `on_step_end` operation took 0.703 s, which may be a performance bottleneck.
2023-11-02 10:09:09,853	WARNING util.py:214 -- The `start_trial` operation took 0.518 s, which may be a performance bottleneck.
2023-11-02 10:09:10,620	WARNING util.py:214 -- The `start_trial` operation took 0.566 s, which may be a performance bottleneck.
2023-11-02 10:09:11,396	WARNING util.py:214 -- The `start_trial` operation took 0.567 s, which may be a performance bottleneck.
2023-11-02 10:09:12,078	WARNING util.py:214 -- The `on_step_end` operation took 0.683 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 10:10:13,484 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536175) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:11:13,658 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536200) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 10:14:07,120	WARNING util.py:214 -- The `on_step_end` operation took 0.702 s, which may be a performance bottleneck.
2023-11-02 10:14:12,919	WARNING util.py:214 -- The `on_step_end` operation took 0.629 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 10:15:09,705 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536301) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:15:10,595 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536304) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:15:12,364 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536309) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:16:09,921 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536331) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:16:10,736 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536333) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:16:12,550 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536336) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:17:10,109 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536352) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:17:10,989 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536354) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:17:12,739 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536357) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:18:10,307 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536378) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:18:11,283 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536380) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:18:12,909 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536383) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:19:10,456 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536400) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:19:11,536 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536402) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:19:13,176 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536409) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:20:10,636 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536551) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:20:11,732 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536553) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:20:13,420 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536556) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:21:10,825 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536581) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:21:11,917 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536584) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:21:13,602 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536587) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:22:10,928 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536603) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:22:13,718 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536608) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:23:11,196 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536650) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:23:13,820 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536653) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:24:11,472 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536670) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:24:14,049 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536673) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:25:11,626 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536691) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:25:14,202 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536695) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:26:11,805 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536715) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:27:12,003 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(536741) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 10:30:11,599	WARNING util.py:214 -- The `on_step_end` operation took 0.930 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 09:23:55 (running for 09:53:01.03)
Memory usage on this node: 29.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 771/1000000 (32 RUNNING, 739 TERMINATED)


== Status ==
Current time: 2023-11-02 09:24:01 (running for 09:53:06.82)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 775/1000000 (31 RUNNING, 744 TERMINATED)


== Status ==
Current time: 2023-11-02 09:30:55 (running for 10:00:00.99)
Memory usage on this node: 29.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 776/1000000 (1 PENDING, 30 RUNNING, 745 TERMINATED)


== Status ==
Current time: 2023-11-02 09:31:04 (running for 10:00:09.69)
Memory usage on this node: 29.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 779/1000000 (32 RUNNING, 747 TERMINATED)


== Status ==
Current time: 2023-11-02 09:56:57 (running for 10:26:03.04)
Memory usage on this node: 30.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 779/1000000 (32 RUNNING, 747 TERMINATED)


== Status ==
Current time: 2023-11-02 09:57:03 (running for 10:26:08.74)
Memory usage on this node: 30.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 784/1000000 (32 RUNNING, 752 TERMINATED)


== Status ==
Current time: 2023-11-02 10:09:05 (running for 10:38:11.28)
Memory usage on this node: 30.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 784/1000000 (32 RUNNING, 752 TERMINATED)


== Status ==
Current time: 2023-11-02 10:09:12 (running for 10:38:17.41)
Memory usage on this node: 30.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 788/1000000 (31 RUNNING, 757 TERMINATED)


== Status ==
Current time: 2023-11-02 10:09:18 (running for 10:38:24.20)
Memory usage on this node: 30.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 789/1000000 (32 RUNNING, 757 TERMINATED)


== Status ==
Current time: 2023-11-02 10:14:07 (running for 10:43:12.52)
Memory usage on this node: 30.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 789/1000000 (32 RUNNING, 757 TERMINATED)


== Status ==
Current time: 2023-11-02 10:14:13 (running for 10:43:18.38)
Memory usage on this node: 29.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 794/1000000 (32 RUNNING, 762 TERMINATED)


2023-11-02 10:30:14,739	WARNING util.py:214 -- The `start_trial` operation took 0.508 s, which may be a performance bottleneck.
2023-11-02 10:30:16,959	WARNING util.py:214 -- The `start_trial` operation took 0.622 s, which may be a performance bottleneck.
2023-11-02 10:30:17,615	WARNING util.py:214 -- The `on_step_end` operation took 0.655 s, which may be a performance bottleneck.
2023-11-02 10:30:19,061	WARNING util.py:214 -- The `start_trial` operation took 0.535 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 10:31:18,740 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537024) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:32:18,929 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537047) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:33:19,167 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537064) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:34:19,298 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537081) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:35:19,544 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537101) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:36:19,774 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537118) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:37:19,962 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537136) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:38:20,176 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537155) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:39:20,330 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537173) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:40:20,457 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537318) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:41:20,716 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537337) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:42:20,894 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537355) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:43:21,073 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537374) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:44:21,247 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537391) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:45:21,543 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537410) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:46:21,745 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537430) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 10:49:23,778	WARNING util.py:214 -- The `on_step_end` operation took 0.665 s, which may be a performance bottleneck.
2023-11-02 10:49:27,374	WARNING util.py:214 -- The `start_trial` operation took 0.621 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 10:50:27,023 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537681) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:50:28,918 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537684) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:51:27,218 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537706) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:51:29,105 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537709) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:52:27,350 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537725) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:52:29,271 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537728) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:53:27,510 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537751) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:53:29,496 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537754) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:54:27,651 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537770) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:55:27,866 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537795) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:56:28,042 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537838) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:57:28,230 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537856) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:58:28,355 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537879) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 10:59:28,570 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(537897) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:00:28,842 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538037) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 11:03:19,963	WARNING util.py:214 -- The `on_step_end` operation took 0.781 s, which may be a performance bottleneck.
2023-11-02 11:03:22,818	WARNING util.py:214 -- The `start_trial` operation took 0.561 s, which may be a performance bottleneck.
2023-11-02 11:03:23,635	WARNING util.py:214 -- The `start_trial` operation took 0.506 s, which may be a performance bottleneck.
2023-11-02 11:03:24,671	WARNING util.py:214 -- The `start_trial` operation took 0.537 s, which may be a performance bottleneck.
2023-11-02 11:03:27,386	WARNING util.py:214 -- The `start_trial` operation took 0.882 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 11:04:26,945 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538157) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:04:28,104 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538165) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:05:27,190 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538293) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:05:28,334 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538295) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:06:27,362 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538312) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:06:28,543 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538314) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:07:27,519 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538331) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:07:28,736 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538333) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:08:27,707 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538351) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:08:28,971 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538353) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 11:11:29,370	WARNING util.py:214 -- The `on_step_end` operation took 0.850 s, which may be a performance bottleneck.
2023-11-02 11:11:31,904	WARNING util.py:214 -- The `start_trial` operation took 0.677 s, which may be a performance bottleneck.
2023-11-02 11:11:32,509	WARNING util.py:214 -- The `start_trial` operation took 0.510 s, which may be a performance bottleneck.
2023-11-02 11:11:33,500	WARNING util.py:214 -- The `start_trial` operation took 0.543 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 11:12:32,282 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538594) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:12:33,176 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538596) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:13:32,518 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538616) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:13:33,330 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538618) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:14:32,674 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538638) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:14:33,524 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538640) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:15:32,863 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538780) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:15:33,786 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538782) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:16:33,102 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538800) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:16:34,038 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538802) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:17:33,300 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538819) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:17:34,270 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538821) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:18:33,486 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538842) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:18:34,437 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538844) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:19:33,650 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538862) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:19:34,681 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538864) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:20:33,846 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538886) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:20:34,846 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538888) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:21:34,036 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538906) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:21:35,108 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538908) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:22:34,184 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538925) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:22:35,320 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538927) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:23:34,360 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(538945) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 11:26:26,079	WARNING util.py:214 -- The `on_step_end` operation took 0.952 s, which may be a performance bottleneck.
2023-11-02 11:26:29,368	WARNING util.py:214 -- The `start_trial` operation took 0.544 s, which may be a performance bottleneck.
2023-11-02 11:26:31,699	WARNING util.py:214 -- The `start_trial` operation took 0.614 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 11:27:29,560 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539219) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:27:31,321 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539221) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:28:29,783 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539245) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:28:31,535 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539247) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:29:29,962 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539266) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:29:31,806 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539268) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:30:30,119 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539310) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:30:32,101 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539312) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:31:30,378 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539330) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:31:32,332 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539332) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:32:30,605 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539350) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:32:32,458 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539352) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-02 10:30:11 (running for 10:59:16.93)
Memory usage on this node: 30.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 794/1000000 (32 RUNNING, 762 TERMINATED)


== Status ==
Current time: 2023-11-02 10:30:17 (running for 10:59:22.95)
Memory usage on this node: 30.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 799/1000000 (31 RUNNING, 768 TERMINATED)


== Status ==
Current time: 2023-11-02 10:30:24 (running for 10:59:29.64)
Memory usage on this node: 30.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 800/1000000 (32 RUNNING, 768 TERMINATED)


== Status ==
Current time: 2023-11-02 10:49:23 (running for 11:18:29.19)
Memory usage on this node: 31.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 800/1000000 (32 RUNNING, 768 TERMINATED)


== Status ==
Current time: 2023-11-02 10:49:29 (running for 11:18:34.62)
Memory usage on this node: 31.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 804/1000000 (32 RUNNING, 772 TERMINATED)


== Status ==
Current time: 2023-11-02 11:03:20 (running for 11:32:25.45)
Memory usage on this node: 31.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 804/1000000 (32 RUNNING, 772 TERMINATED)


== Status ==
Current time: 2023-11-02 11:03:25 (running for 11:32:31.15)
Memory usage on this node: 31.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 808/1000000 (31 RUNNING, 777 TERMINATED)


== Status ==
Current time: 2023-11-02 11:03:33 (running for 11:32:38.93)
Memory usage on this node: 31.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 810/1000000 (32 RUNNING, 778 TERMINATED)


== Status ==
Current time: 2023-11-02 11:11:29 (running for 11:40:34.73)
Memory usage on this node: 31.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 810/1000000 (32 RUNNING, 778 TERMINATED)


== Status ==
Current time: 2023-11-02 11:11:38 (running for 11:40:44.18)
Memory usage on this node: 30.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 813/1000000 (32 RUNNING, 781 TERMINATED)


== Status ==
Current time: 2023-11-02 11:26:26 (running for 11:55:31.49)
Memory usage on this node: 31.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 813/1000000 (32 RUNNING, 781 TERMINATED)


2023-11-02 11:35:14,879	WARNING util.py:214 -- The `on_step_end` operation took 0.756 s, which may be a performance bottleneck.
2023-11-02 11:35:17,643	WARNING util.py:214 -- The `start_trial` operation took 0.521 s, which may be a performance bottleneck.
2023-11-02 11:35:20,236	WARNING util.py:214 -- The `start_trial` operation took 0.556 s, which may be a performance bottleneck.
2023-11-02 11:35:20,984	WARNING util.py:214 -- The `on_step_end` operation took 0.747 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 11:36:19,937 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539594) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:37:20,094 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539623) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:38:20,321 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539641) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:39:20,569 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539659) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:40:20,744 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539703) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:41:20,890 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(539720) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 11:43:55,123	WARNING util.py:214 -- The `on_step_end` operation took 0.637 s, which may be a performance bottleneck.
2023-11-02 11:44:00,758	WARNING util.py:214 -- The `on_step_end` operation took 0.543 s, which may be a performance bottleneck.
2023-11-02 11:46:58,912	WARNING util.py:214 -- The `on_step_end` operation took 0.930 s, which may be a performance bottleneck.
2023-11-02 11:47:00,053	WARNING util.py:214 -- The `start_trial` operation took 0.665 s, which may be a performance bottleneck.
2023-11-02 11:47:01,067	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
2023-11-02 11:47:01,688	WARNING util.py:214 -- The `start_trial` operation took 0.524 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 11:47:59,640 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540024) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:48:02,456 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540031) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:48:59,885 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540054) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:49:02,644 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540056) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:50:00,160 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540155) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:50:02,868 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540157) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:51:00,422 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540173) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:51:03,106 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540175) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:52:00,721 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540193) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:52:03,247 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540195) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:53:00,920 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540219) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:53:03,420 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540222) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 11:56:11,211	WARNING util.py:214 -- The `on_step_end` operation took 0.660 s, which may be a performance bottleneck.
2023-11-02 11:56:14,247	WARNING util.py:214 -- The `start_trial` operation took 0.610 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 11:57:13,848 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540404) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:57:15,587 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540407) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:58:13,975 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540427) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:58:15,779 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540430) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:59:14,181 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540447) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 11:59:15,952 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540450) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:00:14,368 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540546) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:00:16,138 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540549) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:01:14,561 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540566) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:01:16,336 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540569) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:02:14,745 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540585) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:02:16,538 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540588) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:03:14,978 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540604) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:03:16,775 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540607) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:04:17,094 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540626) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:05:17,317 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540734) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:06:17,511 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540752) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:07:17,762 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540769) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:08:17,965 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540791) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:09:18,125 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540809) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 12:12:15,536	WARNING util.py:214 -- The `on_step_end` operation took 0.958 s, which may be a performance bottleneck.
2023-11-02 12:12:18,358	WARNING util.py:214 -- The `start_trial` operation took 0.660 s, which may be a performance bottleneck.
2023-11-02 12:12:19,604	WARNING util.py:214 -- The `start_trial` operation took 0.666 s, which may be a performance bottleneck.
2023-11-02 12:12:20,152	WARNING util.py:214 -- The `start_trial` operation took 0.540 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 12:13:19,906 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(540989) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:14:20,371 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541015) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:15:20,537 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541157) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:16:20,770 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541174) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:17:21,033 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541191) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:18:21,394 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541212) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:19:22,085 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541241) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:20:22,244 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541262) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:21:22,480 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541282) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:22:22,673 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541299) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:23:22,835 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541317) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:24:23,083 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541334) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 12:27:18,700	WARNING util.py:214 -- The `on_step_end` operation took 0.955 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 11:26:31 (running for 11:55:37.33)
Memory usage on this node: 30.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 817/1000000 (32 RUNNING, 785 TERMINATED)


== Status ==
Current time: 2023-11-02 11:35:14 (running for 12:04:20.21)
Memory usage on this node: 31.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 817/1000000 (32 RUNNING, 785 TERMINATED)


== Status ==
Current time: 2023-11-02 11:35:21 (running for 12:04:26.37)
Memory usage on this node: 31.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 822/1000000 (32 RUNNING, 790 TERMINATED)


== Status ==
Current time: 2023-11-02 11:43:55 (running for 12:13:00.53)
Memory usage on this node: 31.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 822/1000000 (32 RUNNING, 790 TERMINATED)


== Status ==
Current time: 2023-11-02 11:44:00 (running for 12:13:06.29)
Memory usage on this node: 30.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 827/1000000 (31 RUNNING, 796 TERMINATED)


== Status ==
Current time: 2023-11-02 11:46:58 (running for 12:16:04.25)
Memory usage on this node: 31.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 828/1000000 (1 PENDING, 31 RUNNING, 796 TERMINATED)


== Status ==
Current time: 2023-11-02 11:47:07 (running for 12:16:13.18)
Memory usage on this node: 30.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 831/1000000 (32 RUNNING, 799 TERMINATED)


== Status ==
Current time: 2023-11-02 11:56:11 (running for 12:25:16.57)
Memory usage on this node: 31.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 831/1000000 (32 RUNNING, 799 TERMINATED)


== Status ==
Current time: 2023-11-02 11:56:20 (running for 12:25:26.27)
Memory usage on this node: 30.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 834/1000000 (32 RUNNING, 802 TERMINATED)


== Status ==
Current time: 2023-11-02 12:12:15 (running for 12:41:20.92)
Memory usage on this node: 31.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 834/1000000 (32 RUNNING, 802 TERMINATED)


== Status ==
Current time: 2023-11-02 12:12:25 (running for 12:41:30.91)
Memory usage on this node: 31.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 838/1000000 (32 RUNNING, 806 TERMINATED)


2023-11-02 12:27:22,008	WARNING util.py:214 -- The `start_trial` operation took 0.540 s, which may be a performance bottleneck.
2023-11-02 12:27:23,465	WARNING util.py:214 -- The `start_trial` operation took 0.551 s, which may be a performance bottleneck.
2023-11-02 12:27:24,799	WARNING util.py:214 -- The `on_step_end` operation took 0.729 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 12:28:22,275 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541580) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:28:23,820 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541584) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:29:22,399 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541612) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:29:23,989 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541614) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:30:22,655 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541646) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:30:24,177 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541648) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:31:22,791 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541666) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:31:24,352 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541684) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:32:22,979 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541702) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:32:24,541 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541704) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:33:23,147 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541721) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:33:24,737 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541723) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:34:23,251 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541740) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:34:24,909 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541742) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:35:23,454 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541876) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:36:23,652 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541921) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:37:23,833 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541939) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:38:24,002 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541958) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:39:24,079 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(541980) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:40:24,267 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542071) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:41:24,403 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542089) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:42:24,624 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542106) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:43:24,829 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542123) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:44:25,034 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542140) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:45:25,157 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542213) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 12:48:27,951	WARNING util.py:214 -- The `on_step_end` operation took 0.659 s, which may be a performance bottleneck.
2023-11-02 12:48:30,517	WARNING util.py:214 -- The `start_trial` operation took 0.601 s, which may be a performance bottleneck.
2023-11-02 12:48:31,334	WARNING util.py:214 -- The `start_trial` operation took 0.505 s, which may be a performance bottleneck.
2023-11-02 12:48:33,783	WARNING util.py:214 -- The `on_step_end` operation took 0.711 s, which may be a performance bottleneck.
2023-11-02 12:48:35,573	WARNING util.py:214 -- The `start_trial` operation took 0.760 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 12:49:35,228 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542335) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:50:35,612 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542429) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:51:36,153 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542448) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:52:36,368 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542464) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:53:36,548 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542488) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:54:36,786 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542508) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:55:36,945 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542613) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:56:37,120 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542630) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:57:37,302 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542647) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:58:37,505 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542665) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 12:59:37,689 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542683) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:00:37,880 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542741) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:01:38,051 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542759) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:02:38,231 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542776) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:03:38,467 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542793) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 13:06:41,924	WARNING util.py:214 -- The `on_step_end` operation took 0.762 s, which may be a performance bottleneck.
2023-11-02 13:06:46,038	WARNING util.py:214 -- The `start_trial` operation took 0.568 s, which may be a performance bottleneck.
2023-11-02 13:06:47,175	WARNING util.py:214 -- The `start_trial` operation took 0.554 s, which may be a performance bottleneck.
2023-11-02 13:06:48,060	WARNING util.py:214 -- The `on_step_end` operation took 0.885 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 13:07:45,818 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(542986) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:08:45,975 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543016) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:09:46,214 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543033) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:10:46,427 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543143) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:11:46,630 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543161) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:12:46,803 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543179) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:13:47,001 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543196) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:14:47,188 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543214) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:15:47,442 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543332) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 13:18:48,590	WARNING util.py:214 -- The `on_step_end` operation took 0.865 s, which may be a performance bottleneck.
2023-11-02 13:18:49,715	WARNING util.py:214 -- The `start_trial` operation took 0.595 s, which may be a performance bottleneck.
2023-11-02 13:18:51,937	WARNING util.py:214 -- The `start_trial` operation took 0.547 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 13:19:49,424 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543436) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:19:52,437 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543447) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:20:49,819 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543562) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:21:50,316 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543582) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:22:50,559 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543624) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:23:50,719 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543642) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:24:50,863 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543664) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:25:51,021 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543801) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 13:28:55,698	WARNING util.py:214 -- The `on_step_end` operation took 0.930 s, which may be a performance bottleneck.
2023-11-02 13:28:58,143	WARNING util.py:214 -- The `start_trial` operation took 0.523 s, which may be a performance bottleneck.
2023-11-02 13:28:59,377	WARNING util.py:214 -- The `start_trial` operation took 0.638 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 13:29:59,271 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543920) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:30:59,843 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543943) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:32:00,055 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543960) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:33:00,246 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543977) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:34:00,460 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(543994) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:35:00,760 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544134) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:36:00,973 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544152) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:37:01,166 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544169) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:38:01,289 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544188) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:39:01,450 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544206) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:40:01,979 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544237) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:41:02,270 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544253) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:42:02,454 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544270) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 13:45:10,345	WARNING util.py:214 -- The `on_step_end` operation took 0.797 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 12:27:18 (running for 12:56:24.06)
Memory usage on this node: 31.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 838/1000000 (32 RUNNING, 806 TERMINATED)


== Status ==
Current time: 2023-11-02 12:27:24 (running for 12:56:30.30)
Memory usage on this node: 31.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 843/1000000 (32 RUNNING, 811 TERMINATED)


== Status ==
Current time: 2023-11-02 12:48:28 (running for 13:17:33.46)
Memory usage on this node: 31.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 843/1000000 (32 RUNNING, 811 TERMINATED)


== Status ==
Current time: 2023-11-02 12:48:34 (running for 13:17:39.40)
Memory usage on this node: 31.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 847/1000000 (31 RUNNING, 816 TERMINATED)


== Status ==
Current time: 2023-11-02 12:48:40 (running for 13:17:46.22)
Memory usage on this node: 31.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 848/1000000 (32 RUNNING, 816 TERMINATED)


== Status ==
Current time: 2023-11-02 13:06:42 (running for 13:35:47.36)
Memory usage on this node: 31.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 848/1000000 (32 RUNNING, 816 TERMINATED)


== Status ==
Current time: 2023-11-02 13:06:48 (running for 13:35:53.46)
Memory usage on this node: 30.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 852/1000000 (31 RUNNING, 821 TERMINATED)


== Status ==
Current time: 2023-11-02 13:18:48 (running for 13:47:53.94)
Memory usage on this node: 31.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 853/1000000 (1 PENDING, 31 RUNNING, 821 TERMINATED)


== Status ==
Current time: 2023-11-02 13:18:58 (running for 13:48:03.35)
Memory usage on this node: 31.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 856/1000000 (32 RUNNING, 824 TERMINATED)


== Status ==
Current time: 2023-11-02 13:28:55 (running for 13:58:01.03)
Memory usage on this node: 31.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 856/1000000 (32 RUNNING, 824 TERMINATED)


== Status ==
Current time: 2023-11-02 13:29:04 (running for 13:58:10.02)
Memory usage on this node: 31.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 859/1000000 (32 RUNNING, 827 TERMINATED)


2023-11-02 13:45:12,852	WARNING util.py:214 -- The `start_trial` operation took 0.620 s, which may be a performance bottleneck.
2023-11-02 13:45:15,280	WARNING util.py:214 -- The `start_trial` operation took 0.571 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 13:46:15,031 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544493) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:47:15,309 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544519) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:48:15,678 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544537) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:49:15,883 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544555) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:50:16,140 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544618) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:51:16,354 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544637) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:52:16,533 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544654) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:53:16,702 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544678) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:54:16,898 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544695) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:55:17,064 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544797) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:56:17,197 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544814) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:57:17,448 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544832) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:58:17,607 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544850) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 13:59:17,833 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(544868) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 14:02:19,241	WARNING util.py:214 -- The `on_step_end` operation took 0.690 s, which may be a performance bottleneck.
2023-11-02 14:02:22,340	WARNING util.py:214 -- The `start_trial` operation took 0.519 s, which may be a performance bottleneck.
2023-11-02 14:02:24,310	WARNING util.py:214 -- The `start_trial` operation took 0.604 s, which may be a performance bottleneck.
2023-11-02 14:02:25,040	WARNING util.py:214 -- The `on_step_end` operation took 0.730 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 14:03:22,094 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545061) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:03:24,106 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545066) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:04:22,261 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545090) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:04:24,326 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545092) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:05:22,441 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545233) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:05:24,543 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545235) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:06:22,674 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545252) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:06:24,762 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545254) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:07:22,848 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545271) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:07:24,933 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545273) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:08:23,055 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545291) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:08:25,108 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545293) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:09:23,252 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545311) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:09:25,238 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545313) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:10:23,499 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545335) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:10:25,475 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545337) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:11:23,681 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545354) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:11:25,715 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545356) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:12:23,863 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545373) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:12:25,869 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545375) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:13:24,020 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545392) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:13:26,063 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545394) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:14:24,235 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545413) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 14:17:26,012	WARNING util.py:214 -- The `on_step_end` operation took 0.895 s, which may be a performance bottleneck.
2023-11-02 14:17:28,644	WARNING util.py:214 -- The `start_trial` operation took 0.593 s, which may be a performance bottleneck.
2023-11-02 14:17:29,574	WARNING util.py:214 -- The `start_trial` operation took 0.805 s, which may be a performance bottleneck.
2023-11-02 14:17:30,479	WARNING util.py:214 -- The `start_trial` operation took 0.605 s, which may be a performance bottleneck.
2023-11-02 14:17:31,924	WARNING util.py:214 -- The `on_step_end` operation took 0.687 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 14:18:29,142 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545674) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:18:31,058 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545678) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:19:29,364 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545703) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:19:31,257 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545705) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:20:29,611 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545727) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:20:31,369 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545729) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:21:29,795 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545746) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:21:31,572 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545748) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:22:30,000 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545765) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:22:31,771 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545767) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:23:30,148 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545786) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:23:31,990 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545788) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:24:30,303 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545805) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:24:32,220 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545808) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:25:30,510 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545953) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:25:32,426 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545955) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:26:30,702 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545972) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:26:32,497 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545974) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:27:30,897 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545991) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:27:32,722 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(545993) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:28:31,042 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546013) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:28:32,943 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546015) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:29:31,158 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546061) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:29:33,160 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546063) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:30:31,352 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546080) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:30:33,436 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546082) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:31:31,627 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546109) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:31:33,635 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546111) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:32:31,800 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546129) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:32:33,868 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546131) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:33:34,056 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546150) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:34:34,181 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546196) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 14:37:48,393	WARNING util.py:214 -- The `on_step_end` operation took 0.827 s, which may be a performance bottleneck.
2023-11-02 14:37:51,072	WARNING util.py:214 -- The `start_trial` operation took 0.614 s, which may be a performance bottleneck.
2023-11-02 14:37:51,821	WARNING util.py:214 -- The `start_trial` operation took 0.584 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 14:38:51,481 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546438) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:38:53,358 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546441) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:39:51,752 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546460) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:39:53,600 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546463) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:40:51,932 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546481) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:40:53,808 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546483) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:41:52,132 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546501) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:41:54,013 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546503) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:42:52,368 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546520) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:42:54,234 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546522) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:43:52,604 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546539) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:43:54,489 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546541) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:44:52,782 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546559) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:44:54,648 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546689) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:45:53,237 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546706) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:45:55,140 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546708) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:46:53,443 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546726) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:46:55,288 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546728) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:47:53,698 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546746) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:47:55,429 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546748) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:48:53,839 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546766) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:48:55,641 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546768) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:49:54,086 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546785) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:49:55,807 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546787) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:50:54,249 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546804) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 14:53:38,704	WARNING util.py:214 -- The `on_step_end` operation took 0.879 s, which may be a performance bottleneck.
2023-11-02 14:53:41,082	WARNING util.py:214 -- The `start_trial` operation took 0.532 s, which may be a performance bottleneck.
2023-11-02 14:53:42,274	WARNING util.py:214 -- The `start_trial` operation took 0.606 s, which may be a performance bottleneck.
2023-11-02 14:53:43,544	WARNING util.py:214 -- The `start_trial` operation took 0.530 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 14:54:41,933 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546942) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:54:44,623 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(546954) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:55:42,087 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547099) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:55:44,880 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547102) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:56:42,335 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547118) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:56:45,041 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547121) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:57:42,544 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547137) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:57:45,241 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547140) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:58:42,762 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547157) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:58:45,472 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547161) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:59:42,997 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547177) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 14:59:45,767 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547180) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:00:43,216 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547198) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:00:46,185 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547202) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:01:43,478 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547218) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:01:46,453 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547221) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:02:43,708 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547237) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:02:46,646 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547240) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:03:43,951 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547256) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:04:44,125 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547279) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:05:44,209 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547446) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 15:08:59,088	WARNING util.py:214 -- The `on_step_end` operation took 0.802 s, which may be a performance bottleneck.
2023-11-02 15:09:01,602	WARNING util.py:214 -- The `start_trial` operation took 0.608 s, which may be a performance bottleneck.
2023-11-02 15:09:03,893	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
2023-11-02 15:09:04,635	WARNING util.py:214 -- The `start_trial` operation took 0.712 s, which may be a performance bottleneck.
2023-11-02 15:09:05,507	WARNING util.py:214 -- The `on_step_end` operation took 0.872 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 15:10:01,931 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547563) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:10:04,348 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547568) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:11:02,429 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547592) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:11:04,793 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547593) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:12:02,610 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547610) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:12:04,982 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547612) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:13:02,877 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547629) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:13:05,093 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547631) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:14:02,953 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547648) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:14:05,319 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547650) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:15:03,143 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547795) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:15:05,505 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547797) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:16:03,373 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547814) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:16:05,717 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547816) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:17:03,557 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547833) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:18:03,764 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(547856) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-02 13:45:10 (running for 14:14:15.92)
Memory usage on this node: 31.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 859/1000000 (32 RUNNING, 827 TERMINATED)


== Status ==
Current time: 2023-11-02 13:45:20 (running for 14:14:25.88)
Memory usage on this node: 31.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 863/1000000 (32 RUNNING, 831 TERMINATED)


== Status ==
Current time: 2023-11-02 14:02:19 (running for 14:31:24.57)
Memory usage on this node: 31.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 863/1000000 (32 RUNNING, 831 TERMINATED)


== Status ==
Current time: 2023-11-02 14:02:25 (running for 14:31:30.37)
Memory usage on this node: 31.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 867/1000000 (32 RUNNING, 835 TERMINATED)


== Status ==
Current time: 2023-11-02 14:17:26 (running for 14:46:31.43)
Memory usage on this node: 31.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 867/1000000 (32 RUNNING, 835 TERMINATED)


== Status ==
Current time: 2023-11-02 14:17:32 (running for 14:46:37.40)
Memory usage on this node: 30.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 871/1000000 (32 RUNNING, 839 TERMINATED)


== Status ==
Current time: 2023-11-02 14:37:48 (running for 15:06:53.73)
Memory usage on this node: 31.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 871/1000000 (32 RUNNING, 839 TERMINATED)


== Status ==
Current time: 2023-11-02 14:37:53 (running for 15:06:59.20)
Memory usage on this node: 30.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 874/1000000 (32 RUNNING, 842 TERMINATED)


== Status ==
Current time: 2023-11-02 14:53:38 (running for 15:22:44.04)
Memory usage on this node: 30.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 94455086 with val_loss=477.9282455033352 and parameters={'n_estimators': 2185, 'num_leaves': 33, 'min_child_samples': 57, 'learning_rate': 0.01072947175067505, 'log_max_bin': 10, 'colsample_bytree': 0.38629867301258336, 'reg_alpha': 0.0009765625, 'reg_lambda': 30.049330013089065, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 874/1000000 (32 RUNNING, 842 TERMINATED)


== Status ==
Current time: 2023-11-02 14:53:44 (running for 15:22:50.22)
Memory usage on this node: 30.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 879/1000000 (32 RUNNING, 847 TERMINATED)


== Status ==
Current time: 2023-11-02 15:08:59 (running for 15:38:04.42)
Memory usage on this node: 30.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 879/1000000 (32 RUNNING, 847 TERMINATED)


2023-11-02 15:21:04,601	WARNING util.py:214 -- The `on_step_end` operation took 0.887 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 15:22:09,173 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548043) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:23:09,327 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548073) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:24:09,554 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548090) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:25:09,820 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548194) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:26:10,026 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548211) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:27:10,268 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548228) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:28:10,405 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548246) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:29:10,678 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548264) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:30:12,108 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548335) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:31:12,999 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548353) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:32:13,188 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548369) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:33:13,383 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548399) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:34:13,533 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548445) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:35:13,695 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548539) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:36:13,878 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548556) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:37:14,111 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548573) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:38:14,599 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548593) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:39:14,739 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548610) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:40:15,123 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548747) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:41:15,391 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548767) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:42:15,536 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548783) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:43:15,750 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548800) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:44:15,988 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548817) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:45:16,222 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548871) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:46:16,455 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(548888) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 15:49:11,771	WARNING util.py:214 -- The `on_step_end` operation took 0.885 s, which may be a performance bottleneck.
2023-11-02 15:49:14,514	WARNING util.py:214 -- The `start_trial` operation took 0.525 s, which may be a performance bottleneck.
2023-11-02 15:49:15,194	WARNING util.py:214 -- The `start_trial` operation took 0.548 s, which may be a performance bottleneck.
2023-11-02 15:49:16,141	WARNING util.py:214 -- The `start_trial` operation took 0.609 s, which may be a performance bottleneck.
2023-11-02 15:49:16,692	WARNING util.py:214 -- The `start_trial` operation took 0.544 s, which may be a performance bottleneck.
2023-11-02 15:49:17,948	WARNING util.py:214 -- The `on_step_end` operation took 1.130 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 15:50:16,367 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549094) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:51:16,501 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549121) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:52:16,695 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549137) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:53:16,942 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549161) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:54:17,111 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549178) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:55:17,385 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549227) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:56:17,577 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549244) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:57:17,756 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549261) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:58:18,105 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549279) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 15:59:18,296 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549297) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:00:18,497 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549411) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:01:18,632 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549428) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:02:18,844 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549444) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:03:19,040 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549461) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:04:19,211 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549478) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:05:19,352 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549528) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:06:19,538 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549545) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:07:19,731 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549562) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:08:19,909 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549580) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:09:20,107 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549598) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 16:12:33,441	WARNING util.py:214 -- The `on_step_end` operation took 0.750 s, which may be a performance bottleneck.
2023-11-02 16:12:34,540	WARNING util.py:214 -- The `start_trial` operation took 0.635 s, which may be a performance bottleneck.
2023-11-02 16:12:36,984	WARNING util.py:214 -- The `start_trial` operation took 0.671 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 16:13:34,284 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549810) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:13:37,404 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549818) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:14:34,798 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549845) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:14:37,867 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549847) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:15:34,966 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549894) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:15:38,081 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549897) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:16:35,124 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549913) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:16:38,274 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549916) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:17:35,312 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549932) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:17:38,492 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549935) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:18:35,473 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549955) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:18:38,599 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549958) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:19:35,680 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549975) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:19:38,750 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(549978) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:20:35,834 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550093) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:20:38,990 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550096) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:21:36,010 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550113) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 16:24:37,646	WARNING util.py:214 -- The `on_step_end` operation took 0.941 s, which may be a performance bottleneck.
2023-11-02 16:24:43,664	WARNING util.py:214 -- The `start_trial` operation took 0.812 s, which may be a performance bottleneck.
2023-11-02 16:24:44,534	WARNING util.py:214 -- The `on_step_end` operation took 0.870 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 16:25:43,269 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550338) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:26:43,559 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550359) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:27:43,729 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550376) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:28:43,871 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550395) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:29:44,024 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550412) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:30:44,295 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550525) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:31:44,486 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550544) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:32:44,699 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550561) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:33:44,984 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550578) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:34:45,138 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550596) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:35:45,337 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550674) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:36:45,527 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550692) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:37:45,686 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550709) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:38:45,906 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550728) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:39:46,117 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550762) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:40:46,266 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550847) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:41:46,361 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550865) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:42:46,562 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550888) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:43:46,713 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550905) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:44:46,951 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(550923) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:45:47,159 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551037) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:46:47,305 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551059) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 16:49:33,917	WARNING util.py:214 -- The `on_step_end` operation took 0.802 s, which may be a performance bottleneck.
2023-11-02 16:49:38,323	WARNING util.py:214 -- The `start_trial` operation took 0.667 s, which may be a performance bottleneck.
2023-11-02 16:49:39,839	WARNING util.py:214 -- The `on_step_end` operation took 0.847 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 16:50:37,886 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551287) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:51:37,978 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551312) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:52:38,140 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551329) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:53:38,323 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551353) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:54:38,586 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551371) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 16:55:38,818 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551394) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 16:58:36,020	WARNING util.py:214 -- The `on_step_end` operation took 0.834 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 15:09:05 (running for 15:38:10.84)
Memory usage on this node: 30.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 883/1000000 (32 RUNNING, 851 TERMINATED)


== Status ==
Current time: 2023-11-02 15:21:04 (running for 15:50:09.94)
Memory usage on this node: 31.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 883/1000000 (32 RUNNING, 851 TERMINATED)


== Status ==
Current time: 2023-11-02 15:21:14 (running for 15:50:20.03)
Memory usage on this node: 31.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 888/1000000 (32 RUNNING, 856 TERMINATED)


== Status ==
Current time: 2023-11-02 15:49:11 (running for 16:18:17.11)
Memory usage on this node: 31.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 888/1000000 (32 RUNNING, 856 TERMINATED)


== Status ==
Current time: 2023-11-02 15:49:17 (running for 16:18:23.28)
Memory usage on this node: 30.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 892/1000000 (31 RUNNING, 861 TERMINATED)


== Status ==
Current time: 2023-11-02 16:12:33 (running for 16:41:38.78)
Memory usage on this node: 30.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 893/1000000 (1 PENDING, 31 RUNNING, 861 TERMINATED)


== Status ==
Current time: 2023-11-02 16:12:42 (running for 16:41:48.14)
Memory usage on this node: 30.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 896/1000000 (32 RUNNING, 864 TERMINATED)


== Status ==
Current time: 2023-11-02 16:24:37 (running for 16:53:43.17)
Memory usage on this node: 31.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 896/1000000 (32 RUNNING, 864 TERMINATED)


== Status ==
Current time: 2023-11-02 16:24:44 (running for 16:53:49.94)
Memory usage on this node: 31.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 898/1000000 (32 RUNNING, 866 TERMINATED)


== Status ==
Current time: 2023-11-02 16:49:34 (running for 17:18:39.49)
Memory usage on this node: 31.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 898/1000000 (32 RUNNING, 866 TERMINATED)


== Status ==
Current time: 2023-11-02 16:49:40 (running for 17:18:45.36)
Memory usage on this node: 30.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 902/1000000 (1 PENDING, 31 RUNNING, 870 TERMINATED)


2023-11-02 17:01:20,981	WARNING util.py:214 -- The `on_step_end` operation took 0.756 s, which may be a performance bottleneck.
2023-11-02 17:01:25,391	WARNING util.py:214 -- The `start_trial` operation took 0.548 s, which may be a performance bottleneck.
2023-11-02 17:01:27,098	WARNING util.py:214 -- The `start_trial` operation took 0.587 s, which may be a performance bottleneck.
2023-11-02 17:01:27,892	WARNING util.py:214 -- The `on_step_end` operation took 0.794 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 17:02:24,106 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551694) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:02:26,719 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551702) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:03:24,320 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551722) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:03:26,872 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551734) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:04:24,491 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551750) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:04:27,040 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551753) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:05:24,640 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551781) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:05:27,229 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551784) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:06:24,819 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551800) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:07:25,004 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551819) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:08:25,172 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551866) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:09:25,362 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(551884) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:10:25,544 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552033) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:11:25,645 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552050) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 17:14:36,151	WARNING util.py:214 -- The `on_step_end` operation took 0.804 s, which may be a performance bottleneck.
2023-11-02 17:14:39,057	WARNING util.py:214 -- The `start_trial` operation took 0.551 s, which may be a performance bottleneck.
2023-11-02 17:14:39,679	WARNING util.py:214 -- The `start_trial` operation took 0.554 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 17:15:40,275 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552198) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:16:40,640 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552221) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:17:40,814 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552238) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:18:41,029 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552259) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:19:41,260 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552277) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:20:41,480 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552379) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:21:41,692 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552398) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:22:41,938 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552415) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 17:25:44,025	WARNING util.py:214 -- The `on_step_end` operation took 0.739 s, which may be a performance bottleneck.
2023-11-02 17:25:46,275	WARNING util.py:214 -- The `start_trial` operation took 0.543 s, which may be a performance bottleneck.
2023-11-02 17:25:48,848	WARNING util.py:214 -- The `start_trial` operation took 0.549 s, which may be a performance bottleneck.
2023-11-02 17:25:49,620	WARNING util.py:214 -- The `on_step_end` operation took 0.771 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 17:26:46,821 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552563) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:27:46,967 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552590) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:28:47,112 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552609) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:29:47,284 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552626) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:30:47,467 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552746) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:31:47,576 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552763) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 17:34:46,731	WARNING util.py:214 -- The `start_trial` operation took 0.567 s, which may be a performance bottleneck.
2023-11-02 17:34:54,708	WARNING util.py:214 -- The `on_step_end` operation took 1.018 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 17:35:46,370 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552972) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:36:46,544 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(552993) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 17:39:56,622	WARNING util.py:214 -- The `on_step_end` operation took 0.878 s, which may be a performance bottleneck.
2023-11-02 17:39:59,082	WARNING util.py:214 -- The `start_trial` operation took 0.614 s, which may be a performance bottleneck.
2023-11-02 17:40:02,600	WARNING util.py:214 -- The `on_step_end` operation took 0.896 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 17:40:59,951 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553172) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:42:00,133 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553194) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:43:00,326 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553211) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:44:00,515 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553228) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:45:00,760 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553304) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:46:00,879 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553321) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 17:49:05,825	WARNING util.py:214 -- The `on_step_end` operation took 0.994 s, which may be a performance bottleneck.
2023-11-02 17:49:07,787	WARNING util.py:214 -- The `start_trial` operation took 0.586 s, which may be a performance bottleneck.
2023-11-02 17:49:08,306	WARNING util.py:214 -- The `start_trial` operation took 0.511 s, which may be a performance bottleneck.
2023-11-02 17:49:11,095	WARNING util.py:214 -- The `start_trial` operation took 0.570 s, which may be a performance bottleneck.
2023-11-02 17:49:11,905	WARNING util.py:214 -- The `on_step_end` operation took 0.809 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 17:50:08,032 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553497) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:50:10,885 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553500) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:51:08,185 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553519) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:51:11,093 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553522) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:52:08,320 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553539) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:53:08,472 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553565) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:54:08,581 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553608) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:55:08,691 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553686) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:56:08,883 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553707) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:57:09,045 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553724) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:58:09,208 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553742) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 17:59:09,384 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553760) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:00:09,543 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553904) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:01:09,717 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553921) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:02:09,958 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553939) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:03:10,145 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(553956) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-02 16:58:36 (running for 17:27:41.35)
Memory usage on this node: 31.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 902/1000000 (32 RUNNING, 870 TERMINATED)


== Status ==
Current time: 2023-11-02 17:01:21 (running for 17:30:26.44)
Memory usage on this node: 31.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 902/1000000 (32 RUNNING, 870 TERMINATED)


== Status ==
Current time: 2023-11-02 17:01:27 (running for 17:30:33.26)
Memory usage on this node: 30.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 906/1000000 (32 RUNNING, 874 TERMINATED)


== Status ==
Current time: 2023-11-02 17:14:36 (running for 17:43:41.74)
Memory usage on this node: 31.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 906/1000000 (32 RUNNING, 874 TERMINATED)


== Status ==
Current time: 2023-11-02 17:14:45 (running for 17:43:51.08)
Memory usage on this node: 31.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 909/1000000 (32 RUNNING, 877 TERMINATED)


== Status ==
Current time: 2023-11-02 17:25:44 (running for 17:54:49.37)
Memory usage on this node: 31.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 909/1000000 (32 RUNNING, 877 TERMINATED)


== Status ==
Current time: 2023-11-02 17:25:49 (running for 17:54:54.95)
Memory usage on this node: 30.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 912/1000000 (31 RUNNING, 881 TERMINATED)


== Status ==
Current time: 2023-11-02 17:34:54 (running for 18:04:00.04)
Memory usage on this node: 30.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 913/1000000 (32 RUNNING, 881 TERMINATED)


== Status ==
Current time: 2023-11-02 17:39:56 (running for 18:09:02.05)
Memory usage on this node: 30.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 913/1000000 (31 RUNNING, 882 TERMINATED)


== Status ==
Current time: 2023-11-02 17:40:02 (running for 18:09:08.02)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 916/1000000 (1 PENDING, 30 RUNNING, 885 TERMINATED)


== Status ==
Current time: 2023-11-02 17:49:05 (running for 18:18:11.16)
Memory usage on this node: 30.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 916/1000000 (31 RUNNING, 885 TERMINATED)


2023-11-02 18:06:10,702	WARNING util.py:214 -- The `on_step_end` operation took 0.989 s, which may be a performance bottleneck.
2023-11-02 18:06:16,715	WARNING util.py:214 -- The `on_step_end` operation took 0.895 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 18:07:13,575 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554160) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:08:13,778 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554188) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:09:13,949 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554206) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:10:14,119 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554249) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:11:14,294 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554267) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:12:14,523 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554283) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:13:14,701 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554300) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:14:14,861 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554317) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 18:17:28,834	WARNING util.py:214 -- The `on_step_end` operation took 0.939 s, which may be a performance bottleneck.
2023-11-02 18:17:30,018	WARNING util.py:214 -- The `start_trial` operation took 0.505 s, which may be a performance bottleneck.
2023-11-02 18:17:31,450	WARNING util.py:214 -- The `start_trial` operation took 0.511 s, which may be a performance bottleneck.
2023-11-02 18:17:33,367	WARNING util.py:214 -- The `start_trial` operation took 0.632 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 18:18:33,101 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554531) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:18:34,643 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554540) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:19:33,299 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554557) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:19:34,890 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554560) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:20:33,588 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554603) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:20:35,108 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554606) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:21:33,813 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554622) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:21:35,275 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554623) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:22:34,006 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554640) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:22:35,503 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554643) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 18:25:36,765	WARNING util.py:214 -- The `on_step_end` operation took 0.965 s, which may be a performance bottleneck.
2023-11-02 18:25:39,656	WARNING util.py:214 -- The `start_trial` operation took 0.552 s, which may be a performance bottleneck.
2023-11-02 18:25:43,132	WARNING util.py:214 -- The `start_trial` operation took 0.647 s, which may be a performance bottleneck.
2023-11-02 18:25:43,872	WARNING util.py:214 -- The `on_step_end` operation took 0.740 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 18:26:42,742 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554889) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:27:43,046 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554913) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:28:43,254 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554933) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:29:43,425 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(554951) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:30:43,611 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555020) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:31:43,838 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555038) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:32:43,893 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555055) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:33:44,123 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555072) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 18:36:50,694	WARNING util.py:214 -- The `on_step_end` operation took 0.956 s, which may be a performance bottleneck.
2023-11-02 18:36:55,096	WARNING util.py:214 -- The `start_trial` operation took 0.632 s, which may be a performance bottleneck.
2023-11-02 18:36:56,859	WARNING util.py:214 -- The `on_step_end` operation took 0.783 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 18:37:54,804 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555256) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 18:41:09,661	WARNING util.py:214 -- The `on_step_end` operation took 1.013 s, which may be a performance bottleneck.
2023-11-02 18:41:10,802	WARNING util.py:214 -- The `start_trial` operation took 0.622 s, which may be a performance bottleneck.
2023-11-02 18:41:12,362	WARNING util.py:214 -- The `start_trial` operation took 0.605 s, which may be a performance bottleneck.
2023-11-02 18:41:13,558	WARNING util.py:214 -- The `start_trial` operation took 0.559 s, which may be a performance bottleneck.
2023-11-02 18:41:14,222	WARNING util.py:214 -- The `start_trial` operation took 0.656 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 18:42:10,407 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555417) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:42:12,058 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555421) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:42:13,865 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555426) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:43:10,644 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555445) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:43:12,319 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555447) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:43:14,146 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555450) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:44:10,800 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555466) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:44:12,507 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555468) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:44:14,406 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555471) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:45:10,984 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555564) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:45:12,672 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555566) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:46:11,194 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555594) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:46:13,204 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555612) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:47:11,480 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555630) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:47:13,661 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555633) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:48:11,609 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555650) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:49:11,783 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555677) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 18:52:27,862	WARNING util.py:214 -- The `on_step_end` operation took 0.697 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-02 17:49:11 (running for 18:18:17.24)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 919/1000000 (32 RUNNING, 887 TERMINATED)


== Status ==
Current time: 2023-11-02 18:06:10 (running for 18:35:16.04)
Memory usage on this node: 30.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 919/1000000 (32 RUNNING, 887 TERMINATED)


== Status ==
Current time: 2023-11-02 18:06:16 (running for 18:35:22.15)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 922/1000000 (31 RUNNING, 891 TERMINATED)


== Status ==
Current time: 2023-11-02 18:17:28 (running for 18:46:34.17)
Memory usage on this node: 30.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 923/1000000 (1 PENDING, 31 RUNNING, 891 TERMINATED)


== Status ==
Current time: 2023-11-02 18:17:35 (running for 18:46:40.53)
Memory usage on this node: 30.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 926/1000000 (32 RUNNING, 894 TERMINATED)


== Status ==
Current time: 2023-11-02 18:25:36 (running for 18:54:42.10)
Memory usage on this node: 30.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 926/1000000 (32 RUNNING, 894 TERMINATED)


== Status ==
Current time: 2023-11-02 18:25:43 (running for 18:54:49.32)
Memory usage on this node: 30.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 930/1000000 (32 RUNNING, 898 TERMINATED)


== Status ==
Current time: 2023-11-02 18:36:50 (running for 19:05:56.03)
Memory usage on this node: 30.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 930/1000000 (32 RUNNING, 898 TERMINATED)


== Status ==
Current time: 2023-11-02 18:36:56 (running for 19:06:02.29)
Memory usage on this node: 30.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 933/1000000 (31 RUNNING, 902 TERMINATED)


== Status ==
Current time: 2023-11-02 18:41:09 (running for 19:10:14.99)
Memory usage on this node: 30.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 934/1000000 (1 PENDING, 31 RUNNING, 902 TERMINATED)


== Status ==
Current time: 2023-11-02 18:41:19 (running for 19:10:24.85)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 937/1000000 (32 RUNNING, 905 TERMINATED)


2023-11-02 18:52:30,811	WARNING util.py:214 -- The `start_trial` operation took 0.547 s, which may be a performance bottleneck.
2023-11-02 18:52:31,362	WARNING util.py:214 -- The `start_trial` operation took 0.537 s, which may be a performance bottleneck.
2023-11-02 18:52:34,537	WARNING util.py:214 -- The `on_step_end` operation took 1.356 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 18:53:31,226 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555869) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:54:31,404 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555889) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 18:55:31,613 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(555984) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 18:58:40,209	WARNING util.py:214 -- The `on_step_end` operation took 1.059 s, which may be a performance bottleneck.
2023-11-02 18:58:42,895	WARNING util.py:214 -- The `start_trial` operation took 0.516 s, which may be a performance bottleneck.
2023-11-02 18:58:43,948	WARNING util.py:214 -- The `start_trial` operation took 0.621 s, which may be a performance bottleneck.
2023-11-02 18:58:45,890	WARNING util.py:214 -- The `start_trial` operation took 0.697 s, which may be a performance bottleneck.
2023-11-02 18:58:46,819	WARNING util.py:214 -- The `on_step_end` operation took 0.930 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 18:59:45,525 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(556094) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:00:45,730 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(556169) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:01:45,903 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(556188) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:02:46,133 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(556204) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:03:46,322 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(556221) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:04:46,632 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(556240) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:05:46,898 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(556334) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:06:47,073 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(556351) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:07:47,291 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(556368) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:08:47,414 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(556387) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 19:11:49,983	WARNING util.py:214 -- The `on_step_end` operation took 0.919 s, which may be a performance bottleneck.
2023-11-02 19:11:53,732	WARNING util.py:214 -- The `start_trial` operation took 0.529 s, which may be a performance bottleneck.
2023-11-02 19:11:54,399	WARNING util.py:214 -- The `start_trial` operation took 0.651 s, which may be a performance bottleneck.
2023-11-02 19:11:56,248	WARNING util.py:214 -- The `on_step_end` operation took 1.178 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 19:12:54,053 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(556544) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:13:54,243 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(556566) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:14:54,403 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(556584) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:15:54,639 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(556678) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:16:54,838 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(556695) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 19:20:05,805	WARNING util.py:214 -- The `on_step_end` operation took 1.039 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 19:20:58,310 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(556909) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 19:24:02,428	WARNING util.py:214 -- The `on_step_end` operation took 1.074 s, which may be a performance bottleneck.
2023-11-02 19:24:04,936	WARNING util.py:214 -- The `start_trial` operation took 0.544 s, which may be a performance bottleneck.
2023-11-02 19:24:05,679	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
2023-11-02 19:24:06,556	WARNING util.py:214 -- The `start_trial` operation took 0.518 s, which may be a performance bottleneck.
2023-11-02 19:24:09,794	WARNING util.py:214 -- The `on_step_end` operation took 0.711 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-02 19:25:08,890 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(557135) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:26:09,124 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(557158) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:27:09,317 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(557175) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:28:09,482 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(557194) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:29:09,704 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(557212) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:30:09,923 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(557349) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-02 19:31:10,126 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(557366) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-02 19:34:06,308	INFO stopper.py:363 -- Reached timeout of 71999.77801203728 seconds. Stopping all trials.
2023-11-02 19:35:59,166	WARNING util.py:214 -- The `on_step_end` operation took 0.642 s, which may be a performance bottleneck.
2023-11-02 22:30:20,683	INFO tune.py:747 -- Total run time: 82815.37 seconds (72304.86 seconds for the tuning loop).
== Status ==
Current time: 2023-11-02 18:52:28 (running for 19:21:33.51)
Memory usage on this node: 29.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 937/1000000 (32 RUNNING, 905 TERMINATED)


== Status ==
Current time: 2023-11-02 18:52:34 (running for 19:21:39.87)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 940/1000000 (1 PENDING, 30 RUNNING, 909 TERMINATED)


== Status ==
Current time: 2023-11-02 18:58:40 (running for 19:27:45.78)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 940/1000000 (31 RUNNING, 909 TERMINATED)


== Status ==
Current time: 2023-11-02 18:58:46 (running for 19:27:52.24)
Memory usage on this node: 29.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 943/1000000 (32 RUNNING, 911 TERMINATED)


== Status ==
Current time: 2023-11-02 19:11:49 (running for 19:40:55.32)
Memory usage on this node: 29.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 943/1000000 (32 RUNNING, 911 TERMINATED)


== Status ==
Current time: 2023-11-02 19:11:56 (running for 19:41:01.58)
Memory usage on this node: 29.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 946/1000000 (1 PENDING, 31 RUNNING, 914 TERMINATED)


== Status ==
Current time: 2023-11-02 19:20:05 (running for 19:49:11.14)
Memory usage on this node: 29.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 946/1000000 (32 RUNNING, 914 TERMINATED)


== Status ==
Current time: 2023-11-02 19:24:02 (running for 19:53:07.76)
Memory usage on this node: 29.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 946/1000000 (32 RUNNING, 914 TERMINATED)


== Status ==
Current time: 2023-11-02 19:24:09 (running for 19:53:15.15)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 951/1000000 (32 RUNNING, 919 TERMINATED)


== Status ==
Current time: 2023-11-02 19:35:59 (running for 20:05:04.50)
Memory usage on this node: 27.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 951/1000000 (951 TERMINATED)


== Status ==
Current time: 2023-11-02 19:36:05 (running for 20:05:11.14)
Memory usage on this node: 27.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 11e2de2e with val_loss=477.8260232538352 and parameters={'n_estimators': 13629, 'num_leaves': 16, 'min_child_samples': 105, 'learning_rate': 0.003094770605797757, 'log_max_bin': 9, 'colsample_bytree': 0.3393982044447686, 'reg_alpha': 0.0010802291567173113, 'reg_lambda': 0.24708517275092362, 'learner': 'lgbm'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-01_23-30-05
Number of trials: 951/1000000 (951 TERMINATED)


[flaml.automl.logger: 11-02 22:30:22] {2493} INFO - selected model: None
[flaml.automl.logger: 11-02 22:31:01] {2627} INFO - retrain lgbm for 39.2s
[flaml.automl.logger: 11-02 22:31:02] {2630} INFO - retrained model: LGBMRegressor(colsample_bytree=0.3393982044447686,
              learning_rate=0.003094770605797757, max_bin=511,
              min_child_samples=105, n_estimators=1, n_jobs=4, num_leaves=16,
              reg_alpha=0.0010802291567173113, reg_lambda=0.24708517275092362,
              verbose=-1)
[flaml.automl.logger: 11-02 22:31:02] {1930} INFO - fit succeeded
[flaml.automl.logger: 11-02 22:31:02] {1931} INFO - Time taken to find the best model: 55250.76256275177
[flaml.automl.logger: 11-02 22:31:02] {1596} WARNING - n_concurrent_trials > 1 is only supported when using Ray or Spark. Ray installed, setting use_ray to True. If you want to use Spark, set use_spark to True.
[flaml.automl.logger: 11-02 22:31:02] {1679} INFO - task = regression
[flaml.automl.logger: 11-02 22:31:02] {1690} INFO - Evaluation method: cv
[flaml.automl.logger: 11-02 22:31:02] {1788} INFO - Minimizing error metric: rmse
[flaml.automl.logger: 11-02 22:31:02] {1900} INFO - List of ML learners in AutoML Run: ['catboost']
2023-11-02 22:31:02,359	WARNING optuna.py:297 -- You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.
[32m[I 2023-11-02 22:31:02,359][0m A new study created in memory with name: optuna[0m
[32m[I 2023-11-02 22:31:02,372][0m A new study created in memory with name: optuna[0m
[2m[36m(train pid=562449)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562449)[0m 
[2m[36m(train pid=562479)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562479)[0m 
[2m[36m(train pid=562481)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562481)[0m 
[2m[36m(train pid=562483)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562483)[0m 
[2m[36m(train pid=562485)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562485)[0m 
[2m[36m(train pid=562487)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562487)[0m 
[2m[36m(train pid=562491)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562491)[0m 
[2m[36m(train pid=562489)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562489)[0m 
[2m[36m(train pid=562493)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562493)[0m 
[2m[36m(train pid=562495)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562495)[0m 
[2m[36m(train pid=562497)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562497)[0m 
[2m[36m(train pid=562499)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562499)[0m 
[2m[36m(train pid=562501)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562501)[0m 
[2m[36m(train pid=562503)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562503)[0m 
[2m[36m(train pid=562505)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562505)[0m 
[2m[36m(train pid=562511)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562511)[0m 
[2m[36m(train pid=562507)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562507)[0m 
[2m[36m(train pid=562509)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=562509)[0m 
[2m[36m(train pid=563013)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=563013)[0m 
[2m[36m(train pid=563069)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=563069)[0m 
[2m[36m(train pid=563268)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=563268)[0m 
[2m[36m(train pid=564025)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=564025)[0m 
[2m[36m(train pid=565347)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=565347)[0m 
[2m[36m(train pid=566809)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=566809)[0m 
[2m[36m(train pid=568110)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=568110)[0m 
[2m[36m(train pid=568108)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=568108)[0m 
[2m[36m(train pid=568104)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=568104)[0m 
[2m[36m(train pid=568114)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=568114)[0m 
[2m[36m(train pid=568116)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=568116)[0m 
[2m[36m(train pid=568106)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=568106)[0m 
[2m[36m(train pid=568121)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=568121)[0m 
[2m[36m(train pid=568118)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=568118)[0m 
[2m[36m(train pid=568130)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=568130)[0m 
[2m[36m(train pid=568132)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=568132)[0m 
[2m[36m(train pid=569870)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=569870)[0m 
[2m[36m(train pid=570640)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=570640)[0m 
[2m[36m(train pid=571318)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=571318)[0m 
== Status ==
Current time: 2023-11-02 22:31:05 (running for 00:00:02.64)
Memory usage on this node: 14.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 4.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1/1000000 (1 RUNNING)


== Status ==
Current time: 2023-11-02 22:31:42 (running for 00:00:39.76)
Memory usage on this node: 18.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 72.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 18/1000000 (18 RUNNING)


== Status ==
Current time: 2023-11-02 22:32:50 (running for 00:01:48.44)
Memory usage on this node: 19.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 76.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 19/1000000 (19 RUNNING)


== Status ==
Current time: 2023-11-02 22:34:05 (running for 00:03:02.98)
Memory usage on this node: 19.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 80.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 20/1000000 (20 RUNNING)


== Status ==
Current time: 2023-11-02 22:35:23 (running for 00:04:21.07)
Memory usage on this node: 20.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 84.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 21/1000000 (21 RUNNING)


== Status ==
Current time: 2023-11-02 22:36:45 (running for 00:05:43.06)
Memory usage on this node: 20.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 88.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 22/1000000 (22 RUNNING)


== Status ==
Current time: 2023-11-02 22:38:05 (running for 00:07:03.09)
Memory usage on this node: 20.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 92.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 23/1000000 (23 RUNNING)


== Status ==
Current time: 2023-11-02 22:39:22 (running for 00:08:20.45)
Memory usage on this node: 20.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 96.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 24/1000000 (24 RUNNING)


== Status ==
Current time: 2023-11-02 22:39:23 (running for 00:08:21.03)
Memory usage on this node: 20.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 96.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac09 with val_loss=480.80783013589934 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08477294518359174, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 25/1000000 (1 PENDING, 24 RUNNING)


== Status ==
Current time: 2023-11-02 22:39:32 (running for 00:08:30.28)
Memory usage on this node: 20.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac01 with val_loss=480.4544294456791 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.08267721340635079, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 36/1000000 (32 RUNNING, 4 TERMINATED)


== Status ==
Current time: 2023-11-02 22:41:04 (running for 00:10:02.30)
Memory usage on this node: 22.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: b377f85e with val_loss=480.02257194506944 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.10630830721360562, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 36/1000000 (32 RUNNING, 4 TERMINATED)


== Status ==
Current time: 2023-11-02 22:41:11 (running for 00:10:09.24)
Memory usage on this node: 22.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 38/1000000 (32 RUNNING, 6 TERMINATED)


== Status ==
Current time: 2023-11-02 22:43:07 (running for 00:12:05.08)
Memory usage on this node: 23.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 38/1000000 (32 RUNNING, 6 TERMINATED)


== Status ==
Current time: 2023-11-02 22:43:13 (running for 00:12:11.39)
Memory usage on this node: 22.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 40/1000000 (32 RUNNING, 8 TERMINATED)


== Status ==
Current time: 2023-11-02 22:45:13 (running for 00:14:10.93)
Memory usage on this node: 23.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 40/1000000 (32 RUNNING, 8 TERMINATED)


== Status ==
Current time: 2023-11-02 22:45:19 (running for 00:14:17.40)
Memory usage on this node: 22.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 41/1000000 (32 RUNNING, 9 TERMINATED)


== Status ==
Current time: 2023-11-02 22:47:22 (running for 00:16:19.62)
Memory usage on this node: 23.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 41/1000000 (32 RUNNING, 9 TERMINATED)


[2m[36m(train pid=571956)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=571956)[0m 
== Status ==
Current time: 2023-11-02 22:47:27 (running for 00:16:25.31)
Memory usage on this node: 22.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 42/1000000 (32 RUNNING, 10 TERMINATED)


== Status ==
Current time: 2023-11-02 22:49:37 (running for 00:18:34.75)
Memory usage on this node: 23.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 42/1000000 (32 RUNNING, 10 TERMINATED)


== Status ==
Current time: 2023-11-02 22:49:42 (running for 00:18:39.75)
Memory usage on this node: 23.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 42/1000000 (32 RUNNING, 10 TERMINATED)


== Status ==
Current time: 2023-11-02 22:49:47 (running for 00:18:45.02)
Memory usage on this node: 23.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 42/1000000 (32 RUNNING, 10 TERMINATED)


== Status ==
Current time: 2023-11-02 22:49:52 (running for 00:18:50.03)
Memory usage on this node: 23.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 42/1000000 (32 RUNNING, 10 TERMINATED)


== Status ==
Current time: 2023-11-02 22:49:57 (running for 00:18:55.18)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 42/1000000 (32 RUNNING, 10 TERMINATED)


== Status ==
Current time: 2023-11-02 22:50:02 (running for 00:19:00.18)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 42/1000000 (32 RUNNING, 10 TERMINATED)


== Status ==
Current time: 2023-11-02 22:50:07 (running for 00:19:05.34)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 42/1000000 (32 RUNNING, 10 TERMINATED)


== Status ==
Current time: 2023-11-02 22:50:12 (running for 00:19:10.34)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 42/1000000 (32 RUNNING, 10 TERMINATED)


== Status ==
Current time: 2023-11-02 22:50:17 (running for 00:19:15.50)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 42/1000000 (32 RUNNING, 10 TERMINATED)


== Status ==
Current time: 2023-11-02 22:50:22 (running for 00:19:20.51)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 42/1000000 (32 RUNNING, 10 TERMINATED)


== Status ==
Current time: 2023-11-02 22:50:28 (running for 00:19:25.62)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 42/1000000 (32 RUNNING, 10 TERMINATED)


== Status ==
Current time: 2023-11-02 22:50:33 (running for 00:19:30.62)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 42/1000000 (32 RUNNING, 10 TERMINATED)


== Status ==
Current time: 2023-11-02 22:50:48 (running for 00:19:46.19)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 42/1000000 (32 RUNNING, 10 TERMINATED)


[2m[36m(train pid=574116)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=574116)[0m 
[2m[36m(train pid=575813)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=575813)[0m 
[2m[36m(train pid=576958)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=576958)[0m 
[2m[36m(train pid=577871)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=577871)[0m 
2023-11-02 23:01:23,448	WARNING util.py:214 -- The `start_trial` operation took 0.545 s, which may be a performance bottleneck.
[2m[36m(train pid=579444)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=579444)[0m 
[2m[36m(train pid=581249)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=581249)[0m 
[2m[36m(train pid=582600)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=582600)[0m 
[2m[36m(train pid=582588)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=582588)[0m 
== Status ==
Current time: 2023-11-02 22:50:54 (running for 00:19:52.38)
Memory usage on this node: 23.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 43/1000000 (32 RUNNING, 11 TERMINATED)


== Status ==
Current time: 2023-11-02 22:52:52 (running for 00:21:49.64)
Memory usage on this node: 23.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7468ac05 with val_loss=479.9208382662782 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08115314174191955, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 43/1000000 (32 RUNNING, 11 TERMINATED)


== Status ==
Current time: 2023-11-02 22:52:58 (running for 00:21:56.42)
Memory usage on this node: 23.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 45/1000000 (32 RUNNING, 13 TERMINATED)


== Status ==
Current time: 2023-11-02 22:54:56 (running for 00:23:54.31)
Memory usage on this node: 23.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 45/1000000 (32 RUNNING, 13 TERMINATED)


== Status ==
Current time: 2023-11-02 22:55:01 (running for 00:23:59.54)
Memory usage on this node: 23.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 45/1000000 (31 RUNNING, 14 TERMINATED)


== Status ==
Current time: 2023-11-02 22:55:07 (running for 00:24:04.78)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 45/1000000 (31 RUNNING, 14 TERMINATED)


== Status ==
Current time: 2023-11-02 22:55:12 (running for 00:24:10.14)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 46/1000000 (32 RUNNING, 14 TERMINATED)


== Status ==
Current time: 2023-11-02 22:57:11 (running for 00:26:08.75)
Memory usage on this node: 23.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 46/1000000 (32 RUNNING, 14 TERMINATED)


== Status ==
Current time: 2023-11-02 22:57:16 (running for 00:26:14.54)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 47/1000000 (32 RUNNING, 15 TERMINATED)


== Status ==
Current time: 2023-11-02 22:59:18 (running for 00:28:16.38)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 47/1000000 (32 RUNNING, 15 TERMINATED)


== Status ==
Current time: 2023-11-02 22:59:24 (running for 00:28:22.48)
Memory usage on this node: 23.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 48/1000000 (32 RUNNING, 16 TERMINATED)


== Status ==
Current time: 2023-11-02 23:01:21 (running for 00:30:19.59)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 48/1000000 (32 RUNNING, 16 TERMINATED)


== Status ==
Current time: 2023-11-02 23:01:28 (running for 00:30:26.05)
Memory usage on this node: 23.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 50/1000000 (32 RUNNING, 18 TERMINATED)


== Status ==
Current time: 2023-11-02 23:03:28 (running for 00:32:26.12)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 50/1000000 (32 RUNNING, 18 TERMINATED)


== Status ==
Current time: 2023-11-02 23:03:36 (running for 00:32:34.51)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:05:38 (running for 00:34:36.40)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:05:43 (running for 00:34:41.40)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:05:48 (running for 00:34:46.58)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:05:53 (running for 00:34:51.58)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:05:59 (running for 00:34:57.05)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:06:04 (running for 00:35:02.05)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:06:09 (running for 00:35:07.24)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:06:14 (running for 00:35:12.25)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:06:20 (running for 00:35:17.92)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:06:25 (running for 00:35:22.93)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:06:30 (running for 00:35:27.93)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:06:35 (running for 00:35:33.21)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:06:40 (running for 00:35:38.22)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:06:45 (running for 00:35:43.40)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:06:50 (running for 00:35:48.41)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:06:55 (running for 00:35:53.59)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:07:00 (running for 00:35:58.59)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:07:06 (running for 00:36:03.77)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:07:11 (running for 00:36:08.78)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:07:16 (running for 00:36:14.04)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:07:21 (running for 00:36:19.04)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:07:26 (running for 00:36:24.36)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:07:31 (running for 00:36:29.36)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:07:37 (running for 00:36:34.76)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:07:42 (running for 00:36:39.76)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:07:47 (running for 00:36:44.95)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:07:52 (running for 00:36:49.95)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:07:57 (running for 00:36:55.13)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:08:02 (running for 00:37:00.13)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:08:07 (running for 00:37:05.30)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


[2m[36m(train pid=585333)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=585333)[0m 
[2m[36m(train pid=587211)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=587211)[0m 
[2m[36m(train pid=589123)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=589123)[0m 
[2m[36m(train pid=589128)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=589128)[0m 
[2m[36m(train pid=589130)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=589130)[0m 
[2m[36m(train pid=590154)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=590154)[0m 
[2m[36m(train pid=590007)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=590007)[0m 
== Status ==
Current time: 2023-11-02 23:08:12 (running for 00:37:10.31)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:08:17 (running for 00:37:15.52)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:08:22 (running for 00:37:20.52)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:08:28 (running for 00:37:25.78)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:08:33 (running for 00:37:30.79)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:08:38 (running for 00:37:36.02)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 53/1000000 (32 RUNNING, 21 TERMINATED)


== Status ==
Current time: 2023-11-02 23:08:47 (running for 00:37:45.53)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 54/1000000 (32 RUNNING, 22 TERMINATED)


== Status ==
Current time: 2023-11-02 23:10:54 (running for 00:39:52.00)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 54/1000000 (32 RUNNING, 22 TERMINATED)


== Status ==
Current time: 2023-11-02 23:11:00 (running for 00:39:58.48)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 56/1000000 (32 RUNNING, 24 TERMINATED)


== Status ==
Current time: 2023-11-02 23:12:56 (running for 00:41:53.77)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 56/1000000 (32 RUNNING, 24 TERMINATED)


== Status ==
Current time: 2023-11-02 23:13:04 (running for 00:42:01.65)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 60/1000000 (32 RUNNING, 28 TERMINATED)


== Status ==
Current time: 2023-11-02 23:14:53 (running for 00:43:51.59)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 60/1000000 (32 RUNNING, 28 TERMINATED)


== Status ==
Current time: 2023-11-02 23:15:03 (running for 00:44:00.64)
Memory usage on this node: 23.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 62/1000000 (32 RUNNING, 30 TERMINATED)


== Status ==
Current time: 2023-11-02 23:17:01 (running for 00:45:59.36)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 62/1000000 (32 RUNNING, 30 TERMINATED)


== Status ==
Current time: 2023-11-02 23:17:07 (running for 00:46:05.59)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 63/1000000 (32 RUNNING, 31 TERMINATED)


[2m[36m(train pid=591572)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=591572)[0m 
[2m[36m(train pid=593466)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=593466)[0m 
2023-11-02 23:23:24,700	WARNING util.py:214 -- The `start_trial` operation took 0.521 s, which may be a performance bottleneck.
[2m[36m(train pid=594667)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=594667)[0m 
[2m[36m(train pid=595886)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=595886)[0m 
[2m[36m(train pid=596613)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=596613)[0m 
== Status ==
Current time: 2023-11-02 23:19:09 (running for 00:48:06.67)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 63/1000000 (32 RUNNING, 31 TERMINATED)


== Status ==
Current time: 2023-11-02 23:19:15 (running for 00:48:12.90)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 64/1000000 (32 RUNNING, 32 TERMINATED)


== Status ==
Current time: 2023-11-02 23:21:17 (running for 00:50:15.54)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 64/1000000 (32 RUNNING, 32 TERMINATED)


== Status ==
Current time: 2023-11-02 23:21:24 (running for 00:50:21.81)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 66/1000000 (32 RUNNING, 34 TERMINATED)


== Status ==
Current time: 2023-11-02 23:23:23 (running for 00:52:20.81)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 66/1000000 (32 RUNNING, 34 TERMINATED)


== Status ==
Current time: 2023-11-02 23:23:29 (running for 00:52:27.30)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 68/1000000 (32 RUNNING, 36 TERMINATED)


== Status ==
Current time: 2023-11-02 23:25:29 (running for 00:54:27.02)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 68/1000000 (32 RUNNING, 36 TERMINATED)


== Status ==
Current time: 2023-11-02 23:25:36 (running for 00:54:33.83)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:27:45 (running for 00:56:43.05)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:27:50 (running for 00:56:48.06)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:27:55 (running for 00:56:53.25)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:28:00 (running for 00:56:58.26)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:28:05 (running for 00:57:03.45)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:28:10 (running for 00:57:08.46)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:28:16 (running for 00:57:13.69)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:28:21 (running for 00:57:18.69)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:28:26 (running for 00:57:23.92)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:28:31 (running for 00:57:28.93)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:28:36 (running for 00:57:34.19)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:28:41 (running for 00:57:39.19)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:28:46 (running for 00:57:44.35)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:28:51 (running for 00:57:49.35)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:28:57 (running for 00:57:54.64)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:29:02 (running for 00:57:59.65)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:29:07 (running for 00:58:04.81)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:29:12 (running for 00:58:09.81)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:29:18 (running for 00:58:15.61)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:29:23 (running for 00:58:20.62)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:29:28 (running for 00:58:25.63)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:29:33 (running for 00:58:30.63)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:29:38 (running for 00:58:35.84)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:29:43 (running for 00:58:40.84)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:29:48 (running for 00:58:46.00)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:29:53 (running for 00:58:51.01)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:29:58 (running for 00:58:56.22)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:30:03 (running for 00:59:01.22)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:30:08 (running for 00:59:06.38)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:30:13 (running for 00:59:11.38)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:30:18 (running for 00:59:16.56)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:30:23 (running for 00:59:21.56)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:30:29 (running for 00:59:26.71)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:30:34 (running for 00:59:31.71)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:30:39 (running for 00:59:36.75)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:30:54 (running for 00:59:52.31)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:30:59 (running for 00:59:57.32)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:31:04 (running for 01:00:02.38)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:31:09 (running for 01:00:07.40)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:31:15 (running for 01:00:12.62)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:31:20 (running for 01:00:17.62)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:31:25 (running for 01:00:22.73)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:31:30 (running for 01:00:27.74)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:31:35 (running for 01:00:32.77)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:31:40 (running for 01:00:37.78)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:31:45 (running for 01:00:42.97)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:31:50 (running for 01:00:47.97)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:31:55 (running for 01:00:53.21)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:32:00 (running for 01:00:58.22)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:32:05 (running for 01:01:03.46)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:32:10 (running for 01:01:08.47)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:32:16 (running for 01:01:13.95)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:32:21 (running for 01:01:18.96)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:32:26 (running for 01:01:24.14)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:32:31 (running for 01:01:29.15)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:32:36 (running for 01:01:34.38)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:32:41 (running for 01:01:39.39)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:32:47 (running for 01:01:44.65)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:32:52 (running for 01:01:49.66)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:32:57 (running for 01:01:54.90)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:33:02 (running for 01:01:59.91)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:33:07 (running for 01:02:05.12)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:33:12 (running for 01:02:10.13)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:33:17 (running for 01:02:15.33)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:33:22 (running for 01:02:20.34)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:33:27 (running for 01:02:25.52)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:33:32 (running for 01:02:30.53)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


[2m[36m(train pid=599028)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=599028)[0m 
[2m[36m(train pid=599700)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=599700)[0m 
[2m[36m(train pid=600378)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=600378)[0m 
[2m[36m(train pid=600380)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=600380)[0m 
== Status ==
Current time: 2023-11-02 23:33:38 (running for 01:02:35.70)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:33:43 (running for 01:02:40.71)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:33:48 (running for 01:02:45.91)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:33:53 (running for 01:02:50.91)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:33:58 (running for 01:02:56.16)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:34:03 (running for 01:03:01.16)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:34:08 (running for 01:03:06.34)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:34:13 (running for 01:03:11.35)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:34:19 (running for 01:03:16.62)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 69/1000000 (32 RUNNING, 37 TERMINATED)


== Status ==
Current time: 2023-11-02 23:34:25 (running for 01:03:22.85)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 70/1000000 (32 RUNNING, 38 TERMINATED)


== Status ==
Current time: 2023-11-02 23:36:26 (running for 01:05:23.96)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 70/1000000 (32 RUNNING, 38 TERMINATED)


== Status ==
Current time: 2023-11-02 23:36:32 (running for 01:05:29.92)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 71/1000000 (32 RUNNING, 39 TERMINATED)


== Status ==
Current time: 2023-11-02 23:38:32 (running for 01:07:30.20)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 71/1000000 (32 RUNNING, 39 TERMINATED)


== Status ==
Current time: 2023-11-02 23:38:39 (running for 01:07:36.93)
Memory usage on this node: 23.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:40:52 (running for 01:09:50.07)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:40:57 (running for 01:09:55.08)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:41:02 (running for 01:10:00.09)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:41:07 (running for 01:10:05.09)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:41:12 (running for 01:10:10.10)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:41:17 (running for 01:10:15.11)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:41:22 (running for 01:10:20.11)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:41:27 (running for 01:10:25.12)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:41:32 (running for 01:10:30.12)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:41:37 (running for 01:10:35.13)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:41:42 (running for 01:10:40.13)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:41:47 (running for 01:10:45.14)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:41:52 (running for 01:10:50.15)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:41:57 (running for 01:10:55.15)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:42:02 (running for 01:11:00.16)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:42:07 (running for 01:11:05.17)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


[2m[36m(train pid=602571)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=602571)[0m 
[2m[36m(train pid=604175)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=604175)[0m 
[2m[36m(train pid=605429)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=605429)[0m 
== Status ==
Current time: 2023-11-02 23:42:12 (running for 01:11:10.17)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:42:17 (running for 01:11:15.18)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:42:22 (running for 01:11:20.18)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:42:27 (running for 01:11:25.19)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:42:32 (running for 01:11:30.20)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:42:37 (running for 01:11:35.20)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:42:42 (running for 01:11:40.21)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:42:47 (running for 01:11:45.21)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 73/1000000 (32 RUNNING, 41 TERMINATED)


== Status ==
Current time: 2023-11-02 23:42:56 (running for 01:11:53.67)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 74/1000000 (32 RUNNING, 42 TERMINATED)


== Status ==
Current time: 2023-11-02 23:44:52 (running for 01:13:50.34)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 74/1000000 (32 RUNNING, 42 TERMINATED)


== Status ==
Current time: 2023-11-02 23:45:00 (running for 01:13:58.09)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 77/1000000 (32 RUNNING, 45 TERMINATED)


== Status ==
Current time: 2023-11-02 23:47:02 (running for 01:15:59.73)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 77/1000000 (32 RUNNING, 45 TERMINATED)


== Status ==
Current time: 2023-11-02 23:47:08 (running for 01:16:05.99)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 78/1000000 (32 RUNNING, 46 TERMINATED)


== Status ==
Current time: 2023-11-02 23:49:15 (running for 01:18:13.55)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 78/1000000 (32 RUNNING, 46 TERMINATED)


== Status ==
Current time: 2023-11-02 23:49:20 (running for 01:18:18.55)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 78/1000000 (32 RUNNING, 46 TERMINATED)


[2m[36m(train pid=606418)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=606418)[0m 
[2m[36m(train pid=607803)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=607803)[0m 
[2m[36m(train pid=609076)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=609076)[0m 
2023-11-02 23:58:00,311	WARNING util.py:214 -- The `start_trial` operation took 0.670 s, which may be a performance bottleneck.
[2m[36m(train pid=610645)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=610645)[0m 
[2m[36m(train pid=611992)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=611992)[0m 
[2m[36m(train pid=612251)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=612251)[0m 
[2m[36m(train pid=612275)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=612275)[0m 
2023-11-03 00:02:10,579	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.519 s, which may be a performance bottleneck.
2023-11-03 00:02:10,579	WARNING util.py:214 -- The `process_trial_result` operation took 0.520 s, which may be a performance bottleneck.
2023-11-03 00:02:10,579	WARNING util.py:214 -- Processing trial results took 0.520 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 00:02:10,580	WARNING util.py:214 -- The `process_trial_result` operation took 0.520 s, which may be a performance bottleneck.
[2m[36m(train pid=612990)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=612990)[0m 
== Status ==
Current time: 2023-11-02 23:49:26 (running for 01:18:23.78)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 78/1000000 (32 RUNNING, 46 TERMINATED)


== Status ==
Current time: 2023-11-02 23:49:31 (running for 01:18:28.78)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 78/1000000 (32 RUNNING, 46 TERMINATED)


== Status ==
Current time: 2023-11-02 23:49:36 (running for 01:18:33.96)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 78/1000000 (32 RUNNING, 46 TERMINATED)


== Status ==
Current time: 2023-11-02 23:49:44 (running for 01:18:42.05)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 79/1000000 (32 RUNNING, 47 TERMINATED)


== Status ==
Current time: 2023-11-02 23:51:45 (running for 01:20:43.26)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 79/1000000 (32 RUNNING, 47 TERMINATED)


== Status ==
Current time: 2023-11-02 23:51:52 (running for 01:20:50.03)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 82/1000000 (32 RUNNING, 50 TERMINATED)


== Status ==
Current time: 2023-11-02 23:53:54 (running for 01:22:52.08)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 82/1000000 (32 RUNNING, 50 TERMINATED)


== Status ==
Current time: 2023-11-02 23:54:00 (running for 01:22:58.12)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 83/1000000 (32 RUNNING, 51 TERMINATED)


== Status ==
Current time: 2023-11-02 23:56:00 (running for 01:24:58.05)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 83/1000000 (32 RUNNING, 51 TERMINATED)


== Status ==
Current time: 2023-11-02 23:56:06 (running for 01:25:04.06)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 84/1000000 (32 RUNNING, 52 TERMINATED)


== Status ==
Current time: 2023-11-02 23:57:58 (running for 01:26:56.58)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 84/1000000 (32 RUNNING, 52 TERMINATED)


== Status ==
Current time: 2023-11-02 23:58:08 (running for 01:27:06.04)
Memory usage on this node: 23.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 88/1000000 (32 RUNNING, 56 TERMINATED)


== Status ==
Current time: 2023-11-03 00:00:00 (running for 01:28:57.63)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 88/1000000 (32 RUNNING, 56 TERMINATED)


== Status ==
Current time: 2023-11-03 00:00:06 (running for 01:29:04.12)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 89/1000000 (32 RUNNING, 57 TERMINATED)


== Status ==
Current time: 2023-11-03 00:02:10 (running for 01:31:07.65)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 89/1000000 (32 RUNNING, 57 TERMINATED)


[2m[36m(train pid=614238)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=614238)[0m 
[2m[36m(train pid=615276)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=615276)[0m 
[2m[36m(train pid=616756)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=616756)[0m 
[2m[36m(train pid=618604)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=618604)[0m 
[2m[36m(train pid=620151)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=620151)[0m 
== Status ==
Current time: 2023-11-03 00:02:17 (running for 01:31:15.21)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 92/1000000 (32 RUNNING, 60 TERMINATED)


== Status ==
Current time: 2023-11-03 00:04:19 (running for 01:33:17.15)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 92/1000000 (32 RUNNING, 60 TERMINATED)


== Status ==
Current time: 2023-11-03 00:04:25 (running for 01:33:23.19)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 93/1000000 (32 RUNNING, 61 TERMINATED)


== Status ==
Current time: 2023-11-03 00:06:35 (running for 01:35:33.14)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 93/1000000 (32 RUNNING, 61 TERMINATED)


== Status ==
Current time: 2023-11-03 00:06:40 (running for 01:35:38.15)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 93/1000000 (32 RUNNING, 61 TERMINATED)


== Status ==
Current time: 2023-11-03 00:06:50 (running for 01:35:47.80)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 94/1000000 (32 RUNNING, 62 TERMINATED)


== Status ==
Current time: 2023-11-03 00:09:01 (running for 01:37:58.86)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 94/1000000 (32 RUNNING, 62 TERMINATED)


== Status ==
Current time: 2023-11-03 00:09:06 (running for 01:38:03.86)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 94/1000000 (32 RUNNING, 62 TERMINATED)


== Status ==
Current time: 2023-11-03 00:09:11 (running for 01:38:09.16)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 94/1000000 (32 RUNNING, 62 TERMINATED)


== Status ==
Current time: 2023-11-03 00:09:16 (running for 01:38:14.17)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 94/1000000 (32 RUNNING, 62 TERMINATED)


== Status ==
Current time: 2023-11-03 00:09:22 (running for 01:38:19.60)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 94/1000000 (32 RUNNING, 62 TERMINATED)


== Status ==
Current time: 2023-11-03 00:09:28 (running for 01:38:26.45)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 95/1000000 (32 RUNNING, 63 TERMINATED)


== Status ==
Current time: 2023-11-03 00:11:31 (running for 01:40:28.74)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 95/1000000 (32 RUNNING, 63 TERMINATED)


== Status ==
Current time: 2023-11-03 00:11:37 (running for 01:40:35.31)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 96/1000000 (32 RUNNING, 64 TERMINATED)


== Status ==
Current time: 2023-11-03 00:13:35 (running for 01:42:33.34)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 96/1000000 (32 RUNNING, 64 TERMINATED)


[2m[36m(train pid=621524)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=621524)[0m 
== Status ==
Current time: 2023-11-03 00:13:42 (running for 01:42:40.32)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:15:55 (running for 01:44:52.82)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:16:00 (running for 01:44:57.83)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:16:05 (running for 01:45:03.03)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:16:10 (running for 01:45:08.04)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:16:15 (running for 01:45:13.35)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:16:20 (running for 01:45:18.36)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:16:26 (running for 01:45:24.09)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:16:31 (running for 01:45:29.10)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:16:36 (running for 01:45:34.10)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:16:42 (running for 01:45:39.72)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:16:47 (running for 01:45:44.73)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:16:52 (running for 01:45:49.73)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:16:57 (running for 01:45:54.92)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:17:02 (running for 01:45:59.93)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


[2m[36m(train pid=622930)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=622930)[0m 
== Status ==
Current time: 2023-11-03 00:17:07 (running for 01:46:05.16)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:17:12 (running for 01:46:10.16)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:17:17 (running for 01:46:15.44)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:17:22 (running for 01:46:20.44)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:17:29 (running for 01:46:27.28)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:17:34 (running for 01:46:32.29)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 99/1000000 (32 RUNNING, 67 TERMINATED)


== Status ==
Current time: 2023-11-03 00:17:39 (running for 01:46:37.39)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:19:54 (running for 01:48:52.56)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:19:59 (running for 01:48:57.56)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:20:05 (running for 01:49:02.83)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:20:10 (running for 01:49:07.83)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:20:15 (running for 01:49:13.02)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:20:20 (running for 01:49:18.02)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:20:25 (running for 01:49:23.15)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:20:30 (running for 01:49:28.17)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:20:35 (running for 01:49:33.42)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:20:40 (running for 01:49:38.42)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:20:56 (running for 01:49:54.50)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:21:01 (running for 01:49:59.51)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:21:07 (running for 01:50:04.80)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:21:12 (running for 01:50:09.81)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:21:17 (running for 01:50:15.08)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:21:22 (running for 01:50:20.09)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:21:27 (running for 01:50:25.43)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:21:32 (running for 01:50:30.43)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:21:38 (running for 01:50:35.74)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:21:43 (running for 01:50:40.75)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:21:49 (running for 01:50:46.82)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:21:54 (running for 01:50:51.83)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:21:59 (running for 01:50:56.84)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:22:04 (running for 01:51:01.85)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:22:09 (running for 01:51:06.85)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:22:14 (running for 01:51:12.19)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:22:19 (running for 01:51:17.19)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:22:24 (running for 01:51:22.55)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:22:29 (running for 01:51:27.56)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:22:35 (running for 01:51:33.12)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:22:40 (running for 01:51:38.13)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:22:45 (running for 01:51:43.14)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:22:50 (running for 01:51:48.53)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:22:55 (running for 01:51:53.54)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:23:01 (running for 01:51:58.84)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:23:06 (running for 01:52:03.90)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:23:11 (running for 01:52:09.28)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:23:16 (running for 01:52:14.29)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:23:21 (running for 01:52:19.59)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:23:27 (running for 01:52:24.60)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:23:32 (running for 01:52:29.90)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:23:37 (running for 01:52:34.91)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:23:42 (running for 01:52:40.15)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:23:47 (running for 01:52:45.16)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:23:52 (running for 01:52:50.46)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:23:57 (running for 01:52:55.47)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:24:05 (running for 01:53:02.87)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:24:10 (running for 01:53:07.88)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:24:15 (running for 01:53:12.88)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:24:20 (running for 01:53:17.89)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:24:25 (running for 01:53:22.89)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:24:30 (running for 01:53:27.90)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:24:35 (running for 01:53:32.91)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


2023-11-03 00:25:02,214	WARNING util.py:214 -- The `start_trial` operation took 0.621 s, which may be a performance bottleneck.
[2m[36m(train pid=626167)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=626167)[0m 
[2m[36m(train pid=627252)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=627252)[0m 
[2m[36m(train pid=628176)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=628176)[0m 
[2m[36m(train pid=629142)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=629142)[0m 
[2m[36m(train pid=630497)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=630497)[0m 
== Status ==
Current time: 2023-11-03 00:24:40 (running for 01:53:37.91)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:24:45 (running for 01:53:42.92)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:24:50 (running for 01:53:47.93)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:24:55 (running for 01:53:53.27)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:25:00 (running for 01:53:58.28)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 100/1000000 (32 RUNNING, 68 TERMINATED)


== Status ==
Current time: 2023-11-03 00:25:08 (running for 01:54:06.16)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 101/1000000 (32 RUNNING, 69 TERMINATED)


== Status ==
Current time: 2023-11-03 00:27:08 (running for 01:56:05.84)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 101/1000000 (32 RUNNING, 69 TERMINATED)


== Status ==
Current time: 2023-11-03 00:27:14 (running for 01:56:12.38)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 102/1000000 (32 RUNNING, 70 TERMINATED)


== Status ==
Current time: 2023-11-03 00:29:18 (running for 01:58:15.87)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 102/1000000 (32 RUNNING, 70 TERMINATED)


== Status ==
Current time: 2023-11-03 00:29:24 (running for 01:58:22.57)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 103/1000000 (32 RUNNING, 71 TERMINATED)


== Status ==
Current time: 2023-11-03 00:31:24 (running for 02:00:21.88)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 103/1000000 (32 RUNNING, 71 TERMINATED)


== Status ==
Current time: 2023-11-03 00:31:30 (running for 02:00:28.55)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 104/1000000 (32 RUNNING, 72 TERMINATED)


== Status ==
Current time: 2023-11-03 00:33:38 (running for 02:02:36.02)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 104/1000000 (32 RUNNING, 72 TERMINATED)


== Status ==
Current time: 2023-11-03 00:33:44 (running for 02:02:42.55)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 105/1000000 (32 RUNNING, 73 TERMINATED)


== Status ==
Current time: 2023-11-03 00:35:39 (running for 02:04:36.78)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 105/1000000 (32 RUNNING, 73 TERMINATED)


[2m[36m(train pid=632442)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=632442)[0m 
[2m[36m(train pid=634405)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=634405)[0m 
[2m[36m(train pid=636589)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=636589)[0m 
[2m[36m(train pid=636612)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=636612)[0m 
[2m[36m(train pid=637984)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=637984)[0m 
2023-11-03 00:44:43,204	WARNING util.py:214 -- The `start_trial` operation took 1.409 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 00:35:46 (running for 02:04:43.86)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 108/1000000 (32 RUNNING, 76 TERMINATED)


== Status ==
Current time: 2023-11-03 00:37:53 (running for 02:06:51.19)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 108/1000000 (32 RUNNING, 76 TERMINATED)


== Status ==
Current time: 2023-11-03 00:37:58 (running for 02:06:56.31)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 108/1000000 (32 RUNNING, 76 TERMINATED)


== Status ==
Current time: 2023-11-03 00:38:03 (running for 02:07:01.56)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 108/1000000 (32 RUNNING, 76 TERMINATED)


== Status ==
Current time: 2023-11-03 00:38:08 (running for 02:07:06.56)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 108/1000000 (32 RUNNING, 76 TERMINATED)


== Status ==
Current time: 2023-11-03 00:38:14 (running for 02:07:11.76)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 108/1000000 (32 RUNNING, 76 TERMINATED)


== Status ==
Current time: 2023-11-03 00:38:19 (running for 02:07:16.79)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 108/1000000 (32 RUNNING, 76 TERMINATED)


== Status ==
Current time: 2023-11-03 00:38:24 (running for 02:07:22.03)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 108/1000000 (32 RUNNING, 76 TERMINATED)


== Status ==
Current time: 2023-11-03 00:38:29 (running for 02:07:27.03)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 108/1000000 (32 RUNNING, 76 TERMINATED)


== Status ==
Current time: 2023-11-03 00:38:38 (running for 02:07:35.85)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 109/1000000 (32 RUNNING, 77 TERMINATED)


== Status ==
Current time: 2023-11-03 00:40:35 (running for 02:09:32.81)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 109/1000000 (32 RUNNING, 77 TERMINATED)


== Status ==
Current time: 2023-11-03 00:40:43 (running for 02:09:40.64)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 113/1000000 (32 RUNNING, 81 TERMINATED)


== Status ==
Current time: 2023-11-03 00:42:35 (running for 02:11:33.57)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 113/1000000 (32 RUNNING, 81 TERMINATED)


== Status ==
Current time: 2023-11-03 00:42:42 (running for 02:11:40.12)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 115/1000000 (32 RUNNING, 83 TERMINATED)


== Status ==
Current time: 2023-11-03 00:44:38 (running for 02:13:36.39)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 115/1000000 (32 RUNNING, 83 TERMINATED)


[2m[36m(train pid=639221)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=639221)[0m 
[2m[36m(train pid=639212)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=639212)[0m 
[2m[36m(train pid=640742)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=640742)[0m 
2023-11-03 00:50:55,931	WARNING util.py:214 -- The `start_trial` operation took 11.037 s, which may be a performance bottleneck.
[2m[36m(train pid=642957)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=642957)[0m 
2023-11-03 00:51:01,147	WARNING util.py:214 -- The `start_trial` operation took 1.297 s, which may be a performance bottleneck.
[2m[36m(train pid=645670)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=645670)[0m 
[2m[36m(train pid=645532)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=645532)[0m 
[2m[36m(train pid=647215)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=647215)[0m 
[2m[36m(train pid=649535)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=649535)[0m 
[2m[36m(train pid=649611)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=649611)[0m 
[2m[36m(train pid=650576)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=650576)[0m 
== Status ==
Current time: 2023-11-03 00:44:48 (running for 02:13:45.81)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 119/1000000 (32 RUNNING, 87 TERMINATED)


== Status ==
Current time: 2023-11-03 00:46:39 (running for 02:15:36.60)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 119/1000000 (32 RUNNING, 87 TERMINATED)


== Status ==
Current time: 2023-11-03 00:46:45 (running for 02:15:42.72)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 121/1000000 (32 RUNNING, 89 TERMINATED)


== Status ==
Current time: 2023-11-03 00:48:44 (running for 02:17:42.53)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 121/1000000 (32 RUNNING, 89 TERMINATED)


== Status ==
Current time: 2023-11-03 00:48:51 (running for 02:17:48.78)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 122/1000000 (32 RUNNING, 90 TERMINATED)


== Status ==
Current time: 2023-11-03 00:50:43 (running for 02:19:41.35)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 122/1000000 (32 RUNNING, 90 TERMINATED)


== Status ==
Current time: 2023-11-03 00:50:56 (running for 02:19:54.03)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 123/1000000 (31 RUNNING, 92 TERMINATED)


== Status ==
Current time: 2023-11-03 00:51:06 (running for 02:20:03.75)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 128/1000000 (32 RUNNING, 96 TERMINATED)


== Status ==
Current time: 2023-11-03 00:52:56 (running for 02:21:53.93)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 128/1000000 (32 RUNNING, 96 TERMINATED)


== Status ==
Current time: 2023-11-03 00:53:03 (running for 02:22:00.85)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 129/1000000 (32 RUNNING, 97 TERMINATED)


== Status ==
Current time: 2023-11-03 00:55:00 (running for 02:23:58.12)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 129/1000000 (32 RUNNING, 97 TERMINATED)


== Status ==
Current time: 2023-11-03 00:55:10 (running for 02:24:07.67)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 134/1000000 (32 RUNNING, 102 TERMINATED)


== Status ==
Current time: 2023-11-03 00:57:02 (running for 02:25:59.83)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 134/1000000 (32 RUNNING, 102 TERMINATED)


== Status ==
Current time: 2023-11-03 00:57:09 (running for 02:26:06.93)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 136/1000000 (32 RUNNING, 104 TERMINATED)


== Status ==
Current time: 2023-11-03 00:59:13 (running for 02:28:10.67)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 136/1000000 (32 RUNNING, 104 TERMINATED)


[2m[36m(train pid=652054)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=652054)[0m 
== Status ==
Current time: 2023-11-03 00:59:19 (running for 02:28:16.88)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 137/1000000 (32 RUNNING, 105 TERMINATED)


== Status ==
Current time: 2023-11-03 01:01:29 (running for 02:30:27.47)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 137/1000000 (32 RUNNING, 105 TERMINATED)


== Status ==
Current time: 2023-11-03 01:01:35 (running for 02:30:32.63)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 137/1000000 (32 RUNNING, 105 TERMINATED)


== Status ==
Current time: 2023-11-03 01:01:40 (running for 02:30:37.89)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 137/1000000 (32 RUNNING, 105 TERMINATED)


== Status ==
Current time: 2023-11-03 01:01:45 (running for 02:30:42.94)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 137/1000000 (32 RUNNING, 105 TERMINATED)


== Status ==
Current time: 2023-11-03 01:01:50 (running for 02:30:48.34)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 137/1000000 (32 RUNNING, 105 TERMINATED)


== Status ==
Current time: 2023-11-03 01:01:55 (running for 02:30:53.34)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 137/1000000 (32 RUNNING, 105 TERMINATED)


== Status ==
Current time: 2023-11-03 01:02:01 (running for 02:30:58.68)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 137/1000000 (32 RUNNING, 105 TERMINATED)


== Status ==
Current time: 2023-11-03 01:02:06 (running for 02:31:03.69)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 137/1000000 (32 RUNNING, 105 TERMINATED)


== Status ==
Current time: 2023-11-03 01:02:11 (running for 02:31:09.02)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 137/1000000 (32 RUNNING, 105 TERMINATED)


== Status ==
Current time: 2023-11-03 01:02:16 (running for 02:31:14.05)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 137/1000000 (32 RUNNING, 105 TERMINATED)


== Status ==
Current time: 2023-11-03 01:02:21 (running for 02:31:19.52)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 137/1000000 (32 RUNNING, 105 TERMINATED)


== Status ==
Current time: 2023-11-03 01:02:26 (running for 02:31:24.53)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 137/1000000 (32 RUNNING, 105 TERMINATED)


== Status ==
Current time: 2023-11-03 01:02:32 (running for 02:31:29.98)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 137/1000000 (32 RUNNING, 105 TERMINATED)


== Status ==
Current time: 2023-11-03 01:02:37 (running for 02:31:35.04)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 137/1000000 (32 RUNNING, 105 TERMINATED)


2023-11-03 01:04:48,606	WARNING util.py:214 -- The `start_trial` operation took 0.858 s, which may be a performance bottleneck.
[2m[36m(train pid=654007)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=654007)[0m 
2023-11-03 01:04:50,521	WARNING util.py:214 -- The `start_trial` operation took 0.539 s, which may be a performance bottleneck.
[2m[36m(train pid=656516)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=656516)[0m 
[2m[36m(train pid=656509)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=656509)[0m 
[2m[36m(train pid=657922)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=657922)[0m 
[2m[36m(train pid=658857)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=658857)[0m 
== Status ==
Current time: 2023-11-03 01:02:42 (running for 02:31:40.29)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 137/1000000 (32 RUNNING, 105 TERMINATED)


== Status ==
Current time: 2023-11-03 01:02:48 (running for 02:31:45.89)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 138/1000000 (32 RUNNING, 106 TERMINATED)


== Status ==
Current time: 2023-11-03 01:04:46 (running for 02:33:43.87)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 138/1000000 (32 RUNNING, 106 TERMINATED)


== Status ==
Current time: 2023-11-03 01:04:55 (running for 02:33:53.12)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 143/1000000 (32 RUNNING, 111 TERMINATED)


== Status ==
Current time: 2023-11-03 01:06:50 (running for 02:35:48.21)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 143/1000000 (32 RUNNING, 111 TERMINATED)


== Status ==
Current time: 2023-11-03 01:06:57 (running for 02:35:54.85)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 144/1000000 (32 RUNNING, 112 TERMINATED)


== Status ==
Current time: 2023-11-03 01:08:56 (running for 02:37:53.89)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 144/1000000 (32 RUNNING, 112 TERMINATED)


== Status ==
Current time: 2023-11-03 01:09:03 (running for 02:38:00.85)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 146/1000000 (32 RUNNING, 114 TERMINATED)


== Status ==
Current time: 2023-11-03 01:11:11 (running for 02:40:09.31)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 146/1000000 (32 RUNNING, 114 TERMINATED)


== Status ==
Current time: 2023-11-03 01:11:16 (running for 02:40:14.46)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 146/1000000 (32 RUNNING, 114 TERMINATED)


== Status ==
Current time: 2023-11-03 01:11:22 (running for 02:40:20.38)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 146/1000000 (32 RUNNING, 114 TERMINATED)


== Status ==
Current time: 2023-11-03 01:11:27 (running for 02:40:25.48)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 146/1000000 (32 RUNNING, 114 TERMINATED)


== Status ==
Current time: 2023-11-03 01:11:32 (running for 02:40:30.50)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 146/1000000 (32 RUNNING, 114 TERMINATED)


== Status ==
Current time: 2023-11-03 01:11:37 (running for 02:40:35.50)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 146/1000000 (32 RUNNING, 114 TERMINATED)


== Status ==
Current time: 2023-11-03 01:11:43 (running for 02:40:40.74)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 146/1000000 (32 RUNNING, 114 TERMINATED)


[2m[36m(train pid=660945)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=660945)[0m 
[2m[36m(train pid=662976)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=662976)[0m 
[2m[36m(train pid=664038)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=664038)[0m 
[2m[36m(train pid=664991)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=664991)[0m 
[2m[36m(train pid=666271)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=666271)[0m 
[2m[36m(train pid=667567)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=667567)[0m 
[2m[36m(train pid=667574)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=667574)[0m 
== Status ==
Current time: 2023-11-03 01:11:48 (running for 02:40:45.86)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 146/1000000 (32 RUNNING, 114 TERMINATED)


== Status ==
Current time: 2023-11-03 01:11:53 (running for 02:40:51.15)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 146/1000000 (32 RUNNING, 114 TERMINATED)


== Status ==
Current time: 2023-11-03 01:11:58 (running for 02:40:56.18)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 146/1000000 (32 RUNNING, 114 TERMINATED)


== Status ==
Current time: 2023-11-03 01:12:08 (running for 02:41:06.13)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 147/1000000 (32 RUNNING, 115 TERMINATED)


== Status ==
Current time: 2023-11-03 01:14:10 (running for 02:43:07.77)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 147/1000000 (32 RUNNING, 115 TERMINATED)


== Status ==
Current time: 2023-11-03 01:14:17 (running for 02:43:14.77)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 149/1000000 (32 RUNNING, 117 TERMINATED)


== Status ==
Current time: 2023-11-03 01:16:17 (running for 02:45:14.89)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 149/1000000 (32 RUNNING, 117 TERMINATED)


== Status ==
Current time: 2023-11-03 01:16:24 (running for 02:45:21.91)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 151/1000000 (32 RUNNING, 119 TERMINATED)


== Status ==
Current time: 2023-11-03 01:18:24 (running for 02:47:21.60)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 151/1000000 (32 RUNNING, 119 TERMINATED)


== Status ==
Current time: 2023-11-03 01:18:30 (running for 02:47:28.04)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 153/1000000 (32 RUNNING, 121 TERMINATED)


== Status ==
Current time: 2023-11-03 01:20:30 (running for 02:49:27.93)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 153/1000000 (32 RUNNING, 121 TERMINATED)


== Status ==
Current time: 2023-11-03 01:20:36 (running for 02:49:34.03)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 154/1000000 (32 RUNNING, 122 TERMINATED)


== Status ==
Current time: 2023-11-03 01:22:36 (running for 02:51:33.92)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 154/1000000 (32 RUNNING, 122 TERMINATED)


== Status ==
Current time: 2023-11-03 01:22:44 (running for 02:51:42.08)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 157/1000000 (32 RUNNING, 125 TERMINATED)


== Status ==
Current time: 2023-11-03 01:24:46 (running for 02:53:43.83)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 157/1000000 (32 RUNNING, 125 TERMINATED)


[2m[36m(train pid=669621)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=669621)[0m 
[2m[36m(train pid=671870)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=671870)[0m 
2023-11-03 01:31:54,871	WARNING util.py:214 -- The `start_trial` operation took 0.540 s, which may be a performance bottleneck.
[2m[36m(train pid=672978)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=672978)[0m 
== Status ==
Current time: 2023-11-03 01:24:51 (running for 02:53:49.02)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 157/1000000 (32 RUNNING, 125 TERMINATED)


== Status ==
Current time: 2023-11-03 01:24:56 (running for 02:53:54.22)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 157/1000000 (32 RUNNING, 125 TERMINATED)


== Status ==
Current time: 2023-11-03 01:25:01 (running for 02:53:59.40)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 157/1000000 (32 RUNNING, 125 TERMINATED)


== Status ==
Current time: 2023-11-03 01:25:07 (running for 02:54:04.71)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 157/1000000 (32 RUNNING, 125 TERMINATED)


== Status ==
Current time: 2023-11-03 01:25:12 (running for 02:54:09.79)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 157/1000000 (32 RUNNING, 125 TERMINATED)


== Status ==
Current time: 2023-11-03 01:25:17 (running for 02:54:15.03)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 157/1000000 (32 RUNNING, 125 TERMINATED)


== Status ==
Current time: 2023-11-03 01:25:22 (running for 02:54:20.21)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 157/1000000 (32 RUNNING, 125 TERMINATED)


== Status ==
Current time: 2023-11-03 01:25:27 (running for 02:54:25.52)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 157/1000000 (32 RUNNING, 125 TERMINATED)


== Status ==
Current time: 2023-11-03 01:25:33 (running for 02:54:30.73)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 157/1000000 (32 RUNNING, 125 TERMINATED)


== Status ==
Current time: 2023-11-03 01:25:41 (running for 02:54:39.51)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 158/1000000 (32 RUNNING, 126 TERMINATED)


== Status ==
Current time: 2023-11-03 01:27:41 (running for 02:56:39.53)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 158/1000000 (32 RUNNING, 126 TERMINATED)


== Status ==
Current time: 2023-11-03 01:27:48 (running for 02:56:46.19)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 160/1000000 (32 RUNNING, 128 TERMINATED)


== Status ==
Current time: 2023-11-03 01:29:48 (running for 02:58:45.68)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 160/1000000 (32 RUNNING, 128 TERMINATED)


== Status ==
Current time: 2023-11-03 01:29:53 (running for 02:58:50.81)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 162/1000000 (32 RUNNING, 130 TERMINATED)


== Status ==
Current time: 2023-11-03 01:31:53 (running for 03:00:50.75)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 162/1000000 (32 RUNNING, 130 TERMINATED)


[2m[36m(train pid=674379)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=674379)[0m 
[2m[36m(train pid=675851)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=675851)[0m 
[2m[36m(train pid=676918)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=676918)[0m 
[2m[36m(train pid=678902)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=678902)[0m 
[2m[36m(train pid=680888)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=680888)[0m 
[2m[36m(train pid=682380)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=682380)[0m 
[2m[36m(train pid=682386)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=682386)[0m 
[2m[36m(train pid=684335)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=684335)[0m 
== Status ==
Current time: 2023-11-03 01:31:59 (running for 03:00:56.77)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 164/1000000 (32 RUNNING, 132 TERMINATED)


== Status ==
Current time: 2023-11-03 01:33:55 (running for 03:02:53.21)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 164/1000000 (32 RUNNING, 132 TERMINATED)


== Status ==
Current time: 2023-11-03 01:34:02 (running for 03:03:00.17)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 166/1000000 (32 RUNNING, 134 TERMINATED)


== Status ==
Current time: 2023-11-03 01:36:00 (running for 03:04:57.80)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 166/1000000 (32 RUNNING, 134 TERMINATED)


== Status ==
Current time: 2023-11-03 01:36:06 (running for 03:05:04.13)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 167/1000000 (32 RUNNING, 135 TERMINATED)


== Status ==
Current time: 2023-11-03 01:38:06 (running for 03:07:04.20)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 167/1000000 (32 RUNNING, 135 TERMINATED)


== Status ==
Current time: 2023-11-03 01:38:13 (running for 03:07:11.15)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 168/1000000 (32 RUNNING, 136 TERMINATED)


== Status ==
Current time: 2023-11-03 01:40:11 (running for 03:09:09.42)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 168/1000000 (32 RUNNING, 136 TERMINATED)


== Status ==
Current time: 2023-11-03 01:40:18 (running for 03:09:16.33)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 170/1000000 (32 RUNNING, 138 TERMINATED)


== Status ==
Current time: 2023-11-03 01:42:17 (running for 03:11:15.09)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 170/1000000 (32 RUNNING, 138 TERMINATED)


== Status ==
Current time: 2023-11-03 01:42:25 (running for 03:11:23.27)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 173/1000000 (32 RUNNING, 141 TERMINATED)


== Status ==
Current time: 2023-11-03 01:44:17 (running for 03:13:14.87)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 173/1000000 (32 RUNNING, 141 TERMINATED)


== Status ==
Current time: 2023-11-03 01:44:24 (running for 03:13:21.69)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 175/1000000 (32 RUNNING, 143 TERMINATED)


== Status ==
Current time: 2023-11-03 01:46:25 (running for 03:15:22.95)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 175/1000000 (32 RUNNING, 143 TERMINATED)


== Status ==
Current time: 2023-11-03 01:46:31 (running for 03:15:29.26)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 22ce62f5 with val_loss=479.2687578609713 and parameters={'early_stopping_rounds': 11, 'learning_rate': 0.2, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 176/1000000 (32 RUNNING, 144 TERMINATED)


2023-11-03 01:48:33,000	WARNING util.py:214 -- The `start_trial` operation took 0.567 s, which may be a performance bottleneck.
[2m[36m(train pid=685543)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=685543)[0m 
[2m[36m(train pid=687324)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=687324)[0m 
[2m[36m(train pid=687326)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=687326)[0m 
2023-11-03 01:50:30,794	WARNING util.py:214 -- The `start_trial` operation took 0.555 s, which may be a performance bottleneck.
[2m[36m(train pid=689347)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=689347)[0m 
2023-11-03 01:54:48,107	WARNING util.py:214 -- The `start_trial` operation took 0.552 s, which may be a performance bottleneck.
[2m[36m(train pid=691153)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=691153)[0m 
[2m[36m(train pid=694123)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=694123)[0m 
[2m[36m(train pid=693985)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=693985)[0m 
[2m[36m(train pid=695648)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=695648)[0m 
[2m[36m(train pid=697579)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=697579)[0m 
[2m[36m(train pid=697583)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=697583)[0m 
== Status ==
Current time: 2023-11-03 01:48:31 (running for 03:17:29.03)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fef8064b with val_loss=479.1437449483613 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08278693655268239, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 176/1000000 (32 RUNNING, 144 TERMINATED)


== Status ==
Current time: 2023-11-03 01:48:38 (running for 03:17:36.35)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fef8064b with val_loss=479.1437449483613 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08278693655268239, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 179/1000000 (32 RUNNING, 147 TERMINATED)


== Status ==
Current time: 2023-11-03 01:50:28 (running for 03:19:25.67)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fef8064b with val_loss=479.1437449483613 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08278693655268239, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 179/1000000 (32 RUNNING, 147 TERMINATED)


== Status ==
Current time: 2023-11-03 01:50:35 (running for 03:19:33.40)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fef8064b with val_loss=479.1437449483613 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08278693655268239, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 183/1000000 (32 RUNNING, 151 TERMINATED)


== Status ==
Current time: 2023-11-03 01:52:44 (running for 03:21:41.87)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fef8064b with val_loss=479.1437449483613 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08278693655268239, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 183/1000000 (32 RUNNING, 151 TERMINATED)


== Status ==
Current time: 2023-11-03 01:52:49 (running for 03:21:47.09)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fef8064b with val_loss=479.1437449483613 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08278693655268239, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 183/1000000 (32 RUNNING, 151 TERMINATED)


== Status ==
Current time: 2023-11-03 01:52:55 (running for 03:21:53.44)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fef8064b with val_loss=479.1437449483613 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08278693655268239, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 184/1000000 (32 RUNNING, 152 TERMINATED)


== Status ==
Current time: 2023-11-03 01:54:45 (running for 03:23:43.47)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fef8064b with val_loss=479.1437449483613 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08278693655268239, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 184/1000000 (32 RUNNING, 152 TERMINATED)


== Status ==
Current time: 2023-11-03 01:54:50 (running for 03:23:48.53)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fef8064b with val_loss=479.1437449483613 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08278693655268239, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 189/1000000 (32 RUNNING, 157 TERMINATED)


== Status ==
Current time: 2023-11-03 01:56:45 (running for 03:25:42.71)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fef8064b with val_loss=479.1437449483613 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08278693655268239, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 189/1000000 (32 RUNNING, 157 TERMINATED)


== Status ==
Current time: 2023-11-03 01:56:51 (running for 03:25:49.30)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fef8064b with val_loss=479.1437449483613 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08278693655268239, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 191/1000000 (32 RUNNING, 159 TERMINATED)


== Status ==
Current time: 2023-11-03 01:58:43 (running for 03:27:40.76)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 191/1000000 (32 RUNNING, 159 TERMINATED)


== Status ==
Current time: 2023-11-03 01:58:51 (running for 03:27:48.75)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 195/1000000 (32 RUNNING, 163 TERMINATED)


== Status ==
Current time: 2023-11-03 02:00:42 (running for 03:29:40.42)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 195/1000000 (32 RUNNING, 163 TERMINATED)


[2m[36m(train pid=699511)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=699511)[0m 
[2m[36m(train pid=701167)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=701167)[0m 
[2m[36m(train pid=703123)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=703123)[0m 
[2m[36m(train pid=703126)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=703126)[0m 
[2m[36m(train pid=705810)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=705810)[0m 
[2m[36m(train pid=708543)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=708543)[0m 
[2m[36m(train pid=708549)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=708549)[0m 
[2m[36m(train pid=710773)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=710773)[0m 
[2m[36m(train pid=710766)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=710766)[0m 
[2m[36m(train pid=712423)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=712423)[0m 
== Status ==
Current time: 2023-11-03 02:00:49 (running for 03:29:46.92)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 197/1000000 (32 RUNNING, 165 TERMINATED)


== Status ==
Current time: 2023-11-03 02:02:52 (running for 03:31:50.53)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 197/1000000 (32 RUNNING, 165 TERMINATED)


== Status ==
Current time: 2023-11-03 02:02:59 (running for 03:31:57.14)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 199/1000000 (32 RUNNING, 167 TERMINATED)


== Status ==
Current time: 2023-11-03 02:04:58 (running for 03:33:55.63)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 199/1000000 (32 RUNNING, 167 TERMINATED)


== Status ==
Current time: 2023-11-03 02:05:05 (running for 03:34:03.01)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 202/1000000 (32 RUNNING, 170 TERMINATED)


== Status ==
Current time: 2023-11-03 02:06:57 (running for 03:35:54.83)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 202/1000000 (32 RUNNING, 170 TERMINATED)


== Status ==
Current time: 2023-11-03 02:07:03 (running for 03:36:01.52)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 204/1000000 (32 RUNNING, 172 TERMINATED)


== Status ==
Current time: 2023-11-03 02:08:54 (running for 03:37:52.45)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 204/1000000 (32 RUNNING, 172 TERMINATED)


== Status ==
Current time: 2023-11-03 02:09:03 (running for 03:38:01.50)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 210/1000000 (32 RUNNING, 178 TERMINATED)


== Status ==
Current time: 2023-11-03 02:11:04 (running for 03:40:01.63)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 210/1000000 (32 RUNNING, 178 TERMINATED)


== Status ==
Current time: 2023-11-03 02:11:11 (running for 03:40:09.03)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 213/1000000 (32 RUNNING, 181 TERMINATED)


== Status ==
Current time: 2023-11-03 02:13:04 (running for 03:42:01.96)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 213/1000000 (32 RUNNING, 181 TERMINATED)


== Status ==
Current time: 2023-11-03 02:13:11 (running for 03:42:09.12)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 215/1000000 (32 RUNNING, 183 TERMINATED)


== Status ==
Current time: 2023-11-03 02:15:03 (running for 03:44:01.19)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 215/1000000 (32 RUNNING, 183 TERMINATED)


2023-11-03 02:17:13,232	WARNING util.py:214 -- The `start_trial` operation took 0.572 s, which may be a performance bottleneck.
[2m[36m(train pid=714732)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=714732)[0m 
2023-11-03 02:19:09,697	WARNING util.py:214 -- The `start_trial` operation took 0.538 s, which may be a performance bottleneck.
[2m[36m(train pid=717512)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=717512)[0m 
[2m[36m(train pid=717516)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=717516)[0m 
[2m[36m(train pid=720515)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=720515)[0m 
[2m[36m(train pid=724028)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=724028)[0m 
[2m[36m(train pid=726944)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=726944)[0m 
[2m[36m(train pid=726946)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=726946)[0m 
[2m[36m(train pid=726939)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=726939)[0m 
[2m[36m(train pid=729669)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=729669)[0m 
[2m[36m(train pid=729819)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=729819)[0m 
[2m[36m(train pid=732191)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=732191)[0m 
2023-11-03 02:28:54,153	WARNING util.py:214 -- The `start_trial` operation took 0.756 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 02:15:11 (running for 03:44:09.20)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 2a13cae0 with val_loss=479.1129333188119 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.08668104947471822, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 219/1000000 (32 RUNNING, 187 TERMINATED)


== Status ==
Current time: 2023-11-03 02:17:11 (running for 03:46:08.81)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 219/1000000 (32 RUNNING, 187 TERMINATED)


== Status ==
Current time: 2023-11-03 02:17:19 (running for 03:46:17.20)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 222/1000000 (32 RUNNING, 190 TERMINATED)


== Status ==
Current time: 2023-11-03 02:19:07 (running for 03:48:05.38)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 222/1000000 (32 RUNNING, 190 TERMINATED)


== Status ==
Current time: 2023-11-03 02:19:14 (running for 03:48:12.57)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 225/1000000 (32 RUNNING, 193 TERMINATED)


== Status ==
Current time: 2023-11-03 02:21:08 (running for 03:50:06.14)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 225/1000000 (32 RUNNING, 193 TERMINATED)


== Status ==
Current time: 2023-11-03 02:21:17 (running for 03:50:15.19)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 230/1000000 (32 RUNNING, 198 TERMINATED)


== Status ==
Current time: 2023-11-03 02:23:10 (running for 03:52:08.39)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 230/1000000 (32 RUNNING, 198 TERMINATED)


== Status ==
Current time: 2023-11-03 02:23:19 (running for 03:52:17.22)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 235/1000000 (32 RUNNING, 203 TERMINATED)


== Status ==
Current time: 2023-11-03 02:25:04 (running for 03:54:02.11)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 235/1000000 (32 RUNNING, 203 TERMINATED)


== Status ==
Current time: 2023-11-03 02:25:09 (running for 03:54:07.37)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 239/1000000 (32 RUNNING, 207 TERMINATED)


== Status ==
Current time: 2023-11-03 02:27:01 (running for 03:55:58.87)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 239/1000000 (32 RUNNING, 207 TERMINATED)


== Status ==
Current time: 2023-11-03 02:27:08 (running for 03:56:06.35)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 242/1000000 (32 RUNNING, 210 TERMINATED)


== Status ==
Current time: 2023-11-03 02:28:50 (running for 03:57:48.23)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 242/1000000 (32 RUNNING, 210 TERMINATED)


[2m[36m(train pid=735681)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=735681)[0m 
[2m[36m(train pid=735687)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=735687)[0m 
[2m[36m(train pid=735689)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=735689)[0m 
[2m[36m(train pid=740210)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=740210)[0m 
[2m[36m(train pid=743801)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=743801)[0m 
[2m[36m(train pid=746308)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=746308)[0m 
[2m[36m(train pid=747783)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=747783)[0m 
[2m[36m(train pid=747803)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=747803)[0m 
[2m[36m(train pid=747935)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=747935)[0m 
[2m[36m(train pid=750465)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=750465)[0m 
[2m[36m(train pid=750462)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=750462)[0m 
[2m[36m(train pid=750328)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=750328)[0m 
[2m[36m(train pid=752372)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=752372)[0m 
== Status ==
Current time: 2023-11-03 02:28:55 (running for 03:57:53.38)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 248/1000000 (32 RUNNING, 216 TERMINATED)


== Status ==
Current time: 2023-11-03 02:30:46 (running for 03:59:43.87)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 248/1000000 (32 RUNNING, 216 TERMINATED)


== Status ==
Current time: 2023-11-03 02:30:52 (running for 03:59:50.44)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 250/1000000 (32 RUNNING, 218 TERMINATED)


== Status ==
Current time: 2023-11-03 02:32:28 (running for 04:01:25.84)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 250/1000000 (32 RUNNING, 218 TERMINATED)


== Status ==
Current time: 2023-11-03 02:32:33 (running for 04:01:31.12)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 259/1000000 (1 PENDING, 31 RUNNING, 227 TERMINATED)


== Status ==
Current time: 2023-11-03 02:34:23 (running for 04:03:21.08)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 259/1000000 (32 RUNNING, 227 TERMINATED)


== Status ==
Current time: 2023-11-03 02:36:04 (running for 04:05:02.10)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 259/1000000 (32 RUNNING, 227 TERMINATED)


== Status ==
Current time: 2023-11-03 02:36:13 (running for 04:05:11.57)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 265/1000000 (32 RUNNING, 233 TERMINATED)


== Status ==
Current time: 2023-11-03 02:37:57 (running for 04:06:55.49)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 265/1000000 (32 RUNNING, 233 TERMINATED)


== Status ==
Current time: 2023-11-03 02:38:05 (running for 04:07:03.52)
Memory usage on this node: 23.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 269/1000000 (32 RUNNING, 237 TERMINATED)


== Status ==
Current time: 2023-11-03 02:39:51 (running for 04:08:49.54)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 269/1000000 (32 RUNNING, 237 TERMINATED)


== Status ==
Current time: 2023-11-03 02:39:58 (running for 04:08:56.49)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 271/1000000 (32 RUNNING, 239 TERMINATED)


== Status ==
Current time: 2023-11-03 02:41:58 (running for 04:10:56.07)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 271/1000000 (32 RUNNING, 239 TERMINATED)


== Status ==
Current time: 2023-11-03 02:42:05 (running for 04:11:03.51)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 273/1000000 (32 RUNNING, 241 TERMINATED)


[2m[36m(train pid=755590)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=755590)[0m 
[2m[36m(train pid=758569)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=758569)[0m 
[2m[36m(train pid=760659)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=760659)[0m 
[2m[36m(train pid=763300)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=763300)[0m 
[2m[36m(train pid=765420)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=765420)[0m 
[2m[36m(train pid=765395)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=765395)[0m 
[2m[36m(train pid=767797)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=767797)[0m 
[2m[36m(train pid=767941)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=767941)[0m 
[2m[36m(train pid=771122)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=771122)[0m 
[2m[36m(train pid=771128)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=771128)[0m 
== Status ==
Current time: 2023-11-03 02:43:58 (running for 04:12:55.78)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 273/1000000 (32 RUNNING, 241 TERMINATED)


== Status ==
Current time: 2023-11-03 02:44:06 (running for 04:13:03.72)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 276/1000000 (32 RUNNING, 244 TERMINATED)


== Status ==
Current time: 2023-11-03 02:45:47 (running for 04:14:44.96)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 276/1000000 (32 RUNNING, 244 TERMINATED)


== Status ==
Current time: 2023-11-03 02:45:56 (running for 04:14:54.58)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 283/1000000 (32 RUNNING, 251 TERMINATED)


== Status ==
Current time: 2023-11-03 02:47:56 (running for 04:16:53.70)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 283/1000000 (32 RUNNING, 251 TERMINATED)


== Status ==
Current time: 2023-11-03 02:48:02 (running for 04:16:59.81)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 284/1000000 (32 RUNNING, 252 TERMINATED)


== Status ==
Current time: 2023-11-03 02:49:59 (running for 04:18:56.83)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 284/1000000 (32 RUNNING, 252 TERMINATED)


== Status ==
Current time: 2023-11-03 02:50:08 (running for 04:19:05.91)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 287/1000000 (32 RUNNING, 255 TERMINATED)


== Status ==
Current time: 2023-11-03 02:51:53 (running for 04:20:51.49)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 287/1000000 (32 RUNNING, 255 TERMINATED)


== Status ==
Current time: 2023-11-03 02:52:03 (running for 04:21:00.87)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 292/1000000 (32 RUNNING, 260 TERMINATED)


== Status ==
Current time: 2023-11-03 02:53:57 (running for 04:22:55.02)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 292/1000000 (32 RUNNING, 260 TERMINATED)


== Status ==
Current time: 2023-11-03 02:54:05 (running for 04:23:02.83)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 295/1000000 (32 RUNNING, 263 TERMINATED)


== Status ==
Current time: 2023-11-03 02:55:47 (running for 04:24:44.84)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 295/1000000 (32 RUNNING, 263 TERMINATED)


== Status ==
Current time: 2023-11-03 02:55:56 (running for 04:24:53.95)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 300/1000000 (32 RUNNING, 268 TERMINATED)


[2m[36m(train pid=773637)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=773637)[0m 
[2m[36m(train pid=777259)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=777259)[0m 
[2m[36m(train pid=777275)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=777275)[0m 
2023-11-03 03:01:49,125	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.590 s, which may be a performance bottleneck.
2023-11-03 03:01:49,126	WARNING util.py:214 -- The `process_trial_result` operation took 0.591 s, which may be a performance bottleneck.
2023-11-03 03:01:49,126	WARNING util.py:214 -- Processing trial results took 0.591 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 03:01:49,126	WARNING util.py:214 -- The `process_trial_result` operation took 0.591 s, which may be a performance bottleneck.
[2m[36m(train pid=780128)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=780128)[0m 
[2m[36m(train pid=784557)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=784557)[0m 
[2m[36m(train pid=784565)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=784565)[0m 
[2m[36m(train pid=789311)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=789311)[0m 
[2m[36m(train pid=789315)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=789315)[0m 
2023-11-03 03:05:31,823	WARNING util.py:214 -- The `start_trial` operation took 0.589 s, which may be a performance bottleneck.
2023-11-03 03:05:32,632	WARNING util.py:214 -- The `start_trial` operation took 0.512 s, which may be a performance bottleneck.
[2m[36m(train pid=794081)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=794081)[0m 
[2m[36m(train pid=794074)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=794074)[0m 
2023-11-03 03:07:13,037	WARNING util.py:214 -- The `start_trial` operation took 0.501 s, which may be a performance bottleneck.
2023-11-03 03:07:20,957	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.684 s, which may be a performance bottleneck.
2023-11-03 03:07:20,957	WARNING util.py:214 -- The `process_trial_result` operation took 0.684 s, which may be a performance bottleneck.
2023-11-03 03:07:20,957	WARNING util.py:214 -- Processing trial results took 0.684 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 03:07:20,957	WARNING util.py:214 -- The `process_trial_result` operation took 0.685 s, which may be a performance bottleneck.
[2m[36m(train pid=798247)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=798247)[0m 
[2m[36m(train pid=798241)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=798241)[0m 
== Status ==
Current time: 2023-11-03 02:57:52 (running for 04:26:50.58)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 300/1000000 (32 RUNNING, 268 TERMINATED)


== Status ==
Current time: 2023-11-03 02:58:01 (running for 04:26:59.22)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 305/1000000 (32 RUNNING, 273 TERMINATED)


== Status ==
Current time: 2023-11-03 02:59:47 (running for 04:28:45.15)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 305/1000000 (32 RUNNING, 273 TERMINATED)


== Status ==
Current time: 2023-11-03 02:59:55 (running for 04:28:53.38)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 309/1000000 (32 RUNNING, 277 TERMINATED)


== Status ==
Current time: 2023-11-03 03:01:47 (running for 04:30:45.44)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 309/1000000 (32 RUNNING, 277 TERMINATED)


== Status ==
Current time: 2023-11-03 03:01:55 (running for 04:30:53.22)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 314/1000000 (32 RUNNING, 282 TERMINATED)


== Status ==
Current time: 2023-11-03 03:03:34 (running for 04:32:32.04)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 314/1000000 (32 RUNNING, 282 TERMINATED)


== Status ==
Current time: 2023-11-03 03:03:44 (running for 04:32:42.02)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 321/1000000 (32 RUNNING, 289 TERMINATED)


== Status ==
Current time: 2023-11-03 03:05:29 (running for 04:34:27.19)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 321/1000000 (32 RUNNING, 289 TERMINATED)


== Status ==
Current time: 2023-11-03 03:05:38 (running for 04:34:36.03)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 326/1000000 (32 RUNNING, 294 TERMINATED)


== Status ==
Current time: 2023-11-03 03:07:09 (running for 04:36:06.93)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 326/1000000 (32 RUNNING, 294 TERMINATED)


== Status ==
Current time: 2023-11-03 03:07:14 (running for 04:36:12.03)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 334/1000000 (31 RUNNING, 303 TERMINATED)


== Status ==
Current time: 2023-11-03 03:07:20 (running for 04:36:18.56)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 337/1000000 (32 RUNNING, 305 TERMINATED)


== Status ==
Current time: 2023-11-03 03:09:10 (running for 04:38:08.47)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 337/1000000 (32 RUNNING, 305 TERMINATED)


[2m[36m(train pid=801478)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=801478)[0m 
[2m[36m(train pid=801476)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=801476)[0m 
[2m[36m(train pid=805910)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=805910)[0m 
[2m[36m(train pid=805775)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=805775)[0m 
[2m[36m(train pid=810815)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=810815)[0m 
[2m[36m(train pid=810819)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=810819)[0m 
[2m[36m(train pid=810821)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=810821)[0m 
[2m[36m(train pid=816576)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=816576)[0m 
[2m[36m(train pid=816580)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=816580)[0m 
[2m[36m(train pid=819996)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=819996)[0m 
[2m[36m(train pid=823847)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=823847)[0m 
[2m[36m(train pid=828779)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=828779)[0m 
[2m[36m(train pid=828937)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=828937)[0m 
2023-11-03 03:20:50,546	WARNING util.py:214 -- The `start_trial` operation took 0.757 s, which may be a performance bottleneck.
[2m[36m(train pid=828946)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=828946)[0m 
[2m[36m(train pid=832253)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=832253)[0m 
[2m[36m(train pid=832412)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=832412)[0m 
== Status ==
Current time: 2023-11-03 03:09:18 (running for 04:38:16.07)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 340/1000000 (32 RUNNING, 308 TERMINATED)


== Status ==
Current time: 2023-11-03 03:11:08 (running for 04:40:06.48)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 340/1000000 (32 RUNNING, 308 TERMINATED)


== Status ==
Current time: 2023-11-03 03:11:14 (running for 04:40:11.96)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 344/1000000 (32 RUNNING, 312 TERMINATED)


== Status ==
Current time: 2023-11-03 03:12:56 (running for 04:41:54.24)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 344/1000000 (32 RUNNING, 312 TERMINATED)


== Status ==
Current time: 2023-11-03 03:13:03 (running for 04:42:00.85)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 349/1000000 (32 RUNNING, 317 TERMINATED)


== Status ==
Current time: 2023-11-03 03:14:33 (running for 04:43:30.73)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 349/1000000 (32 RUNNING, 317 TERMINATED)


== Status ==
Current time: 2023-11-03 03:14:38 (running for 04:43:35.89)
Memory usage on this node: 23.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 357/1000000 (31 RUNNING, 326 TERMINATED)


== Status ==
Current time: 2023-11-03 03:16:10 (running for 04:45:08.54)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 358/1000000 (32 RUNNING, 326 TERMINATED)


== Status ==
Current time: 2023-11-03 03:17:30 (running for 04:46:28.25)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 358/1000000 (32 RUNNING, 326 TERMINATED)


== Status ==
Current time: 2023-11-03 03:17:35 (running for 04:46:33.29)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 367/1000000 (31 RUNNING, 336 TERMINATED)


== Status ==
Current time: 2023-11-03 03:19:11 (running for 04:48:09.54)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 368/1000000 (1 PENDING, 31 RUNNING, 336 TERMINATED)


== Status ==
Current time: 2023-11-03 03:19:17 (running for 04:48:14.68)
Memory usage on this node: 23.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 377/1000000 (1 PENDING, 31 RUNNING, 345 TERMINATED)


== Status ==
Current time: 2023-11-03 03:20:49 (running for 04:49:47.31)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 377/1000000 (1 PENDING, 31 RUNNING, 345 TERMINATED)


== Status ==
Current time: 2023-11-03 03:20:54 (running for 04:49:52.45)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 384/1000000 (31 RUNNING, 353 TERMINATED)


[2m[36m(train pid=834750)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=834750)[0m 
[2m[36m(train pid=837987)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=837987)[0m 
[2m[36m(train pid=837993)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=837993)[0m 
[2m[36m(train pid=838011)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=838011)[0m 
[2m[36m(train pid=841507)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=841507)[0m 
[2m[36m(train pid=841659)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=841659)[0m 
[2m[36m(train pid=846667)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=846667)[0m 
[2m[36m(train pid=846538)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=846538)[0m 
[2m[36m(train pid=851862)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=851862)[0m 
[2m[36m(train pid=851864)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=851864)[0m 
2023-11-03 03:31:49,271	WARNING util.py:214 -- The `start_trial` operation took 1.003 s, which may be a performance bottleneck.
[2m[36m(train pid=855984)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=855984)[0m 
[2m[36m(train pid=859833)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=859833)[0m 
== Status ==
Current time: 2023-11-03 03:22:44 (running for 04:51:42.20)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 385/1000000 (32 RUNNING, 353 TERMINATED)


== Status ==
Current time: 2023-11-03 03:24:28 (running for 04:53:26.16)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 385/1000000 (32 RUNNING, 353 TERMINATED)


== Status ==
Current time: 2023-11-03 03:24:33 (running for 04:53:31.26)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 391/1000000 (32 RUNNING, 359 TERMINATED)


== Status ==
Current time: 2023-11-03 03:26:23 (running for 04:55:20.82)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 391/1000000 (32 RUNNING, 359 TERMINATED)


== Status ==
Current time: 2023-11-03 03:26:31 (running for 04:55:29.36)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 395/1000000 (32 RUNNING, 363 TERMINATED)


== Status ==
Current time: 2023-11-03 03:28:19 (running for 04:57:16.86)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 395/1000000 (32 RUNNING, 363 TERMINATED)


== Status ==
Current time: 2023-11-03 03:28:27 (running for 04:57:25.29)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 399/1000000 (32 RUNNING, 367 TERMINATED)


== Status ==
Current time: 2023-11-03 03:30:07 (running for 04:59:05.02)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 399/1000000 (32 RUNNING, 367 TERMINATED)


== Status ==
Current time: 2023-11-03 03:30:16 (running for 04:59:14.40)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 405/1000000 (32 RUNNING, 373 TERMINATED)


== Status ==
Current time: 2023-11-03 03:31:44 (running for 05:00:41.71)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 405/1000000 (32 RUNNING, 373 TERMINATED)


== Status ==
Current time: 2023-11-03 03:31:49 (running for 05:00:46.88)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 412/1000000 (31 RUNNING, 381 TERMINATED)


== Status ==
Current time: 2023-11-03 03:33:21 (running for 05:02:19.02)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 413/1000000 (1 PENDING, 30 RUNNING, 382 TERMINATED)


== Status ==
Current time: 2023-11-03 03:33:26 (running for 05:02:24.38)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 421/1000000 (31 RUNNING, 390 TERMINATED)


== Status ==
Current time: 2023-11-03 03:35:21 (running for 05:04:18.83)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 422/1000000 (32 RUNNING, 390 TERMINATED)


[2m[36m(train pid=865100)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=865100)[0m 
2023-11-03 03:36:54,859	WARNING util.py:214 -- The `start_trial` operation took 0.619 s, which may be a performance bottleneck.
[2m[36m(train pid=870991)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=870991)[0m 
[2m[36m(train pid=870998)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=870998)[0m 
[2m[36m(train pid=875103)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=875103)[0m 
[2m[36m(train pid=878082)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=878082)[0m 
[2m[36m(train pid=881365)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=881365)[0m 
[2m[36m(train pid=881510)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=881510)[0m 
[2m[36m(train pid=886090)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=886090)[0m 
[2m[36m(train pid=892458)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=892458)[0m 
[2m[36m(train pid=895750)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=895750)[0m 
== Status ==
Current time: 2023-11-03 03:36:49 (running for 05:05:46.88)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 422/1000000 (32 RUNNING, 390 TERMINATED)


== Status ==
Current time: 2023-11-03 03:36:54 (running for 05:05:52.47)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 429/1000000 (31 RUNNING, 398 TERMINATED)


== Status ==
Current time: 2023-11-03 03:38:07 (running for 05:07:05.14)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 430/1000000 (1 PENDING, 31 RUNNING, 398 TERMINATED)


== Status ==
Current time: 2023-11-03 03:38:12 (running for 05:07:10.47)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 440/1000000 (31 RUNNING, 409 TERMINATED)


== Status ==
Current time: 2023-11-03 03:39:48 (running for 05:08:45.96)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 441/1000000 (1 PENDING, 31 RUNNING, 409 TERMINATED)


== Status ==
Current time: 2023-11-03 03:39:53 (running for 05:08:51.23)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 449/1000000 (1 PENDING, 31 RUNNING, 417 TERMINATED)


== Status ==
Current time: 2023-11-03 03:41:50 (running for 05:10:48.38)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 449/1000000 (1 PENDING, 31 RUNNING, 417 TERMINATED)


== Status ==
Current time: 2023-11-03 03:41:59 (running for 05:10:56.77)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 453/1000000 (32 RUNNING, 421 TERMINATED)


== Status ==
Current time: 2023-11-03 03:43:51 (running for 05:12:48.62)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 453/1000000 (32 RUNNING, 421 TERMINATED)


== Status ==
Current time: 2023-11-03 03:43:58 (running for 05:12:55.96)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 455/1000000 (32 RUNNING, 423 TERMINATED)


== Status ==
Current time: 2023-11-03 03:45:40 (running for 05:14:37.78)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 455/1000000 (32 RUNNING, 423 TERMINATED)


== Status ==
Current time: 2023-11-03 03:45:45 (running for 05:14:42.91)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 462/1000000 (31 RUNNING, 431 TERMINATED)


== Status ==
Current time: 2023-11-03 03:47:15 (running for 05:16:13.37)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 463/1000000 (32 RUNNING, 431 TERMINATED)


== Status ==
Current time: 2023-11-03 03:48:38 (running for 05:17:35.99)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 463/1000000 (32 RUNNING, 431 TERMINATED)


[2m[36m(train pid=899322)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=899322)[0m 
[2m[36m(train pid=903109)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=903109)[0m 
[2m[36m(train pid=902961)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=902961)[0m 
[2m[36m(train pid=903263)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=903263)[0m 
[2m[36m(train pid=905642)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=905642)[0m 
[2m[36m(train pid=905646)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=905646)[0m 
[2m[36m(train pid=905648)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=905648)[0m 
2023-11-03 03:53:59,446	WARNING util.py:214 -- The `start_trial` operation took 0.543 s, which may be a performance bottleneck.
2023-11-03 03:54:01,230	WARNING util.py:214 -- The `start_trial` operation took 0.590 s, which may be a performance bottleneck.
[2m[36m(train pid=908941)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=908941)[0m 
[2m[36m(train pid=912801)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=912801)[0m 
2023-11-03 03:57:59,265	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
[2m[36m(train pid=916801)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=916801)[0m 
[2m[36m(train pid=921699)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=921699)[0m 
== Status ==
Current time: 2023-11-03 03:48:43 (running for 05:17:41.30)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 472/1000000 (31 RUNNING, 441 TERMINATED)


== Status ==
Current time: 2023-11-03 03:50:20 (running for 05:19:17.87)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 473/1000000 (1 PENDING, 31 RUNNING, 441 TERMINATED)


== Status ==
Current time: 2023-11-03 03:50:25 (running for 05:19:23.03)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 480/1000000 (32 RUNNING, 448 TERMINATED)


== Status ==
Current time: 2023-11-03 03:52:07 (running for 05:21:04.69)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 480/1000000 (32 RUNNING, 448 TERMINATED)


== Status ==
Current time: 2023-11-03 03:52:16 (running for 05:21:14.52)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 485/1000000 (32 RUNNING, 453 TERMINATED)


== Status ==
Current time: 2023-11-03 03:53:57 (running for 05:22:54.95)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 485/1000000 (32 RUNNING, 453 TERMINATED)


== Status ==
Current time: 2023-11-03 03:54:07 (running for 05:23:04.66)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 491/1000000 (32 RUNNING, 459 TERMINATED)


== Status ==
Current time: 2023-11-03 03:56:04 (running for 05:25:01.64)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 491/1000000 (32 RUNNING, 459 TERMINATED)


== Status ==
Current time: 2023-11-03 03:56:11 (running for 05:25:08.67)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 493/1000000 (32 RUNNING, 461 TERMINATED)


== Status ==
Current time: 2023-11-03 03:57:56 (running for 05:26:53.67)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 493/1000000 (32 RUNNING, 461 TERMINATED)


== Status ==
Current time: 2023-11-03 03:58:01 (running for 05:26:59.06)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 499/1000000 (31 RUNNING, 468 TERMINATED)


== Status ==
Current time: 2023-11-03 03:59:51 (running for 05:28:49.46)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 500/1000000 (32 RUNNING, 468 TERMINATED)


== Status ==
Current time: 2023-11-03 04:01:20 (running for 05:30:18.17)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 500/1000000 (32 RUNNING, 468 TERMINATED)


== Status ==
Current time: 2023-11-03 04:01:25 (running for 05:30:23.48)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 508/1000000 (1 PENDING, 30 RUNNING, 477 TERMINATED)


[2m[36m(train pid=925822)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=925822)[0m 
[2m[36m(train pid=929269)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=929269)[0m 
[2m[36m(train pid=929407)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=929407)[0m 
2023-11-03 04:04:43,380	WARNING util.py:214 -- The `start_trial` operation took 0.702 s, which may be a performance bottleneck.
[2m[36m(train pid=931260)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=931260)[0m 
[2m[36m(train pid=931267)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=931267)[0m 
[2m[36m(train pid=931270)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=931270)[0m 
[2m[36m(train pid=933500)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=933500)[0m 
2023-11-03 04:08:41,130	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.753 s, which may be a performance bottleneck.
2023-11-03 04:08:41,130	WARNING util.py:214 -- The `process_trial_result` operation took 0.754 s, which may be a performance bottleneck.
2023-11-03 04:08:41,130	WARNING util.py:214 -- Processing trial results took 0.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 04:08:41,131	WARNING util.py:214 -- The `process_trial_result` operation took 0.754 s, which may be a performance bottleneck.
[2m[36m(train pid=933502)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=933502)[0m 
[2m[36m(train pid=936007)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=936007)[0m 
[2m[36m(train pid=936009)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=936009)[0m 
[2m[36m(train pid=939279)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=939279)[0m 
2023-11-03 04:12:45,874	WARNING util.py:214 -- The `start_trial` operation took 0.509 s, which may be a performance bottleneck.
[2m[36m(train pid=942630)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=942630)[0m 
[2m[36m(train pid=942636)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=942636)[0m 
2023-11-03 04:14:44,503	WARNING util.py:214 -- The `start_trial` operation took 0.946 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 04:02:53 (running for 05:31:51.49)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 508/1000000 (31 RUNNING, 477 TERMINATED)


== Status ==
Current time: 2023-11-03 04:02:59 (running for 05:31:56.86)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 516/1000000 (31 RUNNING, 485 TERMINATED)


== Status ==
Current time: 2023-11-03 04:04:42 (running for 05:33:39.63)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 517/1000000 (1 PENDING, 31 RUNNING, 485 TERMINATED)


== Status ==
Current time: 2023-11-03 04:04:47 (running for 05:33:44.88)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 522/1000000 (32 RUNNING, 490 TERMINATED)


== Status ==
Current time: 2023-11-03 04:06:41 (running for 05:35:38.77)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 522/1000000 (32 RUNNING, 490 TERMINATED)


== Status ==
Current time: 2023-11-03 04:06:50 (running for 05:35:47.90)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 525/1000000 (32 RUNNING, 493 TERMINATED)


== Status ==
Current time: 2023-11-03 04:08:40 (running for 05:37:37.75)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 525/1000000 (32 RUNNING, 493 TERMINATED)


== Status ==
Current time: 2023-11-03 04:08:48 (running for 05:37:45.93)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 528/1000000 (32 RUNNING, 496 TERMINATED)


== Status ==
Current time: 2023-11-03 04:10:40 (running for 05:39:37.81)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 528/1000000 (32 RUNNING, 496 TERMINATED)


== Status ==
Current time: 2023-11-03 04:10:47 (running for 05:39:44.94)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 530/1000000 (32 RUNNING, 498 TERMINATED)


== Status ==
Current time: 2023-11-03 04:12:43 (running for 05:41:41.27)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 530/1000000 (32 RUNNING, 498 TERMINATED)


== Status ==
Current time: 2023-11-03 04:12:52 (running for 05:41:50.02)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 534/1000000 (32 RUNNING, 502 TERMINATED)


== Status ==
Current time: 2023-11-03 04:14:40 (running for 05:43:38.16)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 534/1000000 (32 RUNNING, 502 TERMINATED)


== Status ==
Current time: 2023-11-03 04:14:49 (running for 05:43:47.12)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 538/1000000 (32 RUNNING, 506 TERMINATED)


[2m[36m(train pid=946747)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=946747)[0m 
[2m[36m(train pid=950337)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=950337)[0m 
[2m[36m(train pid=950481)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=950481)[0m 
2023-11-03 04:18:30,305	WARNING util.py:214 -- The `start_trial` operation took 0.578 s, which may be a performance bottleneck.
[2m[36m(train pid=953150)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=953150)[0m 
[2m[36m(train pid=953157)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=953157)[0m 
[2m[36m(train pid=956167)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=956167)[0m 
[2m[36m(train pid=956022)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=956022)[0m 
[2m[36m(train pid=959523)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=959523)[0m 
[2m[36m(train pid=959521)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=959521)[0m 
2023-11-03 04:24:20,862	WARNING util.py:214 -- The `start_trial` operation took 0.514 s, which may be a performance bottleneck.
[2m[36m(train pid=963049)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=963049)[0m 
[2m[36m(train pid=963047)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=963047)[0m 
[2m[36m(train pid=966366)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=966366)[0m 
[2m[36m(train pid=966358)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=966358)[0m 
[2m[36m(train pid=967874)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=967874)[0m 
== Status ==
Current time: 2023-11-03 04:16:36 (running for 05:45:34.06)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 538/1000000 (32 RUNNING, 506 TERMINATED)


== Status ==
Current time: 2023-11-03 04:16:41 (running for 05:45:39.26)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 544/1000000 (31 RUNNING, 513 TERMINATED)


== Status ==
Current time: 2023-11-03 04:18:25 (running for 05:47:23.53)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 545/1000000 (1 PENDING, 31 RUNNING, 513 TERMINATED)


== Status ==
Current time: 2023-11-03 04:18:35 (running for 05:47:32.92)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 550/1000000 (32 RUNNING, 518 TERMINATED)


== Status ==
Current time: 2023-11-03 04:20:24 (running for 05:49:22.25)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 550/1000000 (32 RUNNING, 518 TERMINATED)


== Status ==
Current time: 2023-11-03 04:20:33 (running for 05:49:31.45)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 554/1000000 (32 RUNNING, 522 TERMINATED)


== Status ==
Current time: 2023-11-03 04:22:23 (running for 05:51:21.38)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 0af58bda with val_loss=479.0628430022928 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.10355840391578017, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 554/1000000 (32 RUNNING, 522 TERMINATED)


== Status ==
Current time: 2023-11-03 04:22:32 (running for 05:51:30.13)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 557/1000000 (32 RUNNING, 525 TERMINATED)


== Status ==
Current time: 2023-11-03 04:24:16 (running for 05:53:13.97)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 557/1000000 (32 RUNNING, 525 TERMINATED)


== Status ==
Current time: 2023-11-03 04:24:25 (running for 05:53:23.48)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 562/1000000 (32 RUNNING, 530 TERMINATED)


== Status ==
Current time: 2023-11-03 04:26:06 (running for 05:55:04.49)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 562/1000000 (32 RUNNING, 530 TERMINATED)


== Status ==
Current time: 2023-11-03 04:26:12 (running for 05:55:09.75)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 568/1000000 (1 PENDING, 31 RUNNING, 536 TERMINATED)


== Status ==
Current time: 2023-11-03 04:27:57 (running for 05:56:54.72)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 568/1000000 (32 RUNNING, 536 TERMINATED)


== Status ==
Current time: 2023-11-03 04:29:39 (running for 05:58:37.03)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 568/1000000 (32 RUNNING, 536 TERMINATED)


[2m[36m(train pid=970325)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=970325)[0m 
[2m[36m(train pid=970465)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=970465)[0m 
[2m[36m(train pid=973256)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=973256)[0m 
2023-11-03 04:33:51,426	WARNING util.py:214 -- The `start_trial` operation took 0.552 s, which may be a performance bottleneck.
[2m[36m(train pid=976147)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=976147)[0m 
[2m[36m(train pid=978987)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=978987)[0m 
[2m[36m(train pid=978995)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=978995)[0m 
[2m[36m(train pid=978992)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=978992)[0m 
2023-11-03 04:37:55,340	WARNING util.py:214 -- The `start_trial` operation took 0.509 s, which may be a performance bottleneck.
[2m[36m(train pid=981815)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=981815)[0m 
2023-11-03 04:39:50,457	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.516 s, which may be a performance bottleneck.
2023-11-03 04:39:50,457	WARNING util.py:214 -- The `process_trial_result` operation took 0.516 s, which may be a performance bottleneck.
2023-11-03 04:39:50,457	WARNING util.py:214 -- Processing trial results took 0.516 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 04:39:50,457	WARNING util.py:214 -- The `process_trial_result` operation took 0.517 s, which may be a performance bottleneck.
[2m[36m(train pid=985064)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=985064)[0m 
[2m[36m(train pid=985058)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=985058)[0m 
2023-11-03 04:41:47,421	WARNING util.py:214 -- The `start_trial` operation took 0.634 s, which may be a performance bottleneck.
[2m[36m(train pid=987699)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=987699)[0m 
[2m[36m(train pid=987828)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=987828)[0m 
== Status ==
Current time: 2023-11-03 04:29:49 (running for 05:58:46.79)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 574/1000000 (32 RUNNING, 542 TERMINATED)


== Status ==
Current time: 2023-11-03 04:31:45 (running for 06:00:43.04)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 574/1000000 (32 RUNNING, 542 TERMINATED)


== Status ==
Current time: 2023-11-03 04:31:53 (running for 06:00:50.96)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 577/1000000 (32 RUNNING, 545 TERMINATED)


== Status ==
Current time: 2023-11-03 04:33:48 (running for 06:02:46.59)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 577/1000000 (32 RUNNING, 545 TERMINATED)


== Status ==
Current time: 2023-11-03 04:33:57 (running for 06:02:55.44)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 581/1000000 (32 RUNNING, 549 TERMINATED)


== Status ==
Current time: 2023-11-03 04:35:51 (running for 06:04:48.91)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 581/1000000 (32 RUNNING, 549 TERMINATED)


== Status ==
Current time: 2023-11-03 04:35:56 (running for 06:04:54.42)
Memory usage on this node: 23.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 586/1000000 (32 RUNNING, 554 TERMINATED)


== Status ==
Current time: 2023-11-03 04:37:53 (running for 06:06:50.73)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 586/1000000 (32 RUNNING, 554 TERMINATED)


== Status ==
Current time: 2023-11-03 04:38:00 (running for 06:06:57.96)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 588/1000000 (32 RUNNING, 556 TERMINATED)


== Status ==
Current time: 2023-11-03 04:39:49 (running for 06:08:47.33)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 588/1000000 (32 RUNNING, 556 TERMINATED)


== Status ==
Current time: 2023-11-03 04:39:58 (running for 06:08:56.57)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 593/1000000 (32 RUNNING, 561 TERMINATED)


== Status ==
Current time: 2023-11-03 04:41:45 (running for 06:10:42.64)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 593/1000000 (32 RUNNING, 561 TERMINATED)


== Status ==
Current time: 2023-11-03 04:41:53 (running for 06:10:51.41)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 596/1000000 (32 RUNNING, 564 TERMINATED)


== Status ==
Current time: 2023-11-03 04:43:37 (running for 06:12:35.26)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 596/1000000 (32 RUNNING, 564 TERMINATED)


[2m[36m(train pid=990041)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=990041)[0m 
[2m[36m(train pid=990044)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=990044)[0m 
[2m[36m(train pid=990034)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=990034)[0m 
[2m[36m(train pid=992664)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=992664)[0m 
[2m[36m(train pid=992804)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=992804)[0m 
[2m[36m(train pid=995434)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=995434)[0m 
[2m[36m(train pid=995428)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=995428)[0m 
[2m[36m(train pid=998982)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=998982)[0m 
[2m[36m(train pid=998979)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=998979)[0m 
[2m[36m(train pid=1002311)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1002311)[0m 
[2m[36m(train pid=1002448)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1002448)[0m 
2023-11-03 04:53:16,912	WARNING util.py:214 -- The `start_trial` operation took 0.578 s, which may be a performance bottleneck.
[2m[36m(train pid=1004394)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1004394)[0m 
[2m[36m(train pid=1004542)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1004542)[0m 
[2m[36m(train pid=1006479)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1006479)[0m 
== Status ==
Current time: 2023-11-03 04:43:43 (running for 06:12:40.73)
Memory usage on this node: 23.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 601/1000000 (32 RUNNING, 569 TERMINATED)


== Status ==
Current time: 2023-11-03 04:45:35 (running for 06:14:33.19)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 601/1000000 (32 RUNNING, 569 TERMINATED)


== Status ==
Current time: 2023-11-03 04:45:41 (running for 06:14:38.70)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 604/1000000 (32 RUNNING, 572 TERMINATED)


== Status ==
Current time: 2023-11-03 04:47:31 (running for 06:16:28.83)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 604/1000000 (32 RUNNING, 572 TERMINATED)


== Status ==
Current time: 2023-11-03 04:47:40 (running for 06:16:37.87)
Memory usage on this node: 23.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 607/1000000 (32 RUNNING, 575 TERMINATED)


== Status ==
Current time: 2023-11-03 04:49:26 (running for 06:18:23.62)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 607/1000000 (32 RUNNING, 575 TERMINATED)


== Status ==
Current time: 2023-11-03 04:49:35 (running for 06:18:32.66)
Memory usage on this node: 23.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 611/1000000 (32 RUNNING, 579 TERMINATED)


== Status ==
Current time: 2023-11-03 04:51:20 (running for 06:20:18.26)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 611/1000000 (32 RUNNING, 579 TERMINATED)


== Status ==
Current time: 2023-11-03 04:51:26 (running for 06:20:24.38)
Memory usage on this node: 23.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 617/1000000 (32 RUNNING, 585 TERMINATED)


== Status ==
Current time: 2023-11-03 04:53:13 (running for 06:22:10.78)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 617/1000000 (32 RUNNING, 585 TERMINATED)


== Status ==
Current time: 2023-11-03 04:53:18 (running for 06:22:16.33)
Memory usage on this node: 23.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 622/1000000 (32 RUNNING, 590 TERMINATED)


== Status ==
Current time: 2023-11-03 04:55:13 (running for 06:24:11.03)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 622/1000000 (32 RUNNING, 590 TERMINATED)


== Status ==
Current time: 2023-11-03 04:55:21 (running for 06:24:18.95)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 625/1000000 (32 RUNNING, 593 TERMINATED)


== Status ==
Current time: 2023-11-03 04:57:22 (running for 06:26:20.29)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 625/1000000 (32 RUNNING, 593 TERMINATED)


[2m[36m(train pid=1008230)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1008230)[0m 
2023-11-03 04:59:23,029	WARNING util.py:214 -- The `start_trial` operation took 0.515 s, which may be a performance bottleneck.
2023-11-03 04:59:25,596	WARNING util.py:214 -- The `start_trial` operation took 0.655 s, which may be a performance bottleneck.
[2m[36m(train pid=1010549)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1010549)[0m 
[2m[36m(train pid=1010684)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1010684)[0m 
[2m[36m(train pid=1013038)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1013038)[0m 
2023-11-03 05:03:36,579	WARNING util.py:214 -- The `start_trial` operation took 0.924 s, which may be a performance bottleneck.
[2m[36m(train pid=1015768)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1015768)[0m 
[2m[36m(train pid=1015771)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1015771)[0m 
2023-11-03 05:05:37,003	WARNING util.py:214 -- The `start_trial` operation took 0.558 s, which may be a performance bottleneck.
[2m[36m(train pid=1017872)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1017872)[0m 
[2m[36m(train pid=1017875)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1017875)[0m 
[2m[36m(train pid=1019698)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1019698)[0m 
[2m[36m(train pid=1019701)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1019701)[0m 
[2m[36m(train pid=1021310)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1021310)[0m 
2023-11-03 05:11:48,608	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.543 s, which may be a performance bottleneck.
2023-11-03 05:11:48,608	WARNING util.py:214 -- The `process_trial_result` operation took 0.543 s, which may be a performance bottleneck.
2023-11-03 05:11:48,609	WARNING util.py:214 -- Processing trial results took 0.543 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 05:11:48,609	WARNING util.py:214 -- The `process_trial_result` operation took 0.543 s, which may be a performance bottleneck.
2023-11-03 05:11:50,198	WARNING util.py:214 -- The `start_trial` operation took 0.544 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 04:57:29 (running for 06:26:26.88)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 626/1000000 (32 RUNNING, 594 TERMINATED)


== Status ==
Current time: 2023-11-03 04:59:20 (running for 06:28:17.96)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 626/1000000 (32 RUNNING, 594 TERMINATED)


== Status ==
Current time: 2023-11-03 04:59:25 (running for 06:28:23.21)
Memory usage on this node: 23.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 630/1000000 (32 RUNNING, 598 TERMINATED)


== Status ==
Current time: 2023-11-03 05:01:27 (running for 06:30:25.18)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 630/1000000 (32 RUNNING, 598 TERMINATED)


== Status ==
Current time: 2023-11-03 05:01:35 (running for 06:30:32.92)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 632/1000000 (32 RUNNING, 600 TERMINATED)


== Status ==
Current time: 2023-11-03 05:03:32 (running for 06:32:30.58)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 632/1000000 (32 RUNNING, 600 TERMINATED)


== Status ==
Current time: 2023-11-03 05:03:42 (running for 06:32:40.09)
Memory usage on this node: 23.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 636/1000000 (32 RUNNING, 604 TERMINATED)


== Status ==
Current time: 2023-11-03 05:05:34 (running for 06:34:32.54)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 636/1000000 (32 RUNNING, 604 TERMINATED)


== Status ==
Current time: 2023-11-03 05:05:43 (running for 06:34:41.17)
Memory usage on this node: 23.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 639/1000000 (32 RUNNING, 607 TERMINATED)


== Status ==
Current time: 2023-11-03 05:07:38 (running for 06:36:36.40)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 639/1000000 (32 RUNNING, 607 TERMINATED)


== Status ==
Current time: 2023-11-03 05:07:47 (running for 06:36:45.38)
Memory usage on this node: 23.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 642/1000000 (32 RUNNING, 610 TERMINATED)


== Status ==
Current time: 2023-11-03 05:09:39 (running for 06:38:36.65)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 642/1000000 (32 RUNNING, 610 TERMINATED)


== Status ==
Current time: 2023-11-03 05:09:45 (running for 06:38:43.22)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 643/1000000 (32 RUNNING, 611 TERMINATED)


== Status ==
Current time: 2023-11-03 05:11:47 (running for 06:40:45.45)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 643/1000000 (32 RUNNING, 611 TERMINATED)


[2m[36m(train pid=1023830)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1023830)[0m 
[2m[36m(train pid=1026164)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1026164)[0m 
[2m[36m(train pid=1028442)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1028442)[0m 
[2m[36m(train pid=1028300)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1028300)[0m 
[2m[36m(train pid=1030964)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1030964)[0m 
2023-11-03 05:22:01,804	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.512 s, which may be a performance bottleneck.
2023-11-03 05:22:01,805	WARNING util.py:214 -- The `process_trial_result` operation took 0.513 s, which may be a performance bottleneck.
2023-11-03 05:22:01,805	WARNING util.py:214 -- Processing trial results took 0.513 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 05:22:01,805	WARNING util.py:214 -- The `process_trial_result` operation took 0.513 s, which may be a performance bottleneck.
[2m[36m(train pid=1033247)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1033247)[0m 
[2m[36m(train pid=1033244)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1033244)[0m 
[2m[36m(train pid=1035184)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1035184)[0m 
[2m[36m(train pid=1037040)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1037040)[0m 
== Status ==
Current time: 2023-11-03 05:11:55 (running for 06:40:52.82)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 645/1000000 (32 RUNNING, 613 TERMINATED)


== Status ==
Current time: 2023-11-03 05:13:51 (running for 06:42:48.91)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 645/1000000 (32 RUNNING, 613 TERMINATED)


== Status ==
Current time: 2023-11-03 05:14:00 (running for 06:42:57.95)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 649/1000000 (32 RUNNING, 617 TERMINATED)


== Status ==
Current time: 2023-11-03 05:15:55 (running for 06:44:52.82)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 649/1000000 (32 RUNNING, 617 TERMINATED)


== Status ==
Current time: 2023-11-03 05:16:04 (running for 06:45:02.52)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 653/1000000 (32 RUNNING, 621 TERMINATED)


== Status ==
Current time: 2023-11-03 05:18:00 (running for 06:46:58.24)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 653/1000000 (32 RUNNING, 621 TERMINATED)


== Status ==
Current time: 2023-11-03 05:18:08 (running for 06:47:06.04)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 656/1000000 (32 RUNNING, 624 TERMINATED)


== Status ==
Current time: 2023-11-03 05:20:06 (running for 06:49:03.64)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 656/1000000 (32 RUNNING, 624 TERMINATED)


== Status ==
Current time: 2023-11-03 05:20:12 (running for 06:49:09.78)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 659/1000000 (32 RUNNING, 627 TERMINATED)


== Status ==
Current time: 2023-11-03 05:22:04 (running for 06:51:02.18)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 659/1000000 (32 RUNNING, 627 TERMINATED)


== Status ==
Current time: 2023-11-03 05:22:12 (running for 06:51:10.35)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 662/1000000 (32 RUNNING, 630 TERMINATED)


== Status ==
Current time: 2023-11-03 05:24:17 (running for 06:53:14.75)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 662/1000000 (32 RUNNING, 630 TERMINATED)


== Status ==
Current time: 2023-11-03 05:24:24 (running for 06:53:21.83)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 663/1000000 (32 RUNNING, 631 TERMINATED)


== Status ==
Current time: 2023-11-03 05:26:21 (running for 06:55:19.39)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 663/1000000 (32 RUNNING, 631 TERMINATED)


[2m[36m(train pid=1038671)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1038671)[0m 
[2m[36m(train pid=1040145)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1040145)[0m 
[2m[36m(train pid=1040959)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1040959)[0m 
2023-11-03 05:33:02,709	WARNING util.py:214 -- The `on_step_end` operation took 0.518 s, which may be a performance bottleneck.
[2m[36m(train pid=1042431)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1042431)[0m 
[2m[36m(train pid=1043749)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1043749)[0m 
[2m[36m(train pid=1045325)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1045325)[0m 
[2m[36m(train pid=1046636)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1046636)[0m 
== Status ==
Current time: 2023-11-03 05:26:30 (running for 06:55:28.31)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 667/1000000 (32 RUNNING, 635 TERMINATED)


== Status ==
Current time: 2023-11-03 05:28:32 (running for 06:57:30.29)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 667/1000000 (32 RUNNING, 635 TERMINATED)


== Status ==
Current time: 2023-11-03 05:28:40 (running for 06:57:37.96)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 669/1000000 (32 RUNNING, 637 TERMINATED)


== Status ==
Current time: 2023-11-03 05:30:45 (running for 06:59:42.87)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 669/1000000 (32 RUNNING, 637 TERMINATED)


== Status ==
Current time: 2023-11-03 05:30:52 (running for 06:59:50.12)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 670/1000000 (32 RUNNING, 638 TERMINATED)


== Status ==
Current time: 2023-11-03 05:33:02 (running for 07:02:00.39)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 670/1000000 (32 RUNNING, 638 TERMINATED)


== Status ==
Current time: 2023-11-03 05:33:09 (running for 07:02:07.25)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 671/1000000 (32 RUNNING, 639 TERMINATED)


== Status ==
Current time: 2023-11-03 05:35:07 (running for 07:04:04.85)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 671/1000000 (32 RUNNING, 639 TERMINATED)


== Status ==
Current time: 2023-11-03 05:35:15 (running for 07:04:12.60)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 673/1000000 (32 RUNNING, 641 TERMINATED)


== Status ==
Current time: 2023-11-03 05:37:15 (running for 07:06:13.21)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 673/1000000 (32 RUNNING, 641 TERMINATED)


== Status ==
Current time: 2023-11-03 05:37:22 (running for 07:06:19.62)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 674/1000000 (32 RUNNING, 642 TERMINATED)


== Status ==
Current time: 2023-11-03 05:39:24 (running for 07:08:21.80)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 674/1000000 (32 RUNNING, 642 TERMINATED)


== Status ==
Current time: 2023-11-03 05:39:31 (running for 07:08:28.84)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 675/1000000 (32 RUNNING, 643 TERMINATED)


== Status ==
Current time: 2023-11-03 05:41:32 (running for 07:10:30.38)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 675/1000000 (32 RUNNING, 643 TERMINATED)


[2m[36m(train pid=1047909)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1047909)[0m 
[2m[36m(train pid=1048978)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1048978)[0m 
2023-11-03 05:45:49,679	WARNING util.py:214 -- The `start_trial` operation took 1.253 s, which may be a performance bottleneck.
[2m[36m(train pid=1049874)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1049874)[0m 
== Status ==
Current time: 2023-11-03 05:41:39 (running for 07:10:36.90)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 676/1000000 (32 RUNNING, 644 TERMINATED)


== Status ==
Current time: 2023-11-03 05:43:42 (running for 07:12:39.84)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 676/1000000 (32 RUNNING, 644 TERMINATED)


== Status ==
Current time: 2023-11-03 05:43:49 (running for 07:12:47.35)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 677/1000000 (32 RUNNING, 645 TERMINATED)


== Status ==
Current time: 2023-11-03 05:45:47 (running for 07:14:44.69)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 677/1000000 (32 RUNNING, 645 TERMINATED)


== Status ==
Current time: 2023-11-03 05:45:55 (running for 07:14:52.75)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:48:08 (running for 07:17:05.91)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:48:13 (running for 07:17:11.33)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:48:19 (running for 07:17:16.74)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:48:24 (running for 07:17:22.12)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:48:29 (running for 07:17:27.56)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:48:35 (running for 07:17:32.93)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:48:40 (running for 07:17:38.29)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:48:46 (running for 07:17:43.66)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:48:51 (running for 07:17:49.13)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


2023-11-03 05:49:57,554	WARNING util.py:214 -- The `on_step_end` operation took 0.510 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 05:49:00 (running for 07:17:57.83)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:49:05 (running for 07:18:03.30)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:49:11 (running for 07:18:08.66)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:49:16 (running for 07:18:14.08)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:49:21 (running for 07:18:19.44)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:49:27 (running for 07:18:24.92)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:49:32 (running for 07:18:30.33)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:49:38 (running for 07:18:35.84)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:49:43 (running for 07:18:41.24)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:49:49 (running for 07:18:46.69)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:49:57 (running for 07:18:55.15)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:50:03 (running for 07:19:00.74)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:50:08 (running for 07:19:05.99)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:50:13 (running for 07:19:11.54)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


[2m[36m(train pid=1052679)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1052679)[0m 
== Status ==
Current time: 2023-11-03 05:50:19 (running for 07:19:16.88)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:50:24 (running for 07:19:22.31)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:50:30 (running for 07:19:27.73)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:50:35 (running for 07:19:33.12)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:50:40 (running for 07:19:38.42)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:50:48 (running for 07:19:46.54)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:50:54 (running for 07:19:51.89)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:50:59 (running for 07:19:57.30)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:51:05 (running for 07:20:02.67)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:51:23 (running for 07:20:20.66)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:51:28 (running for 07:20:26.08)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 679/1000000 (32 RUNNING, 647 TERMINATED)


== Status ==
Current time: 2023-11-03 05:51:38 (running for 07:20:36.01)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 680/1000000 (32 RUNNING, 648 TERMINATED)


== Status ==
Current time: 2023-11-03 05:53:35 (running for 07:22:33.56)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 680/1000000 (32 RUNNING, 648 TERMINATED)


== Status ==
Current time: 2023-11-03 05:53:43 (running for 07:22:40.73)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 682/1000000 (32 RUNNING, 650 TERMINATED)


[2m[36m(train pid=1053734)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1053734)[0m 
[2m[36m(train pid=1055198)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1055198)[0m 
[2m[36m(train pid=1056124)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1056124)[0m 
2023-11-03 06:02:15,225	WARNING util.py:214 -- The `on_step_end` operation took 0.515 s, which may be a performance bottleneck.
[2m[36m(train pid=1057143)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1057143)[0m 
[2m[36m(train pid=1058251)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1058251)[0m 
== Status ==
Current time: 2023-11-03 05:55:43 (running for 07:24:41.38)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 682/1000000 (32 RUNNING, 650 TERMINATED)


== Status ==
Current time: 2023-11-03 05:55:50 (running for 07:24:48.60)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 683/1000000 (32 RUNNING, 651 TERMINATED)


== Status ==
Current time: 2023-11-03 05:57:49 (running for 07:26:46.76)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 683/1000000 (32 RUNNING, 651 TERMINATED)


== Status ==
Current time: 2023-11-03 05:57:56 (running for 07:26:54.17)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 685/1000000 (32 RUNNING, 653 TERMINATED)


== Status ==
Current time: 2023-11-03 06:00:04 (running for 07:29:02.51)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 685/1000000 (32 RUNNING, 653 TERMINATED)


== Status ==
Current time: 2023-11-03 06:00:12 (running for 07:29:09.67)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 686/1000000 (32 RUNNING, 654 TERMINATED)


== Status ==
Current time: 2023-11-03 06:02:15 (running for 07:31:12.84)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 686/1000000 (32 RUNNING, 654 TERMINATED)


== Status ==
Current time: 2023-11-03 06:02:22 (running for 07:31:19.66)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 687/1000000 (32 RUNNING, 655 TERMINATED)


== Status ==
Current time: 2023-11-03 06:04:31 (running for 07:33:28.71)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 687/1000000 (32 RUNNING, 655 TERMINATED)


== Status ==
Current time: 2023-11-03 06:04:36 (running for 07:33:34.04)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 687/1000000 (32 RUNNING, 655 TERMINATED)


== Status ==
Current time: 2023-11-03 06:04:41 (running for 07:33:39.44)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 687/1000000 (32 RUNNING, 655 TERMINATED)


== Status ==
Current time: 2023-11-03 06:04:47 (running for 07:33:44.85)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 687/1000000 (32 RUNNING, 655 TERMINATED)


== Status ==
Current time: 2023-11-03 06:04:52 (running for 07:33:50.22)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 687/1000000 (32 RUNNING, 655 TERMINATED)


== Status ==
Current time: 2023-11-03 06:04:57 (running for 07:33:55.53)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 687/1000000 (32 RUNNING, 655 TERMINATED)


[2m[36m(train pid=1060064)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1060064)[0m 
[2m[36m(train pid=1060991)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1060991)[0m 
[2m[36m(train pid=1062307)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1062307)[0m 
[2m[36m(train pid=1062797)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1062797)[0m 
[2m[36m(train pid=1063454)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1063454)[0m 
2023-11-03 06:16:08,146	WARNING util.py:214 -- The `start_trial` operation took 0.780 s, which may be a performance bottleneck.
[2m[36m(train pid=1064259)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1064259)[0m 
== Status ==
Current time: 2023-11-03 06:05:03 (running for 07:34:01.01)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 687/1000000 (32 RUNNING, 655 TERMINATED)


== Status ==
Current time: 2023-11-03 06:05:09 (running for 07:34:06.89)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 688/1000000 (32 RUNNING, 656 TERMINATED)


== Status ==
Current time: 2023-11-03 06:07:19 (running for 07:36:17.16)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 688/1000000 (32 RUNNING, 656 TERMINATED)


== Status ==
Current time: 2023-11-03 06:07:26 (running for 07:36:23.88)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 689/1000000 (32 RUNNING, 657 TERMINATED)


== Status ==
Current time: 2023-11-03 06:09:32 (running for 07:38:30.08)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 689/1000000 (32 RUNNING, 657 TERMINATED)


== Status ==
Current time: 2023-11-03 06:09:39 (running for 07:38:37.02)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 690/1000000 (32 RUNNING, 658 TERMINATED)


== Status ==
Current time: 2023-11-03 06:11:45 (running for 07:40:43.42)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 690/1000000 (32 RUNNING, 658 TERMINATED)


== Status ==
Current time: 2023-11-03 06:11:52 (running for 07:40:50.16)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 691/1000000 (32 RUNNING, 659 TERMINATED)


== Status ==
Current time: 2023-11-03 06:13:55 (running for 07:42:53.18)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 691/1000000 (32 RUNNING, 659 TERMINATED)


== Status ==
Current time: 2023-11-03 06:14:02 (running for 07:43:00.25)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 692/1000000 (32 RUNNING, 660 TERMINATED)


== Status ==
Current time: 2023-11-03 06:16:05 (running for 07:45:02.99)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 692/1000000 (32 RUNNING, 660 TERMINATED)


== Status ==
Current time: 2023-11-03 06:16:13 (running for 07:45:10.76)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:18:23 (running for 07:47:21.03)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:18:28 (running for 07:47:26.40)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:18:34 (running for 07:47:31.86)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:18:39 (running for 07:47:37.25)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:18:45 (running for 07:47:42.76)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:18:50 (running for 07:47:48.17)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:18:56 (running for 07:47:53.76)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:19:01 (running for 07:47:59.16)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:19:07 (running for 07:48:04.70)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:19:15 (running for 07:48:12.74)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:19:20 (running for 07:48:18.33)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:19:26 (running for 07:48:23.74)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:19:31 (running for 07:48:29.29)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:19:37 (running for 07:48:34.68)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:19:42 (running for 07:48:40.18)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:19:47 (running for 07:48:45.58)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


[2m[36m(train pid=1065972)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1065972)[0m 
2023-11-03 06:24:46,931	WARNING util.py:214 -- The `on_step_end` operation took 0.521 s, which may be a performance bottleneck.
[2m[36m(train pid=1067577)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1067577)[0m 
2023-11-03 06:24:48,908	WARNING util.py:214 -- The `start_trial` operation took 0.507 s, which may be a performance bottleneck.
2023-11-03 06:24:49,481	WARNING util.py:214 -- The `start_trial` operation took 0.551 s, which may be a performance bottleneck.
[2m[36m(train pid=1068579)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1068579)[0m 
== Status ==
Current time: 2023-11-03 06:19:53 (running for 07:48:51.02)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:19:58 (running for 07:48:56.42)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:20:04 (running for 07:49:01.91)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:20:12 (running for 07:49:10.31)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:20:18 (running for 07:49:15.84)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:20:23 (running for 07:49:21.15)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:20:29 (running for 07:49:26.65)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 694/1000000 (32 RUNNING, 662 TERMINATED)


== Status ==
Current time: 2023-11-03 06:20:34 (running for 07:49:32.47)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 695/1000000 (32 RUNNING, 663 TERMINATED)


== Status ==
Current time: 2023-11-03 06:22:40 (running for 07:51:38.23)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 695/1000000 (32 RUNNING, 663 TERMINATED)


== Status ==
Current time: 2023-11-03 06:22:47 (running for 07:51:45.40)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 696/1000000 (32 RUNNING, 664 TERMINATED)


== Status ==
Current time: 2023-11-03 06:24:47 (running for 07:53:44.62)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 696/1000000 (32 RUNNING, 664 TERMINATED)


== Status ==
Current time: 2023-11-03 06:24:52 (running for 07:53:49.83)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 698/1000000 (32 RUNNING, 666 TERMINATED)


== Status ==
Current time: 2023-11-03 06:26:56 (running for 07:55:54.14)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 698/1000000 (32 RUNNING, 666 TERMINATED)


== Status ==
Current time: 2023-11-03 06:27:02 (running for 07:56:00.55)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 699/1000000 (32 RUNNING, 667 TERMINATED)


[2m[36m(train pid=1069544)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1069544)[0m 
2023-11-03 06:29:03,350	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.526 s, which may be a performance bottleneck.
2023-11-03 06:29:03,351	WARNING util.py:214 -- The `process_trial_result` operation took 0.527 s, which may be a performance bottleneck.
2023-11-03 06:29:03,351	WARNING util.py:214 -- Processing trial results took 0.527 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 06:29:03,351	WARNING util.py:214 -- The `process_trial_result` operation took 0.527 s, which may be a performance bottleneck.
[2m[36m(train pid=1070887)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1070887)[0m 
[2m[36m(train pid=1070885)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1070885)[0m 
[2m[36m(train pid=1071874)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1071874)[0m 
== Status ==
Current time: 2023-11-03 06:29:02 (running for 07:58:00.04)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 699/1000000 (32 RUNNING, 667 TERMINATED)


== Status ==
Current time: 2023-11-03 06:29:10 (running for 07:58:08.49)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 702/1000000 (32 RUNNING, 670 TERMINATED)


== Status ==
Current time: 2023-11-03 06:31:08 (running for 08:00:06.55)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 702/1000000 (32 RUNNING, 670 TERMINATED)


== Status ==
Current time: 2023-11-03 06:31:28 (running for 08:00:25.86)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:33:24 (running for 08:02:21.73)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:33:29 (running for 08:02:27.11)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:33:34 (running for 08:02:32.57)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:33:40 (running for 08:02:38.00)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:33:45 (running for 08:02:43.58)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:33:51 (running for 08:02:49.12)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:33:57 (running for 08:02:54.61)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:34:02 (running for 08:02:59.99)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:34:07 (running for 08:03:05.33)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:34:16 (running for 08:03:13.65)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:34:21 (running for 08:03:19.04)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:34:26 (running for 08:03:24.50)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:34:32 (running for 08:03:29.92)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:34:37 (running for 08:03:35.36)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:34:43 (running for 08:03:40.78)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:34:48 (running for 08:03:46.35)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:34:54 (running for 08:03:51.69)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:34:59 (running for 08:03:57.10)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:35:07 (running for 08:04:05.45)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:35:13 (running for 08:04:10.77)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:35:18 (running for 08:04:16.29)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:35:24 (running for 08:04:21.68)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:35:29 (running for 08:04:27.22)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:35:34 (running for 08:04:32.52)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


[2m[36m(train pid=1074554)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1074554)[0m 
2023-11-03 06:38:13,652	WARNING util.py:214 -- The `start_trial` operation took 0.707 s, which may be a performance bottleneck.
[2m[36m(train pid=1076279)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1076279)[0m 
[2m[36m(train pid=1077236)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1077236)[0m 
2023-11-03 06:44:35,535	WARNING util.py:214 -- The `on_step_end` operation took 0.540 s, which may be a performance bottleneck.
[2m[36m(train pid=1078851)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1078851)[0m 
2023-11-03 06:44:38,255	WARNING util.py:214 -- The `start_trial` operation took 0.602 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 06:35:40 (running for 08:04:38.01)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:35:45 (running for 08:04:43.53)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:35:51 (running for 08:04:48.80)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:35:59 (running for 08:04:57.07)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:36:04 (running for 08:05:02.40)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 703/1000000 (32 RUNNING, 671 TERMINATED)


== Status ==
Current time: 2023-11-03 06:36:12 (running for 08:05:09.95)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 704/1000000 (32 RUNNING, 672 TERMINATED)


== Status ==
Current time: 2023-11-03 06:38:10 (running for 08:07:08.24)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 704/1000000 (32 RUNNING, 672 TERMINATED)


== Status ==
Current time: 2023-11-03 06:38:19 (running for 08:07:16.96)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 707/1000000 (32 RUNNING, 675 TERMINATED)


== Status ==
Current time: 2023-11-03 06:40:16 (running for 08:09:13.66)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 707/1000000 (32 RUNNING, 675 TERMINATED)


== Status ==
Current time: 2023-11-03 06:40:24 (running for 08:09:21.81)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 710/1000000 (32 RUNNING, 678 TERMINATED)


== Status ==
Current time: 2023-11-03 06:42:28 (running for 08:11:25.71)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 710/1000000 (32 RUNNING, 678 TERMINATED)


== Status ==
Current time: 2023-11-03 06:42:35 (running for 08:11:33.28)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 711/1000000 (32 RUNNING, 679 TERMINATED)


== Status ==
Current time: 2023-11-03 06:44:35 (running for 08:13:33.19)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 711/1000000 (32 RUNNING, 679 TERMINATED)


== Status ==
Current time: 2023-11-03 06:44:43 (running for 08:13:41.02)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 713/1000000 (32 RUNNING, 681 TERMINATED)


[2m[36m(train pid=1080347)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1080347)[0m 
[2m[36m(train pid=1082013)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1082013)[0m 
[2m[36m(train pid=1083573)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1083573)[0m 
[2m[36m(train pid=1083575)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1083575)[0m 
2023-11-03 06:51:01,398	WARNING util.py:214 -- The `start_trial` operation took 0.548 s, which may be a performance bottleneck.
[2m[36m(train pid=1085265)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1085265)[0m 
[2m[36m(train pid=1086768)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1086768)[0m 
2023-11-03 06:55:18,362	WARNING util.py:214 -- The `start_trial` operation took 0.589 s, which may be a performance bottleneck.
2023-11-03 06:57:28,331	WARNING util.py:214 -- The `on_step_end` operation took 0.567 s, which may be a performance bottleneck.
[2m[36m(train pid=1088835)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1088835)[0m 
[2m[36m(train pid=1090991)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1090991)[0m 
[2m[36m(train pid=1092626)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1092626)[0m 
[2m[36m(train pid=1092633)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1092633)[0m 
2023-11-03 07:01:36,448	WARNING util.py:214 -- The `on_step_end` operation took 0.518 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 06:46:47 (running for 08:15:44.74)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 713/1000000 (32 RUNNING, 681 TERMINATED)


== Status ==
Current time: 2023-11-03 06:46:54 (running for 08:15:52.25)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 714/1000000 (32 RUNNING, 682 TERMINATED)


== Status ==
Current time: 2023-11-03 06:48:50 (running for 08:17:48.18)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 714/1000000 (32 RUNNING, 682 TERMINATED)


== Status ==
Current time: 2023-11-03 06:48:59 (running for 08:17:57.28)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 717/1000000 (32 RUNNING, 685 TERMINATED)


== Status ==
Current time: 2023-11-03 06:50:58 (running for 08:19:55.68)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 717/1000000 (32 RUNNING, 685 TERMINATED)


== Status ==
Current time: 2023-11-03 06:51:06 (running for 08:20:04.13)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 720/1000000 (32 RUNNING, 688 TERMINATED)


== Status ==
Current time: 2023-11-03 06:53:08 (running for 08:22:05.81)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 720/1000000 (32 RUNNING, 688 TERMINATED)


== Status ==
Current time: 2023-11-03 06:53:15 (running for 08:22:13.43)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 722/1000000 (32 RUNNING, 690 TERMINATED)


== Status ==
Current time: 2023-11-03 06:55:15 (running for 08:24:13.29)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 722/1000000 (32 RUNNING, 690 TERMINATED)


== Status ==
Current time: 2023-11-03 06:55:23 (running for 08:24:20.98)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 724/1000000 (32 RUNNING, 692 TERMINATED)


== Status ==
Current time: 2023-11-03 06:57:28 (running for 08:26:25.93)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 724/1000000 (32 RUNNING, 692 TERMINATED)


== Status ==
Current time: 2023-11-03 06:57:36 (running for 08:26:33.66)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 726/1000000 (32 RUNNING, 694 TERMINATED)


== Status ==
Current time: 2023-11-03 06:59:32 (running for 08:28:30.52)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 726/1000000 (32 RUNNING, 694 TERMINATED)


== Status ==
Current time: 2023-11-03 06:59:39 (running for 08:28:36.75)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 729/1000000 (32 RUNNING, 697 TERMINATED)


[2m[36m(train pid=1093831)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1093831)[0m 
[2m[36m(train pid=1093845)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1093845)[0m 
[2m[36m(train pid=1096109)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1096109)[0m 
2023-11-03 07:06:00,949	WARNING util.py:214 -- The `start_trial` operation took 0.500 s, which may be a performance bottleneck.
[2m[36m(train pid=1097740)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1097740)[0m 
2023-11-03 07:08:12,108	WARNING util.py:214 -- The `start_trial` operation took 1.209 s, which may be a performance bottleneck.
[2m[36m(train pid=1099642)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1099642)[0m 
[2m[36m(train pid=1099507)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1099507)[0m 
2023-11-03 07:10:19,042	WARNING util.py:214 -- The `on_step_end` operation took 0.595 s, which may be a performance bottleneck.
[2m[36m(train pid=1101654)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1101654)[0m 
2023-11-03 07:12:28,171	WARNING util.py:214 -- The `start_trial` operation took 0.726 s, which may be a performance bottleneck.
[2m[36m(train pid=1104032)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1104032)[0m 
[2m[36m(train pid=1106853)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1106853)[0m 
[2m[36m(train pid=1106857)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1106857)[0m 
== Status ==
Current time: 2023-11-03 07:01:36 (running for 08:30:34.06)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 729/1000000 (32 RUNNING, 697 TERMINATED)


== Status ==
Current time: 2023-11-03 07:01:42 (running for 08:30:39.82)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 732/1000000 (32 RUNNING, 700 TERMINATED)


== Status ==
Current time: 2023-11-03 07:03:47 (running for 08:32:44.76)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 732/1000000 (32 RUNNING, 700 TERMINATED)


== Status ==
Current time: 2023-11-03 07:03:54 (running for 08:32:51.69)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 733/1000000 (32 RUNNING, 701 TERMINATED)


== Status ==
Current time: 2023-11-03 07:05:58 (running for 08:34:56.11)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 733/1000000 (32 RUNNING, 701 TERMINATED)


== Status ==
Current time: 2023-11-03 07:06:05 (running for 08:35:03.57)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 735/1000000 (32 RUNNING, 703 TERMINATED)


== Status ==
Current time: 2023-11-03 07:08:07 (running for 08:37:04.71)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 735/1000000 (32 RUNNING, 703 TERMINATED)


== Status ==
Current time: 2023-11-03 07:08:17 (running for 08:37:14.72)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 739/1000000 (32 RUNNING, 707 TERMINATED)


== Status ==
Current time: 2023-11-03 07:10:19 (running for 08:39:16.64)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 739/1000000 (32 RUNNING, 707 TERMINATED)


== Status ==
Current time: 2023-11-03 07:10:26 (running for 08:39:23.97)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 740/1000000 (32 RUNNING, 708 TERMINATED)


== Status ==
Current time: 2023-11-03 07:12:25 (running for 08:41:23.01)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 740/1000000 (32 RUNNING, 708 TERMINATED)


== Status ==
Current time: 2023-11-03 07:12:33 (running for 08:41:30.79)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 742/1000000 (32 RUNNING, 710 TERMINATED)


== Status ==
Current time: 2023-11-03 07:14:30 (running for 08:43:28.36)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 742/1000000 (32 RUNNING, 710 TERMINATED)


== Status ==
Current time: 2023-11-03 07:14:40 (running for 08:43:37.97)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 746/1000000 (32 RUNNING, 714 TERMINATED)


2023-11-03 07:16:38,766	WARNING util.py:214 -- The `start_trial` operation took 0.569 s, which may be a performance bottleneck.
[2m[36m(train pid=1108072)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1108072)[0m 
2023-11-03 07:20:57,574	WARNING util.py:214 -- The `on_step_end` operation took 0.535 s, which may be a performance bottleneck.
[2m[36m(train pid=1108999)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1108999)[0m 
[2m[36m(train pid=1110421)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1110421)[0m 
[2m[36m(train pid=1113184)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1113184)[0m 
2023-11-03 07:25:51,178	WARNING util.py:214 -- The `start_trial` operation took 0.549 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 07:16:36 (running for 08:45:34.41)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 746/1000000 (32 RUNNING, 714 TERMINATED)


== Status ==
Current time: 2023-11-03 07:16:44 (running for 08:45:42.05)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 748/1000000 (32 RUNNING, 716 TERMINATED)


== Status ==
Current time: 2023-11-03 07:18:47 (running for 08:47:45.31)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 748/1000000 (32 RUNNING, 716 TERMINATED)


== Status ==
Current time: 2023-11-03 07:18:55 (running for 08:47:53.20)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 750/1000000 (32 RUNNING, 718 TERMINATED)


== Status ==
Current time: 2023-11-03 07:20:57 (running for 08:49:55.17)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 750/1000000 (32 RUNNING, 718 TERMINATED)


== Status ==
Current time: 2023-11-03 07:21:05 (running for 08:50:03.25)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 752/1000000 (32 RUNNING, 720 TERMINATED)


== Status ==
Current time: 2023-11-03 07:23:16 (running for 08:52:13.94)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 752/1000000 (32 RUNNING, 720 TERMINATED)


== Status ==
Current time: 2023-11-03 07:23:21 (running for 08:52:19.41)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 752/1000000 (32 RUNNING, 720 TERMINATED)


== Status ==
Current time: 2023-11-03 07:23:27 (running for 08:52:24.78)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 752/1000000 (32 RUNNING, 720 TERMINATED)


== Status ==
Current time: 2023-11-03 07:23:32 (running for 08:52:30.34)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 752/1000000 (32 RUNNING, 720 TERMINATED)


== Status ==
Current time: 2023-11-03 07:23:38 (running for 08:52:35.88)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 752/1000000 (32 RUNNING, 720 TERMINATED)


== Status ==
Current time: 2023-11-03 07:23:43 (running for 08:52:41.41)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 752/1000000 (32 RUNNING, 720 TERMINATED)


== Status ==
Current time: 2023-11-03 07:23:53 (running for 08:52:51.38)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 753/1000000 (32 RUNNING, 721 TERMINATED)


== Status ==
Current time: 2023-11-03 07:25:46 (running for 08:54:43.61)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 753/1000000 (32 RUNNING, 721 TERMINATED)


[2m[36m(train pid=1115875)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1115875)[0m 
[2m[36m(train pid=1115918)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1115918)[0m 
[2m[36m(train pid=1117999)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1117999)[0m 
2023-11-03 07:30:05,110	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 1.141 s, which may be a performance bottleneck.
2023-11-03 07:30:05,111	WARNING util.py:214 -- The `process_trial_result` operation took 1.142 s, which may be a performance bottleneck.
2023-11-03 07:30:05,111	WARNING util.py:214 -- Processing trial results took 1.142 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 07:30:05,111	WARNING util.py:214 -- The `process_trial_result` operation took 1.142 s, which may be a performance bottleneck.
[2m[36m(train pid=1119746)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1119746)[0m 
2023-11-03 07:31:59,577	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.707 s, which may be a performance bottleneck.
2023-11-03 07:31:59,577	WARNING util.py:214 -- The `process_trial_result` operation took 0.708 s, which may be a performance bottleneck.
2023-11-03 07:31:59,577	WARNING util.py:214 -- Processing trial results took 0.708 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 07:31:59,577	WARNING util.py:214 -- The `process_trial_result` operation took 0.708 s, which may be a performance bottleneck.
[2m[36m(train pid=1122006)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1122006)[0m 
[2m[36m(train pid=1122144)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1122144)[0m 
2023-11-03 07:34:02,862	WARNING util.py:214 -- The `start_trial` operation took 0.530 s, which may be a performance bottleneck.
[2m[36m(train pid=1124301)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1124301)[0m 
[2m[36m(train pid=1124299)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1124299)[0m 
[2m[36m(train pid=1126408)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1126408)[0m 
2023-11-03 07:38:09,713	WARNING util.py:214 -- The `on_step_end` operation took 0.571 s, which may be a performance bottleneck.
[2m[36m(train pid=1128050)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1128050)[0m 
== Status ==
Current time: 2023-11-03 07:25:51 (running for 08:54:49.11)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 758/1000000 (32 RUNNING, 726 TERMINATED)


== Status ==
Current time: 2023-11-03 07:27:50 (running for 08:56:47.96)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 758/1000000 (32 RUNNING, 726 TERMINATED)


== Status ==
Current time: 2023-11-03 07:27:59 (running for 08:56:56.66)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 761/1000000 (32 RUNNING, 729 TERMINATED)


== Status ==
Current time: 2023-11-03 07:29:59 (running for 08:58:57.05)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 761/1000000 (32 RUNNING, 729 TERMINATED)


== Status ==
Current time: 2023-11-03 07:30:05 (running for 08:59:02.94)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 763/1000000 (32 RUNNING, 731 TERMINATED)


== Status ==
Current time: 2023-11-03 07:31:58 (running for 09:00:56.03)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 763/1000000 (32 RUNNING, 731 TERMINATED)


== Status ==
Current time: 2023-11-03 07:32:08 (running for 09:01:06.09)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 768/1000000 (32 RUNNING, 736 TERMINATED)


== Status ==
Current time: 2023-11-03 07:34:00 (running for 09:02:58.50)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 768/1000000 (32 RUNNING, 736 TERMINATED)


== Status ==
Current time: 2023-11-03 07:34:10 (running for 09:03:07.60)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 771/1000000 (32 RUNNING, 739 TERMINATED)


== Status ==
Current time: 2023-11-03 07:35:53 (running for 09:04:51.46)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 771/1000000 (32 RUNNING, 739 TERMINATED)


== Status ==
Current time: 2023-11-03 07:35:59 (running for 09:04:56.90)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 776/1000000 (31 RUNNING, 745 TERMINATED)


== Status ==
Current time: 2023-11-03 07:36:05 (running for 09:05:03.30)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 777/1000000 (32 RUNNING, 745 TERMINATED)


== Status ==
Current time: 2023-11-03 07:38:09 (running for 09:07:07.31)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 777/1000000 (32 RUNNING, 745 TERMINATED)


== Status ==
Current time: 2023-11-03 07:38:17 (running for 09:07:14.72)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 778/1000000 (32 RUNNING, 746 TERMINATED)


2023-11-03 07:40:22,577	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 1.157 s, which may be a performance bottleneck.
2023-11-03 07:40:22,577	WARNING util.py:214 -- The `process_trial_result` operation took 1.157 s, which may be a performance bottleneck.
2023-11-03 07:40:22,577	WARNING util.py:214 -- Processing trial results took 1.157 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 07:40:22,577	WARNING util.py:214 -- The `process_trial_result` operation took 1.157 s, which may be a performance bottleneck.
[2m[36m(train pid=1130271)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1130271)[0m 
2023-11-03 07:42:31,519	WARNING util.py:214 -- The `start_trial` operation took 0.799 s, which may be a performance bottleneck.
[2m[36m(train pid=1133609)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1133609)[0m 
[2m[36m(train pid=1136719)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1136719)[0m 
2023-11-03 07:46:33,062	WARNING util.py:214 -- The `on_step_end` operation took 0.582 s, which may be a performance bottleneck.
[2m[36m(train pid=1140131)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1140131)[0m 
[2m[36m(train pid=1139861)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1139861)[0m 
2023-11-03 07:48:26,169	WARNING util.py:214 -- The `start_trial` operation took 0.984 s, which may be a performance bottleneck.
[2m[36m(train pid=1141383)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1141383)[0m 
[2m[36m(train pid=1141381)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1141381)[0m 
2023-11-03 07:52:39,071	WARNING util.py:214 -- The `on_step_end` operation took 0.544 s, which may be a performance bottleneck.
[2m[36m(train pid=1143107)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1143107)[0m 
[2m[36m(train pid=1145310)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1145310)[0m 
2023-11-03 07:54:44,183	WARNING util.py:214 -- The `on_step_end` operation took 0.557 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 07:40:20 (running for 09:09:17.90)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 778/1000000 (32 RUNNING, 746 TERMINATED)


== Status ==
Current time: 2023-11-03 07:40:28 (running for 09:09:26.35)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 780/1000000 (32 RUNNING, 748 TERMINATED)


== Status ==
Current time: 2023-11-03 07:42:28 (running for 09:11:26.03)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 780/1000000 (32 RUNNING, 748 TERMINATED)


== Status ==
Current time: 2023-11-03 07:42:36 (running for 09:11:34.28)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 782/1000000 (32 RUNNING, 750 TERMINATED)


== Status ==
Current time: 2023-11-03 07:44:27 (running for 09:13:24.73)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 782/1000000 (32 RUNNING, 750 TERMINATED)


== Status ==
Current time: 2023-11-03 07:44:32 (running for 09:13:30.40)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 788/1000000 (1 PENDING, 30 RUNNING, 757 TERMINATED)


== Status ==
Current time: 2023-11-03 07:46:27 (running for 09:15:24.93)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 788/1000000 (31 RUNNING, 757 TERMINATED)


== Status ==
Current time: 2023-11-03 07:46:33 (running for 09:15:30.66)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 793/1000000 (1 PENDING, 31 RUNNING, 761 TERMINATED)


== Status ==
Current time: 2023-11-03 07:48:23 (running for 09:17:21.58)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 793/1000000 (1 PENDING, 31 RUNNING, 761 TERMINATED)


== Status ==
Current time: 2023-11-03 07:48:32 (running for 09:17:29.90)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 795/1000000 (32 RUNNING, 763 TERMINATED)


== Status ==
Current time: 2023-11-03 07:50:26 (running for 09:19:24.24)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 795/1000000 (32 RUNNING, 763 TERMINATED)


== Status ==
Current time: 2023-11-03 07:50:34 (running for 09:19:31.93)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 797/1000000 (32 RUNNING, 765 TERMINATED)


== Status ==
Current time: 2023-11-03 07:52:39 (running for 09:21:36.72)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 797/1000000 (32 RUNNING, 765 TERMINATED)


== Status ==
Current time: 2023-11-03 07:52:46 (running for 09:21:44.27)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 799/1000000 (32 RUNNING, 767 TERMINATED)


[2m[36m(train pid=1147306)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1147306)[0m 
2023-11-03 07:56:53,773	WARNING util.py:214 -- The `start_trial` operation took 0.593 s, which may be a performance bottleneck.
[2m[36m(train pid=1149774)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1149774)[0m 
2023-11-03 07:58:51,300	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.606 s, which may be a performance bottleneck.
2023-11-03 07:58:51,300	WARNING util.py:214 -- The `process_trial_result` operation took 0.607 s, which may be a performance bottleneck.
2023-11-03 07:58:51,300	WARNING util.py:214 -- Processing trial results took 0.607 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 07:58:51,300	WARNING util.py:214 -- The `process_trial_result` operation took 0.607 s, which may be a performance bottleneck.
[2m[36m(train pid=1151973)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1151973)[0m 
[2m[36m(train pid=1151975)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1151975)[0m 
2023-11-03 08:00:58,019	WARNING util.py:214 -- The `start_trial` operation took 0.601 s, which may be a performance bottleneck.
[2m[36m(train pid=1153672)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1153672)[0m 
[2m[36m(train pid=1155738)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1155738)[0m 
[2m[36m(train pid=1158886)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1158886)[0m 
2023-11-03 08:07:11,848	WARNING util.py:214 -- The `on_step_end` operation took 0.531 s, which may be a performance bottleneck.
[2m[36m(train pid=1161964)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1161964)[0m 
== Status ==
Current time: 2023-11-03 07:54:44 (running for 09:23:41.80)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 799/1000000 (32 RUNNING, 767 TERMINATED)


== Status ==
Current time: 2023-11-03 07:54:52 (running for 09:23:50.07)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 801/1000000 (32 RUNNING, 769 TERMINATED)


== Status ==
Current time: 2023-11-03 07:56:49 (running for 09:25:46.90)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 801/1000000 (32 RUNNING, 769 TERMINATED)


== Status ==
Current time: 2023-11-03 07:56:58 (running for 09:25:56.57)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 804/1000000 (32 RUNNING, 772 TERMINATED)


== Status ==
Current time: 2023-11-03 07:58:48 (running for 09:27:46.18)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 804/1000000 (32 RUNNING, 772 TERMINATED)


== Status ==
Current time: 2023-11-03 07:58:54 (running for 09:27:52.32)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 809/1000000 (32 RUNNING, 777 TERMINATED)


== Status ==
Current time: 2023-11-03 08:00:55 (running for 09:29:53.21)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 809/1000000 (32 RUNNING, 777 TERMINATED)


== Status ==
Current time: 2023-11-03 08:01:03 (running for 09:30:00.76)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 811/1000000 (32 RUNNING, 779 TERMINATED)


== Status ==
Current time: 2023-11-03 08:02:59 (running for 09:31:57.37)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 811/1000000 (32 RUNNING, 779 TERMINATED)


== Status ==
Current time: 2023-11-03 08:03:08 (running for 09:32:06.35)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 814/1000000 (32 RUNNING, 782 TERMINATED)


== Status ==
Current time: 2023-11-03 08:05:05 (running for 09:34:03.04)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 814/1000000 (32 RUNNING, 782 TERMINATED)


== Status ==
Current time: 2023-11-03 08:05:14 (running for 09:34:12.53)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 818/1000000 (32 RUNNING, 786 TERMINATED)


== Status ==
Current time: 2023-11-03 08:07:11 (running for 09:36:09.52)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 818/1000000 (32 RUNNING, 786 TERMINATED)


== Status ==
Current time: 2023-11-03 08:07:21 (running for 09:36:18.88)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 822/1000000 (32 RUNNING, 790 TERMINATED)


2023-11-03 08:09:15,505	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.643 s, which may be a performance bottleneck.
2023-11-03 08:09:15,505	WARNING util.py:214 -- The `process_trial_result` operation took 0.644 s, which may be a performance bottleneck.
2023-11-03 08:09:15,505	WARNING util.py:214 -- Processing trial results took 0.644 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 08:09:15,505	WARNING util.py:214 -- The `process_trial_result` operation took 0.644 s, which may be a performance bottleneck.
2023-11-03 08:09:17,380	WARNING util.py:214 -- The `start_trial` operation took 0.559 s, which may be a performance bottleneck.
2023-11-03 08:09:20,127	WARNING util.py:214 -- The `on_step_end` operation took 0.579 s, which may be a performance bottleneck.
[2m[36m(train pid=1165767)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1165767)[0m 
[2m[36m(train pid=1165763)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1165763)[0m 
[2m[36m(train pid=1169081)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1169081)[0m 
[2m[36m(train pid=1171662)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1171662)[0m 
2023-11-03 08:14:18,990	WARNING util.py:214 -- The `start_trial` operation took 0.566 s, which may be a performance bottleneck.
2023-11-03 08:14:19,601	WARNING util.py:214 -- The `start_trial` operation took 0.518 s, which may be a performance bottleneck.
2023-11-03 08:14:21,098	WARNING util.py:214 -- The `on_step_end` operation took 0.580 s, which may be a performance bottleneck.
[2m[36m(train pid=1174639)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1174639)[0m 
[2m[36m(train pid=1176109)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1176109)[0m 
[2m[36m(train pid=1176114)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1176114)[0m 
2023-11-03 08:18:16,382	WARNING util.py:214 -- The `on_step_end` operation took 0.556 s, which may be a performance bottleneck.
[2m[36m(train pid=1177627)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1177627)[0m 
[2m[36m(train pid=1177629)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1177629)[0m 
2023-11-03 08:20:18,395	WARNING util.py:214 -- The `on_step_end` operation took 0.528 s, which may be a performance bottleneck.
[2m[36m(train pid=1180797)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1180797)[0m 
2023-11-03 08:22:25,598	WARNING util.py:214 -- The `start_trial` operation took 0.556 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 08:09:14 (running for 09:38:11.81)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 822/1000000 (32 RUNNING, 790 TERMINATED)


== Status ==
Current time: 2023-11-03 08:09:20 (running for 09:38:17.72)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 827/1000000 (1 PENDING, 31 RUNNING, 795 TERMINATED)


== Status ==
Current time: 2023-11-03 08:11:04 (running for 09:40:01.77)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 827/1000000 (32 RUNNING, 795 TERMINATED)


== Status ==
Current time: 2023-11-03 08:12:30 (running for 09:41:27.94)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 827/1000000 (32 RUNNING, 795 TERMINATED)


== Status ==
Current time: 2023-11-03 08:12:35 (running for 09:41:33.45)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 833/1000000 (31 RUNNING, 802 TERMINATED)


== Status ==
Current time: 2023-11-03 08:14:15 (running for 09:43:13.19)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 834/1000000 (1 PENDING, 30 RUNNING, 803 TERMINATED)


== Status ==
Current time: 2023-11-03 08:14:21 (running for 09:43:18.70)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 840/1000000 (1 PENDING, 30 RUNNING, 809 TERMINATED)


== Status ==
Current time: 2023-11-03 08:16:12 (running for 09:45:09.80)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 840/1000000 (31 RUNNING, 809 TERMINATED)


== Status ==
Current time: 2023-11-03 08:16:22 (running for 09:45:19.74)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 844/1000000 (32 RUNNING, 812 TERMINATED)


== Status ==
Current time: 2023-11-03 08:18:16 (running for 09:47:14.01)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 844/1000000 (32 RUNNING, 812 TERMINATED)


== Status ==
Current time: 2023-11-03 08:18:25 (running for 09:47:22.78)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 846/1000000 (32 RUNNING, 814 TERMINATED)


== Status ==
Current time: 2023-11-03 08:20:18 (running for 09:49:15.99)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 846/1000000 (32 RUNNING, 814 TERMINATED)


== Status ==
Current time: 2023-11-03 08:20:27 (running for 09:49:24.68)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 849/1000000 (32 RUNNING, 817 TERMINATED)


== Status ==
Current time: 2023-11-03 08:22:21 (running for 09:51:18.77)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 849/1000000 (32 RUNNING, 817 TERMINATED)


[2m[36m(train pid=1184309)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1184309)[0m 
2023-11-03 08:24:31,465	WARNING util.py:214 -- The `start_trial` operation took 0.516 s, which may be a performance bottleneck.
[2m[36m(train pid=1188513)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1188513)[0m 
[2m[36m(train pid=1188510)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1188510)[0m 
2023-11-03 08:26:23,294	WARNING util.py:214 -- The `start_trial` operation took 0.513 s, which may be a performance bottleneck.
[2m[36m(train pid=1192645)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1192645)[0m 
[2m[36m(train pid=1192503)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1192503)[0m 
2023-11-03 08:28:09,397	WARNING util.py:214 -- The `start_trial` operation took 0.555 s, which may be a performance bottleneck.
2023-11-03 08:28:12,179	WARNING util.py:214 -- The `on_step_end` operation took 0.601 s, which may be a performance bottleneck.
[2m[36m(train pid=1195968)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1195968)[0m 
[2m[36m(train pid=1199319)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1199319)[0m 
2023-11-03 08:31:53,153	WARNING util.py:214 -- The `on_step_end` operation took 0.561 s, which may be a performance bottleneck.
2023-11-03 08:31:57,442	WARNING util.py:214 -- The `start_trial` operation took 0.523 s, which may be a performance bottleneck.
2023-11-03 08:31:58,751	WARNING util.py:214 -- The `on_step_end` operation took 0.506 s, which may be a performance bottleneck.
[2m[36m(train pid=1203276)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1203276)[0m 
2023-11-03 08:33:48,104	WARNING util.py:214 -- The `start_trial` operation took 0.558 s, which may be a performance bottleneck.
2023-11-03 08:33:52,580	WARNING util.py:214 -- The `start_trial` operation took 0.719 s, which may be a performance bottleneck.
[2m[36m(train pid=1206551)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1206551)[0m 
[2m[36m(train pid=1206691)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1206691)[0m 
[2m[36m(train pid=1206709)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1206709)[0m 
2023-11-03 08:35:43,532	WARNING util.py:214 -- The `on_step_end` operation took 0.537 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 08:22:30 (running for 09:51:28.47)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 853/1000000 (32 RUNNING, 821 TERMINATED)


== Status ==
Current time: 2023-11-03 08:24:28 (running for 09:53:26.49)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 853/1000000 (32 RUNNING, 821 TERMINATED)


== Status ==
Current time: 2023-11-03 08:24:37 (running for 09:53:34.97)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 856/1000000 (32 RUNNING, 824 TERMINATED)


== Status ==
Current time: 2023-11-03 08:26:19 (running for 09:55:16.91)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 856/1000000 (32 RUNNING, 824 TERMINATED)


== Status ==
Current time: 2023-11-03 08:26:25 (running for 09:55:22.83)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 862/1000000 (32 RUNNING, 830 TERMINATED)


== Status ==
Current time: 2023-11-03 08:28:06 (running for 09:57:04.08)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 862/1000000 (32 RUNNING, 830 TERMINATED)


== Status ==
Current time: 2023-11-03 08:28:12 (running for 09:57:09.81)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 867/1000000 (1 PENDING, 30 RUNNING, 836 TERMINATED)


== Status ==
Current time: 2023-11-03 08:29:53 (running for 09:58:51.01)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 867/1000000 (31 RUNNING, 836 TERMINATED)


== Status ==
Current time: 2023-11-03 08:29:58 (running for 09:58:56.55)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 873/1000000 (32 RUNNING, 841 TERMINATED)


== Status ==
Current time: 2023-11-03 08:31:53 (running for 10:00:50.75)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 873/1000000 (32 RUNNING, 841 TERMINATED)


== Status ==
Current time: 2023-11-03 08:31:58 (running for 10:00:56.48)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 878/1000000 (1 PENDING, 30 RUNNING, 847 TERMINATED)


== Status ==
Current time: 2023-11-03 08:33:46 (running for 10:02:44.31)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 878/1000000 (31 RUNNING, 847 TERMINATED)


== Status ==
Current time: 2023-11-03 08:33:52 (running for 10:02:50.42)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 883/1000000 (32 RUNNING, 851 TERMINATED)


== Status ==
Current time: 2023-11-03 08:35:37 (running for 10:04:35.58)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 883/1000000 (32 RUNNING, 851 TERMINATED)


[2m[36m(train pid=1209449)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1209449)[0m 
[2m[36m(train pid=1209724)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1209724)[0m 
2023-11-03 08:37:37,459	WARNING util.py:214 -- The `start_trial` operation took 0.554 s, which may be a performance bottleneck.
[2m[36m(train pid=1212372)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1212372)[0m 
[2m[36m(train pid=1212378)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1212378)[0m 
2023-11-03 08:39:36,732	WARNING util.py:214 -- The `on_step_end` operation took 0.567 s, which may be a performance bottleneck.
2023-11-03 08:39:39,251	WARNING util.py:214 -- The `start_trial` operation took 0.535 s, which may be a performance bottleneck.
[2m[36m(train pid=1215369)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1215369)[0m 
2023-11-03 08:41:48,521	WARNING util.py:214 -- The `start_trial` operation took 0.629 s, which may be a performance bottleneck.
[2m[36m(train pid=1219492)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1219492)[0m 
[2m[36m(train pid=1219346)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1219346)[0m 
[2m[36m(train pid=1224659)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1224659)[0m 
2023-11-03 08:45:32,678	WARNING util.py:214 -- The `on_step_end` operation took 0.560 s, which may be a performance bottleneck.
[2m[36m(train pid=1228585)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1228585)[0m 
2023-11-03 08:47:11,247	WARNING util.py:214 -- The `start_trial` operation took 0.599 s, which may be a performance bottleneck.
2023-11-03 08:47:13,848	WARNING util.py:214 -- The `on_step_end` operation took 0.524 s, which may be a performance bottleneck.
[2m[36m(train pid=1231974)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1231974)[0m 
[2m[36m(train pid=1232120)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1232120)[0m 
[2m[36m(train pid=1232386)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1232386)[0m 
== Status ==
Current time: 2023-11-03 08:35:43 (running for 10:04:41.13)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 888/1000000 (31 RUNNING, 857 TERMINATED)


== Status ==
Current time: 2023-11-03 08:37:32 (running for 10:06:30.52)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 889/1000000 (1 PENDING, 31 RUNNING, 857 TERMINATED)


== Status ==
Current time: 2023-11-03 08:37:38 (running for 10:06:35.96)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 894/1000000 (32 RUNNING, 862 TERMINATED)


== Status ==
Current time: 2023-11-03 08:39:36 (running for 10:08:34.33)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 894/1000000 (32 RUNNING, 862 TERMINATED)


== Status ==
Current time: 2023-11-03 08:39:44 (running for 10:08:42.04)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 896/1000000 (32 RUNNING, 864 TERMINATED)


== Status ==
Current time: 2023-11-03 08:41:43 (running for 10:10:40.61)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 896/1000000 (32 RUNNING, 864 TERMINATED)


== Status ==
Current time: 2023-11-03 08:41:48 (running for 10:10:46.37)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 901/1000000 (32 RUNNING, 869 TERMINATED)


== Status ==
Current time: 2023-11-03 08:43:40 (running for 10:12:38.09)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 901/1000000 (32 RUNNING, 869 TERMINATED)


== Status ==
Current time: 2023-11-03 08:43:46 (running for 10:12:43.73)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 906/1000000 (32 RUNNING, 874 TERMINATED)


== Status ==
Current time: 2023-11-03 08:45:26 (running for 10:14:24.58)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 906/1000000 (32 RUNNING, 874 TERMINATED)


== Status ==
Current time: 2023-11-03 08:45:32 (running for 10:14:30.28)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 912/1000000 (1 PENDING, 30 RUNNING, 881 TERMINATED)


== Status ==
Current time: 2023-11-03 08:47:07 (running for 10:16:05.53)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 912/1000000 (31 RUNNING, 881 TERMINATED)


== Status ==
Current time: 2023-11-03 08:47:13 (running for 10:16:11.45)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 918/1000000 (1 PENDING, 30 RUNNING, 887 TERMINATED)


== Status ==
Current time: 2023-11-03 08:48:43 (running for 10:17:40.72)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 918/1000000 (31 RUNNING, 887 TERMINATED)


[2m[36m(train pid=1236515)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1236515)[0m 
[2m[36m(train pid=1239723)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1239723)[0m 
[2m[36m(train pid=1243277)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1243277)[0m 
[2m[36m(train pid=1243279)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1243279)[0m 
2023-11-03 08:54:05,769	WARNING util.py:214 -- The `on_step_end` operation took 0.529 s, which may be a performance bottleneck.
2023-11-03 08:54:12,878	WARNING util.py:214 -- The `start_trial` operation took 0.609 s, which may be a performance bottleneck.
[2m[36m(train pid=1248417)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1248417)[0m 
[2m[36m(train pid=1248419)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1248419)[0m 
[2m[36m(train pid=1248559)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1248559)[0m 
2023-11-03 08:56:08,673	WARNING util.py:214 -- The `start_trial` operation took 0.608 s, which may be a performance bottleneck.
2023-11-03 08:56:12,572	WARNING util.py:214 -- The `on_step_end` operation took 0.723 s, which may be a performance bottleneck.
[2m[36m(train pid=1253264)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1253264)[0m 
2023-11-03 08:57:58,269	WARNING util.py:214 -- The `on_step_end` operation took 0.620 s, which may be a performance bottleneck.
[2m[36m(train pid=1256778)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1256778)[0m 
[2m[36m(train pid=1257068)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1257068)[0m 
[2m[36m(train pid=1260674)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1260674)[0m 
2023-11-03 09:01:05,706	WARNING util.py:214 -- The `start_trial` operation took 0.540 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 08:48:48 (running for 10:17:46.43)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 924/1000000 (1 PENDING, 30 RUNNING, 893 TERMINATED)


== Status ==
Current time: 2023-11-03 08:50:22 (running for 10:19:20.39)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 924/1000000 (31 RUNNING, 893 TERMINATED)


== Status ==
Current time: 2023-11-03 08:50:28 (running for 10:19:25.79)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 929/1000000 (31 RUNNING, 898 TERMINATED)


== Status ==
Current time: 2023-11-03 08:52:15 (running for 10:21:13.13)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 930/1000000 (1 PENDING, 31 RUNNING, 898 TERMINATED)


== Status ==
Current time: 2023-11-03 08:52:20 (running for 10:21:18.40)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 935/1000000 (32 RUNNING, 903 TERMINATED)


== Status ==
Current time: 2023-11-03 08:54:05 (running for 10:23:03.41)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 935/1000000 (32 RUNNING, 903 TERMINATED)


== Status ==
Current time: 2023-11-03 08:54:11 (running for 10:23:09.10)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 940/1000000 (31 RUNNING, 909 TERMINATED)


== Status ==
Current time: 2023-11-03 08:54:17 (running for 10:23:15.48)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 943/1000000 (32 RUNNING, 911 TERMINATED)


== Status ==
Current time: 2023-11-03 08:56:06 (running for 10:25:03.89)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 943/1000000 (32 RUNNING, 911 TERMINATED)


== Status ==
Current time: 2023-11-03 08:56:12 (running for 10:25:10.23)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 948/1000000 (1 PENDING, 31 RUNNING, 916 TERMINATED)


== Status ==
Current time: 2023-11-03 08:57:52 (running for 10:26:50.08)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 948/1000000 (1 PENDING, 31 RUNNING, 916 TERMINATED)


== Status ==
Current time: 2023-11-03 08:57:58 (running for 10:26:55.98)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 954/1000000 (1 PENDING, 31 RUNNING, 922 TERMINATED)


== Status ==
Current time: 2023-11-03 08:59:36 (running for 10:28:34.28)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 954/1000000 (32 RUNNING, 922 TERMINATED)


== Status ==
Current time: 2023-11-03 09:01:01 (running for 10:29:59.27)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 954/1000000 (32 RUNNING, 922 TERMINATED)


[2m[36m(train pid=1263404)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1263404)[0m 
[2m[36m(train pid=1263831)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1263831)[0m 
2023-11-03 09:03:06,783	WARNING util.py:214 -- The `on_step_end` operation took 0.519 s, which may be a performance bottleneck.
[2m[36m(train pid=1266614)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1266614)[0m 
2023-11-03 09:05:12,325	WARNING util.py:214 -- The `on_step_end` operation took 0.659 s, which may be a performance bottleneck.
[2m[36m(train pid=1269842)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1269842)[0m 
[2m[36m(train pid=1273564)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1273564)[0m 
[2m[36m(train pid=1273854)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1273854)[0m 
2023-11-03 09:09:04,912	WARNING util.py:214 -- The `on_step_end` operation took 0.527 s, which may be a performance bottleneck.
2023-11-03 09:09:07,535	WARNING util.py:214 -- The `start_trial` operation took 0.513 s, which may be a performance bottleneck.
[2m[36m(train pid=1278073)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1278073)[0m 
[2m[36m(train pid=1278222)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1278222)[0m 
2023-11-03 09:10:57,312	WARNING util.py:214 -- The `on_step_end` operation took 0.511 s, which may be a performance bottleneck.
2023-11-03 09:11:02,932	WARNING util.py:214 -- The `on_step_end` operation took 0.600 s, which may be a performance bottleneck.
[2m[36m(train pid=1281127)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1281127)[0m 
[2m[36m(train pid=1281265)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1281265)[0m 
2023-11-03 09:12:47,837	WARNING util.py:214 -- The `on_step_end` operation took 0.516 s, which may be a performance bottleneck.
2023-11-03 09:12:53,779	WARNING util.py:214 -- The `on_step_end` operation took 0.526 s, which may be a performance bottleneck.
[2m[36m(train pid=1283917)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1283917)[0m 
2023-11-03 09:14:59,879	WARNING util.py:214 -- The `on_step_end` operation took 0.586 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 09:01:07 (running for 10:30:04.85)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 960/1000000 (31 RUNNING, 929 TERMINATED)


== Status ==
Current time: 2023-11-03 09:01:12 (running for 10:30:10.51)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 965/1000000 (32 RUNNING, 933 TERMINATED)


== Status ==
Current time: 2023-11-03 09:03:06 (running for 10:32:04.48)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 965/1000000 (32 RUNNING, 933 TERMINATED)


== Status ==
Current time: 2023-11-03 09:03:15 (running for 10:32:13.28)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 968/1000000 (32 RUNNING, 936 TERMINATED)


== Status ==
Current time: 2023-11-03 09:05:06 (running for 10:34:04.19)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 968/1000000 (32 RUNNING, 936 TERMINATED)


== Status ==
Current time: 2023-11-03 09:05:12 (running for 10:34:09.92)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 973/1000000 (1 PENDING, 30 RUNNING, 942 TERMINATED)


== Status ==
Current time: 2023-11-03 09:07:03 (running for 10:36:01.29)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 973/1000000 (31 RUNNING, 942 TERMINATED)


== Status ==
Current time: 2023-11-03 09:07:09 (running for 10:36:07.09)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 978/1000000 (32 RUNNING, 946 TERMINATED)


== Status ==
Current time: 2023-11-03 09:09:04 (running for 10:38:02.51)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 978/1000000 (32 RUNNING, 946 TERMINATED)


== Status ==
Current time: 2023-11-03 09:09:10 (running for 10:38:08.46)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 983/1000000 (32 RUNNING, 951 TERMINATED)


== Status ==
Current time: 2023-11-03 09:10:57 (running for 10:39:54.95)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 983/1000000 (32 RUNNING, 951 TERMINATED)


== Status ==
Current time: 2023-11-03 09:11:02 (running for 10:40:00.57)
Memory usage on this node: 23.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 988/1000000 (1 PENDING, 30 RUNNING, 957 TERMINATED)


== Status ==
Current time: 2023-11-03 09:12:47 (running for 10:41:45.51)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 988/1000000 (31 RUNNING, 957 TERMINATED)


== Status ==
Current time: 2023-11-03 09:12:53 (running for 10:41:51.53)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 993/1000000 (32 RUNNING, 961 TERMINATED)


2023-11-03 09:15:01,928	WARNING util.py:214 -- The `start_trial` operation took 0.537 s, which may be a performance bottleneck.
[2m[36m(train pid=1288627)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1288627)[0m 
[2m[36m(train pid=1288767)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1288767)[0m 
2023-11-03 09:16:57,898	WARNING util.py:214 -- The `start_trial` operation took 0.504 s, which may be a performance bottleneck.
[2m[36m(train pid=1293875)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1293875)[0m 
[2m[36m(train pid=1293869)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1293869)[0m 
[2m[36m(train pid=1298156)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1298156)[0m 
[2m[36m(train pid=1298136)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1298136)[0m 
2023-11-03 09:20:06,035	WARNING util.py:214 -- The `on_step_end` operation took 0.781 s, which may be a performance bottleneck.
[2m[36m(train pid=1301504)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1301504)[0m 
[2m[36m(train pid=1301371)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1301371)[0m 
2023-11-03 09:21:39,950	WARNING util.py:214 -- The `start_trial` operation took 0.570 s, which may be a performance bottleneck.
2023-11-03 09:21:44,047	WARNING util.py:214 -- The `on_step_end` operation took 0.572 s, which may be a performance bottleneck.
[2m[36m(train pid=1304813)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1304813)[0m 
[2m[36m(train pid=1304827)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1304827)[0m 
2023-11-03 09:23:25,566	WARNING util.py:214 -- The `on_step_end` operation took 0.537 s, which may be a performance bottleneck.
[2m[36m(train pid=1308330)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1308330)[0m 
2023-11-03 09:25:17,000	WARNING util.py:214 -- The `start_trial` operation took 1.065 s, which may be a performance bottleneck.
2023-11-03 09:25:19,142	WARNING util.py:214 -- The `on_step_end` operation took 0.563 s, which may be a performance bottleneck.
[2m[36m(train pid=1311705)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1311705)[0m 
[2m[36m(train pid=1311558)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1311558)[0m 
[2m[36m(train pid=1311703)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1311703)[0m 
== Status ==
Current time: 2023-11-03 09:14:59 (running for 10:43:57.48)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 993/1000000 (32 RUNNING, 961 TERMINATED)


== Status ==
Current time: 2023-11-03 09:15:05 (running for 10:44:03.02)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 997/1000000 (32 RUNNING, 965 TERMINATED)


== Status ==
Current time: 2023-11-03 09:16:54 (running for 10:45:52.00)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 997/1000000 (32 RUNNING, 965 TERMINATED)


== Status ==
Current time: 2023-11-03 09:17:00 (running for 10:45:57.85)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1002/1000000 (32 RUNNING, 970 TERMINATED)


== Status ==
Current time: 2023-11-03 09:18:26 (running for 10:47:23.93)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1002/1000000 (32 RUNNING, 970 TERMINATED)


== Status ==
Current time: 2023-11-03 09:18:31 (running for 10:47:29.48)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1008/1000000 (32 RUNNING, 976 TERMINATED)


== Status ==
Current time: 2023-11-03 09:19:59 (running for 10:48:57.48)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1008/1000000 (32 RUNNING, 976 TERMINATED)


== Status ==
Current time: 2023-11-03 09:20:06 (running for 10:49:03.63)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1014/1000000 (1 PENDING, 31 RUNNING, 982 TERMINATED)


== Status ==
Current time: 2023-11-03 09:21:38 (running for 10:50:36.04)
Memory usage on this node: 23.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1014/1000000 (1 PENDING, 30 RUNNING, 983 TERMINATED)


== Status ==
Current time: 2023-11-03 09:21:44 (running for 10:50:41.71)
Memory usage on this node: 23.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1019/1000000 (31 RUNNING, 988 TERMINATED)


== Status ==
Current time: 2023-11-03 09:23:19 (running for 10:52:17.25)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1020/1000000 (1 PENDING, 31 RUNNING, 988 TERMINATED)


== Status ==
Current time: 2023-11-03 09:23:25 (running for 10:52:23.28)
Memory usage on this node: 23.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1026/1000000 (1 PENDING, 31 RUNNING, 994 TERMINATED)


== Status ==
Current time: 2023-11-03 09:25:13 (running for 10:54:11.07)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1026/1000000 (1 PENDING, 31 RUNNING, 994 TERMINATED)


== Status ==
Current time: 2023-11-03 09:25:19 (running for 10:54:16.74)
Memory usage on this node: 23.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1030/1000000 (32 RUNNING, 998 TERMINATED)


2023-11-03 09:28:29,399	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.657 s, which may be a performance bottleneck.
2023-11-03 09:28:29,399	WARNING util.py:214 -- The `process_trial_result` operation took 0.657 s, which may be a performance bottleneck.
2023-11-03 09:28:29,399	WARNING util.py:214 -- Processing trial results took 0.657 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 09:28:29,399	WARNING util.py:214 -- The `process_trial_result` operation took 0.657 s, which may be a performance bottleneck.
[2m[36m(train pid=1316041)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1316041)[0m 
[2m[36m(train pid=1316337)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1316337)[0m 
2023-11-03 09:28:33,131	WARNING util.py:214 -- The `on_step_end` operation took 0.533 s, which may be a performance bottleneck.
2023-11-03 09:28:39,025	WARNING util.py:214 -- The `on_step_end` operation took 0.716 s, which may be a performance bottleneck.
[2m[36m(train pid=1320866)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1320866)[0m 
[2m[36m(train pid=1325157)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1325157)[0m 
2023-11-03 09:32:02,422	WARNING util.py:214 -- The `start_trial` operation took 0.814 s, which may be a performance bottleneck.
2023-11-03 09:32:03,294	WARNING util.py:214 -- The `on_step_end` operation took 0.705 s, which may be a performance bottleneck.
[2m[36m(train pid=1329000)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1329000)[0m 
2023-11-03 09:34:05,793	WARNING util.py:214 -- The `on_step_end` operation took 0.772 s, which may be a performance bottleneck.
2023-11-03 09:34:07,816	WARNING util.py:214 -- The `start_trial` operation took 0.810 s, which may be a performance bottleneck.
[2m[36m(train pid=1335399)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1335399)[0m 
[2m[36m(train pid=1335404)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1335404)[0m 
[2m[36m(train pid=1335539)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1335539)[0m 
2023-11-03 09:35:58,116	WARNING util.py:214 -- The `on_step_end` operation took 0.576 s, which may be a performance bottleneck.
2023-11-03 09:36:00,249	WARNING util.py:214 -- The `start_trial` operation took 0.515 s, which may be a performance bottleneck.
2023-11-03 09:36:03,705	WARNING util.py:214 -- The `on_step_end` operation took 0.567 s, which may be a performance bottleneck.
[2m[36m(train pid=1340373)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1340373)[0m 
2023-11-03 09:37:45,883	WARNING util.py:214 -- The `on_step_end` operation took 0.553 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 09:26:55 (running for 10:55:53.20)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1030/1000000 (32 RUNNING, 998 TERMINATED)


== Status ==
Current time: 2023-11-03 09:27:01 (running for 10:55:58.87)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1035/1000000 (31 RUNNING, 1004 TERMINATED)


== Status ==
Current time: 2023-11-03 09:28:33 (running for 10:57:30.73)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1036/1000000 (1 PENDING, 31 RUNNING, 1004 TERMINATED)


== Status ==
Current time: 2023-11-03 09:28:39 (running for 10:57:36.62)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1042/1000000 (1 PENDING, 31 RUNNING, 1010 TERMINATED)


== Status ==
Current time: 2023-11-03 09:30:11 (running for 10:59:09.15)
Memory usage on this node: 23.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1042/1000000 (1 PENDING, 31 RUNNING, 1010 TERMINATED)


== Status ==
Current time: 2023-11-03 09:30:17 (running for 10:59:14.88)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1048/1000000 (32 RUNNING, 1016 TERMINATED)


== Status ==
Current time: 2023-11-03 09:31:57 (running for 11:00:55.11)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1048/1000000 (31 RUNNING, 1017 TERMINATED)


== Status ==
Current time: 2023-11-03 09:32:03 (running for 11:01:00.95)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1054/1000000 (1 PENDING, 30 RUNNING, 1023 TERMINATED)


== Status ==
Current time: 2023-11-03 09:32:11 (running for 11:01:09.42)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1056/1000000 (32 RUNNING, 1024 TERMINATED)


== Status ==
Current time: 2023-11-03 09:33:59 (running for 11:02:57.28)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1056/1000000 (32 RUNNING, 1024 TERMINATED)


== Status ==
Current time: 2023-11-03 09:34:05 (running for 11:03:03.39)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1062/1000000 (1 PENDING, 31 RUNNING, 1030 TERMINATED)


== Status ==
Current time: 2023-11-03 09:34:12 (running for 11:03:09.85)
Memory usage on this node: 23.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1067/1000000 (32 RUNNING, 1035 TERMINATED)


== Status ==
Current time: 2023-11-03 09:35:58 (running for 11:04:55.71)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1067/1000000 (32 RUNNING, 1035 TERMINATED)


== Status ==
Current time: 2023-11-03 09:36:03 (running for 11:05:01.30)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1071/1000000 (31 RUNNING, 1040 TERMINATED)


[2m[36m(train pid=1345004)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1345004)[0m 
2023-11-03 09:39:04,005	WARNING util.py:214 -- The `on_step_end` operation took 0.503 s, which may be a performance bottleneck.
2023-11-03 09:39:07,606	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 1.010 s, which may be a performance bottleneck.
2023-11-03 09:39:07,607	WARNING util.py:214 -- The `process_trial_result` operation took 1.011 s, which may be a performance bottleneck.
2023-11-03 09:39:07,607	WARNING util.py:214 -- Processing trial results took 1.011 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 09:39:07,607	WARNING util.py:214 -- The `process_trial_result` operation took 1.011 s, which may be a performance bottleneck.
2023-11-03 09:39:09,925	WARNING util.py:214 -- The `on_step_end` operation took 0.605 s, which may be a performance bottleneck.
2023-11-03 09:39:11,806	WARNING util.py:214 -- The `start_trial` operation took 0.513 s, which may be a performance bottleneck.
[2m[36m(train pid=1351189)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1351189)[0m 
[2m[36m(train pid=1351226)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1351226)[0m 
[2m[36m(train pid=1354756)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1354756)[0m 
[2m[36m(train pid=1354760)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1354760)[0m 
2023-11-03 09:42:52,694	WARNING util.py:214 -- The `on_step_end` operation took 0.584 s, which may be a performance bottleneck.
2023-11-03 09:42:58,808	WARNING util.py:214 -- The `on_step_end` operation took 0.907 s, which may be a performance bottleneck.
[2m[36m(train pid=1358474)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1358474)[0m 
2023-11-03 09:44:49,424	WARNING util.py:214 -- The `on_step_end` operation took 0.565 s, which may be a performance bottleneck.
[2m[36m(train pid=1365111)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1365111)[0m 
[2m[36m(train pid=1365136)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1365136)[0m 
[2m[36m(train pid=1365140)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1365140)[0m 
[2m[36m(train pid=1370757)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1370757)[0m 
2023-11-03 09:47:44,027	WARNING util.py:214 -- The `start_trial` operation took 0.674 s, which may be a performance bottleneck.
2023-11-03 09:47:47,838	WARNING util.py:214 -- The `on_step_end` operation took 0.693 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 09:37:45 (running for 11:06:43.53)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1072/1000000 (32 RUNNING, 1040 TERMINATED)


== Status ==
Current time: 2023-11-03 09:39:04 (running for 11:08:01.62)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1072/1000000 (32 RUNNING, 1040 TERMINATED)


== Status ==
Current time: 2023-11-03 09:39:09 (running for 11:08:07.52)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1078/1000000 (1 PENDING, 31 RUNNING, 1046 TERMINATED)


== Status ==
Current time: 2023-11-03 09:39:15 (running for 11:08:13.08)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1083/1000000 (31 RUNNING, 1052 TERMINATED)


== Status ==
Current time: 2023-11-03 09:39:25 (running for 11:08:23.46)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1088/1000000 (32 RUNNING, 1056 TERMINATED)


== Status ==
Current time: 2023-11-03 09:41:04 (running for 11:10:01.76)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1088/1000000 (32 RUNNING, 1056 TERMINATED)


== Status ==
Current time: 2023-11-03 09:41:10 (running for 11:10:07.97)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1093/1000000 (32 RUNNING, 1061 TERMINATED)


== Status ==
Current time: 2023-11-03 09:42:52 (running for 11:11:50.29)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1093/1000000 (32 RUNNING, 1061 TERMINATED)


== Status ==
Current time: 2023-11-03 09:42:58 (running for 11:11:56.42)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1098/1000000 (1 PENDING, 30 RUNNING, 1067 TERMINATED)


== Status ==
Current time: 2023-11-03 09:44:43 (running for 11:13:41.35)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1098/1000000 (31 RUNNING, 1067 TERMINATED)


== Status ==
Current time: 2023-11-03 09:44:49 (running for 11:13:47.13)
Memory usage on this node: 23.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1103/1000000 (32 RUNNING, 1071 TERMINATED)


== Status ==
Current time: 2023-11-03 09:46:17 (running for 11:15:15.42)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1103/1000000 (31 RUNNING, 1072 TERMINATED)


== Status ==
Current time: 2023-11-03 09:46:23 (running for 11:15:20.94)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1109/1000000 (31 RUNNING, 1078 TERMINATED)


== Status ==
Current time: 2023-11-03 09:47:42 (running for 11:16:39.73)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1110/1000000 (1 PENDING, 30 RUNNING, 1079 TERMINATED)


[2m[36m(train pid=1373340)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1373340)[0m 
2023-11-03 09:49:17,984	WARNING util.py:214 -- The `on_step_end` operation took 0.550 s, which may be a performance bottleneck.
2023-11-03 09:49:23,031	WARNING util.py:214 -- The `start_trial` operation took 0.579 s, which may be a performance bottleneck.
[2m[36m(train pid=1375448)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1375448)[0m 
[2m[36m(train pid=1375311)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1375311)[0m 
[2m[36m(train pid=1375471)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1375471)[0m 
2023-11-03 09:51:02,132	WARNING util.py:214 -- The `on_step_end` operation took 0.541 s, which may be a performance bottleneck.
2023-11-03 09:51:08,335	WARNING util.py:214 -- The `on_step_end` operation took 0.701 s, which may be a performance bottleneck.
[2m[36m(train pid=1378424)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1378424)[0m 
[2m[36m(train pid=1378414)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1378414)[0m 
2023-11-03 09:52:54,055	WARNING util.py:214 -- The `on_step_end` operation took 0.761 s, which may be a performance bottleneck.
[2m[36m(train pid=1381880)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1381880)[0m 
2023-11-03 09:54:25,738	WARNING util.py:214 -- The `on_step_end` operation took 0.577 s, which may be a performance bottleneck.
2023-11-03 09:54:31,268	WARNING util.py:214 -- The `start_trial` operation took 0.615 s, which may be a performance bottleneck.
[2m[36m(train pid=1386218)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1386218)[0m 
2023-11-03 09:55:59,336	WARNING util.py:214 -- The `on_step_end` operation took 0.553 s, which may be a performance bottleneck.
[2m[36m(train pid=1389914)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1389914)[0m 
2023-11-03 09:57:43,261	WARNING util.py:214 -- The `on_step_end` operation took 0.708 s, which may be a performance bottleneck.
2023-11-03 09:57:48,878	WARNING util.py:214 -- The `start_trial` operation took 0.566 s, which may be a performance bottleneck.
2023-11-03 09:57:49,640	WARNING util.py:214 -- The `on_step_end` operation took 0.762 s, which may be a performance bottleneck.
[2m[36m(train pid=1393361)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1393361)[0m 
2023-11-03 09:59:50,553	WARNING util.py:214 -- The `on_step_end` operation took 0.782 s, which may be a performance bottleneck.
2023-11-03 09:59:52,342	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.506 s, which may be a performance bottleneck.
2023-11-03 09:59:52,342	WARNING util.py:214 -- The `process_trial_result` operation took 0.507 s, which may be a performance bottleneck.
2023-11-03 09:59:52,342	WARNING util.py:214 -- Processing trial results took 0.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 09:59:52,342	WARNING util.py:214 -- The `process_trial_result` operation took 0.507 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 09:47:47 (running for 11:16:45.48)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1116/1000000 (1 PENDING, 30 RUNNING, 1085 TERMINATED)


== Status ==
Current time: 2023-11-03 09:49:18 (running for 11:18:15.72)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1116/1000000 (31 RUNNING, 1085 TERMINATED)


== Status ==
Current time: 2023-11-03 09:49:23 (running for 11:18:21.11)
Memory usage on this node: 23.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1121/1000000 (32 RUNNING, 1089 TERMINATED)


== Status ==
Current time: 2023-11-03 09:51:02 (running for 11:19:59.90)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1121/1000000 (31 RUNNING, 1090 TERMINATED)


== Status ==
Current time: 2023-11-03 09:51:08 (running for 11:20:05.93)
Memory usage on this node: 23.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1126/1000000 (1 PENDING, 31 RUNNING, 1094 TERMINATED)


== Status ==
Current time: 2023-11-03 09:52:54 (running for 11:21:51.65)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1126/1000000 (32 RUNNING, 1094 TERMINATED)


== Status ==
Current time: 2023-11-03 09:54:25 (running for 11:23:23.38)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1126/1000000 (32 RUNNING, 1094 TERMINATED)


== Status ==
Current time: 2023-11-03 09:54:31 (running for 11:23:29.22)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1131/1000000 (32 RUNNING, 1099 TERMINATED)


== Status ==
Current time: 2023-11-03 09:55:59 (running for 11:24:57.02)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1131/1000000 (31 RUNNING, 1100 TERMINATED)


== Status ==
Current time: 2023-11-03 09:56:05 (running for 11:25:02.60)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1137/1000000 (32 RUNNING, 1105 TERMINATED)


== Status ==
Current time: 2023-11-03 09:57:37 (running for 11:26:35.11)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1137/1000000 (32 RUNNING, 1105 TERMINATED)


== Status ==
Current time: 2023-11-03 09:57:43 (running for 11:26:40.90)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1143/1000000 (1 PENDING, 30 RUNNING, 1112 TERMINATED)


== Status ==
Current time: 2023-11-03 09:57:49 (running for 11:26:47.24)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1149/1000000 (32 RUNNING, 1117 TERMINATED)


== Status ==
Current time: 2023-11-03 09:59:50 (running for 11:28:48.21)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1149/1000000 (32 RUNNING, 1117 TERMINATED)


[2m[36m(train pid=1395576)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1395576)[0m 
[2m[36m(train pid=1395718)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1395718)[0m 
2023-11-03 10:01:50,125	WARNING util.py:214 -- The `on_step_end` operation took 0.628 s, which may be a performance bottleneck.
2023-11-03 10:01:55,852	WARNING util.py:214 -- The `on_step_end` operation took 0.636 s, which may be a performance bottleneck.
[2m[36m(train pid=1398903)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1398903)[0m 
[2m[36m(train pid=1398768)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1398768)[0m 
2023-11-03 10:03:53,245	WARNING util.py:214 -- The `on_step_end` operation took 0.657 s, which may be a performance bottleneck.
[2m[36m(train pid=1403217)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1403217)[0m 
2023-11-03 10:05:43,852	WARNING util.py:214 -- The `on_step_end` operation took 0.591 s, which may be a performance bottleneck.
2023-11-03 10:05:49,841	WARNING util.py:214 -- The `on_step_end` operation took 0.717 s, which may be a performance bottleneck.
[2m[36m(train pid=1408071)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1408071)[0m 
2023-11-03 10:07:22,047	WARNING util.py:214 -- The `on_step_end` operation took 0.687 s, which may be a performance bottleneck.
2023-11-03 10:07:28,020	WARNING util.py:214 -- The `on_step_end` operation took 0.841 s, which may be a performance bottleneck.
[2m[36m(train pid=1410954)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1410954)[0m 
2023-11-03 10:09:03,378	WARNING util.py:214 -- The `on_step_end` operation took 0.539 s, which may be a performance bottleneck.
2023-11-03 10:09:09,403	WARNING util.py:214 -- The `on_step_end` operation took 0.872 s, which may be a performance bottleneck.
[2m[36m(train pid=1414441)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1414441)[0m 
2023-11-03 10:10:47,532	WARNING util.py:214 -- The `on_step_end` operation took 0.597 s, which may be a performance bottleneck.
2023-11-03 10:10:53,957	WARNING util.py:214 -- The `on_step_end` operation took 0.653 s, which may be a performance bottleneck.
[2m[36m(train pid=1417588)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1417588)[0m 
2023-11-03 10:12:46,142	WARNING util.py:214 -- The `on_step_end` operation took 0.636 s, which may be a performance bottleneck.
2023-11-03 10:12:51,938	WARNING util.py:214 -- The `on_step_end` operation took 0.574 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 10:00:00 (running for 11:28:57.86)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1152/1000000 (32 RUNNING, 1120 TERMINATED)


== Status ==
Current time: 2023-11-03 10:01:50 (running for 11:30:47.72)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1152/1000000 (32 RUNNING, 1120 TERMINATED)


== Status ==
Current time: 2023-11-03 10:01:55 (running for 11:30:53.45)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1156/1000000 (32 RUNNING, 1124 TERMINATED)


== Status ==
Current time: 2023-11-03 10:03:53 (running for 11:32:50.84)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1156/1000000 (31 RUNNING, 1125 TERMINATED)


== Status ==
Current time: 2023-11-03 10:04:01 (running for 11:32:58.88)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1158/1000000 (32 RUNNING, 1126 TERMINATED)


== Status ==
Current time: 2023-11-03 10:05:43 (running for 11:34:41.50)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1158/1000000 (32 RUNNING, 1126 TERMINATED)


== Status ==
Current time: 2023-11-03 10:05:49 (running for 11:34:47.44)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1163/1000000 (1 PENDING, 31 RUNNING, 1131 TERMINATED)


== Status ==
Current time: 2023-11-03 10:07:22 (running for 11:36:19.64)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1163/1000000 (1 PENDING, 30 RUNNING, 1132 TERMINATED)


== Status ==
Current time: 2023-11-03 10:07:28 (running for 11:36:25.65)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1169/1000000 (1 PENDING, 30 RUNNING, 1138 TERMINATED)


== Status ==
Current time: 2023-11-03 10:09:03 (running for 11:38:01.04)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 569e8030 with val_loss=478.8072686234582 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.0759679410354305, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1169/1000000 (31 RUNNING, 1138 TERMINATED)


== Status ==
Current time: 2023-11-03 10:09:09 (running for 11:38:07.00)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1174/1000000 (1 PENDING, 30 RUNNING, 1143 TERMINATED)


== Status ==
Current time: 2023-11-03 10:10:47 (running for 11:39:45.19)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1174/1000000 (31 RUNNING, 1143 TERMINATED)


== Status ==
Current time: 2023-11-03 10:10:54 (running for 11:39:51.72)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1180/1000000 (32 RUNNING, 1148 TERMINATED)


== Status ==
Current time: 2023-11-03 10:12:46 (running for 11:41:43.74)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1180/1000000 (32 RUNNING, 1148 TERMINATED)


[2m[36m(train pid=1421041)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1421041)[0m 
[2m[36m(train pid=1421031)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1421031)[0m 
2023-11-03 10:14:37,744	WARNING util.py:214 -- The `on_step_end` operation took 0.697 s, which may be a performance bottleneck.
2023-11-03 10:14:44,040	WARNING util.py:214 -- The `on_step_end` operation took 0.745 s, which may be a performance bottleneck.
[2m[36m(train pid=1424572)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1424572)[0m 
2023-11-03 10:16:37,533	WARNING util.py:214 -- The `on_step_end` operation took 0.638 s, which may be a performance bottleneck.
2023-11-03 10:16:43,855	WARNING util.py:214 -- The `on_step_end` operation took 0.825 s, which may be a performance bottleneck.
[2m[36m(train pid=1426860)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1426860)[0m 
2023-11-03 10:18:48,811	WARNING util.py:214 -- The `on_step_end` operation took 0.794 s, which may be a performance bottleneck.
[2m[36m(train pid=1428491)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1428491)[0m 
[2m[36m(train pid=1428488)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1428488)[0m 
2023-11-03 10:20:55,846	WARNING util.py:214 -- The `on_step_end` operation took 0.906 s, which may be a performance bottleneck.
[2m[36m(train pid=1431716)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1431716)[0m 
2023-11-03 10:23:00,962	WARNING util.py:214 -- The `on_step_end` operation took 0.744 s, which may be a performance bottleneck.
2023-11-03 10:23:06,798	WARNING util.py:214 -- The `on_step_end` operation took 0.684 s, which may be a performance bottleneck.
[2m[36m(train pid=1436400)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1436400)[0m 
2023-11-03 10:24:48,543	WARNING util.py:214 -- The `on_step_end` operation took 0.681 s, which may be a performance bottleneck.
2023-11-03 10:24:49,600	WARNING util.py:214 -- The `start_trial` operation took 0.612 s, which may be a performance bottleneck.
2023-11-03 10:24:50,635	WARNING util.py:214 -- The `start_trial` operation took 0.618 s, which may be a performance bottleneck.
2023-11-03 10:24:54,346	WARNING util.py:214 -- The `on_step_end` operation took 0.720 s, which may be a performance bottleneck.
[2m[36m(train pid=1439410)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1439410)[0m 
2023-11-03 10:26:43,026	WARNING util.py:214 -- The `on_step_end` operation took 0.755 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 10:12:52 (running for 11:41:49.62)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1184/1000000 (32 RUNNING, 1152 TERMINATED)


== Status ==
Current time: 2023-11-03 10:14:37 (running for 11:43:35.38)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1184/1000000 (32 RUNNING, 1152 TERMINATED)


== Status ==
Current time: 2023-11-03 10:14:44 (running for 11:43:41.67)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1189/1000000 (32 RUNNING, 1157 TERMINATED)


== Status ==
Current time: 2023-11-03 10:16:37 (running for 11:45:35.13)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1189/1000000 (32 RUNNING, 1157 TERMINATED)


== Status ==
Current time: 2023-11-03 10:16:43 (running for 11:45:41.45)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1194/1000000 (1 PENDING, 30 RUNNING, 1163 TERMINATED)


== Status ==
Current time: 2023-11-03 10:16:51 (running for 11:45:49.17)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1195/1000000 (32 RUNNING, 1163 TERMINATED)


== Status ==
Current time: 2023-11-03 10:18:48 (running for 11:47:46.42)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1195/1000000 (32 RUNNING, 1163 TERMINATED)


== Status ==
Current time: 2023-11-03 10:18:58 (running for 11:47:56.13)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1198/1000000 (32 RUNNING, 1166 TERMINATED)


== Status ==
Current time: 2023-11-03 10:20:55 (running for 11:49:53.44)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1198/1000000 (32 RUNNING, 1166 TERMINATED)


== Status ==
Current time: 2023-11-03 10:21:03 (running for 11:50:01.19)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1199/1000000 (32 RUNNING, 1167 TERMINATED)


== Status ==
Current time: 2023-11-03 10:23:00 (running for 11:51:58.56)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1199/1000000 (32 RUNNING, 1167 TERMINATED)


== Status ==
Current time: 2023-11-03 10:23:06 (running for 11:52:04.41)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1203/1000000 (1 PENDING, 31 RUNNING, 1171 TERMINATED)


== Status ==
Current time: 2023-11-03 10:24:48 (running for 11:53:46.21)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1203/1000000 (1 PENDING, 31 RUNNING, 1171 TERMINATED)


== Status ==
Current time: 2023-11-03 10:24:54 (running for 11:53:51.99)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1208/1000000 (1 PENDING, 30 RUNNING, 1177 TERMINATED)


2023-11-03 10:26:45,259	WARNING util.py:214 -- The `start_trial` operation took 0.626 s, which may be a performance bottleneck.
2023-11-03 10:26:48,419	WARNING util.py:214 -- The `start_trial` operation took 0.541 s, which may be a performance bottleneck.
2023-11-03 10:26:55,663	WARNING util.py:214 -- The `on_step_end` operation took 0.591 s, which may be a performance bottleneck.
[2m[36m(train pid=1442009)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1442009)[0m 
[2m[36m(train pid=1441993)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1441993)[0m 
[2m[36m(train pid=1442014)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1442014)[0m 
2023-11-03 10:28:48,144	WARNING util.py:214 -- The `on_step_end` operation took 0.945 s, which may be a performance bottleneck.
[2m[36m(train pid=1444129)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1444129)[0m 
[2m[36m(train pid=1444137)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1444137)[0m 
2023-11-03 10:30:51,370	WARNING util.py:214 -- The `on_step_end` operation took 0.750 s, which may be a performance bottleneck.
2023-11-03 10:30:59,959	WARNING util.py:214 -- The `on_step_end` operation took 0.508 s, which may be a performance bottleneck.
[2m[36m(train pid=1445997)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1445997)[0m 
2023-11-03 10:33:01,720	WARNING util.py:214 -- The `on_step_end` operation took 0.714 s, which may be a performance bottleneck.
2023-11-03 10:33:09,942	WARNING util.py:214 -- The `on_step_end` operation took 0.597 s, which may be a performance bottleneck.
[2m[36m(train pid=1449035)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1449035)[0m 
2023-11-03 10:35:05,817	WARNING util.py:214 -- The `on_step_end` operation took 0.758 s, which may be a performance bottleneck.
2023-11-03 10:35:09,232	WARNING util.py:214 -- The `start_trial` operation took 0.538 s, which may be a performance bottleneck.
2023-11-03 10:35:12,022	WARNING util.py:214 -- The `on_step_end` operation took 0.574 s, which may be a performance bottleneck.
[2m[36m(train pid=1453529)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1453529)[0m 
[2m[36m(train pid=1453533)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1453533)[0m 
2023-11-03 10:36:53,920	WARNING util.py:214 -- The `on_step_end` operation took 0.703 s, which may be a performance bottleneck.
2023-11-03 10:36:59,933	WARNING util.py:214 -- The `on_step_end` operation took 0.783 s, which may be a performance bottleneck.
[2m[36m(train pid=1457575)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1457575)[0m 
2023-11-03 10:38:35,000	WARNING util.py:214 -- The `on_step_end` operation took 0.549 s, which may be a performance bottleneck.
2023-11-03 10:38:41,089	WARNING util.py:214 -- The `on_step_end` operation took 0.881 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 10:26:43 (running for 11:55:40.71)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1208/1000000 (31 RUNNING, 1177 TERMINATED)


== Status ==
Current time: 2023-11-03 10:26:48 (running for 11:55:46.38)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1212/1000000 (31 RUNNING, 1181 TERMINATED)


== Status ==
Current time: 2023-11-03 10:26:55 (running for 11:55:53.26)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1215/1000000 (32 RUNNING, 1183 TERMINATED)


== Status ==
Current time: 2023-11-03 10:28:48 (running for 11:57:45.74)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1215/1000000 (32 RUNNING, 1183 TERMINATED)


== Status ==
Current time: 2023-11-03 10:28:57 (running for 11:57:55.44)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1218/1000000 (32 RUNNING, 1186 TERMINATED)


== Status ==
Current time: 2023-11-03 10:30:51 (running for 11:59:49.10)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1218/1000000 (32 RUNNING, 1186 TERMINATED)


== Status ==
Current time: 2023-11-03 10:30:59 (running for 11:59:57.56)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1220/1000000 (32 RUNNING, 1188 TERMINATED)


== Status ==
Current time: 2023-11-03 10:33:01 (running for 12:01:59.32)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1220/1000000 (32 RUNNING, 1188 TERMINATED)


== Status ==
Current time: 2023-11-03 10:33:09 (running for 12:02:07.57)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1221/1000000 (32 RUNNING, 1189 TERMINATED)


== Status ==
Current time: 2023-11-03 10:35:05 (running for 12:04:03.41)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1221/1000000 (32 RUNNING, 1189 TERMINATED)


== Status ==
Current time: 2023-11-03 10:35:12 (running for 12:04:09.62)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1225/1000000 (32 RUNNING, 1193 TERMINATED)


== Status ==
Current time: 2023-11-03 10:36:53 (running for 12:05:51.58)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1225/1000000 (32 RUNNING, 1193 TERMINATED)


== Status ==
Current time: 2023-11-03 10:37:00 (running for 12:05:57.62)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1229/1000000 (1 PENDING, 30 RUNNING, 1198 TERMINATED)


== Status ==
Current time: 2023-11-03 10:38:35 (running for 12:07:32.68)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1229/1000000 (31 RUNNING, 1198 TERMINATED)


2023-11-03 10:38:50,382	WARNING util.py:214 -- The `on_step_end` operation took 0.544 s, which may be a performance bottleneck.
[2m[36m(train pid=1460020)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1460020)[0m 
[2m[36m(train pid=1460022)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1460022)[0m 
2023-11-03 10:40:40,097	WARNING util.py:214 -- The `on_step_end` operation took 0.732 s, which may be a performance bottleneck.
2023-11-03 10:40:46,099	WARNING util.py:214 -- The `on_step_end` operation took 0.847 s, which may be a performance bottleneck.
[2m[36m(train pid=1462179)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1462179)[0m 
[2m[36m(train pid=1462313)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1462313)[0m 
2023-11-03 10:42:48,737	WARNING util.py:214 -- The `on_step_end` operation took 0.962 s, which may be a performance bottleneck.
2023-11-03 10:42:56,979	WARNING util.py:214 -- The `on_step_end` operation took 0.630 s, which may be a performance bottleneck.
[2m[36m(train pid=1464953)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1464953)[0m 
2023-11-03 10:44:50,374	WARNING util.py:214 -- The `on_step_end` operation took 0.651 s, which may be a performance bottleneck.
2023-11-03 10:44:56,000	WARNING util.py:214 -- The `on_step_end` operation took 0.626 s, which may be a performance bottleneck.
[2m[36m(train pid=1469076)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1469076)[0m 
2023-11-03 10:46:53,478	WARNING util.py:214 -- The `on_step_end` operation took 0.798 s, which may be a performance bottleneck.
2023-11-03 10:46:59,765	WARNING util.py:214 -- The `on_step_end` operation took 0.768 s, which may be a performance bottleneck.
[2m[36m(train pid=1472630)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1472630)[0m 
[2m[36m(train pid=1472327)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1472327)[0m 
2023-11-03 10:48:44,920	WARNING util.py:214 -- The `on_step_end` operation took 0.616 s, which may be a performance bottleneck.
2023-11-03 10:48:47,096	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.976 s, which may be a performance bottleneck.
2023-11-03 10:48:47,097	WARNING util.py:214 -- The `process_trial_result` operation took 0.976 s, which may be a performance bottleneck.
2023-11-03 10:48:47,097	WARNING util.py:214 -- Processing trial results took 0.976 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 10:48:47,097	WARNING util.py:214 -- The `process_trial_result` operation took 0.976 s, which may be a performance bottleneck.
2023-11-03 10:48:51,387	WARNING util.py:214 -- The `on_step_end` operation took 0.919 s, which may be a performance bottleneck.
[2m[36m(train pid=1474956)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1474956)[0m 
[2m[36m(train pid=1474961)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1474961)[0m 
2023-11-03 10:50:33,048	WARNING util.py:214 -- The `on_step_end` operation took 0.652 s, which may be a performance bottleneck.
2023-11-03 10:50:39,175	WARNING util.py:214 -- The `on_step_end` operation took 0.663 s, which may be a performance bottleneck.
[2m[36m(train pid=1477029)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1477029)[0m 
[2m[36m(train pid=1477171)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1477171)[0m 
[2m[36m(train pid=1477178)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1477178)[0m 
2023-11-03 10:52:31,369	WARNING util.py:214 -- The `on_step_end` operation took 0.837 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 10:38:41 (running for 12:07:38.72)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1234/1000000 (1 PENDING, 30 RUNNING, 1203 TERMINATED)


== Status ==
Current time: 2023-11-03 10:38:50 (running for 12:07:48.05)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1237/1000000 (32 RUNNING, 1205 TERMINATED)


== Status ==
Current time: 2023-11-03 10:40:40 (running for 12:09:37.78)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1237/1000000 (32 RUNNING, 1205 TERMINATED)


== Status ==
Current time: 2023-11-03 10:40:46 (running for 12:09:43.70)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1241/1000000 (32 RUNNING, 1209 TERMINATED)


== Status ==
Current time: 2023-11-03 10:42:48 (running for 12:11:46.33)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1241/1000000 (32 RUNNING, 1209 TERMINATED)


== Status ==
Current time: 2023-11-03 10:42:57 (running for 12:11:54.63)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1243/1000000 (32 RUNNING, 1211 TERMINATED)


== Status ==
Current time: 2023-11-03 10:44:50 (running for 12:13:47.97)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1243/1000000 (32 RUNNING, 1211 TERMINATED)


== Status ==
Current time: 2023-11-03 10:44:56 (running for 12:13:53.60)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1247/1000000 (31 RUNNING, 1216 TERMINATED)


== Status ==
Current time: 2023-11-03 10:46:53 (running for 12:15:51.08)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1248/1000000 (1 PENDING, 31 RUNNING, 1216 TERMINATED)


== Status ==
Current time: 2023-11-03 10:46:59 (running for 12:15:57.36)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1252/1000000 (1 PENDING, 30 RUNNING, 1221 TERMINATED)


== Status ==
Current time: 2023-11-03 10:48:45 (running for 12:17:42.61)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1252/1000000 (31 RUNNING, 1221 TERMINATED)


== Status ==
Current time: 2023-11-03 10:48:51 (running for 12:17:49.06)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1256/1000000 (1 PENDING, 31 RUNNING, 1224 TERMINATED)


== Status ==
Current time: 2023-11-03 10:50:33 (running for 12:19:30.80)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1256/1000000 (1 PENDING, 31 RUNNING, 1224 TERMINATED)


== Status ==
Current time: 2023-11-03 10:50:39 (running for 12:19:36.81)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1260/1000000 (32 RUNNING, 1228 TERMINATED)


2023-11-03 10:52:35,577	WARNING util.py:214 -- The `start_trial` operation took 0.623 s, which may be a performance bottleneck.
[2m[36m(train pid=1478969)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1478969)[0m 
[2m[36m(train pid=1478974)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1478974)[0m 
2023-11-03 10:54:34,250	WARNING util.py:214 -- The `on_step_end` operation took 0.778 s, which may be a performance bottleneck.
[2m[36m(train pid=1481022)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1481022)[0m 
2023-11-03 10:56:49,416	WARNING util.py:214 -- The `on_step_end` operation took 0.974 s, which may be a performance bottleneck.
2023-11-03 10:56:59,548	WARNING util.py:214 -- The `on_step_end` operation took 0.655 s, which may be a performance bottleneck.
[2m[36m(train pid=1483047)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1483047)[0m 
[2m[36m(train pid=1483064)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1483064)[0m 
2023-11-03 10:58:53,815	WARNING util.py:214 -- The `on_step_end` operation took 0.962 s, which may be a performance bottleneck.
2023-11-03 10:59:02,771	WARNING util.py:214 -- The `on_step_end` operation took 0.660 s, which may be a performance bottleneck.
[2m[36m(train pid=1485706)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1485706)[0m 
2023-11-03 11:01:01,901	WARNING util.py:214 -- The `on_step_end` operation took 0.611 s, which may be a performance bottleneck.
[2m[36m(train pid=1488738)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1488738)[0m 
2023-11-03 11:03:05,415	WARNING util.py:214 -- The `on_step_end` operation took 0.886 s, which may be a performance bottleneck.
2023-11-03 11:03:11,786	WARNING util.py:214 -- The `on_step_end` operation took 0.561 s, which may be a performance bottleneck.
[2m[36m(train pid=1491933)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1491933)[0m 
[2m[36m(train pid=1491930)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1491930)[0m 
2023-11-03 11:05:05,964	WARNING util.py:214 -- The `on_step_end` operation took 0.611 s, which may be a performance bottleneck.
2023-11-03 11:05:12,353	WARNING util.py:214 -- The `on_step_end` operation took 0.829 s, which may be a performance bottleneck.
2023-11-03 11:05:20,903	WARNING util.py:214 -- The `on_step_end` operation took 0.533 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 10:52:31 (running for 12:21:28.99)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1260/1000000 (31 RUNNING, 1229 TERMINATED)


== Status ==
Current time: 2023-11-03 10:52:37 (running for 12:21:34.88)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1264/1000000 (32 RUNNING, 1232 TERMINATED)


== Status ==
Current time: 2023-11-03 10:54:34 (running for 12:23:31.85)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1264/1000000 (32 RUNNING, 1232 TERMINATED)


== Status ==
Current time: 2023-11-03 10:54:44 (running for 12:23:41.78)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1267/1000000 (32 RUNNING, 1235 TERMINATED)


== Status ==
Current time: 2023-11-03 10:56:49 (running for 12:25:47.09)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1267/1000000 (32 RUNNING, 1235 TERMINATED)


== Status ==
Current time: 2023-11-03 10:56:59 (running for 12:25:57.19)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1270/1000000 (32 RUNNING, 1238 TERMINATED)


== Status ==
Current time: 2023-11-03 10:58:53 (running for 12:27:51.41)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1270/1000000 (32 RUNNING, 1238 TERMINATED)


== Status ==
Current time: 2023-11-03 10:59:02 (running for 12:28:00.41)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1272/1000000 (32 RUNNING, 1240 TERMINATED)


== Status ==
Current time: 2023-11-03 11:01:01 (running for 12:29:59.50)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1272/1000000 (32 RUNNING, 1240 TERMINATED)


== Status ==
Current time: 2023-11-03 11:01:10 (running for 12:30:08.16)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1274/1000000 (32 RUNNING, 1242 TERMINATED)


== Status ==
Current time: 2023-11-03 11:03:05 (running for 12:32:03.01)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1274/1000000 (32 RUNNING, 1242 TERMINATED)


== Status ==
Current time: 2023-11-03 11:03:11 (running for 12:32:09.43)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1278/1000000 (32 RUNNING, 1246 TERMINATED)


== Status ==
Current time: 2023-11-03 11:05:06 (running for 12:34:03.75)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1278/1000000 (32 RUNNING, 1246 TERMINATED)


== Status ==
Current time: 2023-11-03 11:05:12 (running for 12:34:09.95)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1282/1000000 (1 PENDING, 31 RUNNING, 1250 TERMINATED)


[2m[36m(train pid=1494648)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1494648)[0m 
[2m[36m(train pid=1494650)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1494650)[0m 
2023-11-03 11:07:19,677	WARNING util.py:214 -- The `on_step_end` operation took 0.866 s, which may be a performance bottleneck.
2023-11-03 11:07:28,938	WARNING util.py:214 -- The `on_step_end` operation took 0.580 s, which may be a performance bottleneck.
[2m[36m(train pid=1496153)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1496153)[0m 
[2m[36m(train pid=1496142)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1496142)[0m 
2023-11-03 11:09:21,368	WARNING util.py:214 -- The `on_step_end` operation took 0.917 s, which may be a performance bottleneck.
[2m[36m(train pid=1497804)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1497804)[0m 
[2m[36m(train pid=1497806)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1497806)[0m 
2023-11-03 11:11:25,443	WARNING util.py:214 -- The `on_step_end` operation took 0.776 s, which may be a performance bottleneck.
[2m[36m(train pid=1501159)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1501159)[0m 
[2m[36m(train pid=1501161)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1501161)[0m 
2023-11-03 11:13:31,722	WARNING util.py:214 -- The `on_step_end` operation took 0.868 s, which may be a performance bottleneck.
2023-11-03 11:13:34,030	WARNING util.py:214 -- The `start_trial` operation took 0.507 s, which may be a performance bottleneck.
[2m[36m(train pid=1503812)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1503812)[0m 
[2m[36m(train pid=1503944)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1503944)[0m 
2023-11-03 11:15:28,478	WARNING util.py:214 -- The `on_step_end` operation took 0.662 s, which may be a performance bottleneck.
2023-11-03 11:15:35,132	WARNING util.py:214 -- The `on_step_end` operation took 0.922 s, which may be a performance bottleneck.
[2m[36m(train pid=1507366)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1507366)[0m 
[2m[36m(train pid=1507352)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1507352)[0m 
2023-11-03 11:17:13,483	WARNING util.py:214 -- The `on_step_end` operation took 0.740 s, which may be a performance bottleneck.
2023-11-03 11:17:19,305	WARNING util.py:214 -- The `start_trial` operation took 0.761 s, which may be a performance bottleneck.
2023-11-03 11:17:19,828	WARNING util.py:214 -- The `on_step_end` operation took 0.523 s, which may be a performance bottleneck.
[2m[36m(train pid=1509442)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1509442)[0m 
2023-11-03 11:19:12,473	WARNING util.py:214 -- The `on_step_end` operation took 0.886 s, which may be a performance bottleneck.
2023-11-03 11:19:17,187	WARNING util.py:214 -- The `start_trial` operation took 0.575 s, which may be a performance bottleneck.
2023-11-03 11:19:18,954	WARNING util.py:214 -- The `on_step_end` operation took 0.884 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 11:05:20 (running for 12:34:18.50)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1283/1000000 (32 RUNNING, 1251 TERMINATED)


== Status ==
Current time: 2023-11-03 11:07:19 (running for 12:36:17.27)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1283/1000000 (32 RUNNING, 1251 TERMINATED)


== Status ==
Current time: 2023-11-03 11:07:29 (running for 12:36:26.63)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1285/1000000 (32 RUNNING, 1253 TERMINATED)


== Status ==
Current time: 2023-11-03 11:09:21 (running for 12:38:19.03)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1285/1000000 (32 RUNNING, 1253 TERMINATED)


== Status ==
Current time: 2023-11-03 11:09:31 (running for 12:38:28.66)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1287/1000000 (32 RUNNING, 1255 TERMINATED)


== Status ==
Current time: 2023-11-03 11:11:25 (running for 12:40:23.05)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1287/1000000 (32 RUNNING, 1255 TERMINATED)


== Status ==
Current time: 2023-11-03 11:11:31 (running for 12:40:28.74)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1290/1000000 (32 RUNNING, 1258 TERMINATED)


== Status ==
Current time: 2023-11-03 11:13:31 (running for 12:42:29.46)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1290/1000000 (32 RUNNING, 1258 TERMINATED)


== Status ==
Current time: 2023-11-03 11:13:41 (running for 12:42:38.76)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1292/1000000 (32 RUNNING, 1260 TERMINATED)


== Status ==
Current time: 2023-11-03 11:15:28 (running for 12:44:26.08)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1292/1000000 (32 RUNNING, 1260 TERMINATED)


== Status ==
Current time: 2023-11-03 11:15:35 (running for 12:44:32.73)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1296/1000000 (1 PENDING, 30 RUNNING, 1265 TERMINATED)


== Status ==
Current time: 2023-11-03 11:17:13 (running for 12:46:11.08)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1296/1000000 (31 RUNNING, 1265 TERMINATED)


== Status ==
Current time: 2023-11-03 11:17:19 (running for 12:46:17.42)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1300/1000000 (32 RUNNING, 1268 TERMINATED)


== Status ==
Current time: 2023-11-03 11:19:12 (running for 12:48:10.07)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1300/1000000 (32 RUNNING, 1268 TERMINATED)


[2m[36m(train pid=1511142)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1511142)[0m 
[2m[36m(train pid=1511139)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1511139)[0m 
2023-11-03 11:21:15,422	WARNING util.py:214 -- The `on_step_end` operation took 0.977 s, which may be a performance bottleneck.
2023-11-03 11:21:25,558	WARNING util.py:214 -- The `on_step_end` operation took 0.576 s, which may be a performance bottleneck.
[2m[36m(train pid=1513651)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1513651)[0m 
2023-11-03 11:23:22,943	WARNING util.py:214 -- The `on_step_end` operation took 0.779 s, which may be a performance bottleneck.
2023-11-03 11:23:26,250	WARNING util.py:214 -- The `start_trial` operation took 0.500 s, which may be a performance bottleneck.
2023-11-03 11:23:29,214	WARNING util.py:214 -- The `on_step_end` operation took 0.828 s, which may be a performance bottleneck.
[2m[36m(train pid=1516780)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1516780)[0m 
[2m[36m(train pid=1516920)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1516920)[0m 
2023-11-03 11:25:19,698	WARNING util.py:214 -- The `on_step_end` operation took 0.720 s, which may be a performance bottleneck.
2023-11-03 11:25:25,656	WARNING util.py:214 -- The `on_step_end` operation took 0.582 s, which may be a performance bottleneck.
2023-11-03 11:25:34,122	WARNING util.py:214 -- The `on_step_end` operation took 0.589 s, which may be a performance bottleneck.
[2m[36m(train pid=1519367)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1519367)[0m 
2023-11-03 11:27:36,470	WARNING util.py:214 -- The `on_step_end` operation took 0.889 s, which may be a performance bottleneck.
2023-11-03 11:27:39,860	WARNING util.py:214 -- The `start_trial` operation took 0.521 s, which may be a performance bottleneck.
2023-11-03 11:27:46,846	WARNING util.py:214 -- The `on_step_end` operation took 0.549 s, which may be a performance bottleneck.
[2m[36m(train pid=1522270)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1522270)[0m 
[2m[36m(train pid=1522272)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1522272)[0m 
2023-11-03 11:29:38,378	WARNING util.py:214 -- The `on_step_end` operation took 0.843 s, which may be a performance bottleneck.
2023-11-03 11:29:44,355	WARNING util.py:214 -- The `on_step_end` operation took 0.783 s, which may be a performance bottleneck.
[2m[36m(train pid=1525555)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1525555)[0m 
[2m[36m(train pid=1525409)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1525409)[0m 
2023-11-03 11:31:51,699	WARNING util.py:214 -- The `on_step_end` operation took 0.802 s, which may be a performance bottleneck.
2023-11-03 11:31:55,361	WARNING util.py:214 -- The `start_trial` operation took 0.554 s, which may be a performance bottleneck.
2023-11-03 11:31:57,960	WARNING util.py:214 -- The `on_step_end` operation took 0.612 s, which may be a performance bottleneck.
2023-11-03 11:33:50,444	WARNING util.py:214 -- The `on_step_end` operation took 0.634 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 11:19:18 (running for 12:48:16.56)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1305/1000000 (32 RUNNING, 1273 TERMINATED)


== Status ==
Current time: 2023-11-03 11:21:15 (running for 12:50:13.02)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1305/1000000 (32 RUNNING, 1273 TERMINATED)


== Status ==
Current time: 2023-11-03 11:21:25 (running for 12:50:23.16)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1308/1000000 (32 RUNNING, 1276 TERMINATED)


== Status ==
Current time: 2023-11-03 11:23:22 (running for 12:52:20.54)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1308/1000000 (32 RUNNING, 1276 TERMINATED)


== Status ==
Current time: 2023-11-03 11:23:29 (running for 12:52:26.95)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1312/1000000 (32 RUNNING, 1280 TERMINATED)


== Status ==
Current time: 2023-11-03 11:25:19 (running for 12:54:17.35)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1312/1000000 (32 RUNNING, 1280 TERMINATED)


== Status ==
Current time: 2023-11-03 11:25:25 (running for 12:54:23.36)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1316/1000000 (31 RUNNING, 1285 TERMINATED)


== Status ==
Current time: 2023-11-03 11:25:34 (running for 12:54:31.72)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1318/1000000 (32 RUNNING, 1286 TERMINATED)


== Status ==
Current time: 2023-11-03 11:27:36 (running for 12:56:34.10)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1318/1000000 (32 RUNNING, 1286 TERMINATED)


== Status ==
Current time: 2023-11-03 11:27:46 (running for 12:56:44.44)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1321/1000000 (32 RUNNING, 1289 TERMINATED)


== Status ==
Current time: 2023-11-03 11:29:38 (running for 12:58:36.08)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1321/1000000 (32 RUNNING, 1289 TERMINATED)


== Status ==
Current time: 2023-11-03 11:29:44 (running for 12:58:41.95)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1325/1000000 (32 RUNNING, 1293 TERMINATED)


== Status ==
Current time: 2023-11-03 11:31:51 (running for 13:00:49.30)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1325/1000000 (32 RUNNING, 1293 TERMINATED)


== Status ==
Current time: 2023-11-03 11:31:57 (running for 13:00:55.56)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1328/1000000 (32 RUNNING, 1296 TERMINATED)


2023-11-03 11:33:53,091	WARNING util.py:214 -- The `start_trial` operation took 0.521 s, which may be a performance bottleneck.
[2m[36m(train pid=1528341)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1528341)[0m 
[2m[36m(train pid=1528344)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1528344)[0m 
2023-11-03 11:33:56,157	WARNING util.py:214 -- The `start_trial` operation took 0.521 s, which may be a performance bottleneck.
2023-11-03 11:33:57,042	WARNING util.py:214 -- The `on_step_end` operation took 0.885 s, which may be a performance bottleneck.
[2m[36m(train pid=1531673)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1531673)[0m 
[2m[36m(train pid=1531688)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1531688)[0m 
2023-11-03 11:35:48,670	WARNING util.py:214 -- The `on_step_end` operation took 0.708 s, which may be a performance bottleneck.
[2m[36m(train pid=1534300)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1534300)[0m 
[2m[36m(train pid=1534305)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1534305)[0m 
2023-11-03 11:37:45,621	WARNING util.py:214 -- The `on_step_end` operation took 0.876 s, which may be a performance bottleneck.
[2m[36m(train pid=1536694)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1536694)[0m 
2023-11-03 11:39:45,657	WARNING util.py:214 -- The `on_step_end` operation took 0.530 s, which may be a performance bottleneck.
2023-11-03 11:39:51,636	WARNING util.py:214 -- The `on_step_end` operation took 0.818 s, which may be a performance bottleneck.
2023-11-03 11:39:54,875	WARNING util.py:214 -- The `start_trial` operation took 0.553 s, which may be a performance bottleneck.
2023-11-03 11:39:58,035	WARNING util.py:214 -- The `on_step_end` operation took 0.862 s, which may be a performance bottleneck.
[2m[36m(train pid=1540303)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1540303)[0m 
[2m[36m(train pid=1540310)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1540310)[0m 
2023-11-03 11:41:56,332	WARNING util.py:214 -- The `on_step_end` operation took 0.870 s, which may be a performance bottleneck.
2023-11-03 11:42:02,802	WARNING util.py:214 -- The `on_step_end` operation took 0.967 s, which may be a performance bottleneck.
[2m[36m(train pid=1543123)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1543123)[0m 
2023-11-03 11:44:09,261	WARNING util.py:214 -- The `on_step_end` operation took 0.928 s, which may be a performance bottleneck.
2023-11-03 11:44:16,691	WARNING util.py:214 -- The `on_step_end` operation took 0.685 s, which may be a performance bottleneck.
[2m[36m(train pid=1546278)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1546278)[0m 
2023-11-03 11:46:08,496	WARNING util.py:214 -- The `on_step_end` operation took 0.835 s, which may be a performance bottleneck.
2023-11-03 11:46:12,875	WARNING util.py:214 -- The `start_trial` operation took 0.755 s, which may be a performance bottleneck.
2023-11-03 11:46:14,598	WARNING util.py:214 -- The `on_step_end` operation took 1.006 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 11:33:50 (running for 13:02:48.18)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1328/1000000 (32 RUNNING, 1296 TERMINATED)


== Status ==
Current time: 2023-11-03 11:33:57 (running for 13:02:54.65)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1332/1000000 (32 RUNNING, 1300 TERMINATED)


== Status ==
Current time: 2023-11-03 11:35:42 (running for 13:04:40.13)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1332/1000000 (32 RUNNING, 1300 TERMINATED)


== Status ==
Current time: 2023-11-03 11:35:48 (running for 13:04:46.43)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1336/1000000 (32 RUNNING, 1304 TERMINATED)


== Status ==
Current time: 2023-11-03 11:37:45 (running for 13:06:43.22)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1336/1000000 (32 RUNNING, 1304 TERMINATED)


== Status ==
Current time: 2023-11-03 11:37:55 (running for 13:06:52.94)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1339/1000000 (32 RUNNING, 1307 TERMINATED)


== Status ==
Current time: 2023-11-03 11:39:45 (running for 13:08:43.41)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1339/1000000 (32 RUNNING, 1307 TERMINATED)


== Status ==
Current time: 2023-11-03 11:39:51 (running for 13:08:49.23)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1343/1000000 (1 PENDING, 31 RUNNING, 1311 TERMINATED)


== Status ==
Current time: 2023-11-03 11:39:58 (running for 13:08:55.63)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1347/1000000 (32 RUNNING, 1315 TERMINATED)


== Status ==
Current time: 2023-11-03 11:41:56 (running for 13:10:54.03)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1347/1000000 (32 RUNNING, 1315 TERMINATED)


== Status ==
Current time: 2023-11-03 11:42:02 (running for 13:11:00.40)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1351/1000000 (32 RUNNING, 1319 TERMINATED)


== Status ==
Current time: 2023-11-03 11:44:09 (running for 13:13:06.86)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1351/1000000 (32 RUNNING, 1319 TERMINATED)


== Status ==
Current time: 2023-11-03 11:44:16 (running for 13:13:14.32)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1353/1000000 (32 RUNNING, 1321 TERMINATED)


== Status ==
Current time: 2023-11-03 11:46:08 (running for 13:15:06.09)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1353/1000000 (32 RUNNING, 1321 TERMINATED)


[2m[36m(train pid=1550011)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1550011)[0m 
2023-11-03 11:48:04,687	WARNING util.py:214 -- The `on_step_end` operation took 0.828 s, which may be a performance bottleneck.
2023-11-03 11:48:10,740	WARNING util.py:214 -- The `on_step_end` operation took 0.775 s, which may be a performance bottleneck.
[2m[36m(train pid=1554326)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1554326)[0m 
2023-11-03 11:49:59,527	WARNING util.py:214 -- The `on_step_end` operation took 0.678 s, which may be a performance bottleneck.
2023-11-03 11:50:02,594	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.853 s, which may be a performance bottleneck.
2023-11-03 11:50:02,594	WARNING util.py:214 -- The `process_trial_result` operation took 0.853 s, which may be a performance bottleneck.
2023-11-03 11:50:02,595	WARNING util.py:214 -- Processing trial results took 0.853 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 11:50:02,595	WARNING util.py:214 -- The `process_trial_result` operation took 0.853 s, which may be a performance bottleneck.
2023-11-03 11:50:03,822	WARNING util.py:214 -- The `start_trial` operation took 1.226 s, which may be a performance bottleneck.
2023-11-03 11:50:05,522	WARNING util.py:214 -- The `on_step_end` operation took 0.750 s, which may be a performance bottleneck.
[2m[36m(train pid=1558024)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1558024)[0m 
2023-11-03 11:51:28,010	WARNING util.py:214 -- The `on_step_end` operation took 0.603 s, which may be a performance bottleneck.
2023-11-03 11:51:33,794	WARNING util.py:214 -- The `on_step_end` operation took 0.701 s, which may be a performance bottleneck.
[2m[36m(train pid=1560066)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1560066)[0m 
2023-11-03 11:53:09,003	WARNING util.py:214 -- The `on_step_end` operation took 0.658 s, which may be a performance bottleneck.
2023-11-03 11:53:14,959	WARNING util.py:214 -- The `on_step_end` operation took 0.874 s, which may be a performance bottleneck.
2023-11-03 11:53:18,047	WARNING util.py:214 -- The `start_trial` operation took 0.511 s, which may be a performance bottleneck.
2023-11-03 11:53:18,942	WARNING util.py:214 -- The `start_trial` operation took 0.642 s, which may be a performance bottleneck.
2023-11-03 11:53:24,567	WARNING util.py:214 -- The `on_step_end` operation took 0.623 s, which may be a performance bottleneck.
[2m[36m(train pid=1562568)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1562568)[0m 
2023-11-03 11:55:23,985	WARNING util.py:214 -- The `on_step_end` operation took 0.803 s, which may be a performance bottleneck.
2023-11-03 11:55:27,693	WARNING util.py:214 -- The `start_trial` operation took 0.643 s, which may be a performance bottleneck.
2023-11-03 11:55:29,871	WARNING util.py:214 -- The `on_step_end` operation took 0.864 s, which may be a performance bottleneck.
2023-11-03 11:57:20,439	WARNING util.py:214 -- The `start_trial` operation took 0.541 s, which may be a performance bottleneck.
[2m[36m(train pid=1565021)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1565021)[0m 
2023-11-03 11:57:25,569	WARNING util.py:214 -- The `on_step_end` operation took 0.784 s, which may be a performance bottleneck.
[2m[36m(train pid=1568444)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1568444)[0m 
2023-11-03 11:59:02,610	WARNING util.py:214 -- The `on_step_end` operation took 0.709 s, which may be a performance bottleneck.
2023-11-03 11:59:09,112	WARNING util.py:214 -- The `on_step_end` operation took 0.757 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 11:46:14 (running for 13:15:12.30)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1357/1000000 (1 PENDING, 31 RUNNING, 1325 TERMINATED)


== Status ==
Current time: 2023-11-03 11:48:04 (running for 13:17:02.36)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1357/1000000 (1 PENDING, 31 RUNNING, 1325 TERMINATED)


== Status ==
Current time: 2023-11-03 11:48:10 (running for 13:17:08.41)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1361/1000000 (32 RUNNING, 1329 TERMINATED)


== Status ==
Current time: 2023-11-03 11:49:59 (running for 13:18:57.12)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1361/1000000 (32 RUNNING, 1329 TERMINATED)


== Status ==
Current time: 2023-11-03 11:50:05 (running for 13:19:03.14)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1363/1000000 (1 PENDING, 30 RUNNING, 1332 TERMINATED)


== Status ==
Current time: 2023-11-03 11:51:28 (running for 13:20:25.68)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1363/1000000 (31 RUNNING, 1332 TERMINATED)


== Status ==
Current time: 2023-11-03 11:51:33 (running for 13:20:31.39)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1368/1000000 (1 PENDING, 31 RUNNING, 1336 TERMINATED)


== Status ==
Current time: 2023-11-03 11:53:09 (running for 13:22:06.73)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1368/1000000 (1 PENDING, 31 RUNNING, 1336 TERMINATED)


== Status ==
Current time: 2023-11-03 11:53:15 (running for 13:22:12.64)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1373/1000000 (1 PENDING, 31 RUNNING, 1341 TERMINATED)


== Status ==
Current time: 2023-11-03 11:53:24 (running for 13:22:22.20)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1376/1000000 (32 RUNNING, 1344 TERMINATED)


== Status ==
Current time: 2023-11-03 11:55:23 (running for 13:24:21.58)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1376/1000000 (32 RUNNING, 1344 TERMINATED)


== Status ==
Current time: 2023-11-03 11:55:29 (running for 13:24:27.47)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1379/1000000 (31 RUNNING, 1348 TERMINATED)


== Status ==
Current time: 2023-11-03 11:57:25 (running for 13:26:23.24)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1380/1000000 (32 RUNNING, 1348 TERMINATED)


== Status ==
Current time: 2023-11-03 11:59:02 (running for 13:28:00.33)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1380/1000000 (32 RUNNING, 1348 TERMINATED)


[2m[36m(train pid=1573351)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1573351)[0m 
2023-11-03 12:00:40,521	WARNING util.py:214 -- The `on_step_end` operation took 0.569 s, which may be a performance bottleneck.
2023-11-03 12:00:45,175	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.722 s, which may be a performance bottleneck.
2023-11-03 12:00:45,175	WARNING util.py:214 -- The `process_trial_result` operation took 0.722 s, which may be a performance bottleneck.
2023-11-03 12:00:45,175	WARNING util.py:214 -- Processing trial results took 0.722 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 12:00:45,176	WARNING util.py:214 -- The `process_trial_result` operation took 0.722 s, which may be a performance bottleneck.
[2m[36m(train pid=1577723)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1577723)[0m 
2023-11-03 12:02:07,602	WARNING util.py:214 -- The `on_step_end` operation took 0.521 s, which may be a performance bottleneck.
2023-11-03 12:02:13,536	WARNING util.py:214 -- The `on_step_end` operation took 0.585 s, which may be a performance bottleneck.
[2m[36m(train pid=1580709)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1580709)[0m 
2023-11-03 12:03:36,318	WARNING util.py:214 -- The `on_step_end` operation took 0.613 s, which may be a performance bottleneck.
2023-11-03 12:03:42,240	WARNING util.py:214 -- The `on_step_end` operation took 0.784 s, which may be a performance bottleneck.
2023-11-03 12:03:48,646	WARNING util.py:214 -- The `on_step_end` operation took 0.962 s, which may be a performance bottleneck.
[2m[36m(train pid=1583002)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1583002)[0m 
[2m[36m(train pid=1583152)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1583152)[0m 
2023-11-03 12:05:34,565	WARNING util.py:214 -- The `on_step_end` operation took 0.886 s, which may be a performance bottleneck.
2023-11-03 12:05:36,354	WARNING util.py:214 -- The `start_trial` operation took 0.518 s, which may be a performance bottleneck.
2023-11-03 12:05:40,752	WARNING util.py:214 -- The `on_step_end` operation took 1.095 s, which may be a performance bottleneck.
[2m[36m(train pid=1586280)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1586280)[0m 
2023-11-03 12:07:27,080	WARNING util.py:214 -- The `on_step_end` operation took 0.844 s, which may be a performance bottleneck.
[2m[36m(train pid=1588990)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1588990)[0m 
2023-11-03 12:08:57,160	WARNING util.py:214 -- The `on_step_end` operation took 0.605 s, which may be a performance bottleneck.
2023-11-03 12:09:03,018	WARNING util.py:214 -- The `on_step_end` operation took 0.763 s, which may be a performance bottleneck.
[2m[36m(train pid=1593359)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1593359)[0m 
[2m[36m(train pid=1593500)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1593500)[0m 
2023-11-03 12:10:24,752	WARNING util.py:214 -- The `on_step_end` operation took 0.625 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 11:59:09 (running for 13:28:06.71)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1385/1000000 (1 PENDING, 30 RUNNING, 1354 TERMINATED)


== Status ==
Current time: 2023-11-03 12:00:40 (running for 13:29:38.14)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1385/1000000 (31 RUNNING, 1354 TERMINATED)


== Status ==
Current time: 2023-11-03 12:00:45 (running for 13:29:43.48)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1389/1000000 (32 RUNNING, 1357 TERMINATED)


== Status ==
Current time: 2023-11-03 12:02:07 (running for 13:31:05.20)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1389/1000000 (32 RUNNING, 1357 TERMINATED)


== Status ==
Current time: 2023-11-03 12:02:13 (running for 13:31:11.20)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1395/1000000 (1 PENDING, 31 RUNNING, 1363 TERMINATED)


== Status ==
Current time: 2023-11-03 12:03:36 (running for 13:32:33.92)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1395/1000000 (1 PENDING, 31 RUNNING, 1363 TERMINATED)


== Status ==
Current time: 2023-11-03 12:03:42 (running for 13:32:39.84)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1400/1000000 (1 PENDING, 30 RUNNING, 1369 TERMINATED)


== Status ==
Current time: 2023-11-03 12:03:48 (running for 13:32:46.31)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1405/1000000 (1 PENDING, 30 RUNNING, 1374 TERMINATED)


== Status ==
Current time: 2023-11-03 12:05:34 (running for 13:34:32.27)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1405/1000000 (31 RUNNING, 1374 TERMINATED)


== Status ==
Current time: 2023-11-03 12:05:40 (running for 13:34:38.35)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1409/1000000 (1 PENDING, 31 RUNNING, 1377 TERMINATED)


== Status ==
Current time: 2023-11-03 12:07:27 (running for 13:36:24.68)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1409/1000000 (32 RUNNING, 1377 TERMINATED)


== Status ==
Current time: 2023-11-03 12:08:57 (running for 13:37:54.82)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1409/1000000 (32 RUNNING, 1377 TERMINATED)


== Status ==
Current time: 2023-11-03 12:09:03 (running for 13:38:00.65)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1413/1000000 (32 RUNNING, 1381 TERMINATED)


== Status ==
Current time: 2023-11-03 12:10:24 (running for 13:39:22.37)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1413/1000000 (32 RUNNING, 1381 TERMINATED)


2023-11-03 12:10:36,277	WARNING util.py:214 -- The `on_step_end` operation took 0.741 s, which may be a performance bottleneck.
[2m[36m(train pid=1598316)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1598316)[0m 
[2m[36m(train pid=1598329)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1598329)[0m 
2023-11-03 12:12:13,608	WARNING util.py:214 -- The `on_step_end` operation took 0.599 s, which may be a performance bottleneck.
2023-11-03 12:12:19,376	WARNING util.py:214 -- The `on_step_end` operation took 0.547 s, which may be a performance bottleneck.
[2m[36m(train pid=1601194)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1601194)[0m 
[2m[36m(train pid=1601332)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1601332)[0m 
2023-11-03 12:13:52,934	WARNING util.py:214 -- The `on_step_end` operation took 0.848 s, which may be a performance bottleneck.
2023-11-03 12:13:58,956	WARNING util.py:214 -- The `on_step_end` operation took 0.914 s, which may be a performance bottleneck.
2023-11-03 12:14:00,032	WARNING util.py:214 -- The `start_trial` operation took 0.529 s, which may be a performance bottleneck.
2023-11-03 12:14:05,265	WARNING util.py:214 -- The `on_step_end` operation took 1.016 s, which may be a performance bottleneck.
[2m[36m(train pid=1603284)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1603284)[0m 
[2m[36m(train pid=1603403)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1603403)[0m 
2023-11-03 12:15:55,617	WARNING util.py:214 -- The `on_step_end` operation took 0.891 s, which may be a performance bottleneck.
2023-11-03 12:15:57,844	WARNING util.py:214 -- The `start_trial` operation took 0.543 s, which may be a performance bottleneck.
2023-11-03 12:16:05,285	WARNING util.py:214 -- The `on_step_end` operation took 0.735 s, which may be a performance bottleneck.
[2m[36m(train pid=1605759)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1605759)[0m 
[2m[36m(train pid=1605762)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1605762)[0m 
2023-11-03 12:17:58,077	WARNING util.py:214 -- The `on_step_end` operation took 0.964 s, which may be a performance bottleneck.
2023-11-03 12:18:01,801	WARNING util.py:214 -- The `start_trial` operation took 0.509 s, which may be a performance bottleneck.
2023-11-03 12:18:04,317	WARNING util.py:214 -- The `on_step_end` operation took 0.630 s, which may be a performance bottleneck.
[2m[36m(train pid=1609513)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1609513)[0m 
[2m[36m(train pid=1609372)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1609372)[0m 
2023-11-03 12:20:02,343	WARNING util.py:214 -- The `on_step_end` operation took 0.592 s, which may be a performance bottleneck.
2023-11-03 12:20:07,552	WARNING util.py:214 -- The `start_trial` operation took 0.526 s, which may be a performance bottleneck.
2023-11-03 12:20:08,222	WARNING util.py:214 -- The `on_step_end` operation took 0.670 s, which may be a performance bottleneck.
[2m[36m(train pid=1613111)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1613111)[0m 
2023-11-03 12:22:03,347	WARNING util.py:214 -- The `on_step_end` operation took 0.802 s, which may be a performance bottleneck.
2023-11-03 12:22:09,734	WARNING util.py:214 -- The `on_step_end` operation took 0.901 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 12:10:30 (running for 13:39:27.95)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1418/1000000 (31 RUNNING, 1387 TERMINATED)


== Status ==
Current time: 2023-11-03 12:10:36 (running for 13:39:33.91)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1423/1000000 (32 RUNNING, 1391 TERMINATED)


== Status ==
Current time: 2023-11-03 12:12:13 (running for 13:41:11.21)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1423/1000000 (32 RUNNING, 1391 TERMINATED)


== Status ==
Current time: 2023-11-03 12:12:19 (running for 13:41:16.97)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1427/1000000 (32 RUNNING, 1395 TERMINATED)


== Status ==
Current time: 2023-11-03 12:13:52 (running for 13:42:50.53)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1427/1000000 (31 RUNNING, 1396 TERMINATED)


== Status ==
Current time: 2023-11-03 12:13:58 (running for 13:42:56.55)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1432/1000000 (1 PENDING, 31 RUNNING, 1400 TERMINATED)


== Status ==
Current time: 2023-11-03 12:14:05 (running for 13:43:02.97)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1436/1000000 (1 PENDING, 30 RUNNING, 1405 TERMINATED)


== Status ==
Current time: 2023-11-03 12:15:55 (running for 13:44:53.26)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1436/1000000 (31 RUNNING, 1405 TERMINATED)


== Status ==
Current time: 2023-11-03 12:16:05 (running for 13:45:02.92)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1438/1000000 (32 RUNNING, 1406 TERMINATED)


== Status ==
Current time: 2023-11-03 12:17:58 (running for 13:46:55.73)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1438/1000000 (32 RUNNING, 1406 TERMINATED)


== Status ==
Current time: 2023-11-03 12:18:04 (running for 13:47:01.91)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1441/1000000 (32 RUNNING, 1409 TERMINATED)


== Status ==
Current time: 2023-11-03 12:20:02 (running for 13:48:59.94)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1441/1000000 (32 RUNNING, 1409 TERMINATED)


== Status ==
Current time: 2023-11-03 12:20:08 (running for 13:49:05.82)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1444/1000000 (31 RUNNING, 1413 TERMINATED)


== Status ==
Current time: 2023-11-03 12:22:03 (running for 13:51:00.94)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1445/1000000 (1 PENDING, 31 RUNNING, 1413 TERMINATED)


[2m[36m(train pid=1617285)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1617285)[0m 
2023-11-03 12:23:59,552	WARNING util.py:214 -- The `on_step_end` operation took 0.713 s, which may be a performance bottleneck.
2023-11-03 12:24:04,275	WARNING util.py:214 -- The `start_trial` operation took 0.509 s, which may be a performance bottleneck.
2023-11-03 12:24:05,482	WARNING util.py:214 -- The `on_step_end` operation took 0.762 s, which may be a performance bottleneck.
2023-11-03 12:24:09,072	WARNING util.py:214 -- The `start_trial` operation took 0.512 s, which may be a performance bottleneck.
2023-11-03 12:24:11,121	WARNING util.py:214 -- The `start_trial` operation took 0.556 s, which may be a performance bottleneck.
2023-11-03 12:24:11,991	WARNING util.py:214 -- The `on_step_end` operation took 0.870 s, which may be a performance bottleneck.
[2m[36m(train pid=1622253)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1622253)[0m 
[2m[36m(train pid=1621988)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1621988)[0m 
2023-11-03 12:26:05,799	WARNING util.py:214 -- The `on_step_end` operation took 0.820 s, which may be a performance bottleneck.
2023-11-03 12:26:12,227	WARNING util.py:214 -- The `on_step_end` operation took 0.694 s, which may be a performance bottleneck.
[2m[36m(train pid=1625353)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1625353)[0m 
2023-11-03 12:28:03,835	WARNING util.py:214 -- The `on_step_end` operation took 0.707 s, which may be a performance bottleneck.
2023-11-03 12:28:10,144	WARNING util.py:214 -- The `on_step_end` operation took 0.907 s, which may be a performance bottleneck.
[2m[36m(train pid=1628388)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1628388)[0m 
2023-11-03 12:30:00,577	WARNING util.py:214 -- The `on_step_end` operation took 0.948 s, which may be a performance bottleneck.
2023-11-03 12:30:06,016	WARNING util.py:214 -- The `start_trial` operation took 1.341 s, which may be a performance bottleneck.
[2m[36m(train pid=1633362)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1633362)[0m 
2023-11-03 12:31:55,363	WARNING util.py:214 -- The `on_step_end` operation took 0.616 s, which may be a performance bottleneck.
[2m[36m(train pid=1638956)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1638956)[0m 
2023-11-03 12:32:58,383	WARNING util.py:214 -- The `start_trial` operation took 1.044 s, which may be a performance bottleneck.
[2m[36m(train pid=1642089)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1642089)[0m 
2023-11-03 12:34:09,557	WARNING util.py:214 -- The `on_step_end` operation took 0.633 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 12:22:09 (running for 13:51:07.33)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1449/1000000 (32 RUNNING, 1417 TERMINATED)


== Status ==
Current time: 2023-11-03 12:23:59 (running for 13:52:57.25)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1449/1000000 (32 RUNNING, 1417 TERMINATED)


== Status ==
Current time: 2023-11-03 12:24:05 (running for 13:53:03.22)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1453/1000000 (1 PENDING, 30 RUNNING, 1422 TERMINATED)


== Status ==
Current time: 2023-11-03 12:24:12 (running for 13:53:09.65)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1458/1000000 (32 RUNNING, 1426 TERMINATED)


== Status ==
Current time: 2023-11-03 12:26:05 (running for 13:55:03.40)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1458/1000000 (32 RUNNING, 1426 TERMINATED)


== Status ==
Current time: 2023-11-03 12:26:12 (running for 13:55:09.82)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1462/1000000 (32 RUNNING, 1430 TERMINATED)


== Status ==
Current time: 2023-11-03 12:28:03 (running for 13:57:01.43)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1462/1000000 (31 RUNNING, 1431 TERMINATED)


== Status ==
Current time: 2023-11-03 12:28:10 (running for 13:57:07.74)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1466/1000000 (1 PENDING, 30 RUNNING, 1435 TERMINATED)


== Status ==
Current time: 2023-11-03 12:30:00 (running for 13:58:58.19)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1466/1000000 (31 RUNNING, 1435 TERMINATED)


== Status ==
Current time: 2023-11-03 12:30:06 (running for 13:59:04.23)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1469/1000000 (31 RUNNING, 1438 TERMINATED)


== Status ==
Current time: 2023-11-03 12:31:55 (running for 14:00:52.96)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1470/1000000 (32 RUNNING, 1438 TERMINATED)


== Status ==
Current time: 2023-11-03 12:32:55 (running for 14:01:53.53)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1470/1000000 (32 RUNNING, 1438 TERMINATED)


== Status ==
Current time: 2023-11-03 12:33:01 (running for 14:01:59.17)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1475/1000000 (31 RUNNING, 1444 TERMINATED)


== Status ==
Current time: 2023-11-03 12:34:03 (running for 14:03:01.39)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1476/1000000 (1 PENDING, 31 RUNNING, 1444 TERMINATED)


[2m[36m(train pid=1644905)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1644905)[0m 
[2m[36m(train pid=1644914)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1644914)[0m 
2023-11-03 12:35:17,725	WARNING util.py:214 -- The `on_step_end` operation took 0.559 s, which may be a performance bottleneck.
2023-11-03 12:35:23,614	WARNING util.py:214 -- The `on_step_end` operation took 0.705 s, which may be a performance bottleneck.
2023-11-03 12:35:29,926	WARNING util.py:214 -- The `on_step_end` operation took 0.906 s, which may be a performance bottleneck.
[2m[36m(train pid=1647384)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1647384)[0m 
2023-11-03 12:37:14,611	WARNING util.py:214 -- The `on_step_end` operation took 1.167 s, which may be a performance bottleneck.
2023-11-03 12:37:16,817	WARNING util.py:214 -- The `start_trial` operation took 0.612 s, which may be a performance bottleneck.
2023-11-03 12:37:20,991	WARNING util.py:214 -- The `on_step_end` operation took 1.151 s, which may be a performance bottleneck.
2023-11-03 12:37:29,646	WARNING util.py:214 -- The `on_step_end` operation took 0.687 s, which may be a performance bottleneck.
[2m[36m(train pid=1649842)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1649842)[0m 
2023-11-03 12:39:28,092	WARNING util.py:214 -- The `on_step_end` operation took 0.791 s, which may be a performance bottleneck.
2023-11-03 12:39:34,002	WARNING util.py:214 -- The `on_step_end` operation took 0.818 s, which may be a performance bottleneck.
2023-11-03 12:39:36,958	WARNING util.py:214 -- The `start_trial` operation took 0.529 s, which may be a performance bottleneck.
2023-11-03 12:39:42,755	WARNING util.py:214 -- The `on_step_end` operation took 0.795 s, which may be a performance bottleneck.
[2m[36m(train pid=1653752)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1653752)[0m 
2023-11-03 12:41:35,954	WARNING util.py:214 -- The `on_step_end` operation took 0.859 s, which may be a performance bottleneck.
2023-11-03 12:41:52,681	WARNING util.py:214 -- The `start_trial` operation took 13.344 s, which may be a performance bottleneck.
2023-11-03 12:41:53,280	WARNING util.py:214 -- The `on_step_end` operation took 0.599 s, which may be a performance bottleneck.
[2m[36m(train pid=1658450)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1658450)[0m 
2023-11-03 12:43:23,605	WARNING util.py:214 -- The `on_step_end` operation took 0.862 s, which may be a performance bottleneck.
2023-11-03 12:43:30,310	WARNING util.py:214 -- The `on_step_end` operation took 0.890 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 12:34:09 (running for 14:03:07.15)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1482/1000000 (1 PENDING, 31 RUNNING, 1450 TERMINATED)


== Status ==
Current time: 2023-11-03 12:35:17 (running for 14:04:15.32)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1482/1000000 (1 PENDING, 31 RUNNING, 1450 TERMINATED)


== Status ==
Current time: 2023-11-03 12:35:23 (running for 14:04:21.21)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1488/1000000 (1 PENDING, 31 RUNNING, 1456 TERMINATED)


== Status ==
Current time: 2023-11-03 12:35:29 (running for 14:04:27.52)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1493/1000000 (1 PENDING, 30 RUNNING, 1462 TERMINATED)


== Status ==
Current time: 2023-11-03 12:37:14 (running for 14:06:12.21)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1493/1000000 (31 RUNNING, 1462 TERMINATED)


== Status ==
Current time: 2023-11-03 12:37:21 (running for 14:06:18.67)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1497/1000000 (1 PENDING, 31 RUNNING, 1465 TERMINATED)


== Status ==
Current time: 2023-11-03 12:37:29 (running for 14:06:27.24)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1498/1000000 (32 RUNNING, 1466 TERMINATED)


== Status ==
Current time: 2023-11-03 12:39:28 (running for 14:08:25.78)
Memory usage on this node: 25.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1498/1000000 (32 RUNNING, 1466 TERMINATED)


== Status ==
Current time: 2023-11-03 12:39:34 (running for 14:08:31.68)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1501/1000000 (31 RUNNING, 1470 TERMINATED)


== Status ==
Current time: 2023-11-03 12:39:42 (running for 14:08:40.35)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1503/1000000 (32 RUNNING, 1471 TERMINATED)


== Status ==
Current time: 2023-11-03 12:41:36 (running for 14:10:33.68)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1503/1000000 (32 RUNNING, 1471 TERMINATED)


== Status ==
Current time: 2023-11-03 12:41:53 (running for 14:10:50.88)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1505/1000000 (32 RUNNING, 1473 TERMINATED)


== Status ==
Current time: 2023-11-03 12:43:23 (running for 14:12:21.20)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1505/1000000 (32 RUNNING, 1473 TERMINATED)


== Status ==
Current time: 2023-11-03 12:43:30 (running for 14:12:27.91)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1510/1000000 (32 RUNNING, 1478 TERMINATED)


[2m[36m(train pid=1663654)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1663654)[0m 
[2m[36m(train pid=1663932)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1663932)[0m 
2023-11-03 12:44:52,423	WARNING util.py:214 -- The `on_step_end` operation took 0.762 s, which may be a performance bottleneck.
2023-11-03 12:44:58,274	WARNING util.py:214 -- The `on_step_end` operation took 0.696 s, which may be a performance bottleneck.
[2m[36m(train pid=1668754)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1668754)[0m 
2023-11-03 12:46:18,949	WARNING util.py:214 -- The `on_step_end` operation took 0.702 s, which may be a performance bottleneck.
2023-11-03 12:46:24,951	WARNING util.py:214 -- The `on_step_end` operation took 0.752 s, which may be a performance bottleneck.
[2m[36m(train pid=1671728)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1671728)[0m 
[2m[36m(train pid=1671585)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1671585)[0m 
[2m[36m(train pid=1674753)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1674753)[0m 
2023-11-03 12:48:56,021	WARNING util.py:214 -- The `on_step_end` operation took 0.570 s, which may be a performance bottleneck.
2023-11-03 12:49:01,869	WARNING util.py:214 -- The `on_step_end` operation took 0.731 s, which may be a performance bottleneck.
[2m[36m(train pid=1678315)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1678315)[0m 
2023-11-03 12:50:21,552	WARNING util.py:214 -- The `on_step_end` operation took 0.825 s, which may be a performance bottleneck.
2023-11-03 12:50:28,076	WARNING util.py:214 -- The `on_step_end` operation took 0.971 s, which may be a performance bottleneck.
[2m[36m(train pid=1682138)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1682138)[0m 
[2m[36m(train pid=1682272)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1682272)[0m 
2023-11-03 12:52:01,454	WARNING util.py:214 -- The `on_step_end` operation took 0.784 s, which may be a performance bottleneck.
2023-11-03 12:52:07,380	WARNING util.py:214 -- The `on_step_end` operation took 0.823 s, which may be a performance bottleneck.
[2m[36m(train pid=1683356)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1683356)[0m 
[2m[36m(train pid=1683489)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1683489)[0m 
2023-11-03 12:53:50,963	WARNING util.py:214 -- The `on_step_end` operation took 0.961 s, which may be a performance bottleneck.
2023-11-03 12:53:56,785	WARNING util.py:214 -- The `on_step_end` operation took 0.805 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 12:44:46 (running for 14:13:44.17)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1510/1000000 (32 RUNNING, 1478 TERMINATED)


== Status ==
Current time: 2023-11-03 12:44:52 (running for 14:13:50.02)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1511/1000000 (1 PENDING, 31 RUNNING, 1479 TERMINATED)


== Status ==
Current time: 2023-11-03 12:44:58 (running for 14:13:55.87)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1516/1000000 (31 RUNNING, 1485 TERMINATED)


== Status ==
Current time: 2023-11-03 12:46:19 (running for 14:15:16.66)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1517/1000000 (1 PENDING, 31 RUNNING, 1485 TERMINATED)


== Status ==
Current time: 2023-11-03 12:46:25 (running for 14:15:22.64)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1522/1000000 (1 PENDING, 31 RUNNING, 1490 TERMINATED)


== Status ==
Current time: 2023-11-03 12:47:42 (running for 14:16:40.16)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1522/1000000 (32 RUNNING, 1490 TERMINATED)


== Status ==
Current time: 2023-11-03 12:48:56 (running for 14:17:53.65)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1522/1000000 (31 RUNNING, 1491 TERMINATED)


== Status ==
Current time: 2023-11-03 12:49:01 (running for 14:17:59.51)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1528/1000000 (1 PENDING, 30 RUNNING, 1497 TERMINATED)


== Status ==
Current time: 2023-11-03 12:50:15 (running for 14:19:13.18)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1528/1000000 (31 RUNNING, 1497 TERMINATED)


== Status ==
Current time: 2023-11-03 12:50:21 (running for 14:19:19.19)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1534/1000000 (1 PENDING, 30 RUNNING, 1503 TERMINATED)


== Status ==
Current time: 2023-11-03 12:50:28 (running for 14:19:25.70)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1539/1000000 (1 PENDING, 31 RUNNING, 1507 TERMINATED)


== Status ==
Current time: 2023-11-03 12:52:01 (running for 14:20:59.05)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1539/1000000 (1 PENDING, 31 RUNNING, 1507 TERMINATED)


== Status ==
Current time: 2023-11-03 12:52:07 (running for 14:21:04.98)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1543/1000000 (31 RUNNING, 1512 TERMINATED)


== Status ==
Current time: 2023-11-03 12:53:50 (running for 14:22:48.56)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1544/1000000 (1 PENDING, 31 RUNNING, 1512 TERMINATED)


[2m[36m(train pid=1686946)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1686946)[0m 
2023-11-03 12:55:43,170	WARNING util.py:214 -- The `on_step_end` operation took 0.811 s, which may be a performance bottleneck.
2023-11-03 12:55:49,429	WARNING util.py:214 -- The `on_step_end` operation took 1.045 s, which may be a performance bottleneck.
[2m[36m(train pid=1691967)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1691967)[0m 
2023-11-03 12:57:23,486	WARNING util.py:214 -- The `on_step_end` operation took 0.699 s, which may be a performance bottleneck.
2023-11-03 12:57:29,478	WARNING util.py:214 -- The `on_step_end` operation took 0.864 s, which may be a performance bottleneck.
[2m[36m(train pid=1695761)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1695761)[0m 
2023-11-03 12:59:02,623	WARNING util.py:214 -- The `on_step_end` operation took 0.973 s, which may be a performance bottleneck.
2023-11-03 12:59:09,323	WARNING util.py:214 -- The `on_step_end` operation took 0.781 s, which may be a performance bottleneck.
[2m[36m(train pid=1698562)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1698562)[0m 
[2m[36m(train pid=1698559)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1698559)[0m 
2023-11-03 13:01:06,658	WARNING util.py:214 -- The `on_step_end` operation took 1.058 s, which may be a performance bottleneck.
2023-11-03 13:01:13,059	WARNING util.py:214 -- The `on_step_end` operation took 1.041 s, which may be a performance bottleneck.
2023-11-03 13:01:23,243	WARNING util.py:214 -- The `on_step_end` operation took 0.842 s, which may be a performance bottleneck.
[2m[36m(train pid=1702309)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1702309)[0m 
2023-11-03 13:03:27,082	WARNING util.py:214 -- The `on_step_end` operation took 0.969 s, which may be a performance bottleneck.
2023-11-03 13:03:33,425	WARNING util.py:214 -- The `on_step_end` operation took 1.202 s, which may be a performance bottleneck.
[2m[36m(train pid=1705158)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1705158)[0m 
[2m[36m(train pid=1705304)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1705304)[0m 
2023-11-03 13:05:26,496	WARNING util.py:214 -- The `on_step_end` operation took 1.037 s, which may be a performance bottleneck.
2023-11-03 13:05:33,410	WARNING util.py:214 -- The `on_step_end` operation took 0.783 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 12:53:56 (running for 14:22:54.38)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1547/1000000 (31 RUNNING, 1516 TERMINATED)


== Status ==
Current time: 2023-11-03 12:55:43 (running for 14:24:40.77)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1548/1000000 (1 PENDING, 31 RUNNING, 1516 TERMINATED)


== Status ==
Current time: 2023-11-03 12:55:49 (running for 14:24:47.03)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1552/1000000 (1 PENDING, 30 RUNNING, 1521 TERMINATED)


== Status ==
Current time: 2023-11-03 12:57:23 (running for 14:26:21.08)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1552/1000000 (31 RUNNING, 1521 TERMINATED)


== Status ==
Current time: 2023-11-03 12:57:29 (running for 14:26:27.20)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1556/1000000 (1 PENDING, 31 RUNNING, 1524 TERMINATED)


== Status ==
Current time: 2023-11-03 12:58:56 (running for 14:27:53.89)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1556/1000000 (1 PENDING, 31 RUNNING, 1524 TERMINATED)


== Status ==
Current time: 2023-11-03 12:59:02 (running for 14:28:00.32)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1561/1000000 (1 PENDING, 30 RUNNING, 1530 TERMINATED)


== Status ==
Current time: 2023-11-03 12:59:09 (running for 14:28:07.09)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1565/1000000 (32 RUNNING, 1533 TERMINATED)


== Status ==
Current time: 2023-11-03 13:01:06 (running for 14:30:04.26)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1565/1000000 (32 RUNNING, 1533 TERMINATED)


== Status ==
Current time: 2023-11-03 13:01:13 (running for 14:30:10.66)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1569/1000000 (1 PENDING, 31 RUNNING, 1537 TERMINATED)


== Status ==
Current time: 2023-11-03 13:01:23 (running for 14:30:20.99)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1571/1000000 (32 RUNNING, 1539 TERMINATED)


== Status ==
Current time: 2023-11-03 13:03:27 (running for 14:32:24.71)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1571/1000000 (32 RUNNING, 1539 TERMINATED)


== Status ==
Current time: 2023-11-03 13:03:33 (running for 14:32:31.05)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1574/1000000 (31 RUNNING, 1543 TERMINATED)


== Status ==
Current time: 2023-11-03 13:05:26 (running for 14:34:24.09)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1575/1000000 (1 PENDING, 31 RUNNING, 1543 TERMINATED)


[2m[36m(train pid=1708506)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1708506)[0m 
[2m[36m(train pid=1708500)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1708500)[0m 
[2m[36m(train pid=1708638)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1708638)[0m 
2023-11-03 13:07:28,320	WARNING util.py:214 -- The `on_step_end` operation took 1.123 s, which may be a performance bottleneck.
2023-11-03 13:07:34,417	WARNING util.py:214 -- The `on_step_end` operation took 1.082 s, which may be a performance bottleneck.
[2m[36m(train pid=1712978)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1712978)[0m 
2023-11-03 13:09:26,535	WARNING util.py:214 -- The `on_step_end` operation took 0.699 s, which may be a performance bottleneck.
2023-11-03 13:10:43,032	WARNING util.py:214 -- The `on_step_end` operation took 0.500 s, which may be a performance bottleneck.
[2m[36m(train pid=1716733)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1716733)[0m 
2023-11-03 13:10:45,162	WARNING util.py:214 -- The `start_trial` operation took 0.602 s, which may be a performance bottleneck.
2023-11-03 13:10:48,922	WARNING util.py:214 -- The `on_step_end` operation took 0.723 s, which may be a performance bottleneck.
[2m[36m(train pid=1719349)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1719349)[0m 
2023-11-03 13:12:13,469	WARNING util.py:214 -- The `on_step_end` operation took 0.782 s, which may be a performance bottleneck.
2023-11-03 13:12:19,838	WARNING util.py:214 -- The `on_step_end` operation took 0.951 s, which may be a performance bottleneck.
[2m[36m(train pid=1721978)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1721978)[0m 
2023-11-03 13:13:50,844	WARNING util.py:214 -- The `on_step_end` operation took 0.858 s, which may be a performance bottleneck.
2023-11-03 13:13:54,137	WARNING util.py:214 -- The `start_trial` operation took 0.562 s, which may be a performance bottleneck.
2023-11-03 13:13:56,761	WARNING util.py:214 -- The `on_step_end` operation took 0.664 s, which may be a performance bottleneck.
2023-11-03 13:13:59,008	WARNING util.py:214 -- The `start_trial` operation took 0.613 s, which may be a performance bottleneck.
2023-11-03 13:14:03,153	WARNING util.py:214 -- The `on_step_end` operation took 1.069 s, which may be a performance bottleneck.
[2m[36m(train pid=1725005)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1725005)[0m 
[2m[36m(train pid=1724749)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1724749)[0m 
2023-11-03 13:15:50,776	WARNING util.py:214 -- The `on_step_end` operation took 0.734 s, which may be a performance bottleneck.
2023-11-03 13:15:57,752	WARNING util.py:214 -- The `on_step_end` operation took 0.927 s, which may be a performance bottleneck.
2023-11-03 13:17:39,931	WARNING util.py:214 -- The `on_step_end` operation took 0.642 s, which may be a performance bottleneck.
[2m[36m(train pid=1728329)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1728329)[0m 
2023-11-03 13:17:51,799	WARNING util.py:214 -- The `on_step_end` operation took 0.913 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 13:05:33 (running for 14:34:31.06)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1578/1000000 (32 RUNNING, 1546 TERMINATED)


== Status ==
Current time: 2023-11-03 13:07:28 (running for 14:36:26.03)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1578/1000000 (32 RUNNING, 1546 TERMINATED)


== Status ==
Current time: 2023-11-03 13:07:34 (running for 14:36:32.06)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1581/1000000 (31 RUNNING, 1550 TERMINATED)


== Status ==
Current time: 2023-11-03 13:09:26 (running for 14:38:24.22)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1582/1000000 (32 RUNNING, 1550 TERMINATED)


== Status ==
Current time: 2023-11-03 13:10:43 (running for 14:39:40.69)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1582/1000000 (32 RUNNING, 1550 TERMINATED)


== Status ==
Current time: 2023-11-03 13:10:48 (running for 14:39:46.52)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1586/1000000 (31 RUNNING, 1555 TERMINATED)


== Status ==
Current time: 2023-11-03 13:12:13 (running for 14:41:11.07)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1587/1000000 (1 PENDING, 31 RUNNING, 1555 TERMINATED)


== Status ==
Current time: 2023-11-03 13:12:19 (running for 14:41:17.44)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1592/1000000 (1 PENDING, 31 RUNNING, 1560 TERMINATED)


== Status ==
Current time: 2023-11-03 13:13:50 (running for 14:42:48.44)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1592/1000000 (1 PENDING, 30 RUNNING, 1561 TERMINATED)


== Status ==
Current time: 2023-11-03 13:13:56 (running for 14:42:54.48)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1596/1000000 (31 RUNNING, 1565 TERMINATED)


== Status ==
Current time: 2023-11-03 13:14:03 (running for 14:43:00.82)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1600/1000000 (32 RUNNING, 1568 TERMINATED)


== Status ==
Current time: 2023-11-03 13:15:50 (running for 14:44:48.53)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1600/1000000 (32 RUNNING, 1568 TERMINATED)


== Status ==
Current time: 2023-11-03 13:15:57 (running for 14:44:55.41)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1604/1000000 (1 PENDING, 31 RUNNING, 1572 TERMINATED)


== Status ==
Current time: 2023-11-03 13:17:39 (running for 14:46:37.60)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1604/1000000 (1 PENDING, 31 RUNNING, 1572 TERMINATED)


2023-11-03 13:19:23,398	WARNING util.py:214 -- The `on_step_end` operation took 0.830 s, which may be a performance bottleneck.
[2m[36m(train pid=1731067)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1731067)[0m 
[2m[36m(train pid=1731217)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1731217)[0m 
2023-11-03 13:19:29,780	WARNING util.py:214 -- The `on_step_end` operation took 1.100 s, which may be a performance bottleneck.
[2m[36m(train pid=1734562)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1734562)[0m 
2023-11-03 13:21:16,602	WARNING util.py:214 -- The `on_step_end` operation took 0.872 s, which may be a performance bottleneck.
2023-11-03 13:21:23,171	WARNING util.py:214 -- The `on_step_end` operation took 0.917 s, which may be a performance bottleneck.
[2m[36m(train pid=1739383)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1739383)[0m 
2023-11-03 13:22:51,418	WARNING util.py:214 -- The `on_step_end` operation took 0.719 s, which may be a performance bottleneck.
[2m[36m(train pid=1739550)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1739550)[0m 
2023-11-03 13:22:58,695	WARNING util.py:214 -- The `on_step_end` operation took 0.740 s, which may be a performance bottleneck.
2023-11-03 13:23:04,550	WARNING util.py:214 -- The `on_step_end` operation took 0.798 s, which may be a performance bottleneck.
2023-11-03 13:23:11,695	WARNING util.py:214 -- The `on_step_end` operation took 1.042 s, which may be a performance bottleneck.
[2m[36m(train pid=1744257)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1744257)[0m 
[2m[36m(train pid=1744108)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1744108)[0m 
2023-11-03 13:24:56,849	WARNING util.py:214 -- The `on_step_end` operation took 1.023 s, which may be a performance bottleneck.
2023-11-03 13:25:01,022	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.675 s, which may be a performance bottleneck.
2023-11-03 13:25:01,022	WARNING util.py:214 -- The `process_trial_result` operation took 0.676 s, which may be a performance bottleneck.
2023-11-03 13:25:01,023	WARNING util.py:214 -- Processing trial results took 0.676 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 13:25:01,023	WARNING util.py:214 -- The `process_trial_result` operation took 0.676 s, which may be a performance bottleneck.
2023-11-03 13:25:03,039	WARNING util.py:214 -- The `on_step_end` operation took 1.039 s, which may be a performance bottleneck.
2023-11-03 13:26:35,867	WARNING util.py:214 -- The `on_step_end` operation took 0.617 s, which may be a performance bottleneck.
[2m[36m(train pid=1747621)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1747621)[0m 
2023-11-03 13:26:41,903	WARNING util.py:214 -- The `on_step_end` operation took 0.851 s, which may be a performance bottleneck.
[2m[36m(train pid=1751051)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1751051)[0m 
2023-11-03 13:28:22,259	WARNING util.py:214 -- The `on_step_end` operation took 0.890 s, which may be a performance bottleneck.
2023-11-03 13:28:28,237	WARNING util.py:214 -- The `on_step_end` operation took 0.954 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 13:17:51 (running for 14:46:49.57)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1607/1000000 (32 RUNNING, 1575 TERMINATED)


== Status ==
Current time: 2023-11-03 13:19:23 (running for 14:48:21.00)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1607/1000000 (32 RUNNING, 1575 TERMINATED)


== Status ==
Current time: 2023-11-03 13:19:29 (running for 14:48:27.47)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1611/1000000 (31 RUNNING, 1580 TERMINATED)


== Status ==
Current time: 2023-11-03 13:21:16 (running for 14:50:14.24)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1612/1000000 (1 PENDING, 31 RUNNING, 1580 TERMINATED)


== Status ==
Current time: 2023-11-03 13:21:23 (running for 14:50:20.80)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1616/1000000 (32 RUNNING, 1584 TERMINATED)


== Status ==
Current time: 2023-11-03 13:22:51 (running for 14:51:49.02)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1616/1000000 (32 RUNNING, 1584 TERMINATED)


== Status ==
Current time: 2023-11-03 13:22:58 (running for 14:51:56.29)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1617/1000000 (1 PENDING, 31 RUNNING, 1585 TERMINATED)


== Status ==
Current time: 2023-11-03 13:23:04 (running for 14:52:02.15)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1621/1000000 (31 RUNNING, 1590 TERMINATED)


== Status ==
Current time: 2023-11-03 13:23:11 (running for 14:52:09.33)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1626/1000000 (32 RUNNING, 1594 TERMINATED)


== Status ==
Current time: 2023-11-03 13:24:56 (running for 14:53:54.45)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1626/1000000 (32 RUNNING, 1594 TERMINATED)


== Status ==
Current time: 2023-11-03 13:25:03 (running for 14:54:00.81)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1629/1000000 (1 PENDING, 31 RUNNING, 1597 TERMINATED)


== Status ==
Current time: 2023-11-03 13:26:35 (running for 14:55:33.54)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1629/1000000 (1 PENDING, 30 RUNNING, 1598 TERMINATED)


== Status ==
Current time: 2023-11-03 13:26:41 (running for 14:55:39.50)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1633/1000000 (31 RUNNING, 1602 TERMINATED)


== Status ==
Current time: 2023-11-03 13:28:22 (running for 14:57:19.88)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1634/1000000 (1 PENDING, 30 RUNNING, 1603 TERMINATED)


2023-11-03 13:28:29,194	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
2023-11-03 13:28:31,366	WARNING util.py:214 -- The `start_trial` operation took 0.603 s, which may be a performance bottleneck.
2023-11-03 13:28:34,379	WARNING util.py:214 -- The `on_step_end` operation took 1.135 s, which may be a performance bottleneck.
[2m[36m(train pid=1755597)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1755597)[0m 
2023-11-03 13:30:16,851	WARNING util.py:214 -- The `on_step_end` operation took 0.779 s, which may be a performance bottleneck.
2023-11-03 13:30:22,841	WARNING util.py:214 -- The `on_step_end` operation took 0.943 s, which may be a performance bottleneck.
[2m[36m(train pid=1759617)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1759617)[0m 
2023-11-03 13:32:00,626	WARNING util.py:214 -- The `on_step_end` operation took 0.785 s, which may be a performance bottleneck.
2023-11-03 13:33:13,705	WARNING util.py:214 -- The `on_step_end` operation took 0.616 s, which may be a performance bottleneck.
[2m[36m(train pid=1762194)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1762194)[0m 
2023-11-03 13:33:19,606	WARNING util.py:214 -- The `on_step_end` operation took 0.717 s, which may be a performance bottleneck.
2023-11-03 13:33:21,459	WARNING util.py:214 -- The `start_trial` operation took 0.721 s, which may be a performance bottleneck.
2023-11-03 13:33:25,962	WARNING util.py:214 -- The `on_step_end` operation took 0.862 s, which may be a performance bottleneck.
[2m[36m(train pid=1766342)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1766342)[0m 
2023-11-03 13:35:04,291	WARNING util.py:214 -- The `on_step_end` operation took 0.911 s, which may be a performance bottleneck.
2023-11-03 13:35:10,388	WARNING util.py:214 -- The `on_step_end` operation took 0.972 s, which may be a performance bottleneck.
2023-11-03 13:36:43,503	WARNING util.py:214 -- The `on_step_end` operation took 0.718 s, which may be a performance bottleneck.
[2m[36m(train pid=1770207)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1770207)[0m 
2023-11-03 13:38:06,249	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.770 s, which may be a performance bottleneck.
2023-11-03 13:38:06,250	WARNING util.py:214 -- The `process_trial_result` operation took 0.771 s, which may be a performance bottleneck.
2023-11-03 13:38:06,250	WARNING util.py:214 -- Processing trial results took 0.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 13:38:06,250	WARNING util.py:214 -- The `process_trial_result` operation took 0.771 s, which may be a performance bottleneck.
[2m[36m(train pid=1772255)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1772255)[0m 
2023-11-03 13:38:11,563	WARNING util.py:214 -- The `on_step_end` operation took 0.816 s, which may be a performance bottleneck.
2023-11-03 13:38:17,860	WARNING util.py:214 -- The `on_step_end` operation took 1.000 s, which may be a performance bottleneck.
2023-11-03 13:38:23,815	WARNING util.py:214 -- The `start_trial` operation took 0.910 s, which may be a performance bottleneck.
2023-11-03 13:38:24,607	WARNING util.py:214 -- The `on_step_end` operation took 0.792 s, which may be a performance bottleneck.
[2m[36m(train pid=1775045)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1775045)[0m 
2023-11-03 13:40:15,815	WARNING util.py:214 -- The `on_step_end` operation took 1.165 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 13:28:28 (running for 14:57:25.90)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1638/1000000 (1 PENDING, 31 RUNNING, 1606 TERMINATED)


== Status ==
Current time: 2023-11-03 13:28:34 (running for 14:57:31.98)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1641/1000000 (1 PENDING, 30 RUNNING, 1610 TERMINATED)


== Status ==
Current time: 2023-11-03 13:30:16 (running for 14:59:14.46)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1641/1000000 (31 RUNNING, 1610 TERMINATED)


== Status ==
Current time: 2023-11-03 13:30:22 (running for 14:59:20.44)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1645/1000000 (1 PENDING, 31 RUNNING, 1613 TERMINATED)


== Status ==
Current time: 2023-11-03 13:32:00 (running for 15:00:58.22)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1645/1000000 (32 RUNNING, 1613 TERMINATED)


== Status ==
Current time: 2023-11-03 13:33:13 (running for 15:02:11.30)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1645/1000000 (31 RUNNING, 1614 TERMINATED)


== Status ==
Current time: 2023-11-03 13:33:19 (running for 15:02:17.20)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1650/1000000 (31 RUNNING, 1619 TERMINATED)


== Status ==
Current time: 2023-11-03 13:33:26 (running for 15:02:23.65)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1655/1000000 (1 PENDING, 30 RUNNING, 1624 TERMINATED)


== Status ==
Current time: 2023-11-03 13:35:04 (running for 15:04:01.89)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1655/1000000 (31 RUNNING, 1624 TERMINATED)


== Status ==
Current time: 2023-11-03 13:35:10 (running for 15:04:07.99)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1659/1000000 (31 RUNNING, 1628 TERMINATED)


== Status ==
Current time: 2023-11-03 13:36:43 (running for 15:05:41.10)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1660/1000000 (32 RUNNING, 1628 TERMINATED)


== Status ==
Current time: 2023-11-03 13:38:11 (running for 15:07:09.17)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1660/1000000 (32 RUNNING, 1628 TERMINATED)


== Status ==
Current time: 2023-11-03 13:38:17 (running for 15:07:15.46)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1664/1000000 (1 PENDING, 31 RUNNING, 1632 TERMINATED)


== Status ==
Current time: 2023-11-03 13:38:24 (running for 15:07:22.20)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1669/1000000 (32 RUNNING, 1637 TERMINATED)


2023-11-03 13:40:22,501	WARNING util.py:214 -- The `start_trial` operation took 0.828 s, which may be a performance bottleneck.
2023-11-03 13:40:23,421	WARNING util.py:214 -- The `on_step_end` operation took 0.920 s, which may be a performance bottleneck.
2023-11-03 13:42:08,871	WARNING util.py:214 -- The `on_step_end` operation took 0.776 s, which may be a performance bottleneck.
[2m[36m(train pid=1778424)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1778424)[0m 
[2m[36m(train pid=1778418)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1778418)[0m 
2023-11-03 13:42:14,929	WARNING util.py:214 -- The `start_trial` operation took 0.536 s, which may be a performance bottleneck.
2023-11-03 13:42:22,377	WARNING util.py:214 -- The `on_step_end` operation took 1.115 s, which may be a performance bottleneck.
2023-11-03 13:43:48,893	WARNING util.py:214 -- The `on_step_end` operation took 0.823 s, which may be a performance bottleneck.
[2m[36m(train pid=1782019)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1782019)[0m 
[2m[36m(train pid=1782015)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1782015)[0m 
2023-11-03 13:43:55,016	WARNING util.py:214 -- The `on_step_end` operation took 0.959 s, which may be a performance bottleneck.
[2m[36m(train pid=1784507)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1784507)[0m 
2023-11-03 13:45:43,723	WARNING util.py:214 -- The `on_step_end` operation took 0.821 s, which may be a performance bottleneck.
2023-11-03 13:45:47,288	WARNING util.py:214 -- The `start_trial` operation took 0.698 s, which may be a performance bottleneck.
2023-11-03 13:45:49,014	WARNING util.py:214 -- The `start_trial` operation took 0.863 s, which may be a performance bottleneck.
2023-11-03 13:45:49,776	WARNING util.py:214 -- The `on_step_end` operation took 0.620 s, which may be a performance bottleneck.
2023-11-03 13:45:53,128	WARNING util.py:214 -- The `start_trial` operation took 0.545 s, which may be a performance bottleneck.
2023-11-03 13:45:54,292	WARNING util.py:214 -- The `start_trial` operation took 0.583 s, which may be a performance bottleneck.
2023-11-03 13:45:57,008	WARNING util.py:214 -- The `on_step_end` operation took 0.928 s, which may be a performance bottleneck.
[2m[36m(train pid=1787821)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1787821)[0m 
[2m[36m(train pid=1787955)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1787955)[0m 
[2m[36m(train pid=1787817)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1787817)[0m 
2023-11-03 13:47:51,384	WARNING util.py:214 -- The `on_step_end` operation took 1.207 s, which may be a performance bottleneck.
2023-11-03 13:47:55,569	WARNING util.py:214 -- The `start_trial` operation took 0.523 s, which may be a performance bottleneck.
2023-11-03 13:47:58,170	WARNING util.py:214 -- The `on_step_end` operation took 0.945 s, which may be a performance bottleneck.
2023-11-03 13:49:40,225	WARNING util.py:214 -- The `on_step_end` operation took 0.814 s, which may be a performance bottleneck.
[2m[36m(train pid=1791162)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1791162)[0m 
[2m[36m(train pid=1791032)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1791032)[0m 
2023-11-03 13:49:45,733	WARNING util.py:214 -- The `start_trial` operation took 0.532 s, which may be a performance bottleneck.
2023-11-03 13:49:46,717	WARNING util.py:214 -- The `on_step_end` operation took 0.983 s, which may be a performance bottleneck.
[2m[36m(train pid=1795261)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1795261)[0m 
2023-11-03 13:51:28,202	WARNING util.py:214 -- The `on_step_end` operation took 0.920 s, which may be a performance bottleneck.
2023-11-03 13:51:29,487	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.687 s, which may be a performance bottleneck.
2023-11-03 13:51:29,488	WARNING util.py:214 -- The `process_trial_result` operation took 0.688 s, which may be a performance bottleneck.
2023-11-03 13:51:29,488	WARNING util.py:214 -- Processing trial results took 0.688 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 13:51:29,488	WARNING util.py:214 -- The `process_trial_result` operation took 0.688 s, which may be a performance bottleneck.
2023-11-03 13:51:34,798	WARNING util.py:214 -- The `on_step_end` operation took 0.789 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 13:40:15 (running for 15:09:13.54)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1669/1000000 (31 RUNNING, 1638 TERMINATED)


== Status ==
Current time: 2023-11-03 13:40:23 (running for 15:09:21.07)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1673/1000000 (32 RUNNING, 1641 TERMINATED)


== Status ==
Current time: 2023-11-03 13:42:08 (running for 15:11:06.47)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1673/1000000 (32 RUNNING, 1641 TERMINATED)


== Status ==
Current time: 2023-11-03 13:42:22 (running for 15:11:20.09)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1677/1000000 (32 RUNNING, 1645 TERMINATED)


== Status ==
Current time: 2023-11-03 13:43:48 (running for 15:12:46.53)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1677/1000000 (32 RUNNING, 1645 TERMINATED)


== Status ==
Current time: 2023-11-03 13:43:55 (running for 15:12:52.61)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1681/1000000 (32 RUNNING, 1649 TERMINATED)


== Status ==
Current time: 2023-11-03 13:45:43 (running for 15:14:41.38)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1681/1000000 (32 RUNNING, 1649 TERMINATED)


== Status ==
Current time: 2023-11-03 13:45:49 (running for 15:14:47.37)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1684/1000000 (31 RUNNING, 1653 TERMINATED)


== Status ==
Current time: 2023-11-03 13:45:57 (running for 15:14:54.68)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1688/1000000 (32 RUNNING, 1656 TERMINATED)


== Status ==
Current time: 2023-11-03 13:47:51 (running for 15:16:48.98)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1688/1000000 (32 RUNNING, 1656 TERMINATED)


== Status ==
Current time: 2023-11-03 13:47:58 (running for 15:16:55.77)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1691/1000000 (32 RUNNING, 1659 TERMINATED)


== Status ==
Current time: 2023-11-03 13:49:40 (running for 15:18:37.83)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1691/1000000 (32 RUNNING, 1659 TERMINATED)


== Status ==
Current time: 2023-11-03 13:49:46 (running for 15:18:44.40)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1694/1000000 (31 RUNNING, 1663 TERMINATED)


== Status ==
Current time: 2023-11-03 13:51:28 (running for 15:20:25.80)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1695/1000000 (1 PENDING, 31 RUNNING, 1663 TERMINATED)


2023-11-03 13:51:40,009	WARNING util.py:214 -- The `start_trial` operation took 0.509 s, which may be a performance bottleneck.
2023-11-03 13:51:41,069	WARNING util.py:214 -- The `on_step_end` operation took 1.061 s, which may be a performance bottleneck.
[2m[36m(train pid=1799549)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1799549)[0m 
[2m[36m(train pid=1799545)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1799545)[0m 
2023-11-03 13:53:31,830	WARNING util.py:214 -- The `on_step_end` operation took 0.750 s, which may be a performance bottleneck.
2023-11-03 13:53:37,121	WARNING util.py:214 -- The `start_trial` operation took 0.657 s, which may be a performance bottleneck.
2023-11-03 13:53:37,843	WARNING util.py:214 -- The `on_step_end` operation took 0.723 s, which may be a performance bottleneck.
2023-11-03 13:55:11,844	WARNING util.py:214 -- The `on_step_end` operation took 0.837 s, which may be a performance bottleneck.
[2m[36m(train pid=1802590)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1802590)[0m 
[2m[36m(train pid=1802456)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1802456)[0m 
2023-11-03 13:55:17,825	WARNING util.py:214 -- The `on_step_end` operation took 0.892 s, which may be a performance bottleneck.
2023-11-03 13:55:27,435	WARNING util.py:214 -- The `on_step_end` operation took 1.309 s, which may be a performance bottleneck.
2023-11-03 13:55:37,176	WARNING util.py:214 -- The `on_step_end` operation took 0.729 s, which may be a performance bottleneck.
2023-11-03 13:57:26,381	WARNING util.py:214 -- The `on_step_end` operation took 0.819 s, which may be a performance bottleneck.
[2m[36m(train pid=1805607)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1805607)[0m 
2023-11-03 13:57:30,654	WARNING util.py:214 -- The `start_trial` operation took 0.580 s, which may be a performance bottleneck.
2023-11-03 13:57:32,816	WARNING util.py:214 -- The `on_step_end` operation took 1.234 s, which may be a performance bottleneck.
[2m[36m(train pid=1808762)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1808762)[0m 
2023-11-03 13:59:23,426	WARNING util.py:214 -- The `on_step_end` operation took 0.913 s, which may be a performance bottleneck.
2023-11-03 13:59:29,134	WARNING util.py:214 -- The `on_step_end` operation took 0.626 s, which may be a performance bottleneck.
2023-11-03 13:59:35,661	WARNING util.py:214 -- The `on_step_end` operation took 1.212 s, which may be a performance bottleneck.
[2m[36m(train pid=1813000)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1813000)[0m 
2023-11-03 14:01:21,024	WARNING util.py:214 -- The `on_step_end` operation took 1.079 s, which may be a performance bottleneck.
2023-11-03 14:01:25,556	WARNING util.py:214 -- The `start_trial` operation took 0.610 s, which may be a performance bottleneck.
2023-11-03 14:01:27,468	WARNING util.py:214 -- The `on_step_end` operation took 1.148 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 13:51:34 (running for 15:20:32.50)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1699/1000000 (1 PENDING, 31 RUNNING, 1667 TERMINATED)


== Status ==
Current time: 2023-11-03 13:51:41 (running for 15:20:38.67)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1702/1000000 (32 RUNNING, 1670 TERMINATED)


== Status ==
Current time: 2023-11-03 13:53:31 (running for 15:22:29.52)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1702/1000000 (32 RUNNING, 1670 TERMINATED)


== Status ==
Current time: 2023-11-03 13:53:37 (running for 15:22:35.55)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1705/1000000 (32 RUNNING, 1673 TERMINATED)


== Status ==
Current time: 2023-11-03 13:55:11 (running for 15:24:09.44)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1705/1000000 (31 RUNNING, 1674 TERMINATED)


== Status ==
Current time: 2023-11-03 13:55:17 (running for 15:24:15.52)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1709/1000000 (31 RUNNING, 1678 TERMINATED)


== Status ==
Current time: 2023-11-03 13:55:27 (running for 15:24:25.03)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1710/1000000 (1 PENDING, 31 RUNNING, 1678 TERMINATED)


== Status ==
Current time: 2023-11-03 13:55:37 (running for 15:24:34.77)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1712/1000000 (32 RUNNING, 1680 TERMINATED)


== Status ==
Current time: 2023-11-03 13:57:26 (running for 15:26:24.06)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1712/1000000 (32 RUNNING, 1680 TERMINATED)


== Status ==
Current time: 2023-11-03 13:57:32 (running for 15:26:30.47)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1715/1000000 (32 RUNNING, 1683 TERMINATED)


== Status ==
Current time: 2023-11-03 13:59:23 (running for 15:28:21.02)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1715/1000000 (32 RUNNING, 1683 TERMINATED)


== Status ==
Current time: 2023-11-03 13:59:29 (running for 15:28:26.89)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1718/1000000 (31 RUNNING, 1687 TERMINATED)


== Status ==
Current time: 2023-11-03 13:59:35 (running for 15:28:33.29)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1722/1000000 (1 PENDING, 30 RUNNING, 1691 TERMINATED)


== Status ==
Current time: 2023-11-03 14:01:21 (running for 15:30:18.62)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1722/1000000 (31 RUNNING, 1691 TERMINATED)


2023-11-03 14:03:06,667	WARNING util.py:214 -- The `on_step_end` operation took 0.826 s, which may be a performance bottleneck.
[2m[36m(train pid=1817033)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1817033)[0m 
2023-11-03 14:03:12,787	WARNING util.py:214 -- The `on_step_end` operation took 1.011 s, which may be a performance bottleneck.
[2m[36m(train pid=1821728)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1821728)[0m 
[2m[36m(train pid=1821697)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1821697)[0m 
2023-11-03 14:04:43,494	WARNING util.py:214 -- The `on_step_end` operation took 0.754 s, which may be a performance bottleneck.
2023-11-03 14:04:49,696	WARNING util.py:214 -- The `on_step_end` operation took 0.987 s, which may be a performance bottleneck.
2023-11-03 14:04:56,007	WARNING util.py:214 -- The `on_step_end` operation took 1.109 s, which may be a performance bottleneck.
[2m[36m(train pid=1825391)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1825391)[0m 
[2m[36m(train pid=1825529)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1825529)[0m 
2023-11-03 14:06:35,446	WARNING util.py:214 -- The `on_step_end` operation took 0.974 s, which may be a performance bottleneck.
2023-11-03 14:06:42,518	WARNING util.py:214 -- The `on_step_end` operation took 1.020 s, which may be a performance bottleneck.
2023-11-03 14:08:13,677	WARNING util.py:214 -- The `on_step_end` operation took 0.777 s, which may be a performance bottleneck.
[2m[36m(train pid=1828848)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1828848)[0m 
[2m[36m(train pid=1828857)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1828857)[0m 
2023-11-03 14:08:19,737	WARNING util.py:214 -- The `on_step_end` operation took 0.905 s, which may be a performance bottleneck.
[2m[36m(train pid=1831726)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1831726)[0m 
[2m[36m(train pid=1831738)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1831738)[0m 
2023-11-03 14:09:46,937	WARNING util.py:214 -- The `on_step_end` operation took 0.888 s, which may be a performance bottleneck.
2023-11-03 14:11:02,643	WARNING util.py:214 -- The `on_step_end` operation took 0.655 s, which may be a performance bottleneck.
[2m[36m(train pid=1834690)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1834690)[0m 
2023-11-03 14:11:09,577	WARNING util.py:214 -- The `on_step_end` operation took 1.135 s, which may be a performance bottleneck.
[2m[36m(train pid=1837712)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1837712)[0m 
2023-11-03 14:12:32,137	WARNING util.py:214 -- The `on_step_end` operation took 0.735 s, which may be a performance bottleneck.
2023-11-03 14:12:37,903	WARNING util.py:214 -- The `on_step_end` operation took 0.728 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 14:01:27 (running for 15:30:25.12)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1726/1000000 (1 PENDING, 31 RUNNING, 1694 TERMINATED)


== Status ==
Current time: 2023-11-03 14:03:06 (running for 15:32:04.26)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1726/1000000 (1 PENDING, 31 RUNNING, 1694 TERMINATED)


== Status ==
Current time: 2023-11-03 14:03:12 (running for 15:32:10.38)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1729/1000000 (32 RUNNING, 1697 TERMINATED)


== Status ==
Current time: 2023-11-03 14:04:43 (running for 15:33:41.09)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1729/1000000 (31 RUNNING, 1698 TERMINATED)


== Status ==
Current time: 2023-11-03 14:04:49 (running for 15:33:47.40)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1734/1000000 (1 PENDING, 30 RUNNING, 1703 TERMINATED)


== Status ==
Current time: 2023-11-03 14:04:56 (running for 15:33:53.73)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1737/1000000 (32 RUNNING, 1705 TERMINATED)


== Status ==
Current time: 2023-11-03 14:06:35 (running for 15:35:33.04)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1737/1000000 (31 RUNNING, 1706 TERMINATED)


== Status ==
Current time: 2023-11-03 14:06:42 (running for 15:35:40.21)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1741/1000000 (32 RUNNING, 1709 TERMINATED)


== Status ==
Current time: 2023-11-03 14:08:13 (running for 15:37:11.29)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1741/1000000 (31 RUNNING, 1710 TERMINATED)


== Status ==
Current time: 2023-11-03 14:08:19 (running for 15:37:17.46)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1745/1000000 (1 PENDING, 31 RUNNING, 1713 TERMINATED)


== Status ==
Current time: 2023-11-03 14:09:46 (running for 15:38:44.53)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1745/1000000 (32 RUNNING, 1713 TERMINATED)


== Status ==
Current time: 2023-11-03 14:11:02 (running for 15:40:00.24)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1745/1000000 (32 RUNNING, 1713 TERMINATED)


== Status ==
Current time: 2023-11-03 14:11:09 (running for 15:40:07.17)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1750/1000000 (1 PENDING, 30 RUNNING, 1719 TERMINATED)


== Status ==
Current time: 2023-11-03 14:12:32 (running for 15:41:29.73)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1750/1000000 (31 RUNNING, 1719 TERMINATED)


[2m[36m(train pid=1841519)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1841519)[0m 
2023-11-03 14:13:45,727	WARNING util.py:214 -- The `on_step_end` operation took 0.531 s, which may be a performance bottleneck.
[2m[36m(train pid=1841663)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1841663)[0m 
2023-11-03 14:13:56,671	WARNING util.py:214 -- The `on_step_end` operation took 0.750 s, which may be a performance bottleneck.
2023-11-03 14:14:03,537	WARNING util.py:214 -- The `on_step_end` operation took 1.087 s, which may be a performance bottleneck.
2023-11-03 14:15:34,168	WARNING util.py:214 -- The `on_step_end` operation took 0.745 s, which may be a performance bottleneck.
[2m[36m(train pid=1843583)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1843583)[0m 
2023-11-03 14:15:40,361	WARNING util.py:214 -- The `on_step_end` operation took 1.134 s, which may be a performance bottleneck.
2023-11-03 14:15:51,184	WARNING util.py:214 -- The `on_step_end` operation took 0.851 s, which may be a performance bottleneck.
[2m[36m(train pid=1845848)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1845848)[0m 
[2m[36m(train pid=1845985)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1845985)[0m 
2023-11-03 14:17:47,381	WARNING util.py:214 -- The `on_step_end` operation took 1.164 s, which may be a performance bottleneck.
2023-11-03 14:17:53,903	WARNING util.py:214 -- The `on_step_end` operation took 1.312 s, which may be a performance bottleneck.
2023-11-03 14:19:36,974	WARNING util.py:214 -- The `on_step_end` operation took 0.853 s, which may be a performance bottleneck.
[2m[36m(train pid=1849749)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1849749)[0m 
2023-11-03 14:19:42,170	WARNING util.py:214 -- The `start_trial` operation took 0.761 s, which may be a performance bottleneck.
2023-11-03 14:19:43,077	WARNING util.py:214 -- The `on_step_end` operation took 0.906 s, which may be a performance bottleneck.
2023-11-03 14:19:51,226	WARNING util.py:214 -- The `on_step_end` operation took 0.971 s, which may be a performance bottleneck.
[2m[36m(train pid=1854688)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1854688)[0m 
2023-11-03 14:21:33,472	WARNING util.py:214 -- The `on_step_end` operation took 0.920 s, which may be a performance bottleneck.
2023-11-03 14:21:39,694	WARNING util.py:214 -- The `on_step_end` operation took 1.118 s, which may be a performance bottleneck.
2023-11-03 14:22:50,996	WARNING util.py:214 -- The `on_step_end` operation took 0.534 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 14:12:37 (running for 15:41:35.57)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1755/1000000 (31 RUNNING, 1724 TERMINATED)


== Status ==
Current time: 2023-11-03 14:13:45 (running for 15:42:43.39)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1756/1000000 (1 PENDING, 31 RUNNING, 1724 TERMINATED)


== Status ==
Current time: 2023-11-03 14:13:56 (running for 15:42:54.27)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1760/1000000 (1 PENDING, 31 RUNNING, 1728 TERMINATED)


== Status ==
Current time: 2023-11-03 14:14:03 (running for 15:43:01.15)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1764/1000000 (1 PENDING, 30 RUNNING, 1733 TERMINATED)


== Status ==
Current time: 2023-11-03 14:15:34 (running for 15:44:31.77)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1764/1000000 (31 RUNNING, 1733 TERMINATED)


== Status ==
Current time: 2023-11-03 14:15:40 (running for 15:44:37.96)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1768/1000000 (1 PENDING, 31 RUNNING, 1736 TERMINATED)


== Status ==
Current time: 2023-11-03 14:15:51 (running for 15:44:48.92)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1771/1000000 (32 RUNNING, 1739 TERMINATED)


== Status ==
Current time: 2023-11-03 14:17:47 (running for 15:46:44.98)
Memory usage on this node: 25.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1771/1000000 (32 RUNNING, 1739 TERMINATED)


== Status ==
Current time: 2023-11-03 14:17:53 (running for 15:46:51.50)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1774/1000000 (1 PENDING, 30 RUNNING, 1743 TERMINATED)


== Status ==
Current time: 2023-11-03 14:19:36 (running for 15:48:34.57)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1774/1000000 (31 RUNNING, 1743 TERMINATED)


== Status ==
Current time: 2023-11-03 14:19:43 (running for 15:48:40.67)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1777/1000000 (31 RUNNING, 1746 TERMINATED)


== Status ==
Current time: 2023-11-03 14:19:51 (running for 15:48:48.82)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1778/1000000 (32 RUNNING, 1746 TERMINATED)


== Status ==
Current time: 2023-11-03 14:21:33 (running for 15:50:31.07)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1778/1000000 (32 RUNNING, 1746 TERMINATED)


== Status ==
Current time: 2023-11-03 14:21:39 (running for 15:50:37.39)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1781/1000000 (1 PENDING, 30 RUNNING, 1750 TERMINATED)


[2m[36m(train pid=1860456)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1860456)[0m 
2023-11-03 14:22:56,985	WARNING util.py:214 -- The `on_step_end` operation took 0.887 s, which may be a performance bottleneck.
2023-11-03 14:23:03,247	WARNING util.py:214 -- The `on_step_end` operation took 1.199 s, which may be a performance bottleneck.
[2m[36m(train pid=1864148)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1864148)[0m 
2023-11-03 14:24:31,034	WARNING util.py:214 -- The `on_step_end` operation took 0.858 s, which may be a performance bottleneck.
2023-11-03 14:25:42,873	WARNING util.py:214 -- The `on_step_end` operation took 0.709 s, which may be a performance bottleneck.
[2m[36m(train pid=1866318)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1866318)[0m 
2023-11-03 14:25:45,446	WARNING util.py:214 -- The `start_trial` operation took 0.549 s, which may be a performance bottleneck.
2023-11-03 14:25:48,895	WARNING util.py:214 -- The `on_step_end` operation took 0.953 s, which may be a performance bottleneck.
2023-11-03 14:25:55,219	WARNING util.py:214 -- The `on_step_end` operation took 1.169 s, which may be a performance bottleneck.
2023-11-03 14:26:00,346	WARNING util.py:214 -- The `start_trial` operation took 0.580 s, which may be a performance bottleneck.
2023-11-03 14:26:01,388	WARNING util.py:214 -- The `on_step_end` operation took 1.041 s, which may be a performance bottleneck.
[2m[36m(train pid=1869322)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1869322)[0m 
2023-11-03 14:27:56,520	WARNING util.py:214 -- The `on_step_end` operation took 1.183 s, which may be a performance bottleneck.
2023-11-03 14:28:02,970	WARNING util.py:214 -- The `on_step_end` operation took 1.058 s, which may be a performance bottleneck.
2023-11-03 14:28:12,761	WARNING util.py:214 -- The `on_step_end` operation took 1.102 s, which may be a performance bottleneck.
2023-11-03 14:29:51,306	WARNING util.py:214 -- The `on_step_end` operation took 0.819 s, which may be a performance bottleneck.
[2m[36m(train pid=1874128)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1874128)[0m 
2023-11-03 14:29:57,354	WARNING util.py:214 -- The `on_step_end` operation took 0.861 s, which may be a performance bottleneck.
2023-11-03 14:30:04,112	WARNING util.py:214 -- The `on_step_end` operation took 1.291 s, which may be a performance bottleneck.
[2m[36m(train pid=1879278)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1879278)[0m 
2023-11-03 14:32:00,013	WARNING util.py:214 -- The `on_step_end` operation took 13.481 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 14:22:51 (running for 15:51:48.65)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1781/1000000 (31 RUNNING, 1750 TERMINATED)


== Status ==
Current time: 2023-11-03 14:22:57 (running for 15:51:54.62)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1786/1000000 (1 PENDING, 31 RUNNING, 1754 TERMINATED)


== Status ==
Current time: 2023-11-03 14:23:03 (running for 15:52:00.88)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1790/1000000 (1 PENDING, 31 RUNNING, 1758 TERMINATED)


== Status ==
Current time: 2023-11-03 14:24:31 (running for 15:53:28.72)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1790/1000000 (32 RUNNING, 1758 TERMINATED)


== Status ==
Current time: 2023-11-03 14:25:42 (running for 15:54:40.49)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1790/1000000 (32 RUNNING, 1758 TERMINATED)


== Status ==
Current time: 2023-11-03 14:25:48 (running for 15:54:46.56)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1794/1000000 (1 PENDING, 30 RUNNING, 1763 TERMINATED)


== Status ==
Current time: 2023-11-03 14:25:55 (running for 15:54:52.94)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1798/1000000 (1 PENDING, 31 RUNNING, 1766 TERMINATED)


== Status ==
Current time: 2023-11-03 14:26:01 (running for 15:54:59.12)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1801/1000000 (31 RUNNING, 1770 TERMINATED)


== Status ==
Current time: 2023-11-03 14:27:56 (running for 15:56:54.12)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1802/1000000 (1 PENDING, 31 RUNNING, 1770 TERMINATED)


== Status ==
Current time: 2023-11-03 14:28:02 (running for 15:57:00.57)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1805/1000000 (31 RUNNING, 1774 TERMINATED)


== Status ==
Current time: 2023-11-03 14:28:12 (running for 15:57:10.36)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1807/1000000 (32 RUNNING, 1775 TERMINATED)


== Status ==
Current time: 2023-11-03 14:29:51 (running for 15:58:48.90)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1807/1000000 (32 RUNNING, 1775 TERMINATED)


== Status ==
Current time: 2023-11-03 14:29:57 (running for 15:58:54.95)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1810/1000000 (31 RUNNING, 1779 TERMINATED)


== Status ==
Current time: 2023-11-03 14:30:04 (running for 15:59:01.71)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1814/1000000 (1 PENDING, 30 RUNNING, 1783 TERMINATED)


2023-11-03 14:32:06,037	WARNING util.py:214 -- The `on_step_end` operation took 0.925 s, which may be a performance bottleneck.
[2m[36m(train pid=1884370)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1884370)[0m 
2023-11-03 14:33:42,630	WARNING util.py:214 -- The `on_step_end` operation took 0.797 s, which may be a performance bottleneck.
2023-11-03 14:33:48,637	WARNING util.py:214 -- The `on_step_end` operation took 1.000 s, which may be a performance bottleneck.
2023-11-03 14:35:05,992	WARNING util.py:214 -- The `on_step_end` operation took 0.606 s, which may be a performance bottleneck.
[2m[36m(train pid=1888752)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1888752)[0m 
2023-11-03 14:35:11,758	WARNING util.py:214 -- The `on_step_end` operation took 0.761 s, which may be a performance bottleneck.
[2m[36m(train pid=1893040)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1893040)[0m 
2023-11-03 14:36:29,482	WARNING util.py:214 -- The `on_step_end` operation took 0.590 s, which may be a performance bottleneck.
2023-11-03 14:36:36,013	WARNING util.py:214 -- The `on_step_end` operation took 0.924 s, which may be a performance bottleneck.
2023-11-03 14:37:50,251	WARNING util.py:214 -- The `on_step_end` operation took 0.671 s, which may be a performance bottleneck.
[2m[36m(train pid=1896138)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1896138)[0m 
2023-11-03 14:38:01,096	WARNING util.py:214 -- The `on_step_end` operation took 0.972 s, which may be a performance bottleneck.
2023-11-03 14:39:11,548	WARNING util.py:214 -- The `on_step_end` operation took 0.627 s, which may be a performance bottleneck.
[2m[36m(train pid=1898557)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1898557)[0m 
2023-11-03 14:39:16,853	WARNING util.py:214 -- The `start_trial` operation took 0.561 s, which may be a performance bottleneck.
2023-11-03 14:39:17,628	WARNING util.py:214 -- The `on_step_end` operation took 0.775 s, which may be a performance bottleneck.
[2m[36m(train pid=1901476)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1901476)[0m 
[2m[36m(train pid=1901326)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1901326)[0m 
2023-11-03 14:40:41,107	WARNING util.py:214 -- The `on_step_end` operation took 0.987 s, which may be a performance bottleneck.
2023-11-03 14:40:47,395	WARNING util.py:214 -- The `on_step_end` operation took 1.146 s, which may be a performance bottleneck.
2023-11-03 14:40:53,922	WARNING util.py:214 -- The `on_step_end` operation took 1.108 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 14:32:00 (running for 16:00:57.61)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1814/1000000 (31 RUNNING, 1783 TERMINATED)


== Status ==
Current time: 2023-11-03 14:32:06 (running for 16:01:03.71)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1818/1000000 (32 RUNNING, 1786 TERMINATED)


== Status ==
Current time: 2023-11-03 14:33:42 (running for 16:02:40.23)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1818/1000000 (32 RUNNING, 1786 TERMINATED)


== Status ==
Current time: 2023-11-03 14:33:48 (running for 16:02:46.26)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1822/1000000 (1 PENDING, 31 RUNNING, 1790 TERMINATED)


== Status ==
Current time: 2023-11-03 14:35:06 (running for 16:04:03.65)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1822/1000000 (1 PENDING, 31 RUNNING, 1790 TERMINATED)


== Status ==
Current time: 2023-11-03 14:35:11 (running for 16:04:09.36)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1826/1000000 (31 RUNNING, 1795 TERMINATED)


== Status ==
Current time: 2023-11-03 14:36:29 (running for 16:05:27.17)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1827/1000000 (1 PENDING, 31 RUNNING, 1795 TERMINATED)


== Status ==
Current time: 2023-11-03 14:36:36 (running for 16:05:33.65)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1833/1000000 (1 PENDING, 30 RUNNING, 1802 TERMINATED)


== Status ==
Current time: 2023-11-03 14:37:50 (running for 16:06:47.90)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1833/1000000 (31 RUNNING, 1802 TERMINATED)


== Status ==
Current time: 2023-11-03 14:38:01 (running for 16:06:58.73)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1836/1000000 (1 PENDING, 30 RUNNING, 1805 TERMINATED)


== Status ==
Current time: 2023-11-03 14:39:11 (running for 16:08:09.17)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1836/1000000 (31 RUNNING, 1805 TERMINATED)


== Status ==
Current time: 2023-11-03 14:39:17 (running for 16:08:15.24)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1841/1000000 (32 RUNNING, 1809 TERMINATED)


== Status ==
Current time: 2023-11-03 14:40:41 (running for 16:09:38.70)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1841/1000000 (32 RUNNING, 1809 TERMINATED)


== Status ==
Current time: 2023-11-03 14:40:47 (running for 16:09:44.99)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1845/1000000 (1 PENDING, 30 RUNNING, 1814 TERMINATED)


[2m[36m(train pid=1903681)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1903681)[0m 
[2m[36m(train pid=1903970)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1903970)[0m 
2023-11-03 14:42:45,607	WARNING util.py:214 -- The `on_step_end` operation took 1.177 s, which may be a performance bottleneck.
2023-11-03 14:42:52,167	WARNING util.py:214 -- The `on_step_end` operation took 1.421 s, which may be a performance bottleneck.
2023-11-03 14:44:28,302	WARNING util.py:214 -- The `on_step_end` operation took 0.742 s, which may be a performance bottleneck.
[2m[36m(train pid=1906695)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1906695)[0m 
2023-11-03 14:44:35,007	WARNING util.py:214 -- The `on_step_end` operation took 1.074 s, which may be a performance bottleneck.
[2m[36m(train pid=1909730)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1909730)[0m 
[2m[36m(train pid=1909754)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1909754)[0m 
2023-11-03 14:46:22,507	WARNING util.py:214 -- The `on_step_end` operation took 1.076 s, which may be a performance bottleneck.
2023-11-03 14:46:29,532	WARNING util.py:214 -- The `on_step_end` operation took 1.087 s, which may be a performance bottleneck.
2023-11-03 14:47:55,678	WARNING util.py:214 -- The `on_step_end` operation took 0.642 s, which may be a performance bottleneck.
[2m[36m(train pid=1914878)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1914878)[0m 
[2m[36m(train pid=1914583)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1914583)[0m 
2023-11-03 14:48:02,004	WARNING util.py:214 -- The `on_step_end` operation took 0.991 s, which may be a performance bottleneck.
2023-11-03 14:48:03,379	WARNING util.py:214 -- The `start_trial` operation took 0.832 s, which may be a performance bottleneck.
2023-11-03 14:48:08,063	WARNING util.py:214 -- The `on_step_end` operation took 0.975 s, which may be a performance bottleneck.
2023-11-03 14:48:27,074	WARNING util.py:214 -- The `on_step_end` operation took 1.222 s, which may be a performance bottleneck.
2023-11-03 14:50:03,848	WARNING util.py:214 -- The `on_step_end` operation took 1.013 s, which may be a performance bottleneck.
[2m[36m(train pid=1918190)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1918190)[0m 
[2m[36m(train pid=1918194)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1918194)[0m 
2023-11-03 14:50:08,219	WARNING util.py:214 -- The `start_trial` operation took 0.525 s, which may be a performance bottleneck.
2023-11-03 14:50:10,559	WARNING util.py:214 -- The `on_step_end` operation took 1.292 s, which may be a performance bottleneck.
[2m[36m(train pid=1921188)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1921188)[0m 
2023-11-03 14:52:09,458	WARNING util.py:214 -- The `on_step_end` operation took 1.165 s, which may be a performance bottleneck.
2023-11-03 14:52:15,772	WARNING util.py:214 -- The `on_step_end` operation took 1.284 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 14:40:53 (running for 16:09:51.52)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1849/1000000 (32 RUNNING, 1817 TERMINATED)


== Status ==
Current time: 2023-11-03 14:42:45 (running for 16:11:43.29)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1849/1000000 (32 RUNNING, 1817 TERMINATED)


== Status ==
Current time: 2023-11-03 14:42:52 (running for 16:11:49.80)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1852/1000000 (1 PENDING, 30 RUNNING, 1821 TERMINATED)


== Status ==
Current time: 2023-11-03 14:44:28 (running for 16:13:25.90)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1852/1000000 (31 RUNNING, 1821 TERMINATED)


== Status ==
Current time: 2023-11-03 14:44:35 (running for 16:13:32.68)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1856/1000000 (32 RUNNING, 1824 TERMINATED)


== Status ==
Current time: 2023-11-03 14:46:22 (running for 16:15:20.22)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1856/1000000 (32 RUNNING, 1824 TERMINATED)


== Status ==
Current time: 2023-11-03 14:46:29 (running for 16:15:27.14)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1860/1000000 (32 RUNNING, 1828 TERMINATED)


== Status ==
Current time: 2023-11-03 14:47:55 (running for 16:16:53.35)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1860/1000000 (32 RUNNING, 1828 TERMINATED)


== Status ==
Current time: 2023-11-03 14:48:02 (running for 16:16:59.60)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1864/1000000 (1 PENDING, 30 RUNNING, 1833 TERMINATED)


== Status ==
Current time: 2023-11-03 14:48:08 (running for 16:17:05.74)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1867/1000000 (31 RUNNING, 1836 TERMINATED)


== Status ==
Current time: 2023-11-03 14:48:27 (running for 16:17:24.71)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1870/1000000 (32 RUNNING, 1838 TERMINATED)


== Status ==
Current time: 2023-11-03 14:50:03 (running for 16:19:01.45)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1870/1000000 (32 RUNNING, 1838 TERMINATED)


== Status ==
Current time: 2023-11-03 14:50:10 (running for 16:19:08.22)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1873/1000000 (1 PENDING, 31 RUNNING, 1841 TERMINATED)


== Status ==
Current time: 2023-11-03 14:52:09 (running for 16:21:07.10)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1873/1000000 (1 PENDING, 31 RUNNING, 1841 TERMINATED)


2023-11-03 14:53:52,728	WARNING util.py:214 -- The `on_step_end` operation took 0.695 s, which may be a performance bottleneck.
[2m[36m(train pid=1924765)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1924765)[0m 
2023-11-03 14:53:54,858	WARNING util.py:214 -- The `start_trial` operation took 0.659 s, which may be a performance bottleneck.
2023-11-03 14:54:04,319	WARNING util.py:214 -- The `on_step_end` operation took 1.122 s, which may be a performance bottleneck.
2023-11-03 14:55:20,891	WARNING util.py:214 -- The `on_step_end` operation took 0.667 s, which may be a performance bottleneck.
[2m[36m(train pid=1928769)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1928769)[0m 
2023-11-03 14:55:26,778	WARNING util.py:214 -- The `on_step_end` operation took 0.887 s, which may be a performance bottleneck.
2023-11-03 14:55:32,914	WARNING util.py:214 -- The `start_trial` operation took 0.639 s, which may be a performance bottleneck.
2023-11-03 14:55:33,805	WARNING util.py:214 -- The `on_step_end` operation took 0.890 s, which may be a performance bottleneck.
[2m[36m(train pid=1933655)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1933655)[0m 
[2m[36m(train pid=1933802)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1933802)[0m 
2023-11-03 14:57:02,046	WARNING util.py:214 -- The `on_step_end` operation took 0.874 s, which may be a performance bottleneck.
2023-11-03 14:57:07,991	WARNING util.py:214 -- The `on_step_end` operation took 0.904 s, which may be a performance bottleneck.
2023-11-03 14:57:14,371	WARNING util.py:214 -- The `on_step_end` operation took 1.310 s, which may be a performance bottleneck.
[2m[36m(train pid=1936810)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1936810)[0m 
2023-11-03 14:59:01,676	WARNING util.py:214 -- The `on_step_end` operation took 1.163 s, which may be a performance bottleneck.
2023-11-03 14:59:05,608	WARNING util.py:214 -- The `start_trial` operation took 0.809 s, which may be a performance bottleneck.
2023-11-03 14:59:07,834	WARNING util.py:214 -- The `on_step_end` operation took 1.101 s, which may be a performance bottleneck.
2023-11-03 15:00:43,997	WARNING util.py:214 -- The `on_step_end` operation took 1.050 s, which may be a performance bottleneck.
[2m[36m(train pid=1939772)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1939772)[0m 
[2m[36m(train pid=1945096)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1945096)[0m 
2023-11-03 15:02:05,611	WARNING util.py:214 -- The `on_step_end` operation took 0.590 s, which may be a performance bottleneck.
2023-11-03 15:02:10,715	WARNING util.py:214 -- The `start_trial` operation took 0.503 s, which may be a performance bottleneck.
2023-11-03 15:03:08,685	WARNING util.py:214 -- The `on_step_end` operation took 0.550 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 14:52:15 (running for 16:21:13.45)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1876/1000000 (1 PENDING, 30 RUNNING, 1845 TERMINATED)


== Status ==
Current time: 2023-11-03 14:53:52 (running for 16:22:50.45)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1876/1000000 (31 RUNNING, 1845 TERMINATED)


== Status ==
Current time: 2023-11-03 14:54:04 (running for 16:23:01.92)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1878/1000000 (1 PENDING, 31 RUNNING, 1846 TERMINATED)


== Status ==
Current time: 2023-11-03 14:55:20 (running for 16:24:18.56)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1878/1000000 (1 PENDING, 31 RUNNING, 1846 TERMINATED)


== Status ==
Current time: 2023-11-03 14:55:26 (running for 16:24:24.38)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1882/1000000 (31 RUNNING, 1851 TERMINATED)


== Status ==
Current time: 2023-11-03 14:55:33 (running for 16:24:31.40)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1886/1000000 (32 RUNNING, 1854 TERMINATED)


== Status ==
Current time: 2023-11-03 14:57:02 (running for 16:25:59.71)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1886/1000000 (32 RUNNING, 1854 TERMINATED)


== Status ==
Current time: 2023-11-03 14:57:08 (running for 16:26:05.66)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1890/1000000 (31 RUNNING, 1859 TERMINATED)


== Status ==
Current time: 2023-11-03 14:57:14 (running for 16:26:12.00)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1894/1000000 (1 PENDING, 31 RUNNING, 1862 TERMINATED)


== Status ==
Current time: 2023-11-03 14:59:01 (running for 16:27:59.27)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1894/1000000 (1 PENDING, 31 RUNNING, 1862 TERMINATED)


== Status ==
Current time: 2023-11-03 14:59:07 (running for 16:28:05.43)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1896/1000000 (31 RUNNING, 1865 TERMINATED)


== Status ==
Current time: 2023-11-03 15:00:43 (running for 16:29:41.59)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1897/1000000 (32 RUNNING, 1865 TERMINATED)


== Status ==
Current time: 2023-11-03 15:02:05 (running for 16:31:03.23)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1897/1000000 (32 RUNNING, 1865 TERMINATED)


== Status ==
Current time: 2023-11-03 15:02:11 (running for 16:31:08.80)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1901/1000000 (32 RUNNING, 1869 TERMINATED)


[2m[36m(train pid=1949999)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1949999)[0m 
2023-11-03 15:03:14,478	WARNING util.py:214 -- The `on_step_end` operation took 0.617 s, which may be a performance bottleneck.
[2m[36m(train pid=1952252)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1952252)[0m 
2023-11-03 15:04:25,998	WARNING util.py:214 -- The `on_step_end` operation took 0.922 s, which may be a performance bottleneck.
2023-11-03 15:04:32,121	WARNING util.py:214 -- The `on_step_end` operation took 1.048 s, which may be a performance bottleneck.
2023-11-03 15:05:51,430	WARNING util.py:214 -- The `on_step_end` operation took 0.803 s, which may be a performance bottleneck.
[2m[36m(train pid=1954203)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1954203)[0m 
2023-11-03 15:05:57,554	WARNING util.py:214 -- The `on_step_end` operation took 1.009 s, which may be a performance bottleneck.
[2m[36m(train pid=1956097)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1956097)[0m 
2023-11-03 15:07:26,658	WARNING util.py:214 -- The `on_step_end` operation took 0.927 s, which may be a performance bottleneck.
2023-11-03 15:07:32,929	WARNING util.py:214 -- The `on_step_end` operation took 1.086 s, which may be a performance bottleneck.
2023-11-03 15:09:01,140	WARNING util.py:214 -- The `on_step_end` operation took 0.808 s, which may be a performance bottleneck.
[2m[36m(train pid=1957995)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1957995)[0m 
2023-11-03 15:09:07,636	WARNING util.py:214 -- The `on_step_end` operation took 1.257 s, which may be a performance bottleneck.
2023-11-03 15:10:41,670	WARNING util.py:214 -- The `start_trial` operation took 0.740 s, which may be a performance bottleneck.
[2m[36m(train pid=1960820)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1960820)[0m 
2023-11-03 15:10:48,724	WARNING util.py:214 -- The `on_step_end` operation took 1.054 s, which may be a performance bottleneck.
2023-11-03 15:12:02,235	WARNING util.py:214 -- The `on_step_end` operation took 0.594 s, which may be a performance bottleneck.
[2m[36m(train pid=1964517)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1964517)[0m 
2023-11-03 15:12:08,360	WARNING util.py:214 -- The `on_step_end` operation took 1.007 s, which may be a performance bottleneck.
2023-11-03 15:12:14,501	WARNING util.py:214 -- The `on_step_end` operation took 1.067 s, which may be a performance bottleneck.
2023-11-03 15:12:16,740	WARNING util.py:214 -- The `start_trial` operation took 0.579 s, which may be a performance bottleneck.
2023-11-03 15:12:20,899	WARNING util.py:214 -- The `on_step_end` operation took 1.282 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 15:03:08 (running for 16:32:06.33)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1901/1000000 (31 RUNNING, 1870 TERMINATED)


== Status ==
Current time: 2023-11-03 15:03:14 (running for 16:32:12.08)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1907/1000000 (31 RUNNING, 1876 TERMINATED)


== Status ==
Current time: 2023-11-03 15:04:25 (running for 16:33:23.60)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1908/1000000 (1 PENDING, 31 RUNNING, 1876 TERMINATED)


== Status ==
Current time: 2023-11-03 15:04:32 (running for 16:33:29.82)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1913/1000000 (1 PENDING, 31 RUNNING, 1881 TERMINATED)


== Status ==
Current time: 2023-11-03 15:05:51 (running for 16:34:49.03)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1913/1000000 (1 PENDING, 31 RUNNING, 1881 TERMINATED)


== Status ==
Current time: 2023-11-03 15:05:57 (running for 16:34:55.15)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1917/1000000 (1 PENDING, 31 RUNNING, 1885 TERMINATED)


== Status ==
Current time: 2023-11-03 15:07:26 (running for 16:36:24.39)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1917/1000000 (1 PENDING, 31 RUNNING, 1885 TERMINATED)


== Status ==
Current time: 2023-11-03 15:07:32 (running for 16:36:30.53)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1921/1000000 (1 PENDING, 30 RUNNING, 1890 TERMINATED)


== Status ==
Current time: 2023-11-03 15:09:01 (running for 16:37:58.74)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1921/1000000 (31 RUNNING, 1890 TERMINATED)


== Status ==
Current time: 2023-11-03 15:09:07 (running for 16:38:05.23)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1925/1000000 (1 PENDING, 31 RUNNING, 1893 TERMINATED)


== Status ==
Current time: 2023-11-03 15:10:48 (running for 16:39:46.37)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1925/1000000 (32 RUNNING, 1893 TERMINATED)


== Status ==
Current time: 2023-11-03 15:12:02 (running for 16:40:59.85)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1925/1000000 (32 RUNNING, 1893 TERMINATED)


== Status ==
Current time: 2023-11-03 15:12:08 (running for 16:41:05.96)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1930/1000000 (1 PENDING, 31 RUNNING, 1898 TERMINATED)


== Status ==
Current time: 2023-11-03 15:12:14 (running for 16:41:12.18)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1934/1000000 (31 RUNNING, 1903 TERMINATED)


[2m[36m(train pid=1968232)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1968232)[0m 
2023-11-03 15:14:02,669	WARNING util.py:214 -- The `on_step_end` operation took 1.169 s, which may be a performance bottleneck.
2023-11-03 15:14:09,606	WARNING util.py:214 -- The `on_step_end` operation took 1.319 s, which may be a performance bottleneck.
2023-11-03 15:15:44,020	WARNING util.py:214 -- The `on_step_end` operation took 0.841 s, which may be a performance bottleneck.
[2m[36m(train pid=1971707)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1971707)[0m 
2023-11-03 15:15:50,260	WARNING util.py:214 -- The `on_step_end` operation took 1.217 s, which may be a performance bottleneck.
[2m[36m(train pid=1974141)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1974141)[0m 
2023-11-03 15:17:21,524	WARNING util.py:214 -- The `on_step_end` operation took 1.142 s, which may be a performance bottleneck.
2023-11-03 15:17:28,045	WARNING util.py:214 -- The `on_step_end` operation took 1.233 s, which may be a performance bottleneck.
2023-11-03 15:18:57,766	WARNING util.py:214 -- The `on_step_end` operation took 0.870 s, which may be a performance bottleneck.
[2m[36m(train pid=1977295)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1977295)[0m 
2023-11-03 15:19:04,563	WARNING util.py:214 -- The `on_step_end` operation took 1.372 s, which may be a performance bottleneck.
2023-11-03 15:19:10,941	WARNING util.py:214 -- The `on_step_end` operation took 1.147 s, which may be a performance bottleneck.
[2m[36m(train pid=1981390)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1981390)[0m 
2023-11-03 15:21:08,407	WARNING util.py:214 -- The `on_step_end` operation took 1.150 s, which may be a performance bottleneck.
2023-11-03 15:21:09,639	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.507 s, which may be a performance bottleneck.
2023-11-03 15:21:09,639	WARNING util.py:214 -- The `process_trial_result` operation took 0.508 s, which may be a performance bottleneck.
2023-11-03 15:21:09,639	WARNING util.py:214 -- Processing trial results took 0.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 15:21:09,639	WARNING util.py:214 -- The `process_trial_result` operation took 0.508 s, which may be a performance bottleneck.
2023-11-03 15:21:14,950	WARNING util.py:214 -- The `on_step_end` operation took 1.247 s, which may be a performance bottleneck.
2023-11-03 15:22:37,226	WARNING util.py:214 -- The `on_step_end` operation took 0.661 s, which may be a performance bottleneck.
[2m[36m(train pid=1986072)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1986072)[0m 
2023-11-03 15:22:43,542	WARNING util.py:214 -- The `on_step_end` operation took 0.820 s, which may be a performance bottleneck.
[2m[36m(train pid=1989900)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1989900)[0m 
[2m[36m(train pid=1990047)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1990047)[0m 
2023-11-03 15:24:03,805	WARNING util.py:214 -- The `on_step_end` operation took 0.886 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 15:12:21 (running for 16:41:18.63)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1937/1000000 (1 PENDING, 30 RUNNING, 1906 TERMINATED)


== Status ==
Current time: 2023-11-03 15:14:02 (running for 16:43:00.38)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1937/1000000 (31 RUNNING, 1906 TERMINATED)


== Status ==
Current time: 2023-11-03 15:14:09 (running for 16:43:07.20)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1941/1000000 (1 PENDING, 30 RUNNING, 1910 TERMINATED)


== Status ==
Current time: 2023-11-03 15:15:44 (running for 16:44:41.64)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1941/1000000 (31 RUNNING, 1910 TERMINATED)


== Status ==
Current time: 2023-11-03 15:15:50 (running for 16:44:47.86)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1944/1000000 (1 PENDING, 30 RUNNING, 1913 TERMINATED)


== Status ==
Current time: 2023-11-03 15:17:21 (running for 16:46:19.19)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1944/1000000 (31 RUNNING, 1913 TERMINATED)


== Status ==
Current time: 2023-11-03 15:17:28 (running for 16:46:25.64)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1948/1000000 (1 PENDING, 31 RUNNING, 1916 TERMINATED)


== Status ==
Current time: 2023-11-03 15:18:57 (running for 16:47:55.36)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1948/1000000 (1 PENDING, 31 RUNNING, 1916 TERMINATED)


== Status ==
Current time: 2023-11-03 15:19:04 (running for 16:48:02.16)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1952/1000000 (1 PENDING, 31 RUNNING, 1920 TERMINATED)


== Status ==
Current time: 2023-11-03 15:19:10 (running for 16:48:08.54)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1955/1000000 (32 RUNNING, 1923 TERMINATED)


== Status ==
Current time: 2023-11-03 15:21:08 (running for 16:50:06.08)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1955/1000000 (32 RUNNING, 1923 TERMINATED)


== Status ==
Current time: 2023-11-03 15:21:14 (running for 16:50:12.55)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1958/1000000 (1 PENDING, 30 RUNNING, 1927 TERMINATED)


== Status ==
Current time: 2023-11-03 15:22:37 (running for 16:51:34.82)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1958/1000000 (31 RUNNING, 1927 TERMINATED)


== Status ==
Current time: 2023-11-03 15:22:43 (running for 16:51:41.19)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1962/1000000 (32 RUNNING, 1930 TERMINATED)


2023-11-03 15:24:08,999	WARNING util.py:214 -- The `start_trial` operation took 0.501 s, which may be a performance bottleneck.
2023-11-03 15:24:09,774	WARNING util.py:214 -- The `on_step_end` operation took 0.775 s, which may be a performance bottleneck.
2023-11-03 15:25:35,376	WARNING util.py:214 -- The `on_step_end` operation took 0.873 s, which may be a performance bottleneck.
[2m[36m(train pid=1993123)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1993123)[0m 
2023-11-03 15:25:48,087	WARNING util.py:214 -- The `on_step_end` operation took 1.007 s, which may be a performance bottleneck.
2023-11-03 15:27:02,533	WARNING util.py:214 -- The `on_step_end` operation took 0.733 s, which may be a performance bottleneck.
[2m[36m(train pid=1995414)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1995414)[0m 
2023-11-03 15:27:07,903	WARNING util.py:214 -- The `start_trial` operation took 0.687 s, which may be a performance bottleneck.
2023-11-03 15:27:08,794	WARNING util.py:214 -- The `on_step_end` operation took 0.891 s, which may be a performance bottleneck.
2023-11-03 15:27:15,391	WARNING util.py:214 -- The `on_step_end` operation took 1.335 s, which may be a performance bottleneck.
[2m[36m(train pid=1998152)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=1998152)[0m 
2023-11-03 15:28:48,505	WARNING util.py:214 -- The `on_step_end` operation took 1.065 s, which may be a performance bottleneck.
2023-11-03 15:28:55,063	WARNING util.py:214 -- The `on_step_end` operation took 1.372 s, which may be a performance bottleneck.
2023-11-03 15:29:01,791	WARNING util.py:214 -- The `on_step_end` operation took 1.284 s, which may be a performance bottleneck.
2023-11-03 15:30:43,490	WARNING util.py:214 -- The `on_step_end` operation took 1.088 s, which may be a performance bottleneck.
[2m[36m(train pid=2001042)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2001042)[0m 
[2m[36m(train pid=2001047)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2001047)[0m 
2023-11-03 15:30:57,805	WARNING util.py:214 -- The `on_step_end` operation took 1.321 s, which may be a performance bottleneck.
2023-11-03 15:32:34,192	WARNING util.py:214 -- The `on_step_end` operation took 0.992 s, which may be a performance bottleneck.
[2m[36m(train pid=2003594)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2003594)[0m 
2023-11-03 15:32:41,602	WARNING util.py:214 -- The `on_step_end` operation took 1.259 s, which may be a performance bottleneck.
[2m[36m(train pid=2006634)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2006634)[0m 
2023-11-03 15:34:36,227	WARNING util.py:214 -- The `on_step_end` operation took 1.092 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 15:24:03 (running for 16:53:01.40)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1962/1000000 (32 RUNNING, 1930 TERMINATED)


== Status ==
Current time: 2023-11-03 15:24:09 (running for 16:53:07.37)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1966/1000000 (32 RUNNING, 1934 TERMINATED)


== Status ==
Current time: 2023-11-03 15:25:35 (running for 16:54:32.97)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1966/1000000 (32 RUNNING, 1934 TERMINATED)


== Status ==
Current time: 2023-11-03 15:25:48 (running for 16:54:45.68)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1970/1000000 (1 PENDING, 31 RUNNING, 1938 TERMINATED)


== Status ==
Current time: 2023-11-03 15:27:02 (running for 16:56:00.13)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1970/1000000 (1 PENDING, 31 RUNNING, 1938 TERMINATED)


== Status ==
Current time: 2023-11-03 15:27:08 (running for 16:56:06.39)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1973/1000000 (31 RUNNING, 1942 TERMINATED)


== Status ==
Current time: 2023-11-03 15:27:15 (running for 16:56:12.99)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1977/1000000 (1 PENDING, 30 RUNNING, 1946 TERMINATED)


== Status ==
Current time: 2023-11-03 15:28:48 (running for 16:57:46.22)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1977/1000000 (31 RUNNING, 1946 TERMINATED)


== Status ==
Current time: 2023-11-03 15:28:55 (running for 16:57:52.66)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1981/1000000 (1 PENDING, 31 RUNNING, 1949 TERMINATED)


== Status ==
Current time: 2023-11-03 15:29:01 (running for 16:57:59.39)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1984/1000000 (32 RUNNING, 1952 TERMINATED)


== Status ==
Current time: 2023-11-03 15:30:43 (running for 16:59:41.09)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1984/1000000 (32 RUNNING, 1952 TERMINATED)


== Status ==
Current time: 2023-11-03 15:30:57 (running for 16:59:55.40)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1987/1000000 (1 PENDING, 31 RUNNING, 1955 TERMINATED)


== Status ==
Current time: 2023-11-03 15:32:34 (running for 17:01:31.90)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1987/1000000 (1 PENDING, 31 RUNNING, 1955 TERMINATED)


== Status ==
Current time: 2023-11-03 15:32:41 (running for 17:01:39.25)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1991/1000000 (32 RUNNING, 1959 TERMINATED)


2023-11-03 15:34:43,358	WARNING util.py:214 -- The `on_step_end` operation took 1.367 s, which may be a performance bottleneck.
2023-11-03 15:36:22,461	WARNING util.py:214 -- The `on_step_end` operation took 0.809 s, which may be a performance bottleneck.
[2m[36m(train pid=2010984)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2010984)[0m 
2023-11-03 15:36:29,240	WARNING util.py:214 -- The `on_step_end` operation took 1.189 s, which may be a performance bottleneck.
[2m[36m(train pid=2015953)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2015953)[0m 
2023-11-03 15:37:54,113	WARNING util.py:214 -- The `on_step_end` operation took 0.831 s, which may be a performance bottleneck.
2023-11-03 15:38:00,465	WARNING util.py:214 -- The `on_step_end` operation took 1.062 s, which may be a performance bottleneck.
2023-11-03 15:39:15,548	WARNING util.py:214 -- The `on_step_end` operation took 0.675 s, which may be a performance bottleneck.
[2m[36m(train pid=2020211)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2020211)[0m 
[2m[36m(train pid=2023685)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2023685)[0m 
2023-11-03 15:40:20,406	WARNING util.py:214 -- The `on_step_end` operation took 0.694 s, which may be a performance bottleneck.
2023-11-03 15:41:07,600	WARNING util.py:214 -- The `on_step_end` operation took 0.528 s, which may be a performance bottleneck.
[2m[36m(train pid=2026655)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2026655)[0m 
2023-11-03 15:41:13,435	WARNING util.py:214 -- The `on_step_end` operation took 0.835 s, which may be a performance bottleneck.
[2m[36m(train pid=2028134)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2028134)[0m 
2023-11-03 15:42:23,421	WARNING util.py:214 -- The `on_step_end` operation took 0.723 s, which may be a performance bottleneck.
2023-11-03 15:42:29,449	WARNING util.py:214 -- The `on_step_end` operation took 0.910 s, which may be a performance bottleneck.
2023-11-03 15:42:35,960	WARNING util.py:214 -- The `on_step_end` operation took 1.223 s, which may be a performance bottleneck.
[2m[36m(train pid=2030731)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2030731)[0m 
2023-11-03 15:44:15,036	WARNING util.py:214 -- The `on_step_end` operation took 1.228 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 15:34:36 (running for 17:03:33.84)
Memory usage on this node: 25.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1991/1000000 (32 RUNNING, 1959 TERMINATED)


== Status ==
Current time: 2023-11-03 15:34:43 (running for 17:03:40.96)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1994/1000000 (32 RUNNING, 1962 TERMINATED)


== Status ==
Current time: 2023-11-03 15:36:22 (running for 17:05:20.11)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1994/1000000 (32 RUNNING, 1962 TERMINATED)


== Status ==
Current time: 2023-11-03 15:36:29 (running for 17:05:26.90)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1998/1000000 (1 PENDING, 31 RUNNING, 1966 TERMINATED)


== Status ==
Current time: 2023-11-03 15:37:54 (running for 17:06:51.71)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 1998/1000000 (1 PENDING, 31 RUNNING, 1966 TERMINATED)


== Status ==
Current time: 2023-11-03 15:38:00 (running for 17:06:58.06)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2002/1000000 (1 PENDING, 31 RUNNING, 1970 TERMINATED)


== Status ==
Current time: 2023-11-03 15:39:15 (running for 17:08:13.22)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2002/1000000 (32 RUNNING, 1970 TERMINATED)


== Status ==
Current time: 2023-11-03 15:40:14 (running for 17:09:12.30)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2002/1000000 (32 RUNNING, 1970 TERMINATED)


== Status ==
Current time: 2023-11-03 15:40:20 (running for 17:09:18.00)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2008/1000000 (1 PENDING, 31 RUNNING, 1976 TERMINATED)


== Status ==
Current time: 2023-11-03 15:41:07 (running for 17:10:05.27)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2008/1000000 (1 PENDING, 31 RUNNING, 1976 TERMINATED)


== Status ==
Current time: 2023-11-03 15:41:13 (running for 17:10:11.06)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2014/1000000 (1 PENDING, 31 RUNNING, 1982 TERMINATED)


== Status ==
Current time: 2023-11-03 15:42:23 (running for 17:11:21.02)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2014/1000000 (1 PENDING, 31 RUNNING, 1982 TERMINATED)


== Status ==
Current time: 2023-11-03 15:42:29 (running for 17:11:27.06)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2019/1000000 (31 RUNNING, 1988 TERMINATED)


== Status ==
Current time: 2023-11-03 15:42:35 (running for 17:11:33.56)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2023/1000000 (31 RUNNING, 1992 TERMINATED)


2023-11-03 15:44:21,287	WARNING util.py:214 -- The `on_step_end` operation took 1.260 s, which may be a performance bottleneck.
2023-11-03 15:45:48,303	WARNING util.py:214 -- The `on_step_end` operation took 0.950 s, which may be a performance bottleneck.
[2m[36m(train pid=2034241)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2034241)[0m 
[2m[36m(train pid=2037623)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2037623)[0m 
2023-11-03 15:47:10,612	WARNING util.py:214 -- The `on_step_end` operation took 0.948 s, which may be a performance bottleneck.
2023-11-03 15:47:16,946	WARNING util.py:214 -- The `on_step_end` operation took 0.989 s, which may be a performance bottleneck.
2023-11-03 15:48:21,926	WARNING util.py:214 -- The `on_step_end` operation took 0.696 s, which may be a performance bottleneck.
[2m[36m(train pid=2041615)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2041615)[0m 
2023-11-03 15:48:28,198	WARNING util.py:214 -- The `on_step_end` operation took 1.054 s, which may be a performance bottleneck.
[2m[36m(train pid=2044740)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2044740)[0m 
[2m[36m(train pid=2044889)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2044889)[0m 
[2m[36m(train pid=2044893)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2044893)[0m 
2023-11-03 15:49:31,961	WARNING util.py:214 -- The `on_step_end` operation took 0.567 s, which may be a performance bottleneck.
2023-11-03 15:49:37,747	WARNING util.py:214 -- The `on_step_end` operation took 0.779 s, which may be a performance bottleneck.
2023-11-03 15:50:47,196	WARNING util.py:214 -- The `on_step_end` operation took 0.801 s, which may be a performance bottleneck.
[2m[36m(train pid=2047415)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2047415)[0m 
2023-11-03 15:50:53,656	WARNING util.py:214 -- The `on_step_end` operation took 0.986 s, which may be a performance bottleneck.
[2m[36m(train pid=2049593)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2049593)[0m 
2023-11-03 15:52:20,961	WARNING util.py:214 -- The `on_step_end` operation took 0.805 s, which may be a performance bottleneck.
2023-11-03 15:52:27,326	WARNING util.py:214 -- The `on_step_end` operation took 1.169 s, which may be a performance bottleneck.
2023-11-03 15:52:34,243	WARNING util.py:214 -- The `on_step_end` operation took 1.315 s, which may be a performance bottleneck.
[2m[36m(train pid=2052191)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2052191)[0m 
2023-11-03 15:54:14,700	WARNING util.py:214 -- The `on_step_end` operation took 1.080 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 15:44:15 (running for 17:13:12.63)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2024/1000000 (1 PENDING, 30 RUNNING, 1993 TERMINATED)


== Status ==
Current time: 2023-11-03 15:44:21 (running for 17:13:18.88)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2027/1000000 (31 RUNNING, 1996 TERMINATED)


== Status ==
Current time: 2023-11-03 15:45:48 (running for 17:14:45.93)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2028/1000000 (32 RUNNING, 1996 TERMINATED)


== Status ==
Current time: 2023-11-03 15:47:10 (running for 17:16:08.21)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2028/1000000 (32 RUNNING, 1996 TERMINATED)


== Status ==
Current time: 2023-11-03 15:47:16 (running for 17:16:14.54)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2032/1000000 (1 PENDING, 31 RUNNING, 2000 TERMINATED)


== Status ==
Current time: 2023-11-03 15:48:21 (running for 17:17:19.58)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2032/1000000 (1 PENDING, 31 RUNNING, 2000 TERMINATED)


== Status ==
Current time: 2023-11-03 15:48:28 (running for 17:17:25.79)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2036/1000000 (1 PENDING, 31 RUNNING, 2004 TERMINATED)


== Status ==
Current time: 2023-11-03 15:49:31 (running for 17:18:29.58)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2036/1000000 (1 PENDING, 31 RUNNING, 2004 TERMINATED)


== Status ==
Current time: 2023-11-03 15:49:37 (running for 17:18:35.44)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2041/1000000 (32 RUNNING, 2009 TERMINATED)


== Status ==
Current time: 2023-11-03 15:50:47 (running for 17:19:44.83)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2041/1000000 (32 RUNNING, 2009 TERMINATED)


== Status ==
Current time: 2023-11-03 15:50:53 (running for 17:19:51.25)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2046/1000000 (1 PENDING, 31 RUNNING, 2014 TERMINATED)


== Status ==
Current time: 2023-11-03 15:52:20 (running for 17:21:18.56)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2046/1000000 (1 PENDING, 31 RUNNING, 2014 TERMINATED)


== Status ==
Current time: 2023-11-03 15:52:27 (running for 17:21:24.98)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2050/1000000 (1 PENDING, 30 RUNNING, 2019 TERMINATED)


== Status ==
Current time: 2023-11-03 15:52:34 (running for 17:21:31.84)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2054/1000000 (1 PENDING, 30 RUNNING, 2023 TERMINATED)


2023-11-03 15:54:21,908	WARNING util.py:214 -- The `on_step_end` operation took 1.281 s, which may be a performance bottleneck.
2023-11-03 15:55:51,119	WARNING util.py:214 -- The `on_step_end` operation took 0.999 s, which may be a performance bottleneck.
[2m[36m(train pid=2054771)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2054771)[0m 
[2m[36m(train pid=2054764)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2054764)[0m 
2023-11-03 15:55:54,314	WARNING util.py:214 -- The `start_trial` operation took 0.731 s, which may be a performance bottleneck.
2023-11-03 15:55:57,810	WARNING util.py:214 -- The `on_step_end` operation took 1.354 s, which may be a performance bottleneck.
[2m[36m(train pid=2056987)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2056987)[0m 
2023-11-03 15:57:43,918	WARNING util.py:214 -- The `on_step_end` operation took 1.336 s, which may be a performance bottleneck.
2023-11-03 15:57:47,596	WARNING util.py:214 -- The `start_trial` operation took 0.786 s, which may be a performance bottleneck.
2023-11-03 15:57:50,447	WARNING util.py:214 -- The `on_step_end` operation took 1.204 s, which may be a performance bottleneck.
2023-11-03 15:59:27,199	WARNING util.py:214 -- The `on_step_end` operation took 1.016 s, which may be a performance bottleneck.
[2m[36m(train pid=2060999)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2060999)[0m 
2023-11-03 15:59:33,653	WARNING util.py:214 -- The `on_step_end` operation took 1.395 s, which may be a performance bottleneck.
[2m[36m(train pid=2066315)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2066315)[0m 
2023-11-03 16:00:59,686	WARNING util.py:214 -- The `on_step_end` operation took 0.842 s, which may be a performance bottleneck.
2023-11-03 16:01:05,662	WARNING util.py:214 -- The `on_step_end` operation took 0.866 s, which may be a performance bottleneck.
2023-11-03 16:02:17,021	WARNING util.py:214 -- The `on_step_end` operation took 0.791 s, which may be a performance bottleneck.
[2m[36m(train pid=2070580)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2070580)[0m 
[2m[36m(train pid=2070575)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2070575)[0m 
2023-11-03 16:02:23,671	WARNING util.py:214 -- The `on_step_end` operation took 0.963 s, which may be a performance bottleneck.
2023-11-03 16:02:30,387	WARNING util.py:214 -- The `on_step_end` operation took 1.467 s, which may be a performance bottleneck.
2023-11-03 16:02:36,696	WARNING util.py:214 -- The `on_step_end` operation took 1.161 s, which may be a performance bottleneck.
[2m[36m(train pid=2073750)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2073750)[0m 
2023-11-03 16:04:24,704	WARNING util.py:214 -- The `on_step_end` operation took 1.311 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 15:54:14 (running for 17:23:12.30)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2054/1000000 (31 RUNNING, 2023 TERMINATED)


== Status ==
Current time: 2023-11-03 15:54:21 (running for 17:23:19.51)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2058/1000000 (1 PENDING, 31 RUNNING, 2026 TERMINATED)


== Status ==
Current time: 2023-11-03 15:55:51 (running for 17:24:48.79)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2058/1000000 (1 PENDING, 30 RUNNING, 2027 TERMINATED)


== Status ==
Current time: 2023-11-03 15:55:57 (running for 17:24:55.49)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2061/1000000 (1 PENDING, 30 RUNNING, 2030 TERMINATED)


== Status ==
Current time: 2023-11-03 15:57:43 (running for 17:26:41.52)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2061/1000000 (31 RUNNING, 2030 TERMINATED)


== Status ==
Current time: 2023-11-03 15:57:50 (running for 17:26:48.13)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2064/1000000 (31 RUNNING, 2033 TERMINATED)


== Status ==
Current time: 2023-11-03 15:59:27 (running for 17:28:24.94)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2065/1000000 (1 PENDING, 30 RUNNING, 2034 TERMINATED)


== Status ==
Current time: 2023-11-03 15:59:33 (running for 17:28:31.34)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2068/1000000 (31 RUNNING, 2037 TERMINATED)


== Status ==
Current time: 2023-11-03 16:00:59 (running for 17:29:57.28)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2069/1000000 (1 PENDING, 30 RUNNING, 2038 TERMINATED)


== Status ==
Current time: 2023-11-03 16:01:05 (running for 17:30:03.26)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2073/1000000 (32 RUNNING, 2041 TERMINATED)


== Status ==
Current time: 2023-11-03 16:02:17 (running for 17:31:14.66)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2073/1000000 (32 RUNNING, 2041 TERMINATED)


== Status ==
Current time: 2023-11-03 16:02:23 (running for 17:31:21.33)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2078/1000000 (1 PENDING, 31 RUNNING, 2046 TERMINATED)


== Status ==
Current time: 2023-11-03 16:02:30 (running for 17:31:27.98)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2082/1000000 (1 PENDING, 31 RUNNING, 2050 TERMINATED)


== Status ==
Current time: 2023-11-03 16:02:36 (running for 17:31:34.36)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2085/1000000 (32 RUNNING, 2053 TERMINATED)


2023-11-03 16:04:30,871	WARNING util.py:214 -- The `on_step_end` operation took 1.159 s, which may be a performance bottleneck.
2023-11-03 16:04:37,902	WARNING util.py:214 -- The `on_step_end` operation took 1.368 s, which may be a performance bottleneck.
2023-11-03 16:06:27,761	WARNING util.py:214 -- The `on_step_end` operation took 1.039 s, which may be a performance bottleneck.
[2m[36m(train pid=2076730)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2076730)[0m 
2023-11-03 16:06:34,589	WARNING util.py:214 -- The `on_step_end` operation took 1.372 s, which may be a performance bottleneck.
[2m[36m(train pid=2080980)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2080980)[0m 
[2m[36m(train pid=2081265)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2081265)[0m 
2023-11-03 16:08:21,108	WARNING util.py:214 -- The `on_step_end` operation took 1.361 s, which may be a performance bottleneck.
2023-11-03 16:08:22,520	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.649 s, which may be a performance bottleneck.
2023-11-03 16:08:22,520	WARNING util.py:214 -- The `process_trial_result` operation took 0.649 s, which may be a performance bottleneck.
2023-11-03 16:08:22,520	WARNING util.py:214 -- Processing trial results took 0.649 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 16:08:22,520	WARNING util.py:214 -- The `process_trial_result` operation took 0.649 s, which may be a performance bottleneck.
2023-11-03 16:08:27,802	WARNING util.py:214 -- The `on_step_end` operation took 1.307 s, which may be a performance bottleneck.
2023-11-03 16:08:32,836	WARNING util.py:214 -- The `start_trial` operation took 1.583 s, which may be a performance bottleneck.
2023-11-03 16:08:33,887	WARNING util.py:214 -- The `on_step_end` operation took 1.050 s, which may be a performance bottleneck.
2023-11-03 16:10:10,470	WARNING util.py:214 -- The `on_step_end` operation took 0.827 s, which may be a performance bottleneck.
[2m[36m(train pid=2086780)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2086780)[0m 
2023-11-03 16:10:16,386	WARNING util.py:214 -- The `on_step_end` operation took 0.860 s, which may be a performance bottleneck.
[2m[36m(train pid=2091800)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2091800)[0m 
2023-11-03 16:11:28,572	WARNING util.py:214 -- The `on_step_end` operation took 0.697 s, which may be a performance bottleneck.
2023-11-03 16:11:32,192	WARNING util.py:214 -- The `start_trial` operation took 0.552 s, which may be a performance bottleneck.
2023-11-03 16:11:34,550	WARNING util.py:214 -- The `on_step_end` operation took 0.758 s, which may be a performance bottleneck.
2023-11-03 16:12:40,810	WARNING util.py:214 -- The `on_step_end` operation took 0.822 s, which may be a performance bottleneck.
[2m[36m(train pid=2095621)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2095621)[0m 
2023-11-03 16:12:42,547	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.611 s, which may be a performance bottleneck.
2023-11-03 16:12:42,547	WARNING util.py:214 -- The `process_trial_result` operation took 0.611 s, which may be a performance bottleneck.
2023-11-03 16:12:42,547	WARNING util.py:214 -- Processing trial results took 0.612 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 16:12:42,547	WARNING util.py:214 -- The `process_trial_result` operation took 0.612 s, which may be a performance bottleneck.
2023-11-03 16:12:47,163	WARNING util.py:214 -- The `on_step_end` operation took 0.947 s, which may be a performance bottleneck.
2023-11-03 16:12:53,961	WARNING util.py:214 -- The `on_step_end` operation took 1.086 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 16:04:24 (running for 17:33:22.37)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2085/1000000 (32 RUNNING, 2053 TERMINATED)


== Status ==
Current time: 2023-11-03 16:04:30 (running for 17:33:28.47)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2088/1000000 (1 PENDING, 31 RUNNING, 2056 TERMINATED)


== Status ==
Current time: 2023-11-03 16:04:38 (running for 17:33:35.61)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2091/1000000 (32 RUNNING, 2059 TERMINATED)


== Status ==
Current time: 2023-11-03 16:06:27 (running for 17:35:25.44)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2091/1000000 (32 RUNNING, 2059 TERMINATED)


== Status ==
Current time: 2023-11-03 16:06:34 (running for 17:35:32.21)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2094/1000000 (32 RUNNING, 2062 TERMINATED)


== Status ==
Current time: 2023-11-03 16:08:21 (running for 17:37:18.71)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2094/1000000 (32 RUNNING, 2062 TERMINATED)


== Status ==
Current time: 2023-11-03 16:08:27 (running for 17:37:25.50)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2097/1000000 (1 PENDING, 30 RUNNING, 2066 TERMINATED)


== Status ==
Current time: 2023-11-03 16:08:33 (running for 17:37:31.55)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2099/1000000 (32 RUNNING, 2067 TERMINATED)


== Status ==
Current time: 2023-11-03 16:10:10 (running for 17:39:08.07)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2099/1000000 (32 RUNNING, 2067 TERMINATED)


== Status ==
Current time: 2023-11-03 16:10:16 (running for 17:39:13.98)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2102/1000000 (1 PENDING, 31 RUNNING, 2070 TERMINATED)


== Status ==
Current time: 2023-11-03 16:11:28 (running for 17:40:26.22)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 23cfd02c with val_loss=478.8050513113247 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.09772634435791809, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2102/1000000 (1 PENDING, 31 RUNNING, 2070 TERMINATED)


== Status ==
Current time: 2023-11-03 16:11:34 (running for 17:40:32.23)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2106/1000000 (31 RUNNING, 2075 TERMINATED)


== Status ==
Current time: 2023-11-03 16:12:40 (running for 17:41:38.42)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2107/1000000 (1 PENDING, 31 RUNNING, 2075 TERMINATED)


== Status ==
Current time: 2023-11-03 16:12:47 (running for 17:41:44.83)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2112/1000000 (1 PENDING, 31 RUNNING, 2080 TERMINATED)


[2m[36m(train pid=2097774)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2097774)[0m 
2023-11-03 16:14:33,152	WARNING util.py:214 -- The `on_step_end` operation took 0.967 s, which may be a performance bottleneck.
2023-11-03 16:14:39,724	WARNING util.py:214 -- The `on_step_end` operation took 1.168 s, which may be a performance bottleneck.
2023-11-03 16:16:03,896	WARNING util.py:214 -- The `on_step_end` operation took 0.735 s, which may be a performance bottleneck.
[2m[36m(train pid=2100826)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2100826)[0m 
[2m[36m(train pid=2100694)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2100694)[0m 
2023-11-03 16:16:10,594	WARNING util.py:214 -- The `on_step_end` operation took 1.262 s, which may be a performance bottleneck.
2023-11-03 16:17:42,469	WARNING util.py:214 -- The `start_trial` operation took 0.568 s, which may be a performance bottleneck.
[2m[36m(train pid=2103033)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2103033)[0m 
2023-11-03 16:17:50,747	WARNING util.py:214 -- The `on_step_end` operation took 1.206 s, which may be a performance bottleneck.
2023-11-03 16:17:57,451	WARNING util.py:214 -- The `on_step_end` operation took 1.462 s, which may be a performance bottleneck.
2023-11-03 16:18:01,920	WARNING util.py:214 -- The `start_trial` operation took 0.662 s, which may be a performance bottleneck.
2023-11-03 16:18:03,548	WARNING util.py:214 -- The `start_trial` operation took 1.079 s, which may be a performance bottleneck.
2023-11-03 16:18:04,763	WARNING util.py:214 -- The `on_step_end` operation took 1.216 s, which may be a performance bottleneck.
2023-11-03 16:19:55,378	WARNING util.py:214 -- The `on_step_end` operation took 1.097 s, which may be a performance bottleneck.
[2m[36m(train pid=2106482)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2106482)[0m 
2023-11-03 16:20:02,300	WARNING util.py:214 -- The `on_step_end` operation took 1.342 s, which may be a performance bottleneck.
[2m[36m(train pid=2110071)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2110071)[0m 
[2m[36m(train pid=2110347)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2110347)[0m 
2023-11-03 16:21:34,070	WARNING util.py:214 -- The `on_step_end` operation took 1.240 s, which may be a performance bottleneck.
2023-11-03 16:21:41,348	WARNING util.py:214 -- The `on_step_end` operation took 1.188 s, which may be a performance bottleneck.
[2m[36m(train pid=2113002)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2113002)[0m 
2023-11-03 16:23:16,253	WARNING util.py:214 -- The `on_step_end` operation took 1.011 s, which may be a performance bottleneck.
[2m[36m(train pid=2113150)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2113150)[0m 
2023-11-03 16:23:23,539	WARNING util.py:214 -- The `on_step_end` operation took 1.403 s, which may be a performance bottleneck.
[2m[36m(train pid=2116889)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2116889)[0m 
2023-11-03 16:24:58,647	WARNING util.py:214 -- The `on_step_end` operation took 1.159 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 16:12:53 (running for 17:41:51.59)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2116/1000000 (32 RUNNING, 2084 TERMINATED)


== Status ==
Current time: 2023-11-03 16:14:33 (running for 17:43:30.85)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2116/1000000 (32 RUNNING, 2084 TERMINATED)


== Status ==
Current time: 2023-11-03 16:14:39 (running for 17:43:37.32)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2119/1000000 (32 RUNNING, 2087 TERMINATED)


== Status ==
Current time: 2023-11-03 16:16:03 (running for 17:45:01.57)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2119/1000000 (32 RUNNING, 2087 TERMINATED)


== Status ==
Current time: 2023-11-03 16:16:10 (running for 17:45:08.19)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2123/1000000 (1 PENDING, 30 RUNNING, 2092 TERMINATED)


== Status ==
Current time: 2023-11-03 16:17:50 (running for 17:46:48.43)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2123/1000000 (31 RUNNING, 2092 TERMINATED)


== Status ==
Current time: 2023-11-03 16:17:57 (running for 17:46:55.12)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2127/1000000 (1 PENDING, 31 RUNNING, 2095 TERMINATED)


== Status ==
Current time: 2023-11-03 16:18:04 (running for 17:47:02.45)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2130/1000000 (32 RUNNING, 2098 TERMINATED)


== Status ==
Current time: 2023-11-03 16:19:55 (running for 17:48:53.08)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2130/1000000 (32 RUNNING, 2098 TERMINATED)


== Status ==
Current time: 2023-11-03 16:20:02 (running for 17:48:59.90)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2133/1000000 (1 PENDING, 30 RUNNING, 2102 TERMINATED)


== Status ==
Current time: 2023-11-03 16:21:34 (running for 17:50:31.67)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2133/1000000 (31 RUNNING, 2102 TERMINATED)


== Status ==
Current time: 2023-11-03 16:21:41 (running for 17:50:38.96)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2137/1000000 (32 RUNNING, 2105 TERMINATED)


== Status ==
Current time: 2023-11-03 16:23:16 (running for 17:52:13.91)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2137/1000000 (32 RUNNING, 2105 TERMINATED)


== Status ==
Current time: 2023-11-03 16:23:23 (running for 17:52:21.15)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2141/1000000 (1 PENDING, 31 RUNNING, 2109 TERMINATED)


2023-11-03 16:25:02,075	WARNING util.py:214 -- The `start_trial` operation took 0.929 s, which may be a performance bottleneck.
2023-11-03 16:25:05,118	WARNING util.py:214 -- The `on_step_end` operation took 1.269 s, which may be a performance bottleneck.
2023-11-03 16:25:11,492	WARNING util.py:214 -- The `on_step_end` operation took 1.274 s, which may be a performance bottleneck.
2023-11-03 16:26:44,284	WARNING util.py:214 -- The `on_step_end` operation took 1.222 s, which may be a performance bottleneck.
[2m[36m(train pid=2121124)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2121124)[0m 
2023-11-03 16:26:51,522	WARNING util.py:214 -- The `on_step_end` operation took 1.358 s, which may be a performance bottleneck.
2023-11-03 16:26:54,365	WARNING util.py:214 -- The `start_trial` operation took 0.503 s, which may be a performance bottleneck.
2023-11-03 16:26:58,926	WARNING util.py:214 -- The `on_step_end` operation took 1.555 s, which may be a performance bottleneck.
[2m[36m(train pid=2123026)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2123026)[0m 
2023-11-03 16:28:57,365	WARNING util.py:214 -- The `on_step_end` operation took 1.460 s, which may be a performance bottleneck.
2023-11-03 16:29:02,163	WARNING util.py:214 -- The `start_trial` operation took 0.578 s, which may be a performance bottleneck.
2023-11-03 16:29:05,642	WARNING util.py:214 -- The `on_step_end` operation took 1.223 s, which may be a performance bottleneck.
2023-11-03 16:30:53,625	WARNING util.py:214 -- The `on_step_end` operation took 1.129 s, which may be a performance bottleneck.
[2m[36m(train pid=2126279)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2126279)[0m 
[2m[36m(train pid=2126254)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2126254)[0m 
2023-11-03 16:30:57,206	WARNING util.py:214 -- The `start_trial` operation took 0.744 s, which may be a performance bottleneck.
2023-11-03 16:31:00,940	WARNING util.py:214 -- The `on_step_end` operation took 1.608 s, which may be a performance bottleneck.
[2m[36m(train pid=2131104)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2131104)[0m 
2023-11-03 16:32:37,923	WARNING util.py:214 -- The `on_step_end` operation took 1.108 s, which may be a performance bottleneck.
2023-11-03 16:32:44,599	WARNING util.py:214 -- The `on_step_end` operation took 1.173 s, which may be a performance bottleneck.
2023-11-03 16:33:59,531	WARNING util.py:214 -- The `on_step_end` operation took 0.787 s, which may be a performance bottleneck.
[2m[36m(train pid=2135911)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2135911)[0m 
[2m[36m(train pid=2136076)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2136076)[0m 
[2m[36m(train pid=2139078)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2139078)[0m 
2023-11-03 16:35:08,667	WARNING util.py:214 -- The `on_step_end` operation took 0.960 s, which may be a performance bottleneck.
2023-11-03 16:35:12,886	WARNING util.py:214 -- The `start_trial` operation took 0.554 s, which may be a performance bottleneck.
2023-11-03 16:35:14,533	WARNING util.py:214 -- The `on_step_end` operation took 0.839 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 16:24:58 (running for 17:53:56.29)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2141/1000000 (1 PENDING, 31 RUNNING, 2109 TERMINATED)


== Status ==
Current time: 2023-11-03 16:25:05 (running for 17:54:02.72)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2144/1000000 (1 PENDING, 30 RUNNING, 2113 TERMINATED)


== Status ==
Current time: 2023-11-03 16:25:11 (running for 17:54:09.11)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2147/1000000 (31 RUNNING, 2116 TERMINATED)


== Status ==
Current time: 2023-11-03 16:26:44 (running for 17:55:41.94)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2148/1000000 (1 PENDING, 31 RUNNING, 2116 TERMINATED)


== Status ==
Current time: 2023-11-03 16:26:51 (running for 17:55:49.27)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2152/1000000 (1 PENDING, 30 RUNNING, 2121 TERMINATED)


== Status ==
Current time: 2023-11-03 16:26:58 (running for 17:55:56.52)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2155/1000000 (1 PENDING, 31 RUNNING, 2123 TERMINATED)


== Status ==
Current time: 2023-11-03 16:28:57 (running for 17:57:55.09)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2155/1000000 (1 PENDING, 31 RUNNING, 2123 TERMINATED)


== Status ==
Current time: 2023-11-03 16:29:05 (running for 17:58:03.24)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2158/1000000 (32 RUNNING, 2126 TERMINATED)


== Status ==
Current time: 2023-11-03 16:30:53 (running for 17:59:51.22)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2158/1000000 (32 RUNNING, 2126 TERMINATED)


== Status ==
Current time: 2023-11-03 16:31:00 (running for 17:59:58.54)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2161/1000000 (1 PENDING, 31 RUNNING, 2129 TERMINATED)


== Status ==
Current time: 2023-11-03 16:32:37 (running for 18:01:35.52)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2161/1000000 (1 PENDING, 31 RUNNING, 2129 TERMINATED)


== Status ==
Current time: 2023-11-03 16:32:44 (running for 18:01:42.20)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2165/1000000 (1 PENDING, 31 RUNNING, 2133 TERMINATED)


== Status ==
Current time: 2023-11-03 16:33:59 (running for 18:02:57.13)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2165/1000000 (32 RUNNING, 2133 TERMINATED)


== Status ==
Current time: 2023-11-03 16:35:08 (running for 18:04:06.28)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2165/1000000 (32 RUNNING, 2133 TERMINATED)


2023-11-03 16:36:14,718	WARNING util.py:214 -- The `on_step_end` operation took 0.727 s, which may be a performance bottleneck.
[2m[36m(train pid=2141837)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2141837)[0m 
2023-11-03 16:36:21,019	WARNING util.py:214 -- The `on_step_end` operation took 1.132 s, which may be a performance bottleneck.
2023-11-03 16:36:23,382	WARNING util.py:214 -- The `start_trial` operation took 0.743 s, which may be a performance bottleneck.
2023-11-03 16:36:27,627	WARNING util.py:214 -- The `on_step_end` operation took 1.249 s, which may be a performance bottleneck.
2023-11-03 16:36:42,792	WARNING util.py:214 -- The `on_step_end` operation took 1.297 s, which may be a performance bottleneck.
2023-11-03 16:38:07,953	WARNING util.py:214 -- The `on_step_end` operation took 1.114 s, which may be a performance bottleneck.
[2m[36m(train pid=2144171)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2144171)[0m 
[2m[36m(train pid=2144007)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2144007)[0m 
2023-11-03 16:38:11,556	WARNING util.py:214 -- The `start_trial` operation took 0.577 s, which may be a performance bottleneck.
2023-11-03 16:38:14,326	WARNING util.py:214 -- The `on_step_end` operation took 1.160 s, which may be a performance bottleneck.
[2m[36m(train pid=2146369)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2146369)[0m 
2023-11-03 16:40:01,345	WARNING util.py:214 -- The `on_step_end` operation took 1.315 s, which may be a performance bottleneck.
2023-11-03 16:40:02,881	WARNING util.py:214 -- The `start_trial` operation took 0.660 s, which may be a performance bottleneck.
2023-11-03 16:40:08,146	WARNING util.py:214 -- The `on_step_end` operation took 1.424 s, which may be a performance bottleneck.
2023-11-03 16:41:48,642	WARNING util.py:214 -- The `on_step_end` operation took 1.054 s, which may be a performance bottleneck.
[2m[36m(train pid=2150142)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2150142)[0m 
2023-11-03 16:41:54,980	WARNING util.py:214 -- The `on_step_end` operation took 1.285 s, which may be a performance bottleneck.
[2m[36m(train pid=2154693)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2154693)[0m 
2023-11-03 16:43:28,798	WARNING util.py:214 -- The `on_step_end` operation took 0.822 s, which may be a performance bottleneck.
2023-11-03 16:43:33,091	WARNING util.py:214 -- The `start_trial` operation took 0.626 s, which may be a performance bottleneck.
2023-11-03 16:43:34,691	WARNING util.py:214 -- The `on_step_end` operation took 0.761 s, which may be a performance bottleneck.
2023-11-03 16:44:35,974	WARNING util.py:214 -- The `on_step_end` operation took 0.518 s, which may be a performance bottleneck.
[2m[36m(train pid=2160462)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2160462)[0m 
2023-11-03 16:44:41,728	WARNING util.py:214 -- The `on_step_end` operation took 0.640 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 16:35:14 (running for 18:04:12.13)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2169/1000000 (1 PENDING, 30 RUNNING, 2138 TERMINATED)


== Status ==
Current time: 2023-11-03 16:36:14 (running for 18:05:12.32)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2169/1000000 (31 RUNNING, 2138 TERMINATED)


== Status ==
Current time: 2023-11-03 16:36:21 (running for 18:05:18.66)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2174/1000000 (1 PENDING, 31 RUNNING, 2142 TERMINATED)


== Status ==
Current time: 2023-11-03 16:36:27 (running for 18:05:25.22)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2178/1000000 (1 PENDING, 30 RUNNING, 2147 TERMINATED)


== Status ==
Current time: 2023-11-03 16:36:42 (running for 18:05:40.39)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2181/1000000 (32 RUNNING, 2149 TERMINATED)


== Status ==
Current time: 2023-11-03 16:38:08 (running for 18:07:05.65)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2181/1000000 (32 RUNNING, 2149 TERMINATED)


== Status ==
Current time: 2023-11-03 16:38:14 (running for 18:07:11.92)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2184/1000000 (31 RUNNING, 2153 TERMINATED)


== Status ==
Current time: 2023-11-03 16:40:01 (running for 18:08:58.94)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2185/1000000 (1 PENDING, 31 RUNNING, 2153 TERMINATED)


== Status ==
Current time: 2023-11-03 16:40:08 (running for 18:09:05.74)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2188/1000000 (32 RUNNING, 2156 TERMINATED)


== Status ==
Current time: 2023-11-03 16:41:48 (running for 18:10:46.30)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2188/1000000 (32 RUNNING, 2156 TERMINATED)


== Status ==
Current time: 2023-11-03 16:41:55 (running for 18:10:52.67)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2191/1000000 (32 RUNNING, 2159 TERMINATED)


== Status ==
Current time: 2023-11-03 16:43:28 (running for 18:12:26.40)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2191/1000000 (32 RUNNING, 2159 TERMINATED)


== Status ==
Current time: 2023-11-03 16:43:34 (running for 18:12:32.38)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2194/1000000 (32 RUNNING, 2162 TERMINATED)


== Status ==
Current time: 2023-11-03 16:44:36 (running for 18:13:33.67)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2194/1000000 (32 RUNNING, 2162 TERMINATED)


2023-11-03 16:44:47,962	WARNING util.py:214 -- The `on_step_end` operation took 1.108 s, which may be a performance bottleneck.
[2m[36m(train pid=2165033)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2165033)[0m 
2023-11-03 16:46:09,251	WARNING util.py:214 -- The `on_step_end` operation took 1.007 s, which may be a performance bottleneck.
2023-11-03 16:46:15,155	WARNING util.py:214 -- The `on_step_end` operation took 0.814 s, which may be a performance bottleneck.
2023-11-03 16:46:21,469	WARNING util.py:214 -- The `on_step_end` operation took 1.017 s, which may be a performance bottleneck.
2023-11-03 16:47:48,131	WARNING util.py:214 -- The `on_step_end` operation took 1.136 s, which may be a performance bottleneck.
[2m[36m(train pid=2167451)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2167451)[0m 
2023-11-03 16:47:54,788	WARNING util.py:214 -- The `on_step_end` operation took 1.215 s, which may be a performance bottleneck.
[2m[36m(train pid=2170723)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2170723)[0m 
2023-11-03 16:49:33,284	WARNING util.py:214 -- The `on_step_end` operation took 1.217 s, which may be a performance bottleneck.
2023-11-03 16:49:40,704	WARNING util.py:214 -- The `on_step_end` operation took 1.397 s, which may be a performance bottleneck.
2023-11-03 16:51:06,206	WARNING util.py:214 -- The `on_step_end` operation took 0.823 s, which may be a performance bottleneck.
[2m[36m(train pid=2175441)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2175441)[0m 
2023-11-03 16:51:12,846	WARNING util.py:214 -- The `on_step_end` operation took 1.175 s, which may be a performance bottleneck.
[2m[36m(train pid=2181607)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2181607)[0m 
[2m[36m(train pid=2181620)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2181620)[0m 
2023-11-03 16:52:13,619	WARNING util.py:214 -- The `on_step_end` operation took 0.660 s, which may be a performance bottleneck.
2023-11-03 16:52:19,603	WARNING util.py:214 -- The `on_step_end` operation took 0.971 s, which may be a performance bottleneck.
2023-11-03 16:52:21,191	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 1.098 s, which may be a performance bottleneck.
2023-11-03 16:52:21,191	WARNING util.py:214 -- The `process_trial_result` operation took 1.099 s, which may be a performance bottleneck.
2023-11-03 16:52:21,192	WARNING util.py:214 -- Processing trial results took 1.099 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 16:52:21,192	WARNING util.py:214 -- The `process_trial_result` operation took 1.099 s, which may be a performance bottleneck.
2023-11-03 16:52:25,821	WARNING util.py:214 -- The `on_step_end` operation took 1.178 s, which may be a performance bottleneck.
2023-11-03 16:52:32,413	WARNING util.py:214 -- The `on_step_end` operation took 1.276 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 16:44:41 (running for 18:13:39.38)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2199/1000000 (31 RUNNING, 2168 TERMINATED)


== Status ==
Current time: 2023-11-03 16:44:47 (running for 18:13:45.56)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2204/1000000 (32 RUNNING, 2172 TERMINATED)


== Status ==
Current time: 2023-11-03 16:46:09 (running for 18:15:06.85)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2204/1000000 (32 RUNNING, 2172 TERMINATED)


== Status ==
Current time: 2023-11-03 16:46:15 (running for 18:15:12.81)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2208/1000000 (31 RUNNING, 2177 TERMINATED)


== Status ==
Current time: 2023-11-03 16:46:21 (running for 18:15:19.10)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2212/1000000 (31 RUNNING, 2181 TERMINATED)


== Status ==
Current time: 2023-11-03 16:47:48 (running for 18:16:45.82)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2213/1000000 (1 PENDING, 30 RUNNING, 2182 TERMINATED)


== Status ==
Current time: 2023-11-03 16:47:54 (running for 18:16:52.49)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2217/1000000 (32 RUNNING, 2185 TERMINATED)


== Status ==
Current time: 2023-11-03 16:49:33 (running for 18:18:30.91)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2217/1000000 (31 RUNNING, 2186 TERMINATED)


== Status ==
Current time: 2023-11-03 16:49:40 (running for 18:18:38.30)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2221/1000000 (32 RUNNING, 2189 TERMINATED)


== Status ==
Current time: 2023-11-03 16:51:06 (running for 18:20:03.80)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2221/1000000 (32 RUNNING, 2189 TERMINATED)


== Status ==
Current time: 2023-11-03 16:51:12 (running for 18:20:10.48)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2225/1000000 (1 PENDING, 31 RUNNING, 2193 TERMINATED)


== Status ==
Current time: 2023-11-03 16:52:13 (running for 18:21:11.22)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2225/1000000 (1 PENDING, 30 RUNNING, 2194 TERMINATED)


== Status ==
Current time: 2023-11-03 16:52:19 (running for 18:21:17.20)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2231/1000000 (1 PENDING, 31 RUNNING, 2199 TERMINATED)


== Status ==
Current time: 2023-11-03 16:52:25 (running for 18:21:23.50)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2234/1000000 (1 PENDING, 30 RUNNING, 2203 TERMINATED)


[2m[36m(train pid=2186149)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2186149)[0m 
2023-11-03 16:54:03,317	WARNING util.py:214 -- The `on_step_end` operation took 1.118 s, which may be a performance bottleneck.
2023-11-03 16:55:07,970	WARNING util.py:214 -- The `on_step_end` operation took 0.771 s, which may be a performance bottleneck.
[2m[36m(train pid=2188572)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2188572)[0m 
2023-11-03 16:55:14,370	WARNING util.py:214 -- The `on_step_end` operation took 0.837 s, which may be a performance bottleneck.
[2m[36m(train pid=2192417)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2192417)[0m 
[2m[36m(train pid=2192431)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2192431)[0m 
2023-11-03 16:56:28,172	WARNING util.py:214 -- The `on_step_end` operation took 0.822 s, which may be a performance bottleneck.
2023-11-03 16:56:34,678	WARNING util.py:214 -- The `on_step_end` operation took 1.295 s, which may be a performance bottleneck.
[2m[36m(train pid=2196818)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2196818)[0m 
2023-11-03 16:57:34,485	WARNING util.py:214 -- The `start_trial` operation took 0.565 s, which may be a performance bottleneck.
2023-11-03 16:57:36,255	WARNING util.py:214 -- The `start_trial` operation took 1.472 s, which may be a performance bottleneck.
2023-11-03 16:57:38,571	WARNING util.py:214 -- The `on_step_end` operation took 0.715 s, which may be a performance bottleneck.
[2m[36m(train pid=2200734)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2200734)[0m 
2023-11-03 16:58:27,682	WARNING util.py:214 -- The `on_step_end` operation took 0.554 s, which may be a performance bottleneck.
2023-11-03 16:58:33,545	WARNING util.py:214 -- The `on_step_end` operation took 0.861 s, which may be a performance bottleneck.
2023-11-03 16:59:23,115	WARNING util.py:214 -- The `on_step_end` operation took 0.599 s, which may be a performance bottleneck.
[2m[36m(train pid=2203556)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2203556)[0m 
2023-11-03 16:59:29,431	WARNING util.py:214 -- The `on_step_end` operation took 0.985 s, which may be a performance bottleneck.
[2m[36m(train pid=2206849)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2206849)[0m 
2023-11-03 17:00:28,136	WARNING util.py:214 -- The `on_step_end` operation took 0.701 s, which may be a performance bottleneck.
2023-11-03 17:00:34,180	WARNING util.py:214 -- The `on_step_end` operation took 0.979 s, which may be a performance bottleneck.
2023-11-03 17:00:40,458	WARNING util.py:214 -- The `on_step_end` operation took 1.225 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 16:52:32 (running for 18:21:30.02)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2238/1000000 (1 PENDING, 31 RUNNING, 2206 TERMINATED)


== Status ==
Current time: 2023-11-03 16:54:03 (running for 18:23:00.91)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2238/1000000 (32 RUNNING, 2206 TERMINATED)


== Status ==
Current time: 2023-11-03 16:55:07 (running for 18:24:05.57)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2238/1000000 (32 RUNNING, 2206 TERMINATED)


== Status ==
Current time: 2023-11-03 16:55:14 (running for 18:24:11.97)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2243/1000000 (32 RUNNING, 2211 TERMINATED)


== Status ==
Current time: 2023-11-03 16:56:28 (running for 18:25:25.77)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2243/1000000 (32 RUNNING, 2211 TERMINATED)


== Status ==
Current time: 2023-11-03 16:56:34 (running for 18:25:32.28)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2247/1000000 (1 PENDING, 31 RUNNING, 2215 TERMINATED)


== Status ==
Current time: 2023-11-03 16:57:32 (running for 18:26:30.21)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2247/1000000 (1 PENDING, 31 RUNNING, 2215 TERMINATED)


== Status ==
Current time: 2023-11-03 16:57:38 (running for 18:26:36.17)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2251/1000000 (1 PENDING, 31 RUNNING, 2219 TERMINATED)


== Status ==
Current time: 2023-11-03 16:58:27 (running for 18:27:25.28)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2251/1000000 (1 PENDING, 31 RUNNING, 2219 TERMINATED)


== Status ==
Current time: 2023-11-03 16:58:33 (running for 18:27:31.19)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2256/1000000 (1 PENDING, 30 RUNNING, 2225 TERMINATED)


== Status ==
Current time: 2023-11-03 16:59:23 (running for 18:28:20.72)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2256/1000000 (31 RUNNING, 2225 TERMINATED)


== Status ==
Current time: 2023-11-03 16:59:29 (running for 18:28:27.03)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2262/1000000 (1 PENDING, 31 RUNNING, 2230 TERMINATED)


== Status ==
Current time: 2023-11-03 17:00:28 (running for 18:29:25.73)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2262/1000000 (1 PENDING, 31 RUNNING, 2230 TERMINATED)


== Status ==
Current time: 2023-11-03 17:00:34 (running for 18:29:31.83)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2267/1000000 (1 PENDING, 31 RUNNING, 2235 TERMINATED)


2023-11-03 17:00:46,767	WARNING util.py:214 -- The `on_step_end` operation took 1.197 s, which may be a performance bottleneck.
[2m[36m(train pid=2209413)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2209413)[0m 
2023-11-03 17:02:35,786	WARNING util.py:214 -- The `on_step_end` operation took 1.393 s, which may be a performance bottleneck.
2023-11-03 17:02:38,206	WARNING util.py:214 -- The `start_trial` operation took 0.603 s, which may be a performance bottleneck.
2023-11-03 17:02:42,194	WARNING util.py:214 -- The `on_step_end` operation took 1.368 s, which may be a performance bottleneck.
2023-11-03 17:04:19,683	WARNING util.py:214 -- The `on_step_end` operation took 1.154 s, which may be a performance bottleneck.
[2m[36m(train pid=2212265)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2212265)[0m 
2023-11-03 17:04:26,844	WARNING util.py:214 -- The `on_step_end` operation took 1.345 s, which may be a performance bottleneck.
[2m[36m(train pid=2216594)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2216594)[0m 
[2m[36m(train pid=2216735)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2216735)[0m 
2023-11-03 17:05:57,853	WARNING util.py:214 -- The `on_step_end` operation took 0.956 s, which may be a performance bottleneck.
2023-11-03 17:06:05,081	WARNING util.py:214 -- The `on_step_end` operation took 1.355 s, which may be a performance bottleneck.
2023-11-03 17:06:11,705	WARNING util.py:214 -- The `on_step_end` operation took 1.290 s, which may be a performance bottleneck.
2023-11-03 17:07:46,559	WARNING util.py:214 -- The `on_step_end` operation took 1.008 s, which may be a performance bottleneck.
[2m[36m(train pid=2222129)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2222129)[0m 
2023-11-03 17:07:54,135	WARNING util.py:214 -- The `on_step_end` operation took 0.750 s, which may be a performance bottleneck.
2023-11-03 17:07:57,800	WARNING util.py:214 -- The `start_trial` operation took 0.566 s, which may be a performance bottleneck.
2023-11-03 17:08:00,404	WARNING util.py:214 -- The `on_step_end` operation took 0.981 s, which may be a performance bottleneck.
2023-11-03 17:09:04,918	WARNING util.py:214 -- The `on_step_end` operation took 0.838 s, which may be a performance bottleneck.
[2m[36m(train pid=2227875)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2227875)[0m 
2023-11-03 17:09:11,065	WARNING util.py:214 -- The `on_step_end` operation took 1.060 s, which may be a performance bottleneck.
[2m[36m(train pid=2229959)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2229959)[0m 
2023-11-03 17:10:23,839	WARNING util.py:214 -- The `on_step_end` operation took 1.106 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 17:00:40 (running for 18:29:38.10)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2271/1000000 (1 PENDING, 31 RUNNING, 2239 TERMINATED)


== Status ==
Current time: 2023-11-03 17:00:46 (running for 18:29:44.36)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2274/1000000 (31 RUNNING, 2243 TERMINATED)


== Status ==
Current time: 2023-11-03 17:02:35 (running for 18:31:33.42)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2275/1000000 (1 PENDING, 30 RUNNING, 2244 TERMINATED)


== Status ==
Current time: 2023-11-03 17:02:42 (running for 18:31:39.84)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2278/1000000 (1 PENDING, 31 RUNNING, 2246 TERMINATED)


== Status ==
Current time: 2023-11-03 17:04:19 (running for 18:33:17.28)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2278/1000000 (1 PENDING, 31 RUNNING, 2246 TERMINATED)


== Status ==
Current time: 2023-11-03 17:04:26 (running for 18:33:24.47)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2281/1000000 (32 RUNNING, 2249 TERMINATED)


== Status ==
Current time: 2023-11-03 17:05:57 (running for 18:34:55.54)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2281/1000000 (32 RUNNING, 2249 TERMINATED)


== Status ==
Current time: 2023-11-03 17:06:05 (running for 18:35:02.68)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2285/1000000 (1 PENDING, 31 RUNNING, 2253 TERMINATED)


== Status ==
Current time: 2023-11-03 17:06:11 (running for 18:35:09.30)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2288/1000000 (31 RUNNING, 2257 TERMINATED)


== Status ==
Current time: 2023-11-03 17:07:46 (running for 18:36:44.16)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2289/1000000 (1 PENDING, 31 RUNNING, 2257 TERMINATED)


== Status ==
Current time: 2023-11-03 17:07:54 (running for 18:36:51.77)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2289/1000000 (1 PENDING, 30 RUNNING, 2258 TERMINATED)


== Status ==
Current time: 2023-11-03 17:08:00 (running for 18:36:58.00)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2293/1000000 (1 PENDING, 31 RUNNING, 2261 TERMINATED)


== Status ==
Current time: 2023-11-03 17:09:04 (running for 18:38:02.51)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2293/1000000 (1 PENDING, 31 RUNNING, 2261 TERMINATED)


== Status ==
Current time: 2023-11-03 17:09:11 (running for 18:38:08.78)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2297/1000000 (1 PENDING, 30 RUNNING, 2266 TERMINATED)


2023-11-03 17:10:30,043	WARNING util.py:214 -- The `on_step_end` operation took 1.184 s, which may be a performance bottleneck.
2023-11-03 17:11:43,051	WARNING util.py:214 -- The `on_step_end` operation took 0.925 s, which may be a performance bottleneck.
[2m[36m(train pid=2232962)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2232962)[0m 
2023-11-03 17:11:49,384	WARNING util.py:214 -- The `on_step_end` operation took 0.954 s, which may be a performance bottleneck.
[2m[36m(train pid=2235687)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2235687)[0m 
[2m[36m(train pid=2235673)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2235673)[0m 
[2m[36m(train pid=2235962)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2235962)[0m 
2023-11-03 17:13:11,945	WARNING util.py:214 -- The `on_step_end` operation took 0.959 s, which may be a performance bottleneck.
2023-11-03 17:13:15,691	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
2023-11-03 17:13:18,563	WARNING util.py:214 -- The `on_step_end` operation took 1.168 s, which may be a performance bottleneck.
2023-11-03 17:13:24,880	WARNING util.py:214 -- The `on_step_end` operation took 1.107 s, which may be a performance bottleneck.
2023-11-03 17:13:31,480	WARNING util.py:214 -- The `on_step_end` operation took 1.478 s, which may be a performance bottleneck.
2023-11-03 17:15:03,560	WARNING util.py:214 -- The `on_step_end` operation took 1.156 s, which may be a performance bottleneck.
[2m[36m(train pid=2240441)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2240441)[0m 
2023-11-03 17:15:04,925	WARNING util.py:214 -- The `start_trial` operation took 0.867 s, which may be a performance bottleneck.
2023-11-03 17:15:09,717	WARNING util.py:214 -- The `on_step_end` operation took 1.131 s, which may be a performance bottleneck.
2023-11-03 17:15:21,871	WARNING util.py:214 -- The `on_step_end` operation took 1.491 s, which may be a performance bottleneck.
2023-11-03 17:16:45,821	WARNING util.py:214 -- The `on_step_end` operation took 1.166 s, which may be a performance bottleneck.
[2m[36m(train pid=2243921)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2243921)[0m 
2023-11-03 17:16:52,040	WARNING util.py:214 -- The `on_step_end` operation took 1.179 s, which may be a performance bottleneck.
2023-11-03 17:16:58,651	WARNING util.py:214 -- The `on_step_end` operation took 1.476 s, which may be a performance bottleneck.
[2m[36m(train pid=2246660)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2246660)[0m 
[2m[36m(train pid=2246665)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2246665)[0m 
2023-11-03 17:18:40,914	WARNING util.py:214 -- The `on_step_end` operation took 1.346 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 17:10:23 (running for 18:39:21.46)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2297/1000000 (31 RUNNING, 2266 TERMINATED)


== Status ==
Current time: 2023-11-03 17:10:30 (running for 18:39:27.64)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2301/1000000 (1 PENDING, 31 RUNNING, 2269 TERMINATED)


== Status ==
Current time: 2023-11-03 17:11:43 (running for 18:40:40.65)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2301/1000000 (1 PENDING, 31 RUNNING, 2269 TERMINATED)


== Status ==
Current time: 2023-11-03 17:11:49 (running for 18:40:47.07)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2305/1000000 (32 RUNNING, 2273 TERMINATED)


== Status ==
Current time: 2023-11-03 17:13:11 (running for 18:42:09.54)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2305/1000000 (32 RUNNING, 2273 TERMINATED)


== Status ==
Current time: 2023-11-03 17:13:18 (running for 18:42:16.16)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2309/1000000 (1 PENDING, 31 RUNNING, 2277 TERMINATED)


== Status ==
Current time: 2023-11-03 17:13:24 (running for 18:42:22.48)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2312/1000000 (31 RUNNING, 2281 TERMINATED)


== Status ==
Current time: 2023-11-03 17:13:31 (running for 18:42:29.08)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2315/1000000 (31 RUNNING, 2284 TERMINATED)


== Status ==
Current time: 2023-11-03 17:15:03 (running for 18:44:01.21)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2316/1000000 (1 PENDING, 30 RUNNING, 2285 TERMINATED)


== Status ==
Current time: 2023-11-03 17:15:09 (running for 18:44:07.31)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2319/1000000 (31 RUNNING, 2288 TERMINATED)


== Status ==
Current time: 2023-11-03 17:15:21 (running for 18:44:19.52)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2320/1000000 (32 RUNNING, 2288 TERMINATED)


== Status ==
Current time: 2023-11-03 17:16:45 (running for 18:45:43.43)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2320/1000000 (32 RUNNING, 2288 TERMINATED)


== Status ==
Current time: 2023-11-03 17:16:52 (running for 18:45:49.74)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2323/1000000 (1 PENDING, 31 RUNNING, 2291 TERMINATED)


== Status ==
Current time: 2023-11-03 17:16:58 (running for 18:45:56.25)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2326/1000000 (1 PENDING, 31 RUNNING, 2294 TERMINATED)


2023-11-03 17:18:47,959	WARNING util.py:214 -- The `on_step_end` operation took 1.774 s, which may be a performance bottleneck.
2023-11-03 17:20:17,720	WARNING util.py:214 -- The `on_step_end` operation took 1.053 s, which may be a performance bottleneck.
[2m[36m(train pid=2251377)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2251377)[0m 
2023-11-03 17:20:24,304	WARNING util.py:214 -- The `on_step_end` operation took 1.318 s, which may be a performance bottleneck.
[2m[36m(train pid=2256809)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2256809)[0m 
2023-11-03 17:21:35,056	WARNING util.py:214 -- The `on_step_end` operation took 0.666 s, which may be a performance bottleneck.
2023-11-03 17:22:15,165	WARNING util.py:214 -- The `on_step_end` operation took 0.526 s, which may be a performance bottleneck.
[2m[36m(train pid=2260887)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2260887)[0m 
2023-11-03 17:22:21,203	WARNING util.py:214 -- The `on_step_end` operation took 0.844 s, which may be a performance bottleneck.
2023-11-03 17:22:27,301	WARNING util.py:214 -- The `on_step_end` operation took 0.938 s, which may be a performance bottleneck.
[2m[36m(train pid=2263879)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2263879)[0m 
2023-11-03 17:23:35,608	WARNING util.py:214 -- The `on_step_end` operation took 0.821 s, which may be a performance bottleneck.
2023-11-03 17:23:42,033	WARNING util.py:214 -- The `on_step_end` operation took 1.140 s, which may be a performance bottleneck.
2023-11-03 17:23:44,351	WARNING util.py:214 -- The `start_trial` operation took 0.640 s, which may be a performance bottleneck.
2023-11-03 17:23:48,882	WARNING util.py:214 -- The `on_step_end` operation took 0.962 s, which may be a performance bottleneck.
2023-11-03 17:23:55,422	WARNING util.py:214 -- The `on_step_end` operation took 1.464 s, which may be a performance bottleneck.
2023-11-03 17:24:02,762	WARNING util.py:214 -- The `on_step_end` operation took 1.590 s, which may be a performance bottleneck.
[2m[36m(train pid=2267022)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2267022)[0m 
2023-11-03 17:26:07,564	WARNING util.py:214 -- The `on_step_end` operation took 1.428 s, which may be a performance bottleneck.
2023-11-03 17:26:14,692	WARNING util.py:214 -- The `on_step_end` operation took 1.309 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 17:18:41 (running for 18:47:38.61)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2326/1000000 (1 PENDING, 30 RUNNING, 2295 TERMINATED)


== Status ==
Current time: 2023-11-03 17:18:47 (running for 18:47:45.56)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2329/1000000 (1 PENDING, 31 RUNNING, 2297 TERMINATED)


== Status ==
Current time: 2023-11-03 17:20:17 (running for 18:49:15.32)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2329/1000000 (1 PENDING, 30 RUNNING, 2298 TERMINATED)


== Status ==
Current time: 2023-11-03 17:20:24 (running for 18:49:21.92)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2332/1000000 (1 PENDING, 31 RUNNING, 2300 TERMINATED)


== Status ==
Current time: 2023-11-03 17:21:35 (running for 18:50:32.67)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2332/1000000 (32 RUNNING, 2300 TERMINATED)


== Status ==
Current time: 2023-11-03 17:22:15 (running for 18:51:12.76)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2332/1000000 (32 RUNNING, 2300 TERMINATED)


== Status ==
Current time: 2023-11-03 17:22:21 (running for 18:51:18.80)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2338/1000000 (1 PENDING, 31 RUNNING, 2306 TERMINATED)


== Status ==
Current time: 2023-11-03 17:22:27 (running for 18:51:24.93)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2342/1000000 (31 RUNNING, 2311 TERMINATED)


== Status ==
Current time: 2023-11-03 17:23:35 (running for 18:52:33.21)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2343/1000000 (1 PENDING, 31 RUNNING, 2311 TERMINATED)


== Status ==
Current time: 2023-11-03 17:23:42 (running for 18:52:39.63)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2348/1000000 (1 PENDING, 30 RUNNING, 2317 TERMINATED)


== Status ==
Current time: 2023-11-03 17:23:49 (running for 18:52:46.61)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2352/1000000 (1 PENDING, 31 RUNNING, 2320 TERMINATED)


== Status ==
Current time: 2023-11-03 17:23:55 (running for 18:52:53.02)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2355/1000000 (1 PENDING, 31 RUNNING, 2323 TERMINATED)


== Status ==
Current time: 2023-11-03 17:24:02 (running for 18:53:00.36)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2358/1000000 (32 RUNNING, 2326 TERMINATED)


== Status ==
Current time: 2023-11-03 17:26:07 (running for 18:55:05.18)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2358/1000000 (32 RUNNING, 2326 TERMINATED)


2023-11-03 17:27:48,650	WARNING util.py:214 -- The `on_step_end` operation took 0.980 s, which may be a performance bottleneck.
[2m[36m(train pid=2272441)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2272441)[0m 
2023-11-03 17:27:55,009	WARNING util.py:214 -- The `on_step_end` operation took 1.227 s, which may be a performance bottleneck.
2023-11-03 17:27:57,149	WARNING util.py:214 -- The `start_trial` operation took 0.586 s, which may be a performance bottleneck.
2023-11-03 17:28:01,580	WARNING util.py:214 -- The `on_step_end` operation took 1.546 s, which may be a performance bottleneck.
[2m[36m(train pid=2277619)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2277619)[0m 
[2m[36m(train pid=2277614)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2277614)[0m 
2023-11-03 17:29:31,405	WARNING util.py:214 -- The `on_step_end` operation took 1.149 s, which may be a performance bottleneck.
2023-11-03 17:29:34,230	WARNING util.py:214 -- The `start_trial` operation took 0.520 s, which may be a performance bottleneck.
2023-11-03 17:29:37,618	WARNING util.py:214 -- The `on_step_end` operation took 1.146 s, which may be a performance bottleneck.
2023-11-03 17:29:44,936	WARNING util.py:214 -- The `on_step_end` operation took 1.464 s, which may be a performance bottleneck.
2023-11-03 17:31:16,698	WARNING util.py:214 -- The `on_step_end` operation took 1.191 s, which may be a performance bottleneck.
[2m[36m(train pid=2281729)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2281729)[0m 
2023-11-03 17:31:23,113	WARNING util.py:214 -- The `on_step_end` operation took 1.291 s, which may be a performance bottleneck.
2023-11-03 17:31:27,744	WARNING util.py:214 -- The `start_trial` operation took 0.593 s, which may be a performance bottleneck.
2023-11-03 17:31:30,784	WARNING util.py:214 -- The `on_step_end` operation took 1.656 s, which may be a performance bottleneck.
[2m[36m(train pid=2284325)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2284325)[0m 
2023-11-03 17:33:28,254	WARNING util.py:214 -- The `on_step_end` operation took 1.595 s, which may be a performance bottleneck.
2023-11-03 17:33:34,958	WARNING util.py:214 -- The `on_step_end` operation took 1.433 s, which may be a performance bottleneck.
2023-11-03 17:33:42,064	WARNING util.py:214 -- The `on_step_end` operation took 1.764 s, which may be a performance bottleneck.
2023-11-03 17:35:30,253	WARNING util.py:214 -- The `on_step_end` operation took 1.303 s, which may be a performance bottleneck.
[2m[36m(train pid=2287499)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2287499)[0m 
2023-11-03 17:35:33,006	WARNING util.py:214 -- The `start_trial` operation took 0.833 s, which may be a performance bottleneck.
2023-11-03 17:35:37,869	WARNING util.py:214 -- The `on_step_end` operation took 1.652 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 17:26:14 (running for 18:55:12.29)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2361/1000000 (32 RUNNING, 2329 TERMINATED)


== Status ==
Current time: 2023-11-03 17:27:48 (running for 18:56:46.25)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2361/1000000 (32 RUNNING, 2329 TERMINATED)


== Status ==
Current time: 2023-11-03 17:27:55 (running for 18:56:52.61)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2364/1000000 (31 RUNNING, 2333 TERMINATED)


== Status ==
Current time: 2023-11-03 17:28:01 (running for 18:56:59.18)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2367/1000000 (31 RUNNING, 2336 TERMINATED)


== Status ==
Current time: 2023-11-03 17:29:31 (running for 18:58:29.01)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2368/1000000 (1 PENDING, 31 RUNNING, 2336 TERMINATED)


== Status ==
Current time: 2023-11-03 17:29:37 (running for 18:58:35.22)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2371/1000000 (1 PENDING, 31 RUNNING, 2339 TERMINATED)


== Status ==
Current time: 2023-11-03 17:29:44 (running for 18:58:42.53)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2375/1000000 (1 PENDING, 30 RUNNING, 2344 TERMINATED)


== Status ==
Current time: 2023-11-03 17:31:16 (running for 19:00:14.36)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2375/1000000 (31 RUNNING, 2344 TERMINATED)


== Status ==
Current time: 2023-11-03 17:31:23 (running for 19:00:20.71)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2378/1000000 (31 RUNNING, 2347 TERMINATED)


== Status ==
Current time: 2023-11-03 17:31:30 (running for 19:00:28.51)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2381/1000000 (1 PENDING, 30 RUNNING, 2350 TERMINATED)


== Status ==
Current time: 2023-11-03 17:33:28 (running for 19:02:25.85)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2381/1000000 (31 RUNNING, 2350 TERMINATED)


== Status ==
Current time: 2023-11-03 17:33:34 (running for 19:02:32.56)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2383/1000000 (31 RUNNING, 2352 TERMINATED)


== Status ==
Current time: 2023-11-03 17:33:42 (running for 19:02:39.66)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2386/1000000 (1 PENDING, 30 RUNNING, 2355 TERMINATED)


== Status ==
Current time: 2023-11-03 17:35:30 (running for 19:04:27.85)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2386/1000000 (31 RUNNING, 2355 TERMINATED)


[2m[36m(train pid=2291156)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2291156)[0m 
2023-11-03 17:37:31,979	WARNING util.py:214 -- The `on_step_end` operation took 1.284 s, which may be a performance bottleneck.
2023-11-03 17:38:54,204	WARNING util.py:214 -- The `on_step_end` operation took 0.997 s, which may be a performance bottleneck.
[2m[36m(train pid=2294457)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2294457)[0m 
2023-11-03 17:39:01,005	WARNING util.py:214 -- The `on_step_end` operation took 1.441 s, which may be a performance bottleneck.
[2m[36m(train pid=2298341)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2298341)[0m 
2023-11-03 17:40:21,818	WARNING util.py:214 -- The `on_step_end` operation took 0.981 s, which may be a performance bottleneck.
2023-11-03 17:40:29,152	WARNING util.py:214 -- The `on_step_end` operation took 1.285 s, which may be a performance bottleneck.
2023-11-03 17:41:43,618	WARNING util.py:214 -- The `on_step_end` operation took 0.850 s, which may be a performance bottleneck.
[2m[36m(train pid=2302407)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2302407)[0m 
2023-11-03 17:41:50,058	WARNING util.py:214 -- The `on_step_end` operation took 1.063 s, which may be a performance bottleneck.
2023-11-03 17:41:52,224	WARNING util.py:214 -- The `start_trial` operation took 0.602 s, which may be a performance bottleneck.
2023-11-03 17:41:56,883	WARNING util.py:214 -- The `on_step_end` operation took 1.198 s, which may be a performance bottleneck.
[2m[36m(train pid=2306253)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2306253)[0m 
2023-11-03 17:43:23,779	WARNING util.py:214 -- The `on_step_end` operation took 0.937 s, which may be a performance bottleneck.
2023-11-03 17:43:30,269	WARNING util.py:214 -- The `on_step_end` operation took 1.246 s, which may be a performance bottleneck.
2023-11-03 17:43:37,451	WARNING util.py:214 -- The `on_step_end` operation took 1.141 s, which may be a performance bottleneck.
2023-11-03 17:43:44,108	WARNING util.py:214 -- The `on_step_end` operation took 1.627 s, which may be a performance bottleneck.
2023-11-03 17:43:45,402	WARNING util.py:214 -- The `start_trial` operation took 0.592 s, which may be a performance bottleneck.
2023-11-03 17:43:51,525	WARNING util.py:214 -- The `on_step_end` operation took 1.870 s, which may be a performance bottleneck.
[2m[36m(train pid=2309279)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2309279)[0m 
2023-11-03 17:46:08,029	WARNING util.py:214 -- The `on_step_end` operation took 1.878 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 17:35:37 (running for 19:04:35.48)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2389/1000000 (1 PENDING, 31 RUNNING, 2357 TERMINATED)


== Status ==
Current time: 2023-11-03 17:37:32 (running for 19:06:29.69)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2389/1000000 (32 RUNNING, 2357 TERMINATED)


== Status ==
Current time: 2023-11-03 17:38:54 (running for 19:07:51.80)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2389/1000000 (32 RUNNING, 2357 TERMINATED)


== Status ==
Current time: 2023-11-03 17:39:01 (running for 19:07:58.60)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2392/1000000 (1 PENDING, 31 RUNNING, 2360 TERMINATED)


== Status ==
Current time: 2023-11-03 17:40:21 (running for 19:09:19.42)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2392/1000000 (1 PENDING, 31 RUNNING, 2360 TERMINATED)


== Status ==
Current time: 2023-11-03 17:40:29 (running for 19:09:26.75)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2396/1000000 (32 RUNNING, 2364 TERMINATED)


== Status ==
Current time: 2023-11-03 17:41:43 (running for 19:10:41.29)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2396/1000000 (32 RUNNING, 2364 TERMINATED)


== Status ==
Current time: 2023-11-03 17:41:50 (running for 19:10:47.72)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2401/1000000 (1 PENDING, 30 RUNNING, 2370 TERMINATED)


== Status ==
Current time: 2023-11-03 17:41:56 (running for 19:10:54.48)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2405/1000000 (1 PENDING, 31 RUNNING, 2373 TERMINATED)


== Status ==
Current time: 2023-11-03 17:43:23 (running for 19:12:21.38)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2405/1000000 (1 PENDING, 31 RUNNING, 2373 TERMINATED)


== Status ==
Current time: 2023-11-03 17:43:30 (running for 19:12:27.92)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2408/1000000 (31 RUNNING, 2377 TERMINATED)


== Status ==
Current time: 2023-11-03 17:43:37 (running for 19:12:35.19)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2412/1000000 (1 PENDING, 30 RUNNING, 2381 TERMINATED)


== Status ==
Current time: 2023-11-03 17:43:44 (running for 19:12:41.75)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2415/1000000 (1 PENDING, 30 RUNNING, 2384 TERMINATED)


== Status ==
Current time: 2023-11-03 17:43:51 (running for 19:12:49.12)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2418/1000000 (32 RUNNING, 2386 TERMINATED)


2023-11-03 17:46:15,643	WARNING util.py:214 -- The `on_step_end` operation took 1.531 s, which may be a performance bottleneck.
2023-11-03 17:48:09,435	WARNING util.py:214 -- The `on_step_end` operation took 1.303 s, which may be a performance bottleneck.
[2m[36m(train pid=2312359)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2312359)[0m 
2023-11-03 17:48:16,917	WARNING util.py:214 -- The `on_step_end` operation took 1.651 s, which may be a performance bottleneck.
[2m[36m(train pid=2316932)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2316932)[0m 
2023-11-03 17:50:13,043	WARNING util.py:214 -- The `on_step_end` operation took 1.410 s, which may be a performance bottleneck.
2023-11-03 17:50:20,549	WARNING util.py:214 -- The `on_step_end` operation took 1.666 s, which may be a performance bottleneck.
2023-11-03 17:50:25,247	WARNING util.py:214 -- The `start_trial` operation took 0.538 s, which may be a performance bottleneck.
2023-11-03 17:50:28,161	WARNING util.py:214 -- The `on_step_end` operation took 1.587 s, which may be a performance bottleneck.
2023-11-03 17:51:54,195	WARNING util.py:214 -- The `on_step_end` operation took 0.975 s, which may be a performance bottleneck.
[2m[36m(train pid=2322923)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2322923)[0m 
2023-11-03 17:51:56,957	WARNING util.py:214 -- The `start_trial` operation took 0.501 s, which may be a performance bottleneck.
2023-11-03 17:52:01,436	WARNING util.py:214 -- The `on_step_end` operation took 1.328 s, which may be a performance bottleneck.
[2m[36m(train pid=2326895)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2326895)[0m 
2023-11-03 17:53:24,330	WARNING util.py:214 -- The `on_step_end` operation took 1.135 s, which may be a performance bottleneck.
2023-11-03 17:53:30,625	WARNING util.py:214 -- The `on_step_end` operation took 1.091 s, which may be a performance bottleneck.
2023-11-03 17:54:50,246	WARNING util.py:214 -- The `on_step_end` operation took 1.230 s, which may be a performance bottleneck.
[2m[36m(train pid=2330049)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2330049)[0m 
2023-11-03 17:54:57,405	WARNING util.py:214 -- The `on_step_end` operation took 1.526 s, which may be a performance bottleneck.
[2m[36m(train pid=2333249)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2333249)[0m 
2023-11-03 17:56:18,732	WARNING util.py:214 -- The `on_step_end` operation took 0.890 s, which may be a performance bottleneck.
2023-11-03 17:57:15,721	WARNING util.py:214 -- The `on_step_end` operation took 0.791 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 17:46:08 (running for 19:15:05.68)
Memory usage on this node: 25.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2418/1000000 (32 RUNNING, 2386 TERMINATED)


== Status ==
Current time: 2023-11-03 17:46:15 (running for 19:15:13.24)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2420/1000000 (32 RUNNING, 2388 TERMINATED)


== Status ==
Current time: 2023-11-03 17:48:09 (running for 19:17:07.03)
Memory usage on this node: 25.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2420/1000000 (32 RUNNING, 2388 TERMINATED)


== Status ==
Current time: 2023-11-03 17:48:16 (running for 19:17:14.53)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2423/1000000 (32 RUNNING, 2391 TERMINATED)


== Status ==
Current time: 2023-11-03 17:50:13 (running for 19:19:10.64)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2423/1000000 (32 RUNNING, 2391 TERMINATED)


== Status ==
Current time: 2023-11-03 17:50:20 (running for 19:19:18.15)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2426/1000000 (1 PENDING, 30 RUNNING, 2395 TERMINATED)


== Status ==
Current time: 2023-11-03 17:50:28 (running for 19:19:25.87)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2429/1000000 (1 PENDING, 30 RUNNING, 2398 TERMINATED)


== Status ==
Current time: 2023-11-03 17:51:54 (running for 19:20:51.79)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2429/1000000 (31 RUNNING, 2398 TERMINATED)


== Status ==
Current time: 2023-11-03 17:52:01 (running for 19:20:59.04)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2433/1000000 (1 PENDING, 31 RUNNING, 2401 TERMINATED)


== Status ==
Current time: 2023-11-03 17:53:24 (running for 19:22:21.98)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2433/1000000 (1 PENDING, 31 RUNNING, 2401 TERMINATED)


== Status ==
Current time: 2023-11-03 17:53:30 (running for 19:22:28.24)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2436/1000000 (31 RUNNING, 2405 TERMINATED)


== Status ==
Current time: 2023-11-03 17:54:50 (running for 19:23:47.84)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2437/1000000 (1 PENDING, 31 RUNNING, 2405 TERMINATED)


== Status ==
Current time: 2023-11-03 17:54:57 (running for 19:23:55.00)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2441/1000000 (1 PENDING, 31 RUNNING, 2409 TERMINATED)


== Status ==
Current time: 2023-11-03 17:56:18 (running for 19:25:16.33)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2441/1000000 (32 RUNNING, 2409 TERMINATED)


[2m[36m(train pid=2336227)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2336227)[0m 
2023-11-03 17:57:21,889	WARNING util.py:214 -- The `on_step_end` operation took 1.144 s, which may be a performance bottleneck.
[2m[36m(train pid=2339238)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2339238)[0m 
2023-11-03 17:58:25,556	WARNING util.py:214 -- The `on_step_end` operation took 0.764 s, which may be a performance bottleneck.
2023-11-03 17:58:31,760	WARNING util.py:214 -- The `on_step_end` operation took 1.062 s, which may be a performance bottleneck.
2023-11-03 17:59:36,670	WARNING util.py:214 -- The `on_step_end` operation took 1.022 s, which may be a performance bottleneck.
[2m[36m(train pid=2341660)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2341660)[0m 
2023-11-03 17:59:42,684	WARNING util.py:214 -- The `on_step_end` operation took 0.965 s, which may be a performance bottleneck.
[2m[36m(train pid=2343709)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2343709)[0m 
2023-11-03 18:00:59,628	WARNING util.py:214 -- The `on_step_end` operation took 0.999 s, which may be a performance bottleneck.
2023-11-03 18:01:06,310	WARNING util.py:214 -- The `on_step_end` operation took 1.249 s, which may be a performance bottleneck.
2023-11-03 18:02:28,769	WARNING util.py:214 -- The `on_step_end` operation took 0.994 s, which may be a performance bottleneck.
[2m[36m(train pid=2345484)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2345484)[0m 
2023-11-03 18:02:35,600	WARNING util.py:214 -- The `on_step_end` operation took 1.408 s, which may be a performance bottleneck.
2023-11-03 18:02:40,928	WARNING util.py:214 -- The `start_trial` operation took 1.382 s, which may be a performance bottleneck.
2023-11-03 18:02:42,170	WARNING util.py:214 -- The `on_step_end` operation took 1.242 s, which may be a performance bottleneck.
2023-11-03 18:02:49,477	WARNING util.py:214 -- The `on_step_end` operation took 1.858 s, which may be a performance bottleneck.
2023-11-03 18:02:56,619	WARNING util.py:214 -- The `on_step_end` operation took 1.506 s, which may be a performance bottleneck.
[2m[36m(train pid=2347404)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2347404)[0m 
[2m[36m(train pid=2347412)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2347412)[0m 
2023-11-03 18:05:05,969	WARNING util.py:214 -- The `on_step_end` operation took 1.946 s, which may be a performance bottleneck.
2023-11-03 18:05:15,873	WARNING util.py:214 -- The `on_step_end` operation took 1.645 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 17:57:15 (running for 19:26:13.37)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2441/1000000 (31 RUNNING, 2410 TERMINATED)


== Status ==
Current time: 2023-11-03 17:57:21 (running for 19:26:19.53)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2445/1000000 (1 PENDING, 31 RUNNING, 2413 TERMINATED)


== Status ==
Current time: 2023-11-03 17:58:25 (running for 19:27:23.17)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2445/1000000 (1 PENDING, 30 RUNNING, 2414 TERMINATED)


== Status ==
Current time: 2023-11-03 17:58:31 (running for 19:27:29.36)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2450/1000000 (31 RUNNING, 2419 TERMINATED)


== Status ==
Current time: 2023-11-03 17:59:36 (running for 19:28:34.32)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2451/1000000 (1 PENDING, 31 RUNNING, 2419 TERMINATED)


== Status ==
Current time: 2023-11-03 17:59:42 (running for 19:28:40.36)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2454/1000000 (31 RUNNING, 2423 TERMINATED)


== Status ==
Current time: 2023-11-03 18:00:59 (running for 19:29:57.23)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2455/1000000 (1 PENDING, 31 RUNNING, 2423 TERMINATED)


== Status ==
Current time: 2023-11-03 18:01:06 (running for 19:30:03.95)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2459/1000000 (1 PENDING, 30 RUNNING, 2428 TERMINATED)


== Status ==
Current time: 2023-11-03 18:02:28 (running for 19:31:26.41)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2459/1000000 (31 RUNNING, 2428 TERMINATED)


== Status ==
Current time: 2023-11-03 18:02:35 (running for 19:31:33.30)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2463/1000000 (1 PENDING, 31 RUNNING, 2431 TERMINATED)


== Status ==
Current time: 2023-11-03 18:02:42 (running for 19:31:39.89)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2465/1000000 (31 RUNNING, 2434 TERMINATED)


== Status ==
Current time: 2023-11-03 18:02:49 (running for 19:31:47.07)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2468/1000000 (1 PENDING, 31 RUNNING, 2436 TERMINATED)


== Status ==
Current time: 2023-11-03 18:02:56 (running for 19:31:54.35)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2470/1000000 (32 RUNNING, 2438 TERMINATED)


== Status ==
Current time: 2023-11-03 18:05:06 (running for 19:34:03.69)
Memory usage on this node: 25.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2470/1000000 (32 RUNNING, 2438 TERMINATED)


2023-11-03 18:07:08,730	WARNING util.py:214 -- The `on_step_end` operation took 1.407 s, which may be a performance bottleneck.
[2m[36m(train pid=2350464)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2350464)[0m 
2023-11-03 18:07:15,464	WARNING util.py:214 -- The `on_step_end` operation took 1.673 s, which may be a performance bottleneck.
[2m[36m(train pid=2354186)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2354186)[0m 
2023-11-03 18:09:04,441	WARNING util.py:214 -- The `on_step_end` operation took 1.488 s, which may be a performance bottleneck.
2023-11-03 18:09:10,902	WARNING util.py:214 -- The `on_step_end` operation took 1.445 s, which may be a performance bottleneck.
2023-11-03 18:10:29,898	WARNING util.py:214 -- The `on_step_end` operation took 1.000 s, which may be a performance bottleneck.
[2m[36m(train pid=2359769)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2359769)[0m 
2023-11-03 18:11:27,410	WARNING util.py:214 -- The `on_step_end` operation took 0.653 s, which may be a performance bottleneck.
[2m[36m(train pid=2363727)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2363727)[0m 
2023-11-03 18:11:33,402	WARNING util.py:214 -- The `on_step_end` operation took 0.928 s, which may be a performance bottleneck.
2023-11-03 18:11:40,566	WARNING util.py:214 -- The `on_step_end` operation took 0.936 s, which may be a performance bottleneck.
2023-11-03 18:11:47,292	WARNING util.py:214 -- The `on_step_end` operation took 1.239 s, which may be a performance bottleneck.
2023-11-03 18:11:53,705	WARNING util.py:214 -- The `on_step_end` operation took 1.365 s, which may be a performance bottleneck.
2023-11-03 18:13:26,336	WARNING util.py:214 -- The `on_step_end` operation took 1.430 s, which may be a performance bottleneck.
[2m[36m(train pid=2366759)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2366759)[0m 
2023-11-03 18:13:36,424	WARNING util.py:214 -- The `on_step_end` operation took 1.216 s, which may be a performance bottleneck.
2023-11-03 18:13:43,045	WARNING util.py:214 -- The `on_step_end` operation took 1.219 s, which may be a performance bottleneck.
2023-11-03 18:13:44,389	WARNING util.py:214 -- The `start_trial` operation took 0.614 s, which may be a performance bottleneck.
2023-11-03 18:13:50,282	WARNING util.py:214 -- The `on_step_end` operation took 1.759 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 18:05:15 (running for 19:34:13.47)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2471/1000000 (32 RUNNING, 2439 TERMINATED)


== Status ==
Current time: 2023-11-03 18:07:08 (running for 19:36:06.42)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2471/1000000 (32 RUNNING, 2439 TERMINATED)


== Status ==
Current time: 2023-11-03 18:07:15 (running for 19:36:13.15)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2473/1000000 (31 RUNNING, 2442 TERMINATED)


== Status ==
Current time: 2023-11-03 18:09:04 (running for 19:38:02.04)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2474/1000000 (1 PENDING, 31 RUNNING, 2442 TERMINATED)


== Status ==
Current time: 2023-11-03 18:09:10 (running for 19:38:08.58)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2476/1000000 (31 RUNNING, 2445 TERMINATED)


== Status ==
Current time: 2023-11-03 18:10:29 (running for 19:39:27.50)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2477/1000000 (32 RUNNING, 2445 TERMINATED)


== Status ==
Current time: 2023-11-03 18:11:27 (running for 19:40:25.01)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2477/1000000 (32 RUNNING, 2445 TERMINATED)


== Status ==
Current time: 2023-11-03 18:11:33 (running for 19:40:31.05)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2482/1000000 (1 PENDING, 31 RUNNING, 2450 TERMINATED)


== Status ==
Current time: 2023-11-03 18:11:40 (running for 19:40:38.22)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2482/1000000 (1 PENDING, 31 RUNNING, 2450 TERMINATED)


== Status ==
Current time: 2023-11-03 18:11:47 (running for 19:40:44.95)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2487/1000000 (1 PENDING, 30 RUNNING, 2456 TERMINATED)


== Status ==
Current time: 2023-11-03 18:11:53 (running for 19:40:51.46)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2490/1000000 (31 RUNNING, 2459 TERMINATED)


== Status ==
Current time: 2023-11-03 18:13:26 (running for 19:42:24.03)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2491/1000000 (1 PENDING, 31 RUNNING, 2459 TERMINATED)


== Status ==
Current time: 2023-11-03 18:13:36 (running for 19:42:34.02)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2491/1000000 (1 PENDING, 30 RUNNING, 2460 TERMINATED)


== Status ==
Current time: 2023-11-03 18:13:43 (running for 19:42:40.71)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2494/1000000 (1 PENDING, 30 RUNNING, 2463 TERMINATED)


2023-11-03 18:13:58,014	WARNING util.py:214 -- The `on_step_end` operation took 1.558 s, which may be a performance bottleneck.
2023-11-03 18:15:55,082	WARNING util.py:214 -- The `on_step_end` operation took 1.901 s, which may be a performance bottleneck.
[2m[36m(train pid=2368393)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2368393)[0m 
[2m[36m(train pid=2368672)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2368672)[0m 
2023-11-03 18:15:58,882	WARNING util.py:214 -- The `start_trial` operation took 0.676 s, which may be a performance bottleneck.
2023-11-03 18:16:05,458	WARNING util.py:214 -- The `on_step_end` operation took 1.573 s, which may be a performance bottleneck.
[2m[36m(train pid=2370593)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2370593)[0m 
2023-11-03 18:18:15,817	WARNING util.py:214 -- The `on_step_end` operation took 2.056 s, which may be a performance bottleneck.
2023-11-03 18:18:22,850	WARNING util.py:214 -- The `on_step_end` operation took 1.889 s, which may be a performance bottleneck.
2023-11-03 18:20:03,002	WARNING util.py:214 -- The `on_step_end` operation took 1.253 s, which may be a performance bottleneck.
[2m[36m(train pid=2374733)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2374733)[0m 
2023-11-03 18:21:26,832	WARNING util.py:214 -- The `on_step_end` operation took 1.009 s, which may be a performance bottleneck.
[2m[36m(train pid=2379305)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2379305)[0m 
2023-11-03 18:21:40,176	WARNING util.py:214 -- The `on_step_end` operation took 1.427 s, which may be a performance bottleneck.
2023-11-03 18:21:45,490	WARNING util.py:214 -- The `start_trial` operation took 0.534 s, which may be a performance bottleneck.
2023-11-03 18:21:46,550	WARNING util.py:214 -- The `on_step_end` operation took 1.060 s, which may be a performance bottleneck.
2023-11-03 18:23:10,738	WARNING util.py:214 -- The `on_step_end` operation took 1.037 s, which may be a performance bottleneck.
[2m[36m(train pid=2383346)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2383346)[0m 
[2m[36m(train pid=2386482)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2386482)[0m 
2023-11-03 18:24:16,341	WARNING util.py:214 -- The `on_step_end` operation took 0.751 s, which may be a performance bottleneck.
2023-11-03 18:24:22,324	WARNING util.py:214 -- The `on_step_end` operation took 0.966 s, which may be a performance bottleneck.
2023-11-03 18:25:23,868	WARNING util.py:214 -- The `on_step_end` operation took 0.939 s, which may be a performance bottleneck.
[2m[36m(train pid=2388934)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2388934)[0m 
2023-11-03 18:25:30,047	WARNING util.py:214 -- The `on_step_end` operation took 1.040 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 18:13:50 (running for 19:42:47.88)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2497/1000000 (1 PENDING, 31 RUNNING, 2465 TERMINATED)


== Status ==
Current time: 2023-11-03 18:13:58 (running for 19:42:55.74)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2500/1000000 (32 RUNNING, 2468 TERMINATED)


== Status ==
Current time: 2023-11-03 18:15:55 (running for 19:44:52.68)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2500/1000000 (32 RUNNING, 2468 TERMINATED)


== Status ==
Current time: 2023-11-03 18:16:05 (running for 19:45:03.14)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2501/1000000 (32 RUNNING, 2469 TERMINATED)


== Status ==
Current time: 2023-11-03 18:18:15 (running for 19:47:13.46)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2501/1000000 (32 RUNNING, 2469 TERMINATED)


== Status ==
Current time: 2023-11-03 18:18:23 (running for 19:47:20.61)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2503/1000000 (1 PENDING, 31 RUNNING, 2471 TERMINATED)


== Status ==
Current time: 2023-11-03 18:20:03 (running for 19:49:00.60)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2503/1000000 (32 RUNNING, 2471 TERMINATED)


== Status ==
Current time: 2023-11-03 18:21:26 (running for 19:50:24.49)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2503/1000000 (32 RUNNING, 2471 TERMINATED)


== Status ==
Current time: 2023-11-03 18:21:40 (running for 19:50:37.77)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2505/1000000 (31 RUNNING, 2474 TERMINATED)


== Status ==
Current time: 2023-11-03 18:21:46 (running for 19:50:44.15)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2508/1000000 (31 RUNNING, 2477 TERMINATED)


== Status ==
Current time: 2023-11-03 18:23:10 (running for 19:52:08.41)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2509/1000000 (32 RUNNING, 2477 TERMINATED)


== Status ==
Current time: 2023-11-03 18:24:16 (running for 19:53:14.00)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2509/1000000 (32 RUNNING, 2477 TERMINATED)


== Status ==
Current time: 2023-11-03 18:24:22 (running for 19:53:19.92)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2513/1000000 (32 RUNNING, 2481 TERMINATED)


== Status ==
Current time: 2023-11-03 18:25:23 (running for 19:54:21.51)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2513/1000000 (31 RUNNING, 2482 TERMINATED)


[2m[36m(train pid=2390837)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2390837)[0m 
2023-11-03 18:26:43,519	WARNING util.py:214 -- The `on_step_end` operation took 1.120 s, which may be a performance bottleneck.
2023-11-03 18:26:49,071	WARNING util.py:214 -- The `start_trial` operation took 0.598 s, which may be a performance bottleneck.
2023-11-03 18:26:50,189	WARNING util.py:214 -- The `on_step_end` operation took 1.117 s, which may be a performance bottleneck.
2023-11-03 18:26:56,647	WARNING util.py:214 -- The `on_step_end` operation took 1.275 s, which may be a performance bottleneck.
2023-11-03 18:26:59,679	WARNING util.py:214 -- The `start_trial` operation took 1.093 s, which may be a performance bottleneck.
2023-11-03 18:27:03,523	WARNING util.py:214 -- The `on_step_end` operation took 1.595 s, which may be a performance bottleneck.
2023-11-03 18:27:11,481	WARNING util.py:214 -- The `on_step_end` operation took 1.807 s, which may be a performance bottleneck.
[2m[36m(train pid=2393181)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2393181)[0m 
2023-11-03 18:29:19,874	WARNING util.py:214 -- The `on_step_end` operation took 1.542 s, which may be a performance bottleneck.
2023-11-03 18:29:26,645	WARNING util.py:214 -- The `on_step_end` operation took 1.721 s, which may be a performance bottleneck.
2023-11-03 18:31:11,516	INFO stopper.py:363 -- Reached timeout of 71999.65471291542 seconds. Stopping all trials.
2023-11-03 18:31:13,725	WARNING util.py:214 -- The `on_step_end` operation took 1.625 s, which may be a performance bottleneck.
[2m[36m(train pid=2395817)[0m TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.
[2m[36m(train pid=2395817)[0m 
2023-11-03 18:36:18,498	INFO tune.py:747 -- Total run time: 72316.13 seconds (72012.04 seconds for the tuning loop).
== Status ==
Current time: 2023-11-03 18:25:30 (running for 19:54:27.64)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2517/1000000 (31 RUNNING, 2486 TERMINATED)


== Status ==
Current time: 2023-11-03 18:26:43 (running for 19:55:41.14)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2518/1000000 (1 PENDING, 30 RUNNING, 2487 TERMINATED)


== Status ==
Current time: 2023-11-03 18:26:50 (running for 19:55:47.79)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2522/1000000 (31 RUNNING, 2491 TERMINATED)


== Status ==
Current time: 2023-11-03 18:26:56 (running for 19:55:54.27)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2525/1000000 (31 RUNNING, 2494 TERMINATED)


== Status ==
Current time: 2023-11-03 18:27:03 (running for 19:56:01.12)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2528/1000000 (1 PENDING, 30 RUNNING, 2497 TERMINATED)


== Status ==
Current time: 2023-11-03 18:27:11 (running for 19:56:09.12)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2531/1000000 (32 RUNNING, 2499 TERMINATED)


== Status ==
Current time: 2023-11-03 18:29:19 (running for 19:58:17.47)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2531/1000000 (32 RUNNING, 2499 TERMINATED)


== Status ==
Current time: 2023-11-03 18:29:26 (running for 19:58:24.29)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2533/1000000 (32 RUNNING, 2501 TERMINATED)


== Status ==
Current time: 2023-11-03 18:31:13 (running for 20:00:11.32)
Memory usage on this node: 22.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2533/1000000 (2533 TERMINATED)


== Status ==
Current time: 2023-11-03 18:34:14 (running for 20:03:12.23)
Memory usage on this node: 19.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 21ed5c26 with val_loss=478.7550058860903 and parameters={'early_stopping_rounds': 10, 'learning_rate': 0.12403441698840942, 'n_estimators': 8192, 'learner': 'catboost'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-02_22-31-02
Number of trials: 2533/1000000 (2533 TERMINATED)


[flaml.automl.logger: 11-03 18:36:23] {2493} INFO - selected model: None
TBB Warning: The number of workers is currently limited to 1. The request for 127 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.

[flaml.automl.logger: 11-03 18:36:27] {2627} INFO - retrain catboost for 3.5s
[flaml.automl.logger: 11-03 18:36:27] {2630} INFO - retrained model: <catboost.core.CatBoostRegressor object at 0x7f09c15cc940>
[flaml.automl.logger: 11-03 18:36:27] {1930} INFO - fit succeeded
[flaml.automl.logger: 11-03 18:36:27] {1931} INFO - Time taken to find the best model: 63595.02823972702
[flaml.automl.logger: 11-03 18:36:27] {1596} WARNING - n_concurrent_trials > 1 is only supported when using Ray or Spark. Ray installed, setting use_ray to True. If you want to use Spark, set use_spark to True.
[flaml.automl.logger: 11-03 18:36:27] {1679} INFO - task = regression
[flaml.automl.logger: 11-03 18:36:27] {1690} INFO - Evaluation method: cv
[flaml.automl.logger: 11-03 18:36:27] {1788} INFO - Minimizing error metric: rmse
[flaml.automl.logger: 11-03 18:36:27] {1900} INFO - List of ML learners in AutoML Run: ['xgb_limitdepth']
2023-11-03 18:36:27,496	WARNING optuna.py:297 -- You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.
[32m[I 2023-11-03 18:36:27,496][0m A new study created in memory with name: optuna[0m
[32m[I 2023-11-03 18:36:27,510][0m A new study created in memory with name: optuna[0m
2023-11-03 18:36:33,720	WARNING util.py:214 -- The `start_trial` operation took 0.798 s, which may be a performance bottleneck.
2023-11-03 18:38:28,204	WARNING util.py:214 -- The `start_trial` operation took 0.514 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 18:36:30 (running for 00:00:02.77)
Memory usage on this node: 15.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 4.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1/1000000 (1 RUNNING)


== Status ==
Current time: 2023-11-03 18:36:57 (running for 00:00:30.42)
Memory usage on this node: 17.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 56.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 14/1000000 (14 RUNNING)


== Status ==
Current time: 2023-11-03 18:37:04 (running for 00:00:36.86)
Memory usage on this node: 18.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 60.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 15/1000000 (15 RUNNING)


== Status ==
Current time: 2023-11-03 18:37:04 (running for 00:00:36.90)
Memory usage on this node: 18.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 60.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: dab21ffc with val_loss=498.99596938568146 and parameters={'n_estimators': 10, 'max_depth': 2, 'min_child_weight': 0.007542436216426655, 'learning_rate': 0.4864879854106905, 'subsample': 0.31148844204215487, 'colsample_bylevel': 0.46110388279105274, 'colsample_bytree': 0.7589960152492904, 'reg_alpha': 0.001152836621937114, 'reg_lambda': 0.2924499728221112, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 16/1000000 (1 PENDING, 15 RUNNING)


== Status ==
Current time: 2023-11-03 18:37:09 (running for 00:00:41.97)
Memory usage on this node: 18.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d7ff3dec with val_loss=484.06393470117274 and parameters={'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.29999999999999993, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 35/1000000 (1 PENDING, 31 RUNNING, 3 TERMINATED)


== Status ==
Current time: 2023-11-03 18:37:46 (running for 00:01:19.08)
Memory usage on this node: 21.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d7ff3dec with val_loss=484.06393470117274 and parameters={'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.29999999999999993, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 35/1000000 (32 RUNNING, 3 TERMINATED)


== Status ==
Current time: 2023-11-03 18:37:51 (running for 00:01:24.19)
Memory usage on this node: 21.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d7ff3dec with val_loss=484.06393470117274 and parameters={'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.29999999999999993, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 36/1000000 (31 RUNNING, 5 TERMINATED)


== Status ==
Current time: 2023-11-03 18:37:57 (running for 00:01:30.37)
Memory usage on this node: 21.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d7ff3dec with val_loss=484.06393470117274 and parameters={'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.29999999999999993, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 50/1000000 (31 RUNNING, 19 TERMINATED)


== Status ==
Current time: 2023-11-03 18:38:12 (running for 00:01:44.45)
Memory usage on this node: 21.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d7ff3dec with val_loss=484.06393470117274 and parameters={'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.29999999999999993, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 51/1000000 (1 PENDING, 31 RUNNING, 19 TERMINATED)


== Status ==
Current time: 2023-11-03 18:38:17 (running for 00:01:49.50)
Memory usage on this node: 22.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 09ffaba8 with val_loss=483.3824170570909 and parameters={'n_estimators': 19, 'max_depth': 6, 'min_child_weight': 1.4286246232619986, 'learning_rate': 0.17561193248220394, 'subsample': 0.9110003705945974, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8625855998922161, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.14369373704832392, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 66/1000000 (1 PENDING, 30 RUNNING, 35 TERMINATED)


== Status ==
Current time: 2023-11-03 18:38:24 (running for 00:01:57.14)
Memory usage on this node: 22.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 09ffaba8 with val_loss=483.3824170570909 and parameters={'n_estimators': 19, 'max_depth': 6, 'min_child_weight': 1.4286246232619986, 'learning_rate': 0.17561193248220394, 'subsample': 0.9110003705945974, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8625855998922161, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.14369373704832392, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 74/1000000 (1 PENDING, 30 RUNNING, 43 TERMINATED)


== Status ==
Current time: 2023-11-03 18:38:29 (running for 00:02:02.32)
Memory usage on this node: 22.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 09ffaba8 with val_loss=483.3824170570909 and parameters={'n_estimators': 19, 'max_depth': 6, 'min_child_weight': 1.4286246232619986, 'learning_rate': 0.17561193248220394, 'subsample': 0.9110003705945974, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8625855998922161, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.14369373704832392, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 79/1000000 (1 PENDING, 31 RUNNING, 47 TERMINATED)


2023-11-03 18:39:02,329	WARNING util.py:214 -- The `start_trial` operation took 0.790 s, which may be a performance bottleneck.
2023-11-03 18:39:49,354	WARNING util.py:214 -- The `start_trial` operation took 1.140 s, which may be a performance bottleneck.
2023-11-03 18:39:56,978	WARNING util.py:214 -- The `start_trial` operation took 0.589 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 18:38:57 (running for 00:02:29.55)
Memory usage on this node: 22.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 195fe61d with val_loss=481.58875810576154 and parameters={'n_estimators': 71, 'max_depth': 5, 'min_child_weight': 10.13988550375854, 'learning_rate': 0.07967285653958725, 'subsample': 0.9449939497232395, 'colsample_bylevel': 0.9657899536690636, 'colsample_bytree': 0.8486333628749121, 'reg_alpha': 0.006071449702897917, 'reg_lambda': 0.3959421879798694, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 79/1000000 (1 PENDING, 31 RUNNING, 47 TERMINATED)


== Status ==
Current time: 2023-11-03 18:39:02 (running for 00:02:34.75)
Memory usage on this node: 23.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 1639e814 with val_loss=480.8349524716461 and parameters={'n_estimators': 69, 'max_depth': 4, 'min_child_weight': 1.0990981881180875, 'learning_rate': 0.24918945798018013, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.002393288320124817, 'reg_lambda': 1.0136537325263002, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 90/1000000 (31 RUNNING, 59 TERMINATED)


== Status ==
Current time: 2023-11-03 18:39:17 (running for 00:02:50.32)
Memory usage on this node: 23.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 1639e814 with val_loss=480.8349524716461 and parameters={'n_estimators': 69, 'max_depth': 4, 'min_child_weight': 1.0990981881180875, 'learning_rate': 0.24918945798018013, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.002393288320124817, 'reg_lambda': 1.0136537325263002, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 91/1000000 (1 PENDING, 31 RUNNING, 59 TERMINATED)


== Status ==
Current time: 2023-11-03 18:39:22 (running for 00:02:55.33)
Memory usage on this node: 23.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 1639e814 with val_loss=480.8349524716461 and parameters={'n_estimators': 69, 'max_depth': 4, 'min_child_weight': 1.0990981881180875, 'learning_rate': 0.24918945798018013, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.002393288320124817, 'reg_lambda': 1.0136537325263002, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 106/1000000 (1 PENDING, 30 RUNNING, 75 TERMINATED)


== Status ==
Current time: 2023-11-03 18:39:45 (running for 00:03:17.93)
Memory usage on this node: 23.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 1639e814 with val_loss=480.8349524716461 and parameters={'n_estimators': 69, 'max_depth': 4, 'min_child_weight': 1.0990981881180875, 'learning_rate': 0.24918945798018013, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.002393288320124817, 'reg_lambda': 1.0136537325263002, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 106/1000000 (31 RUNNING, 75 TERMINATED)


== Status ==
Current time: 2023-11-03 18:39:50 (running for 00:03:23.26)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3e307075 with val_loss=480.4265491801927 and parameters={'n_estimators': 125, 'max_depth': 4, 'min_child_weight': 0.1735610671247028, 'learning_rate': 0.12079257389941757, 'subsample': 1.0, 'colsample_bylevel': 0.9446275800544811, 'colsample_bytree': 0.7905718703543153, 'reg_alpha': 0.0018896501708835734, 'reg_lambda': 1.5312650200398432, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 120/1000000 (31 RUNNING, 89 TERMINATED)


== Status ==
Current time: 2023-11-03 18:39:56 (running for 00:03:28.60)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3e307075 with val_loss=480.4265491801927 and parameters={'n_estimators': 125, 'max_depth': 4, 'min_child_weight': 0.1735610671247028, 'learning_rate': 0.12079257389941757, 'subsample': 1.0, 'colsample_bylevel': 0.9446275800544811, 'colsample_bytree': 0.7905718703543153, 'reg_alpha': 0.0018896501708835734, 'reg_lambda': 1.5312650200398432, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 131/1000000 (31 RUNNING, 100 TERMINATED)


== Status ==
Current time: 2023-11-03 18:40:05 (running for 00:03:37.45)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3e307075 with val_loss=480.4265491801927 and parameters={'n_estimators': 125, 'max_depth': 4, 'min_child_weight': 0.1735610671247028, 'learning_rate': 0.12079257389941757, 'subsample': 1.0, 'colsample_bylevel': 0.9446275800544811, 'colsample_bytree': 0.7905718703543153, 'reg_alpha': 0.0018896501708835734, 'reg_lambda': 1.5312650200398432, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 135/1000000 (32 RUNNING, 103 TERMINATED)


== Status ==
Current time: 2023-11-03 18:40:46 (running for 00:04:19.30)
Memory usage on this node: 24.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3e307075 with val_loss=480.4265491801927 and parameters={'n_estimators': 125, 'max_depth': 4, 'min_child_weight': 0.1735610671247028, 'learning_rate': 0.12079257389941757, 'subsample': 1.0, 'colsample_bylevel': 0.9446275800544811, 'colsample_bytree': 0.7905718703543153, 'reg_alpha': 0.0018896501708835734, 'reg_lambda': 1.5312650200398432, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 135/1000000 (32 RUNNING, 103 TERMINATED)


== Status ==
Current time: 2023-11-03 18:40:52 (running for 00:04:24.45)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3e307075 with val_loss=480.4265491801927 and parameters={'n_estimators': 125, 'max_depth': 4, 'min_child_weight': 0.1735610671247028, 'learning_rate': 0.12079257389941757, 'subsample': 1.0, 'colsample_bylevel': 0.9446275800544811, 'colsample_bytree': 0.7905718703543153, 'reg_alpha': 0.0018896501708835734, 'reg_lambda': 1.5312650200398432, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 148/1000000 (32 RUNNING, 116 TERMINATED)


2023-11-03 18:43:45,566	WARNING util.py:214 -- The `start_trial` operation took 1.048 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 18:41:14 (running for 00:04:47.14)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3e307075 with val_loss=480.4265491801927 and parameters={'n_estimators': 125, 'max_depth': 4, 'min_child_weight': 0.1735610671247028, 'learning_rate': 0.12079257389941757, 'subsample': 1.0, 'colsample_bylevel': 0.9446275800544811, 'colsample_bytree': 0.7905718703543153, 'reg_alpha': 0.0018896501708835734, 'reg_lambda': 1.5312650200398432, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 148/1000000 (32 RUNNING, 116 TERMINATED)


== Status ==
Current time: 2023-11-03 18:41:19 (running for 00:04:52.16)
Memory usage on this node: 23.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3e307075 with val_loss=480.4265491801927 and parameters={'n_estimators': 125, 'max_depth': 4, 'min_child_weight': 0.1735610671247028, 'learning_rate': 0.12079257389941757, 'subsample': 1.0, 'colsample_bylevel': 0.9446275800544811, 'colsample_bytree': 0.7905718703543153, 'reg_alpha': 0.0018896501708835734, 'reg_lambda': 1.5312650200398432, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 164/1000000 (1 PENDING, 30 RUNNING, 133 TERMINATED)


== Status ==
Current time: 2023-11-03 18:41:59 (running for 00:05:32.21)
Memory usage on this node: 24.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3e307075 with val_loss=480.4265491801927 and parameters={'n_estimators': 125, 'max_depth': 4, 'min_child_weight': 0.1735610671247028, 'learning_rate': 0.12079257389941757, 'subsample': 1.0, 'colsample_bylevel': 0.9446275800544811, 'colsample_bytree': 0.7905718703543153, 'reg_alpha': 0.0018896501708835734, 'reg_lambda': 1.5312650200398432, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 164/1000000 (31 RUNNING, 133 TERMINATED)


== Status ==
Current time: 2023-11-03 18:42:04 (running for 00:05:37.32)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3e307075 with val_loss=480.4265491801927 and parameters={'n_estimators': 125, 'max_depth': 4, 'min_child_weight': 0.1735610671247028, 'learning_rate': 0.12079257389941757, 'subsample': 1.0, 'colsample_bylevel': 0.9446275800544811, 'colsample_bytree': 0.7905718703543153, 'reg_alpha': 0.0018896501708835734, 'reg_lambda': 1.5312650200398432, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 178/1000000 (1 PENDING, 31 RUNNING, 146 TERMINATED)


== Status ==
Current time: 2023-11-03 18:42:45 (running for 00:06:18.32)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3e307075 with val_loss=480.4265491801927 and parameters={'n_estimators': 125, 'max_depth': 4, 'min_child_weight': 0.1735610671247028, 'learning_rate': 0.12079257389941757, 'subsample': 1.0, 'colsample_bylevel': 0.9446275800544811, 'colsample_bytree': 0.7905718703543153, 'reg_alpha': 0.0018896501708835734, 'reg_lambda': 1.5312650200398432, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 178/1000000 (32 RUNNING, 146 TERMINATED)


== Status ==
Current time: 2023-11-03 18:42:54 (running for 00:06:26.84)
Memory usage on this node: 23.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3e307075 with val_loss=480.4265491801927 and parameters={'n_estimators': 125, 'max_depth': 4, 'min_child_weight': 0.1735610671247028, 'learning_rate': 0.12079257389941757, 'subsample': 1.0, 'colsample_bylevel': 0.9446275800544811, 'colsample_bytree': 0.7905718703543153, 'reg_alpha': 0.0018896501708835734, 'reg_lambda': 1.5312650200398432, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 178/1000000 (32 RUNNING, 146 TERMINATED)


== Status ==
Current time: 2023-11-03 18:42:59 (running for 00:06:31.98)
Memory usage on this node: 23.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3e307075 with val_loss=480.4265491801927 and parameters={'n_estimators': 125, 'max_depth': 4, 'min_child_weight': 0.1735610671247028, 'learning_rate': 0.12079257389941757, 'subsample': 1.0, 'colsample_bylevel': 0.9446275800544811, 'colsample_bytree': 0.7905718703543153, 'reg_alpha': 0.0018896501708835734, 'reg_lambda': 1.5312650200398432, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 193/1000000 (31 RUNNING, 162 TERMINATED)


== Status ==
Current time: 2023-11-03 18:43:42 (running for 00:07:15.17)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3e307075 with val_loss=480.4265491801927 and parameters={'n_estimators': 125, 'max_depth': 4, 'min_child_weight': 0.1735610671247028, 'learning_rate': 0.12079257389941757, 'subsample': 1.0, 'colsample_bylevel': 0.9446275800544811, 'colsample_bytree': 0.7905718703543153, 'reg_alpha': 0.0018896501708835734, 'reg_lambda': 1.5312650200398432, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 194/1000000 (1 PENDING, 31 RUNNING, 162 TERMINATED)


== Status ==
Current time: 2023-11-03 18:43:47 (running for 00:07:20.25)
Memory usage on this node: 23.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3e307075 with val_loss=480.4265491801927 and parameters={'n_estimators': 125, 'max_depth': 4, 'min_child_weight': 0.1735610671247028, 'learning_rate': 0.12079257389941757, 'subsample': 1.0, 'colsample_bylevel': 0.9446275800544811, 'colsample_bytree': 0.7905718703543153, 'reg_alpha': 0.0018896501708835734, 'reg_lambda': 1.5312650200398432, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 204/1000000 (31 RUNNING, 173 TERMINATED)


== Status ==
Current time: 2023-11-03 18:44:20 (running for 00:07:53.12)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 3e307075 with val_loss=480.4265491801927 and parameters={'n_estimators': 125, 'max_depth': 4, 'min_child_weight': 0.1735610671247028, 'learning_rate': 0.12079257389941757, 'subsample': 1.0, 'colsample_bylevel': 0.9446275800544811, 'colsample_bytree': 0.7905718703543153, 'reg_alpha': 0.0018896501708835734, 'reg_lambda': 1.5312650200398432, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 205/1000000 (1 PENDING, 31 RUNNING, 173 TERMINATED)


2023-11-03 18:45:02,000	WARNING util.py:214 -- The `start_trial` operation took 0.718 s, which may be a performance bottleneck.
2023-11-03 18:46:49,538	WARNING util.py:214 -- The `start_trial` operation took 0.619 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 18:44:28 (running for 00:08:00.87)
Memory usage on this node: 23.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c0db24a8 with val_loss=480.4222239848876 and parameters={'n_estimators': 486, 'max_depth': 5, 'min_child_weight': 0.14496806953121316, 'learning_rate': 0.06697454476881624, 'subsample': 0.6997600003476192, 'colsample_bylevel': 0.21500446012860844, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.11783876285463536, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 218/1000000 (1 PENDING, 30 RUNNING, 187 TERMINATED)


== Status ==
Current time: 2023-11-03 18:44:56 (running for 00:08:29.11)
Memory usage on this node: 24.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c0db24a8 with val_loss=480.4222239848876 and parameters={'n_estimators': 486, 'max_depth': 5, 'min_child_weight': 0.14496806953121316, 'learning_rate': 0.06697454476881624, 'subsample': 0.6997600003476192, 'colsample_bylevel': 0.21500446012860844, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.11783876285463536, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 218/1000000 (31 RUNNING, 187 TERMINATED)


== Status ==
Current time: 2023-11-03 18:45:02 (running for 00:08:34.43)
Memory usage on this node: 24.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: be8c2039 with val_loss=480.1610511505137 and parameters={'n_estimators': 343, 'max_depth': 4, 'min_child_weight': 0.04848017940335291, 'learning_rate': 0.05270345958650989, 'subsample': 0.8606273372315839, 'colsample_bylevel': 0.3291698530591124, 'colsample_bytree': 0.9262867388626229, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.044757099016447754, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 230/1000000 (31 RUNNING, 199 TERMINATED)


== Status ==
Current time: 2023-11-03 18:45:07 (running for 00:08:39.63)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: be8c2039 with val_loss=480.1610511505137 and parameters={'n_estimators': 343, 'max_depth': 4, 'min_child_weight': 0.04848017940335291, 'learning_rate': 0.05270345958650989, 'subsample': 0.8606273372315839, 'colsample_bylevel': 0.3291698530591124, 'colsample_bytree': 0.9262867388626229, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.044757099016447754, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 241/1000000 (1 PENDING, 30 RUNNING, 210 TERMINATED)


== Status ==
Current time: 2023-11-03 18:45:50 (running for 00:09:22.89)
Memory usage on this node: 24.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: be8c2039 with val_loss=480.1610511505137 and parameters={'n_estimators': 343, 'max_depth': 4, 'min_child_weight': 0.04848017940335291, 'learning_rate': 0.05270345958650989, 'subsample': 0.8606273372315839, 'colsample_bylevel': 0.3291698530591124, 'colsample_bytree': 0.9262867388626229, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.044757099016447754, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 241/1000000 (31 RUNNING, 210 TERMINATED)


== Status ==
Current time: 2023-11-03 18:45:55 (running for 00:09:27.94)
Memory usage on this node: 23.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: be8c2039 with val_loss=480.1610511505137 and parameters={'n_estimators': 343, 'max_depth': 4, 'min_child_weight': 0.04848017940335291, 'learning_rate': 0.05270345958650989, 'subsample': 0.8606273372315839, 'colsample_bylevel': 0.3291698530591124, 'colsample_bytree': 0.9262867388626229, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.044757099016447754, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 255/1000000 (32 RUNNING, 223 TERMINATED)


== Status ==
Current time: 2023-11-03 18:46:44 (running for 00:10:17.27)
Memory usage on this node: 24.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: be8c2039 with val_loss=480.1610511505137 and parameters={'n_estimators': 343, 'max_depth': 4, 'min_child_weight': 0.04848017940335291, 'learning_rate': 0.05270345958650989, 'subsample': 0.8606273372315839, 'colsample_bylevel': 0.3291698530591124, 'colsample_bytree': 0.9262867388626229, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.044757099016447754, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 255/1000000 (32 RUNNING, 223 TERMINATED)


== Status ==
Current time: 2023-11-03 18:46:50 (running for 00:10:22.50)
Memory usage on this node: 24.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 29aa7d6d with val_loss=479.60041685545883 and parameters={'n_estimators': 394, 'max_depth': 3, 'min_child_weight': 0.024337007423056365, 'learning_rate': 0.15714637545664714, 'subsample': 1.0, 'colsample_bylevel': 0.4283467840947942, 'colsample_bytree': 0.9527919600328474, 'reg_alpha': 0.0012111633633716784, 'reg_lambda': 0.0291938866484351, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 267/1000000 (31 RUNNING, 236 TERMINATED)


== Status ==
Current time: 2023-11-03 18:47:51 (running for 00:11:23.58)
Memory usage on this node: 24.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 29aa7d6d with val_loss=479.60041685545883 and parameters={'n_estimators': 394, 'max_depth': 3, 'min_child_weight': 0.024337007423056365, 'learning_rate': 0.15714637545664714, 'subsample': 1.0, 'colsample_bylevel': 0.4283467840947942, 'colsample_bytree': 0.9527919600328474, 'reg_alpha': 0.0012111633633716784, 'reg_lambda': 0.0291938866484351, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 268/1000000 (1 PENDING, 31 RUNNING, 236 TERMINATED)


== Status ==
Current time: 2023-11-03 18:47:56 (running for 00:11:28.62)
Memory usage on this node: 24.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 29aa7d6d with val_loss=479.60041685545883 and parameters={'n_estimators': 394, 'max_depth': 3, 'min_child_weight': 0.024337007423056365, 'learning_rate': 0.15714637545664714, 'subsample': 1.0, 'colsample_bylevel': 0.4283467840947942, 'colsample_bytree': 0.9527919600328474, 'reg_alpha': 0.0012111633633716784, 'reg_lambda': 0.0291938866484351, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 277/1000000 (31 RUNNING, 246 TERMINATED)


== Status ==
Current time: 2023-11-03 18:48:01 (running for 00:11:33.83)
Memory usage on this node: 24.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 29aa7d6d with val_loss=479.60041685545883 and parameters={'n_estimators': 394, 'max_depth': 3, 'min_child_weight': 0.024337007423056365, 'learning_rate': 0.15714637545664714, 'subsample': 1.0, 'colsample_bylevel': 0.4283467840947942, 'colsample_bytree': 0.9527919600328474, 'reg_alpha': 0.0012111633633716784, 'reg_lambda': 0.0291938866484351, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 286/1000000 (31 RUNNING, 255 TERMINATED)


== Status ==
Current time: 2023-11-03 18:49:37 (running for 00:13:09.82)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 29aa7d6d with val_loss=479.60041685545883 and parameters={'n_estimators': 394, 'max_depth': 3, 'min_child_weight': 0.024337007423056365, 'learning_rate': 0.15714637545664714, 'subsample': 1.0, 'colsample_bylevel': 0.4283467840947942, 'colsample_bytree': 0.9527919600328474, 'reg_alpha': 0.0012111633633716784, 'reg_lambda': 0.0291938866484351, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 287/1000000 (32 RUNNING, 255 TERMINATED)


== Status ==
Current time: 2023-11-03 18:50:14 (running for 00:13:47.16)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 29aa7d6d with val_loss=479.60041685545883 and parameters={'n_estimators': 394, 'max_depth': 3, 'min_child_weight': 0.024337007423056365, 'learning_rate': 0.15714637545664714, 'subsample': 1.0, 'colsample_bylevel': 0.4283467840947942, 'colsample_bytree': 0.9527919600328474, 'reg_alpha': 0.0012111633633716784, 'reg_lambda': 0.0291938866484351, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 287/1000000 (32 RUNNING, 255 TERMINATED)


== Status ==
Current time: 2023-11-03 18:50:19 (running for 00:13:52.34)
Memory usage on this node: 25.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 6fe5cea5 with val_loss=479.12329020518683 and parameters={'n_estimators': 239, 'max_depth': 5, 'min_child_weight': 0.13708694588419673, 'learning_rate': 0.07865124231627124, 'subsample': 1.0, 'colsample_bylevel': 0.4058302317970512, 'colsample_bytree': 1.0, 'reg_alpha': 0.010877981048708437, 'reg_lambda': 0.1075598982594782, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 297/1000000 (31 RUNNING, 266 TERMINATED)


== Status ==
Current time: 2023-11-03 18:50:25 (running for 00:13:57.59)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 6fe5cea5 with val_loss=479.12329020518683 and parameters={'n_estimators': 239, 'max_depth': 5, 'min_child_weight': 0.13708694588419673, 'learning_rate': 0.07865124231627124, 'subsample': 1.0, 'colsample_bylevel': 0.4058302317970512, 'colsample_bytree': 1.0, 'reg_alpha': 0.010877981048708437, 'reg_lambda': 0.1075598982594782, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 309/1000000 (31 RUNNING, 278 TERMINATED)


== Status ==
Current time: 2023-11-03 18:50:33 (running for 00:14:05.70)
Memory usage on this node: 25.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 6fe5cea5 with val_loss=479.12329020518683 and parameters={'n_estimators': 239, 'max_depth': 5, 'min_child_weight': 0.13708694588419673, 'learning_rate': 0.07865124231627124, 'subsample': 1.0, 'colsample_bylevel': 0.4058302317970512, 'colsample_bytree': 1.0, 'reg_alpha': 0.010877981048708437, 'reg_lambda': 0.1075598982594782, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 312/1000000 (32 RUNNING, 280 TERMINATED)


== Status ==
Current time: 2023-11-03 18:51:59 (running for 00:15:31.81)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 6fe5cea5 with val_loss=479.12329020518683 and parameters={'n_estimators': 239, 'max_depth': 5, 'min_child_weight': 0.13708694588419673, 'learning_rate': 0.07865124231627124, 'subsample': 1.0, 'colsample_bylevel': 0.4058302317970512, 'colsample_bytree': 1.0, 'reg_alpha': 0.010877981048708437, 'reg_lambda': 0.1075598982594782, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 312/1000000 (32 RUNNING, 280 TERMINATED)


== Status ==
Current time: 2023-11-03 18:52:04 (running for 00:15:37.16)
Memory usage on this node: 25.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c7026f0a with val_loss=479.0468959643289 and parameters={'n_estimators': 272, 'max_depth': 5, 'min_child_weight': 0.03616935675937006, 'learning_rate': 0.07492175141355718, 'subsample': 1.0, 'colsample_bylevel': 0.31935149589769857, 'colsample_bytree': 1.0, 'reg_alpha': 0.07094295299429064, 'reg_lambda': 0.0069734288883372166, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 323/1000000 (31 RUNNING, 292 TERMINATED)


== Status ==
Current time: 2023-11-03 18:53:07 (running for 00:16:40.20)
Memory usage on this node: 25.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c7026f0a with val_loss=479.0468959643289 and parameters={'n_estimators': 272, 'max_depth': 5, 'min_child_weight': 0.03616935675937006, 'learning_rate': 0.07492175141355718, 'subsample': 1.0, 'colsample_bylevel': 0.31935149589769857, 'colsample_bytree': 1.0, 'reg_alpha': 0.07094295299429064, 'reg_lambda': 0.0069734288883372166, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 324/1000000 (1 PENDING, 31 RUNNING, 292 TERMINATED)


== Status ==
Current time: 2023-11-03 18:53:13 (running for 00:16:45.57)
Memory usage on this node: 25.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c7026f0a with val_loss=479.0468959643289 and parameters={'n_estimators': 272, 'max_depth': 5, 'min_child_weight': 0.03616935675937006, 'learning_rate': 0.07492175141355718, 'subsample': 1.0, 'colsample_bylevel': 0.31935149589769857, 'colsample_bytree': 1.0, 'reg_alpha': 0.07094295299429064, 'reg_lambda': 0.0069734288883372166, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 333/1000000 (31 RUNNING, 302 TERMINATED)


2023-11-03 18:53:19,298	WARNING util.py:214 -- The `start_trial` operation took 0.593 s, which may be a performance bottleneck.
2023-11-03 18:53:22,592	WARNING util.py:214 -- The `start_trial` operation took 0.586 s, which may be a performance bottleneck.
2023-11-03 18:54:41,325	WARNING util.py:214 -- The `start_trial` operation took 0.921 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 18:53:18 (running for 00:16:50.67)
Memory usage on this node: 25.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c7026f0a with val_loss=479.0468959643289 and parameters={'n_estimators': 272, 'max_depth': 5, 'min_child_weight': 0.03616935675937006, 'learning_rate': 0.07492175141355718, 'subsample': 1.0, 'colsample_bylevel': 0.31935149589769857, 'colsample_bytree': 1.0, 'reg_alpha': 0.07094295299429064, 'reg_lambda': 0.0069734288883372166, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 343/1000000 (1 PENDING, 31 RUNNING, 311 TERMINATED)


== Status ==
Current time: 2023-11-03 18:53:25 (running for 00:16:58.17)
Memory usage on this node: 25.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c7026f0a with val_loss=479.0468959643289 and parameters={'n_estimators': 272, 'max_depth': 5, 'min_child_weight': 0.03616935675937006, 'learning_rate': 0.07492175141355718, 'subsample': 1.0, 'colsample_bylevel': 0.31935149589769857, 'colsample_bytree': 1.0, 'reg_alpha': 0.07094295299429064, 'reg_lambda': 0.0069734288883372166, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 347/1000000 (32 RUNNING, 315 TERMINATED)


== Status ==
Current time: 2023-11-03 18:54:08 (running for 00:17:40.93)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c7026f0a with val_loss=479.0468959643289 and parameters={'n_estimators': 272, 'max_depth': 5, 'min_child_weight': 0.03616935675937006, 'learning_rate': 0.07492175141355718, 'subsample': 1.0, 'colsample_bylevel': 0.31935149589769857, 'colsample_bytree': 1.0, 'reg_alpha': 0.07094295299429064, 'reg_lambda': 0.0069734288883372166, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 347/1000000 (32 RUNNING, 315 TERMINATED)


== Status ==
Current time: 2023-11-03 18:54:13 (running for 00:17:45.99)
Memory usage on this node: 25.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c7026f0a with val_loss=479.0468959643289 and parameters={'n_estimators': 272, 'max_depth': 5, 'min_child_weight': 0.03616935675937006, 'learning_rate': 0.07492175141355718, 'subsample': 1.0, 'colsample_bylevel': 0.31935149589769857, 'colsample_bytree': 1.0, 'reg_alpha': 0.07094295299429064, 'reg_lambda': 0.0069734288883372166, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 357/1000000 (32 RUNNING, 325 TERMINATED)


== Status ==
Current time: 2023-11-03 18:54:39 (running for 00:18:11.74)
Memory usage on this node: 26.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c7026f0a with val_loss=479.0468959643289 and parameters={'n_estimators': 272, 'max_depth': 5, 'min_child_weight': 0.03616935675937006, 'learning_rate': 0.07492175141355718, 'subsample': 1.0, 'colsample_bylevel': 0.31935149589769857, 'colsample_bytree': 1.0, 'reg_alpha': 0.07094295299429064, 'reg_lambda': 0.0069734288883372166, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 357/1000000 (32 RUNNING, 325 TERMINATED)


== Status ==
Current time: 2023-11-03 18:54:44 (running for 00:18:16.91)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c7026f0a with val_loss=479.0468959643289 and parameters={'n_estimators': 272, 'max_depth': 5, 'min_child_weight': 0.03616935675937006, 'learning_rate': 0.07492175141355718, 'subsample': 1.0, 'colsample_bylevel': 0.31935149589769857, 'colsample_bytree': 1.0, 'reg_alpha': 0.07094295299429064, 'reg_lambda': 0.0069734288883372166, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 368/1000000 (31 RUNNING, 337 TERMINATED)


== Status ==
Current time: 2023-11-03 18:55:34 (running for 00:19:07.29)
Memory usage on this node: 25.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c7026f0a with val_loss=479.0468959643289 and parameters={'n_estimators': 272, 'max_depth': 5, 'min_child_weight': 0.03616935675937006, 'learning_rate': 0.07492175141355718, 'subsample': 1.0, 'colsample_bylevel': 0.31935149589769857, 'colsample_bytree': 1.0, 'reg_alpha': 0.07094295299429064, 'reg_lambda': 0.0069734288883372166, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 369/1000000 (1 PENDING, 31 RUNNING, 337 TERMINATED)


== Status ==
Current time: 2023-11-03 18:55:40 (running for 00:19:12.50)
Memory usage on this node: 25.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c7026f0a with val_loss=479.0468959643289 and parameters={'n_estimators': 272, 'max_depth': 5, 'min_child_weight': 0.03616935675937006, 'learning_rate': 0.07492175141355718, 'subsample': 1.0, 'colsample_bylevel': 0.31935149589769857, 'colsample_bytree': 1.0, 'reg_alpha': 0.07094295299429064, 'reg_lambda': 0.0069734288883372166, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 381/1000000 (1 PENDING, 30 RUNNING, 350 TERMINATED)


== Status ==
Current time: 2023-11-03 18:56:50 (running for 00:20:22.87)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c7026f0a with val_loss=479.0468959643289 and parameters={'n_estimators': 272, 'max_depth': 5, 'min_child_weight': 0.03616935675937006, 'learning_rate': 0.07492175141355718, 'subsample': 1.0, 'colsample_bylevel': 0.31935149589769857, 'colsample_bytree': 1.0, 'reg_alpha': 0.07094295299429064, 'reg_lambda': 0.0069734288883372166, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 381/1000000 (31 RUNNING, 350 TERMINATED)


== Status ==
Current time: 2023-11-03 18:56:55 (running for 00:20:28.08)
Memory usage on this node: 26.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c7026f0a with val_loss=479.0468959643289 and parameters={'n_estimators': 272, 'max_depth': 5, 'min_child_weight': 0.03616935675937006, 'learning_rate': 0.07492175141355718, 'subsample': 1.0, 'colsample_bylevel': 0.31935149589769857, 'colsample_bytree': 1.0, 'reg_alpha': 0.07094295299429064, 'reg_lambda': 0.0069734288883372166, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 393/1000000 (31 RUNNING, 362 TERMINATED)


2023-11-03 18:58:51,837	WARNING util.py:214 -- The `start_trial` operation took 1.173 s, which may be a performance bottleneck.
2023-11-03 19:00:09,216	WARNING util.py:214 -- The `start_trial` operation took 0.524 s, which may be a performance bottleneck.
2023-11-03 19:02:26,915	WARNING util.py:214 -- The `start_trial` operation took 0.540 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 18:57:00 (running for 00:20:33.30)
Memory usage on this node: 26.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c7026f0a with val_loss=479.0468959643289 and parameters={'n_estimators': 272, 'max_depth': 5, 'min_child_weight': 0.03616935675937006, 'learning_rate': 0.07492175141355718, 'subsample': 1.0, 'colsample_bylevel': 0.31935149589769857, 'colsample_bytree': 1.0, 'reg_alpha': 0.07094295299429064, 'reg_lambda': 0.0069734288883372166, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 402/1000000 (32 RUNNING, 370 TERMINATED)


== Status ==
Current time: 2023-11-03 18:58:48 (running for 00:22:21.29)
Memory usage on this node: 27.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: c7026f0a with val_loss=479.0468959643289 and parameters={'n_estimators': 272, 'max_depth': 5, 'min_child_weight': 0.03616935675937006, 'learning_rate': 0.07492175141355718, 'subsample': 1.0, 'colsample_bylevel': 0.31935149589769857, 'colsample_bytree': 1.0, 'reg_alpha': 0.07094295299429064, 'reg_lambda': 0.0069734288883372166, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 402/1000000 (32 RUNNING, 370 TERMINATED)


== Status ==
Current time: 2023-11-03 18:58:54 (running for 00:22:26.57)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ad with val_loss=478.91935545100614 and parameters={'n_estimators': 590, 'max_depth': 4, 'min_child_weight': 5.077071164962135, 'learning_rate': 0.058443238663675665, 'subsample': 0.8692384119418014, 'colsample_bylevel': 0.5316480423141845, 'colsample_bytree': 0.8134165079569555, 'reg_alpha': 1.8788361558121107, 'reg_lambda': 0.015852894848852495, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 408/1000000 (31 RUNNING, 377 TERMINATED)


== Status ==
Current time: 2023-11-03 18:59:58 (running for 00:23:31.11)
Memory usage on this node: 26.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ad with val_loss=478.91935545100614 and parameters={'n_estimators': 590, 'max_depth': 4, 'min_child_weight': 5.077071164962135, 'learning_rate': 0.058443238663675665, 'subsample': 0.8692384119418014, 'colsample_bylevel': 0.5316480423141845, 'colsample_bytree': 0.8134165079569555, 'reg_alpha': 1.8788361558121107, 'reg_lambda': 0.015852894848852495, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 409/1000000 (1 PENDING, 31 RUNNING, 377 TERMINATED)


== Status ==
Current time: 2023-11-03 19:00:03 (running for 00:23:36.32)
Memory usage on this node: 27.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ad with val_loss=478.91935545100614 and parameters={'n_estimators': 590, 'max_depth': 4, 'min_child_weight': 5.077071164962135, 'learning_rate': 0.058443238663675665, 'subsample': 0.8692384119418014, 'colsample_bylevel': 0.5316480423141845, 'colsample_bytree': 0.8134165079569555, 'reg_alpha': 1.8788361558121107, 'reg_lambda': 0.015852894848852495, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 419/1000000 (31 RUNNING, 388 TERMINATED)


== Status ==
Current time: 2023-11-03 19:00:09 (running for 00:23:41.87)
Memory usage on this node: 25.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ad with val_loss=478.91935545100614 and parameters={'n_estimators': 590, 'max_depth': 4, 'min_child_weight': 5.077071164962135, 'learning_rate': 0.058443238663675665, 'subsample': 0.8692384119418014, 'colsample_bylevel': 0.5316480423141845, 'colsample_bytree': 0.8134165079569555, 'reg_alpha': 1.8788361558121107, 'reg_lambda': 0.015852894848852495, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 427/1000000 (31 RUNNING, 396 TERMINATED)


== Status ==
Current time: 2023-11-03 19:02:26 (running for 00:25:58.68)
Memory usage on this node: 26.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ad with val_loss=478.91935545100614 and parameters={'n_estimators': 590, 'max_depth': 4, 'min_child_weight': 5.077071164962135, 'learning_rate': 0.058443238663675665, 'subsample': 0.8692384119418014, 'colsample_bylevel': 0.5316480423141845, 'colsample_bytree': 0.8134165079569555, 'reg_alpha': 1.8788361558121107, 'reg_lambda': 0.015852894848852495, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 428/1000000 (1 PENDING, 31 RUNNING, 396 TERMINATED)


== Status ==
Current time: 2023-11-03 19:02:31 (running for 00:26:03.77)
Memory usage on this node: 25.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ae with val_loss=478.901402620703 and parameters={'n_estimators': 745, 'max_depth': 5, 'min_child_weight': 0.6491770920915159, 'learning_rate': 0.029842532645655204, 'subsample': 0.9404249499852889, 'colsample_bylevel': 0.5910233842384885, 'colsample_bytree': 0.7805360253502063, 'reg_alpha': 0.1275370204490719, 'reg_lambda': 0.052190497420415025, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 434/1000000 (31 RUNNING, 403 TERMINATED)


== Status ==
Current time: 2023-11-03 19:04:18 (running for 00:27:50.58)
Memory usage on this node: 25.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ae with val_loss=478.901402620703 and parameters={'n_estimators': 745, 'max_depth': 5, 'min_child_weight': 0.6491770920915159, 'learning_rate': 0.029842532645655204, 'subsample': 0.9404249499852889, 'colsample_bylevel': 0.5910233842384885, 'colsample_bytree': 0.7805360253502063, 'reg_alpha': 0.1275370204490719, 'reg_lambda': 0.052190497420415025, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 435/1000000 (32 RUNNING, 403 TERMINATED)


== Status ==
Current time: 2023-11-03 19:05:19 (running for 00:28:52.17)
Memory usage on this node: 26.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ae with val_loss=478.901402620703 and parameters={'n_estimators': 745, 'max_depth': 5, 'min_child_weight': 0.6491770920915159, 'learning_rate': 0.029842532645655204, 'subsample': 0.9404249499852889, 'colsample_bylevel': 0.5910233842384885, 'colsample_bytree': 0.7805360253502063, 'reg_alpha': 0.1275370204490719, 'reg_lambda': 0.052190497420415025, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 435/1000000 (32 RUNNING, 403 TERMINATED)


2023-11-03 19:06:55,004	WARNING util.py:214 -- The `start_trial` operation took 0.511 s, which may be a performance bottleneck.
2023-11-03 19:08:32,564	WARNING util.py:214 -- The `start_trial` operation took 0.512 s, which may be a performance bottleneck.
2023-11-03 19:09:52,980	WARNING util.py:214 -- The `start_trial` operation took 0.579 s, which may be a performance bottleneck.
2023-11-03 19:12:38,360	WARNING util.py:214 -- The `start_trial` operation took 0.739 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 19:05:24 (running for 00:28:57.35)
Memory usage on this node: 25.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ae with val_loss=478.901402620703 and parameters={'n_estimators': 745, 'max_depth': 5, 'min_child_weight': 0.6491770920915159, 'learning_rate': 0.029842532645655204, 'subsample': 0.9404249499852889, 'colsample_bylevel': 0.5910233842384885, 'colsample_bytree': 0.7805360253502063, 'reg_alpha': 0.1275370204490719, 'reg_lambda': 0.052190497420415025, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 446/1000000 (31 RUNNING, 415 TERMINATED)


== Status ==
Current time: 2023-11-03 19:06:50 (running for 00:30:23.37)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ae with val_loss=478.901402620703 and parameters={'n_estimators': 745, 'max_depth': 5, 'min_child_weight': 0.6491770920915159, 'learning_rate': 0.029842532645655204, 'subsample': 0.9404249499852889, 'colsample_bylevel': 0.5910233842384885, 'colsample_bytree': 0.7805360253502063, 'reg_alpha': 0.1275370204490719, 'reg_lambda': 0.052190497420415025, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 447/1000000 (1 PENDING, 31 RUNNING, 415 TERMINATED)


== Status ==
Current time: 2023-11-03 19:06:56 (running for 00:30:28.67)
Memory usage on this node: 25.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ae with val_loss=478.901402620703 and parameters={'n_estimators': 745, 'max_depth': 5, 'min_child_weight': 0.6491770920915159, 'learning_rate': 0.029842532645655204, 'subsample': 0.9404249499852889, 'colsample_bylevel': 0.5910233842384885, 'colsample_bytree': 0.7805360253502063, 'reg_alpha': 0.1275370204490719, 'reg_lambda': 0.052190497420415025, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 455/1000000 (31 RUNNING, 424 TERMINATED)


== Status ==
Current time: 2023-11-03 19:08:29 (running for 00:32:01.87)
Memory usage on this node: 26.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ae with val_loss=478.901402620703 and parameters={'n_estimators': 745, 'max_depth': 5, 'min_child_weight': 0.6491770920915159, 'learning_rate': 0.029842532645655204, 'subsample': 0.9404249499852889, 'colsample_bylevel': 0.5910233842384885, 'colsample_bytree': 0.7805360253502063, 'reg_alpha': 0.1275370204490719, 'reg_lambda': 0.052190497420415025, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 456/1000000 (1 PENDING, 31 RUNNING, 424 TERMINATED)


== Status ==
Current time: 2023-11-03 19:08:34 (running for 00:32:07.13)
Memory usage on this node: 25.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ae with val_loss=478.901402620703 and parameters={'n_estimators': 745, 'max_depth': 5, 'min_child_weight': 0.6491770920915159, 'learning_rate': 0.029842532645655204, 'subsample': 0.9404249499852889, 'colsample_bylevel': 0.5910233842384885, 'colsample_bytree': 0.7805360253502063, 'reg_alpha': 0.1275370204490719, 'reg_lambda': 0.052190497420415025, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 465/1000000 (1 PENDING, 30 RUNNING, 434 TERMINATED)


== Status ==
Current time: 2023-11-03 19:09:52 (running for 00:33:24.59)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ae with val_loss=478.901402620703 and parameters={'n_estimators': 745, 'max_depth': 5, 'min_child_weight': 0.6491770920915159, 'learning_rate': 0.029842532645655204, 'subsample': 0.9404249499852889, 'colsample_bylevel': 0.5910233842384885, 'colsample_bytree': 0.7805360253502063, 'reg_alpha': 0.1275370204490719, 'reg_lambda': 0.052190497420415025, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 465/1000000 (31 RUNNING, 434 TERMINATED)


== Status ==
Current time: 2023-11-03 19:09:57 (running for 00:33:29.79)
Memory usage on this node: 25.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ae with val_loss=478.901402620703 and parameters={'n_estimators': 745, 'max_depth': 5, 'min_child_weight': 0.6491770920915159, 'learning_rate': 0.029842532645655204, 'subsample': 0.9404249499852889, 'colsample_bylevel': 0.5910233842384885, 'colsample_bytree': 0.7805360253502063, 'reg_alpha': 0.1275370204490719, 'reg_lambda': 0.052190497420415025, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 474/1000000 (31 RUNNING, 443 TERMINATED)


== Status ==
Current time: 2023-11-03 19:11:26 (running for 00:34:58.51)
Memory usage on this node: 25.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ae with val_loss=478.901402620703 and parameters={'n_estimators': 745, 'max_depth': 5, 'min_child_weight': 0.6491770920915159, 'learning_rate': 0.029842532645655204, 'subsample': 0.9404249499852889, 'colsample_bylevel': 0.5910233842384885, 'colsample_bytree': 0.7805360253502063, 'reg_alpha': 0.1275370204490719, 'reg_lambda': 0.052190497420415025, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 475/1000000 (32 RUNNING, 443 TERMINATED)


== Status ==
Current time: 2023-11-03 19:12:34 (running for 00:36:07.15)
Memory usage on this node: 25.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ae with val_loss=478.901402620703 and parameters={'n_estimators': 745, 'max_depth': 5, 'min_child_weight': 0.6491770920915159, 'learning_rate': 0.029842532645655204, 'subsample': 0.9404249499852889, 'colsample_bylevel': 0.5910233842384885, 'colsample_bytree': 0.7805360253502063, 'reg_alpha': 0.1275370204490719, 'reg_lambda': 0.052190497420415025, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 475/1000000 (31 RUNNING, 444 TERMINATED)


== Status ==
Current time: 2023-11-03 19:12:39 (running for 00:36:12.41)
Memory usage on this node: 25.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ae with val_loss=478.901402620703 and parameters={'n_estimators': 745, 'max_depth': 5, 'min_child_weight': 0.6491770920915159, 'learning_rate': 0.029842532645655204, 'subsample': 0.9404249499852889, 'colsample_bylevel': 0.5910233842384885, 'colsample_bytree': 0.7805360253502063, 'reg_alpha': 0.1275370204490719, 'reg_lambda': 0.052190497420415025, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 484/1000000 (32 RUNNING, 452 TERMINATED)


2023-11-03 19:14:15,995	WARNING util.py:214 -- The `start_trial` operation took 0.596 s, which may be a performance bottleneck.
2023-11-03 19:17:56,724	WARNING util.py:214 -- The `start_trial` operation took 0.514 s, which may be a performance bottleneck.
2023-11-03 19:20:18,645	WARNING util.py:214 -- The `start_trial` operation took 0.555 s, which may be a performance bottleneck.
2023-11-03 19:20:20,534	WARNING util.py:214 -- The `start_trial` operation took 0.654 s, which may be a performance bottleneck.
2023-11-03 19:20:23,151	WARNING util.py:214 -- The `start_trial` operation took 0.634 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 19:14:05 (running for 00:37:37.64)
Memory usage on this node: 26.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 855e39ae with val_loss=478.901402620703 and parameters={'n_estimators': 745, 'max_depth': 5, 'min_child_weight': 0.6491770920915159, 'learning_rate': 0.029842532645655204, 'subsample': 0.9404249499852889, 'colsample_bylevel': 0.5910233842384885, 'colsample_bytree': 0.7805360253502063, 'reg_alpha': 0.1275370204490719, 'reg_lambda': 0.052190497420415025, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 484/1000000 (32 RUNNING, 452 TERMINATED)


== Status ==
Current time: 2023-11-03 19:14:10 (running for 00:37:43.05)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: e09eb8de with val_loss=478.7754270960073 and parameters={'n_estimators': 1236, 'max_depth': 6, 'min_child_weight': 0.46190747802958476, 'learning_rate': 0.01224797152511112, 'subsample': 1.0, 'colsample_bylevel': 0.6900508713513978, 'colsample_bytree': 0.6313848754471425, 'reg_alpha': 0.6197527142031248, 'reg_lambda': 0.11457392371371025, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 494/1000000 (31 RUNNING, 463 TERMINATED)


== Status ==
Current time: 2023-11-03 19:14:16 (running for 00:37:48.60)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 502/1000000 (31 RUNNING, 471 TERMINATED)


== Status ==
Current time: 2023-11-03 19:16:09 (running for 00:39:41.66)
Memory usage on this node: 26.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 503/1000000 (1 PENDING, 31 RUNNING, 471 TERMINATED)


== Status ==
Current time: 2023-11-03 19:16:14 (running for 00:39:47.21)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 510/1000000 (1 PENDING, 30 RUNNING, 479 TERMINATED)


== Status ==
Current time: 2023-11-03 19:17:55 (running for 00:41:28.35)
Memory usage on this node: 26.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 510/1000000 (31 RUNNING, 479 TERMINATED)


== Status ==
Current time: 2023-11-03 19:18:01 (running for 00:41:33.92)
Memory usage on this node: 26.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 519/1000000 (31 RUNNING, 488 TERMINATED)


== Status ==
Current time: 2023-11-03 19:20:17 (running for 00:43:50.35)
Memory usage on this node: 27.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 520/1000000 (1 PENDING, 31 RUNNING, 488 TERMINATED)


== Status ==
Current time: 2023-11-03 19:20:23 (running for 00:43:55.81)
Memory usage on this node: 26.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 527/1000000 (32 RUNNING, 495 TERMINATED)


== Status ==
Current time: 2023-11-03 19:22:25 (running for 00:45:57.45)
Memory usage on this node: 27.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 527/1000000 (32 RUNNING, 495 TERMINATED)


2023-11-03 19:30:23,399	WARNING util.py:214 -- The `start_trial` operation took 0.739 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 19:22:30 (running for 00:46:02.81)
Memory usage on this node: 26.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 535/1000000 (1 PENDING, 31 RUNNING, 503 TERMINATED)


== Status ==
Current time: 2023-11-03 19:24:14 (running for 00:47:46.62)
Memory usage on this node: 26.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 535/1000000 (32 RUNNING, 503 TERMINATED)


== Status ==
Current time: 2023-11-03 19:25:40 (running for 00:49:13.26)
Memory usage on this node: 27.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 535/1000000 (32 RUNNING, 503 TERMINATED)


== Status ==
Current time: 2023-11-03 19:25:46 (running for 00:49:18.43)
Memory usage on this node: 26.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 543/1000000 (31 RUNNING, 512 TERMINATED)


== Status ==
Current time: 2023-11-03 19:27:23 (running for 00:50:55.55)
Memory usage on this node: 27.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 544/1000000 (1 PENDING, 31 RUNNING, 512 TERMINATED)


== Status ==
Current time: 2023-11-03 19:27:28 (running for 00:51:01.07)
Memory usage on this node: 26.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 551/1000000 (1 PENDING, 31 RUNNING, 519 TERMINATED)


== Status ==
Current time: 2023-11-03 19:29:03 (running for 00:52:35.66)
Memory usage on this node: 27.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 551/1000000 (32 RUNNING, 519 TERMINATED)


== Status ==
Current time: 2023-11-03 19:30:14 (running for 00:53:46.49)
Memory usage on this node: 27.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 551/1000000 (32 RUNNING, 519 TERMINATED)


== Status ==
Current time: 2023-11-03 19:30:19 (running for 00:53:51.70)
Memory usage on this node: 27.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 561/1000000 (31 RUNNING, 530 TERMINATED)


== Status ==
Current time: 2023-11-03 19:30:25 (running for 00:53:57.49)
Memory usage on this node: 26.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 569/1000000 (31 RUNNING, 538 TERMINATED)


2023-11-03 19:35:31,276	WARNING util.py:214 -- The `start_trial` operation took 0.563 s, which may be a performance bottleneck.
2023-11-03 19:35:32,236	WARNING util.py:214 -- The `start_trial` operation took 0.605 s, which may be a performance bottleneck.
2023-11-03 19:35:34,293	WARNING util.py:214 -- The `start_trial` operation took 0.518 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 19:36:30,854 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2422302) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 19:39:16,775	WARNING util.py:214 -- The `start_trial` operation took 0.510 s, which may be a performance bottleneck.
2023-11-03 19:39:17,572	WARNING util.py:214 -- The `start_trial` operation took 0.664 s, which may be a performance bottleneck.
2023-11-03 19:39:19,310	WARNING util.py:214 -- The `start_trial` operation took 0.531 s, which may be a performance bottleneck.
2023-11-03 19:41:59,491	WARNING util.py:214 -- The `start_trial` operation took 0.545 s, which may be a performance bottleneck.
2023-11-03 19:42:01,416	WARNING util.py:214 -- The `on_step_end` operation took 0.552 s, which may be a performance bottleneck.
2023-11-03 19:44:46,030	WARNING util.py:214 -- The `start_trial` operation took 0.682 s, which may be a performance bottleneck.
2023-11-03 19:44:47,249	WARNING util.py:214 -- The `start_trial` operation took 0.550 s, which may be a performance bottleneck.
2023-11-03 19:44:47,835	WARNING util.py:214 -- The `start_trial` operation took 0.548 s, which may be a performance bottleneck.
2023-11-03 19:47:36,131	WARNING util.py:214 -- The `start_trial` operation took 0.507 s, which may be a performance bottleneck.
2023-11-03 19:47:36,918	WARNING util.py:214 -- The `start_trial` operation took 0.506 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 19:48:38,501 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2423003) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-03 19:33:04 (running for 00:56:36.46)
Memory usage on this node: 27.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 570/1000000 (32 RUNNING, 538 TERMINATED)


== Status ==
Current time: 2023-11-03 19:35:28 (running for 00:59:01.37)
Memory usage on this node: 27.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 570/1000000 (31 RUNNING, 539 TERMINATED)


== Status ==
Current time: 2023-11-03 19:35:34 (running for 00:59:07.12)
Memory usage on this node: 26.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5360f6e8 with val_loss=478.43132000004897 and parameters={'n_estimators': 469, 'max_depth': 5, 'min_child_weight': 0.034829817549931245, 'learning_rate': 0.039191550647977545, 'subsample': 0.9610205321799405, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.4325981023972749, 'reg_alpha': 0.07680814868417611, 'reg_lambda': 0.921118486835268, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 576/1000000 (31 RUNNING, 545 TERMINATED)


== Status ==
Current time: 2023-11-03 19:39:14 (running for 01:02:47.02)
Memory usage on this node: 27.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5ed9772f with val_loss=478.31428812639825 and parameters={'n_estimators': 1168, 'max_depth': 5, 'min_child_weight': 0.0074559371151022135, 'learning_rate': 0.027470830118497196, 'subsample': 0.9254034974528295, 'colsample_bylevel': 0.9340076342621546, 'colsample_bytree': 0.2563118637850799, 'reg_alpha': 0.01043444029677144, 'reg_lambda': 0.9070954279007869, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 577/1000000 (1 PENDING, 31 RUNNING, 545 TERMINATED)


== Status ==
Current time: 2023-11-03 19:39:20 (running for 01:02:52.56)
Memory usage on this node: 27.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5ed9772f with val_loss=478.31428812639825 and parameters={'n_estimators': 1168, 'max_depth': 5, 'min_child_weight': 0.0074559371151022135, 'learning_rate': 0.027470830118497196, 'subsample': 0.9254034974528295, 'colsample_bylevel': 0.9340076342621546, 'colsample_bytree': 0.2563118637850799, 'reg_alpha': 0.01043444029677144, 'reg_lambda': 0.9070954279007869, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 582/1000000 (31 RUNNING, 551 TERMINATED)


== Status ==
Current time: 2023-11-03 19:41:55 (running for 01:05:28.23)
Memory usage on this node: 27.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5ed9772f with val_loss=478.31428812639825 and parameters={'n_estimators': 1168, 'max_depth': 5, 'min_child_weight': 0.0074559371151022135, 'learning_rate': 0.027470830118497196, 'subsample': 0.9254034974528295, 'colsample_bylevel': 0.9340076342621546, 'colsample_bytree': 0.2563118637850799, 'reg_alpha': 0.01043444029677144, 'reg_lambda': 0.9070954279007869, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 583/1000000 (1 PENDING, 31 RUNNING, 551 TERMINATED)


== Status ==
Current time: 2023-11-03 19:42:01 (running for 01:05:33.84)
Memory usage on this node: 27.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5ed9772f with val_loss=478.31428812639825 and parameters={'n_estimators': 1168, 'max_depth': 5, 'min_child_weight': 0.0074559371151022135, 'learning_rate': 0.027470830118497196, 'subsample': 0.9254034974528295, 'colsample_bylevel': 0.9340076342621546, 'colsample_bytree': 0.2563118637850799, 'reg_alpha': 0.01043444029677144, 'reg_lambda': 0.9070954279007869, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 588/1000000 (31 RUNNING, 557 TERMINATED)


== Status ==
Current time: 2023-11-03 19:44:45 (running for 01:08:17.44)
Memory usage on this node: 27.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5ed9772f with val_loss=478.31428812639825 and parameters={'n_estimators': 1168, 'max_depth': 5, 'min_child_weight': 0.0074559371151022135, 'learning_rate': 0.027470830118497196, 'subsample': 0.9254034974528295, 'colsample_bylevel': 0.9340076342621546, 'colsample_bytree': 0.2563118637850799, 'reg_alpha': 0.01043444029677144, 'reg_lambda': 0.9070954279007869, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 589/1000000 (1 PENDING, 31 RUNNING, 557 TERMINATED)


== Status ==
Current time: 2023-11-03 19:44:53 (running for 01:08:25.78)
Memory usage on this node: 26.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5ed9772f with val_loss=478.31428812639825 and parameters={'n_estimators': 1168, 'max_depth': 5, 'min_child_weight': 0.0074559371151022135, 'learning_rate': 0.027470830118497196, 'subsample': 0.9254034974528295, 'colsample_bylevel': 0.9340076342621546, 'colsample_bytree': 0.2563118637850799, 'reg_alpha': 0.01043444029677144, 'reg_lambda': 0.9070954279007869, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 592/1000000 (32 RUNNING, 560 TERMINATED)


== Status ==
Current time: 2023-11-03 19:47:32 (running for 01:11:05.11)
Memory usage on this node: 27.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5ed9772f with val_loss=478.31428812639825 and parameters={'n_estimators': 1168, 'max_depth': 5, 'min_child_weight': 0.0074559371151022135, 'learning_rate': 0.027470830118497196, 'subsample': 0.9254034974528295, 'colsample_bylevel': 0.9340076342621546, 'colsample_bytree': 0.2563118637850799, 'reg_alpha': 0.01043444029677144, 'reg_lambda': 0.9070954279007869, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 592/1000000 (32 RUNNING, 560 TERMINATED)


2023-11-03 19:53:32,503	WARNING util.py:214 -- The `start_trial` operation took 0.551 s, which may be a performance bottleneck.
2023-11-03 19:53:35,082	WARNING util.py:214 -- The `start_trial` operation took 0.585 s, which may be a performance bottleneck.
2023-11-03 19:53:36,788	WARNING util.py:214 -- The `start_trial` operation took 0.738 s, which may be a performance bottleneck.
2023-11-03 19:53:37,812	WARNING util.py:214 -- The `start_trial` operation took 0.582 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 19:54:36,348 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2423357) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 19:54:38,082 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2423364) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 19:57:33,423	WARNING util.py:214 -- The `start_trial` operation took 0.507 s, which may be a performance bottleneck.
2023-11-03 19:57:34,441	WARNING util.py:214 -- The `start_trial` operation took 0.512 s, which may be a performance bottleneck.
2023-11-03 20:00:26,802	WARNING util.py:214 -- The `on_step_end` operation took 0.567 s, which may be a performance bottleneck.
2023-11-03 20:00:29,716	WARNING util.py:214 -- The `start_trial` operation took 0.524 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 20:01:28,210 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2423780) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 20:01:29,455 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2423783) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 20:01:31,223 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2423785) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 20:04:16,309	WARNING util.py:214 -- The `on_step_end` operation took 0.624 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 19:47:38 (running for 01:11:11.11)
Memory usage on this node: 27.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5ed9772f with val_loss=478.31428812639825 and parameters={'n_estimators': 1168, 'max_depth': 5, 'min_child_weight': 0.0074559371151022135, 'learning_rate': 0.027470830118497196, 'subsample': 0.9254034974528295, 'colsample_bylevel': 0.9340076342621546, 'colsample_bytree': 0.2563118637850799, 'reg_alpha': 0.01043444029677144, 'reg_lambda': 0.9070954279007869, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 598/1000000 (32 RUNNING, 566 TERMINATED)


== Status ==
Current time: 2023-11-03 19:51:07 (running for 01:14:39.77)
Memory usage on this node: 27.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 5ed9772f with val_loss=478.31428812639825 and parameters={'n_estimators': 1168, 'max_depth': 5, 'min_child_weight': 0.0074559371151022135, 'learning_rate': 0.027470830118497196, 'subsample': 0.9254034974528295, 'colsample_bylevel': 0.9340076342621546, 'colsample_bytree': 0.2563118637850799, 'reg_alpha': 0.01043444029677144, 'reg_lambda': 0.9070954279007869, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 598/1000000 (32 RUNNING, 566 TERMINATED)


== Status ==
Current time: 2023-11-03 19:51:12 (running for 01:14:45.07)
Memory usage on this node: 26.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 604/1000000 (31 RUNNING, 573 TERMINATED)


== Status ==
Current time: 2023-11-03 19:53:30 (running for 01:17:02.52)
Memory usage on this node: 27.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 605/1000000 (1 PENDING, 31 RUNNING, 573 TERMINATED)


== Status ==
Current time: 2023-11-03 19:53:35 (running for 01:17:08.05)
Memory usage on this node: 27.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 612/1000000 (1 PENDING, 31 RUNNING, 580 TERMINATED)


== Status ==
Current time: 2023-11-03 19:53:43 (running for 01:17:15.70)
Memory usage on this node: 27.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 614/1000000 (32 RUNNING, 582 TERMINATED)


== Status ==
Current time: 2023-11-03 19:57:30 (running for 01:21:03.08)
Memory usage on this node: 27.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 614/1000000 (32 RUNNING, 582 TERMINATED)


== Status ==
Current time: 2023-11-03 19:57:36 (running for 01:21:08.55)
Memory usage on this node: 26.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 618/1000000 (32 RUNNING, 586 TERMINATED)


== Status ==
Current time: 2023-11-03 20:00:26 (running for 01:23:59.24)
Memory usage on this node: 27.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 618/1000000 (32 RUNNING, 586 TERMINATED)


== Status ==
Current time: 2023-11-03 20:00:36 (running for 01:24:08.95)
Memory usage on this node: 26.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 621/1000000 (32 RUNNING, 589 TERMINATED)


2023-11-03 20:04:18,470	WARNING util.py:214 -- The `start_trial` operation took 0.522 s, which may be a performance bottleneck.
2023-11-03 20:04:20,760	WARNING util.py:214 -- The `start_trial` operation took 0.511 s, which may be a performance bottleneck.
2023-11-03 20:04:21,765	WARNING util.py:214 -- The `start_trial` operation took 0.539 s, which may be a performance bottleneck.
2023-11-03 20:06:48,564	WARNING util.py:214 -- The `on_step_end` operation took 0.579 s, which may be a performance bottleneck.
2023-11-03 20:06:53,803	WARNING util.py:214 -- The `start_trial` operation took 0.518 s, which may be a performance bottleneck.
2023-11-03 20:09:42,873	WARNING util.py:214 -- The `on_step_end` operation took 0.729 s, which may be a performance bottleneck.
2023-11-03 20:12:31,389	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 16.783 s, which may be a performance bottleneck.
2023-11-03 20:12:31,390	WARNING util.py:214 -- The `process_trial_result` operation took 16.784 s, which may be a performance bottleneck.
2023-11-03 20:12:31,390	WARNING util.py:214 -- Processing trial results took 16.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 20:12:31,390	WARNING util.py:214 -- The `process_trial_result` operation took 16.784 s, which may be a performance bottleneck.
2023-11-03 20:12:38,396	WARNING util.py:214 -- The `start_trial` operation took 0.596 s, which may be a performance bottleneck.
2023-11-03 20:12:41,173	WARNING util.py:214 -- The `start_trial` operation took 0.548 s, which may be a performance bottleneck.
2023-11-03 20:12:41,764	WARNING util.py:214 -- The `on_step_end` operation took 0.591 s, which may be a performance bottleneck.
2023-11-03 20:15:27,295	WARNING util.py:214 -- The `on_step_end` operation took 0.646 s, which may be a performance bottleneck.
2023-11-03 20:15:29,451	WARNING util.py:214 -- The `start_trial` operation took 0.606 s, which may be a performance bottleneck.
2023-11-03 20:18:15,874	WARNING util.py:214 -- The `start_trial` operation took 0.579 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 20:04:16 (running for 01:27:48.83)
Memory usage on this node: 27.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 621/1000000 (32 RUNNING, 589 TERMINATED)


== Status ==
Current time: 2023-11-03 20:04:22 (running for 01:27:54.60)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 626/1000000 (32 RUNNING, 594 TERMINATED)


== Status ==
Current time: 2023-11-03 20:06:48 (running for 01:30:20.99)
Memory usage on this node: 27.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 626/1000000 (32 RUNNING, 594 TERMINATED)


== Status ==
Current time: 2023-11-03 20:06:54 (running for 01:30:26.70)
Memory usage on this node: 26.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 631/1000000 (31 RUNNING, 600 TERMINATED)


== Status ==
Current time: 2023-11-03 20:09:42 (running for 01:33:15.30)
Memory usage on this node: 27.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 632/1000000 (32 RUNNING, 600 TERMINATED)


== Status ==
Current time: 2023-11-03 20:12:35 (running for 01:36:08.31)
Memory usage on this node: 27.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 632/1000000 (32 RUNNING, 600 TERMINATED)


== Status ==
Current time: 2023-11-03 20:12:41 (running for 01:36:14.19)
Memory usage on this node: 26.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 637/1000000 (32 RUNNING, 605 TERMINATED)


== Status ==
Current time: 2023-11-03 20:15:27 (running for 01:38:59.80)
Memory usage on this node: 26.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 637/1000000 (32 RUNNING, 605 TERMINATED)


== Status ==
Current time: 2023-11-03 20:15:36 (running for 01:39:08.60)
Memory usage on this node: 25.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 640/1000000 (32 RUNNING, 608 TERMINATED)


== Status ==
Current time: 2023-11-03 20:18:10 (running for 01:41:43.03)
Memory usage on this node: 26.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 640/1000000 (32 RUNNING, 608 TERMINATED)


2023-11-03 20:21:03,542	WARNING util.py:214 -- The `start_trial` operation took 0.581 s, which may be a performance bottleneck.
2023-11-03 20:23:35,083	WARNING util.py:214 -- The `start_trial` operation took 0.605 s, which may be a performance bottleneck.
2023-11-03 20:23:37,122	WARNING util.py:214 -- The `start_trial` operation took 0.558 s, which may be a performance bottleneck.
2023-11-03 20:23:38,072	WARNING util.py:214 -- The `start_trial` operation took 0.537 s, which may be a performance bottleneck.
2023-11-03 20:31:12,012	WARNING util.py:214 -- The `start_trial` operation took 0.587 s, which may be a performance bottleneck.
2023-11-03 20:33:35,839	WARNING util.py:214 -- The `on_step_end` operation took 0.622 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 20:18:16 (running for 01:41:48.65)
Memory usage on this node: 26.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 645/1000000 (32 RUNNING, 613 TERMINATED)


== Status ==
Current time: 2023-11-03 20:20:59 (running for 01:44:31.68)
Memory usage on this node: 26.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 645/1000000 (32 RUNNING, 613 TERMINATED)


== Status ==
Current time: 2023-11-03 20:21:04 (running for 01:44:37.12)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 650/1000000 (32 RUNNING, 618 TERMINATED)


== Status ==
Current time: 2023-11-03 20:23:32 (running for 01:47:05.28)
Memory usage on this node: 26.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 650/1000000 (32 RUNNING, 618 TERMINATED)


== Status ==
Current time: 2023-11-03 20:23:38 (running for 01:47:10.75)
Memory usage on this node: 25.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 655/1000000 (32 RUNNING, 623 TERMINATED)


== Status ==
Current time: 2023-11-03 20:26:03 (running for 01:49:35.42)
Memory usage on this node: 26.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 655/1000000 (32 RUNNING, 623 TERMINATED)


== Status ==
Current time: 2023-11-03 20:26:08 (running for 01:49:40.90)
Memory usage on this node: 26.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 661/1000000 (1 PENDING, 31 RUNNING, 629 TERMINATED)


== Status ==
Current time: 2023-11-03 20:28:43 (running for 01:52:15.68)
Memory usage on this node: 26.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 661/1000000 (32 RUNNING, 629 TERMINATED)


== Status ==
Current time: 2023-11-03 20:31:07 (running for 01:54:40.19)
Memory usage on this node: 27.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 661/1000000 (32 RUNNING, 629 TERMINATED)


== Status ==
Current time: 2023-11-03 20:31:13 (running for 01:54:45.97)
Memory usage on this node: 26.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 666/1000000 (31 RUNNING, 635 TERMINATED)


2023-11-03 20:33:38,618	WARNING util.py:214 -- The `start_trial` operation took 0.515 s, which may be a performance bottleneck.
2023-11-03 20:33:39,292	WARNING util.py:214 -- The `start_trial` operation took 0.540 s, which may be a performance bottleneck.
2023-11-03 20:36:03,682	WARNING util.py:214 -- The `start_trial` operation took 0.562 s, which may be a performance bottleneck.
2023-11-03 20:38:21,484	WARNING util.py:214 -- The `on_step_end` operation took 0.698 s, which may be a performance bottleneck.
2023-11-03 20:42:43,139	WARNING util.py:214 -- The `start_trial` operation took 0.799 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 20:33:35 (running for 01:57:08.38)
Memory usage on this node: 26.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 667/1000000 (1 PENDING, 31 RUNNING, 635 TERMINATED)


== Status ==
Current time: 2023-11-03 20:33:41 (running for 01:57:13.67)
Memory usage on this node: 26.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 672/1000000 (32 RUNNING, 640 TERMINATED)


== Status ==
Current time: 2023-11-03 20:36:01 (running for 01:59:34.28)
Memory usage on this node: 27.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 672/1000000 (32 RUNNING, 640 TERMINATED)


== Status ==
Current time: 2023-11-03 20:36:07 (running for 01:59:39.82)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 678/1000000 (32 RUNNING, 646 TERMINATED)


== Status ==
Current time: 2023-11-03 20:38:15 (running for 02:01:48.04)
Memory usage on this node: 26.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: fe611eaf with val_loss=478.28274924380264 and parameters={'n_estimators': 872, 'max_depth': 6, 'min_child_weight': 0.007648924064871191, 'learning_rate': 0.01512201847513249, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.2197193309936901, 'reg_alpha': 0.024508703870367157, 'reg_lambda': 0.4678160068055238, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 678/1000000 (32 RUNNING, 646 TERMINATED)


== Status ==
Current time: 2023-11-03 20:38:21 (running for 02:01:53.96)
Memory usage on this node: 26.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 1c96ecf5 with val_loss=478.19126911136044 and parameters={'n_estimators': 3716, 'max_depth': 6, 'min_child_weight': 0.012545093330557174, 'learning_rate': 0.003257867231270162, 'subsample': 1.0, 'colsample_bylevel': 0.6678616903210407, 'colsample_bytree': 0.3699673638468417, 'reg_alpha': 0.1782183522626473, 'reg_lambda': 0.37789168638768106, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 686/1000000 (1 PENDING, 31 RUNNING, 654 TERMINATED)


== Status ==
Current time: 2023-11-03 20:40:38 (running for 02:04:11.06)
Memory usage on this node: 27.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 1c96ecf5 with val_loss=478.19126911136044 and parameters={'n_estimators': 3716, 'max_depth': 6, 'min_child_weight': 0.012545093330557174, 'learning_rate': 0.003257867231270162, 'subsample': 1.0, 'colsample_bylevel': 0.6678616903210407, 'colsample_bytree': 0.3699673638468417, 'reg_alpha': 0.1782183522626473, 'reg_lambda': 0.37789168638768106, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 686/1000000 (32 RUNNING, 654 TERMINATED)


== Status ==
Current time: 2023-11-03 20:42:38 (running for 02:06:11.35)
Memory usage on this node: 27.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 1c96ecf5 with val_loss=478.19126911136044 and parameters={'n_estimators': 3716, 'max_depth': 6, 'min_child_weight': 0.012545093330557174, 'learning_rate': 0.003257867231270162, 'subsample': 1.0, 'colsample_bylevel': 0.6678616903210407, 'colsample_bytree': 0.3699673638468417, 'reg_alpha': 0.1782183522626473, 'reg_lambda': 0.37789168638768106, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 686/1000000 (32 RUNNING, 654 TERMINATED)


== Status ==
Current time: 2023-11-03 20:42:44 (running for 02:06:16.92)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 1c96ecf5 with val_loss=478.19126911136044 and parameters={'n_estimators': 3716, 'max_depth': 6, 'min_child_weight': 0.012545093330557174, 'learning_rate': 0.003257867231270162, 'subsample': 1.0, 'colsample_bylevel': 0.6678616903210407, 'colsample_bytree': 0.3699673638468417, 'reg_alpha': 0.1782183522626473, 'reg_lambda': 0.37789168638768106, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 692/1000000 (31 RUNNING, 661 TERMINATED)


== Status ==
Current time: 2023-11-03 20:45:03 (running for 02:08:35.86)
Memory usage on this node: 26.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 1c96ecf5 with val_loss=478.19126911136044 and parameters={'n_estimators': 3716, 'max_depth': 6, 'min_child_weight': 0.012545093330557174, 'learning_rate': 0.003257867231270162, 'subsample': 1.0, 'colsample_bylevel': 0.6678616903210407, 'colsample_bytree': 0.3699673638468417, 'reg_alpha': 0.1782183522626473, 'reg_lambda': 0.37789168638768106, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 693/1000000 (32 RUNNING, 661 TERMINATED)


2023-11-03 20:47:18,527	WARNING util.py:214 -- The `start_trial` operation took 0.571 s, which may be a performance bottleneck.
2023-11-03 20:47:20,801	WARNING util.py:214 -- The `on_step_end` operation took 0.589 s, which may be a performance bottleneck.
2023-11-03 20:49:46,016	WARNING util.py:214 -- The `start_trial` operation took 0.583 s, which may be a performance bottleneck.
2023-11-03 20:49:48,448	WARNING util.py:214 -- The `start_trial` operation took 0.647 s, which may be a performance bottleneck.
2023-11-03 20:49:49,338	WARNING util.py:214 -- The `on_step_end` operation took 0.703 s, which may be a performance bottleneck.
2023-11-03 20:49:50,411	WARNING util.py:214 -- The `start_trial` operation took 0.655 s, which may be a performance bottleneck.
2023-11-03 20:52:44,883	WARNING util.py:214 -- The `on_step_end` operation took 0.709 s, which may be a performance bottleneck.
2023-11-03 20:52:47,920	WARNING util.py:214 -- The `start_trial` operation took 0.777 s, which may be a performance bottleneck.
2023-11-03 20:52:49,137	WARNING util.py:214 -- The `start_trial` operation took 0.908 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 20:53:49,038 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2426989) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 20:56:35,928	WARNING util.py:214 -- The `on_step_end` operation took 0.518 s, which may be a performance bottleneck.
2023-11-03 20:56:40,330	WARNING util.py:214 -- The `start_trial` operation took 0.561 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 20:57:39,106 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2427221) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 21:00:37,247	WARNING util.py:214 -- The `on_step_end` operation took 0.572 s, which may be a performance bottleneck.
2023-11-03 21:00:39,946	WARNING util.py:214 -- The `start_trial` operation took 0.585 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 21:01:39,577 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2427395) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-03 20:47:14 (running for 02:10:47.32)
Memory usage on this node: 27.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 1c96ecf5 with val_loss=478.19126911136044 and parameters={'n_estimators': 3716, 'max_depth': 6, 'min_child_weight': 0.012545093330557174, 'learning_rate': 0.003257867231270162, 'subsample': 1.0, 'colsample_bylevel': 0.6678616903210407, 'colsample_bytree': 0.3699673638468417, 'reg_alpha': 0.1782183522626473, 'reg_lambda': 0.37789168638768106, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 693/1000000 (32 RUNNING, 661 TERMINATED)


== Status ==
Current time: 2023-11-03 20:47:20 (running for 02:10:53.22)
Memory usage on this node: 26.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7361c3be with val_loss=478.1453169847001 and parameters={'n_estimators': 3925, 'max_depth': 4, 'min_child_weight': 0.00970033344380572, 'learning_rate': 0.01097023674231854, 'subsample': 1.0, 'colsample_bylevel': 0.5835631734733866, 'colsample_bytree': 0.31924307950991193, 'reg_alpha': 13.861130377105596, 'reg_lambda': 0.1620650328134453, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 699/1000000 (32 RUNNING, 667 TERMINATED)


== Status ==
Current time: 2023-11-03 20:49:43 (running for 02:13:16.04)
Memory usage on this node: 26.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7361c3be with val_loss=478.1453169847001 and parameters={'n_estimators': 3925, 'max_depth': 4, 'min_child_weight': 0.00970033344380572, 'learning_rate': 0.01097023674231854, 'subsample': 1.0, 'colsample_bylevel': 0.5835631734733866, 'colsample_bytree': 0.31924307950991193, 'reg_alpha': 13.861130377105596, 'reg_lambda': 0.1620650328134453, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 699/1000000 (31 RUNNING, 668 TERMINATED)


== Status ==
Current time: 2023-11-03 20:49:49 (running for 02:13:21.94)
Memory usage on this node: 26.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7361c3be with val_loss=478.1453169847001 and parameters={'n_estimators': 3925, 'max_depth': 4, 'min_child_weight': 0.00970033344380572, 'learning_rate': 0.01097023674231854, 'subsample': 1.0, 'colsample_bylevel': 0.5835631734733866, 'colsample_bytree': 0.31924307950991193, 'reg_alpha': 13.861130377105596, 'reg_lambda': 0.1620650328134453, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 706/1000000 (1 PENDING, 30 RUNNING, 675 TERMINATED)


== Status ==
Current time: 2023-11-03 20:49:57 (running for 02:13:29.88)
Memory usage on this node: 26.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7361c3be with val_loss=478.1453169847001 and parameters={'n_estimators': 3925, 'max_depth': 4, 'min_child_weight': 0.00970033344380572, 'learning_rate': 0.01097023674231854, 'subsample': 1.0, 'colsample_bylevel': 0.5835631734733866, 'colsample_bytree': 0.31924307950991193, 'reg_alpha': 13.861130377105596, 'reg_lambda': 0.1620650328134453, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 708/1000000 (32 RUNNING, 676 TERMINATED)


== Status ==
Current time: 2023-11-03 20:52:44 (running for 02:16:17.31)
Memory usage on this node: 27.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7361c3be with val_loss=478.1453169847001 and parameters={'n_estimators': 3925, 'max_depth': 4, 'min_child_weight': 0.00970033344380572, 'learning_rate': 0.01097023674231854, 'subsample': 1.0, 'colsample_bylevel': 0.5835631734733866, 'colsample_bytree': 0.31924307950991193, 'reg_alpha': 13.861130377105596, 'reg_lambda': 0.1620650328134453, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 708/1000000 (32 RUNNING, 676 TERMINATED)


== Status ==
Current time: 2023-11-03 20:52:54 (running for 02:16:26.58)
Memory usage on this node: 26.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7361c3be with val_loss=478.1453169847001 and parameters={'n_estimators': 3925, 'max_depth': 4, 'min_child_weight': 0.00970033344380572, 'learning_rate': 0.01097023674231854, 'subsample': 1.0, 'colsample_bylevel': 0.5835631734733866, 'colsample_bytree': 0.31924307950991193, 'reg_alpha': 13.861130377105596, 'reg_lambda': 0.1620650328134453, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 711/1000000 (32 RUNNING, 679 TERMINATED)


== Status ==
Current time: 2023-11-03 20:56:35 (running for 02:20:08.35)
Memory usage on this node: 27.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7361c3be with val_loss=478.1453169847001 and parameters={'n_estimators': 3925, 'max_depth': 4, 'min_child_weight': 0.00970033344380572, 'learning_rate': 0.01097023674231854, 'subsample': 1.0, 'colsample_bylevel': 0.5835631734733866, 'colsample_bytree': 0.31924307950991193, 'reg_alpha': 13.861130377105596, 'reg_lambda': 0.1620650328134453, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 711/1000000 (32 RUNNING, 679 TERMINATED)


== Status ==
Current time: 2023-11-03 20:56:41 (running for 02:20:14.02)
Memory usage on this node: 26.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 7361c3be with val_loss=478.1453169847001 and parameters={'n_estimators': 3925, 'max_depth': 4, 'min_child_weight': 0.00970033344380572, 'learning_rate': 0.01097023674231854, 'subsample': 1.0, 'colsample_bylevel': 0.5835631734733866, 'colsample_bytree': 0.31924307950991193, 'reg_alpha': 13.861130377105596, 'reg_lambda': 0.1620650328134453, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 716/1000000 (32 RUNNING, 684 TERMINATED)


== Status ==
Current time: 2023-11-03 21:00:37 (running for 02:24:09.91)
Memory usage on this node: 28.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 716/1000000 (32 RUNNING, 684 TERMINATED)


2023-11-03 21:04:19,422	WARNING util.py:214 -- The `on_step_end` operation took 0.595 s, which may be a performance bottleneck.
2023-11-03 21:04:25,222	WARNING util.py:214 -- The `on_step_end` operation took 0.755 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 21:05:24,238 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2427610) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 21:08:14,251	WARNING util.py:214 -- The `start_trial` operation took 0.524 s, which may be a performance bottleneck.
2023-11-03 21:11:01,799	WARNING util.py:214 -- The `on_step_end` operation took 0.786 s, which may be a performance bottleneck.
2023-11-03 21:11:02,973	WARNING util.py:214 -- The `start_trial` operation took 0.675 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 21:12:03,546 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2427916) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 21:12:04,408 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2427918) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 21:14:54,626	WARNING util.py:214 -- The `on_step_end` operation took 0.753 s, which may be a performance bottleneck.
2023-11-03 21:14:56,970	WARNING util.py:214 -- The `start_trial` operation took 0.600 s, which may be a performance bottleneck.
2023-11-03 21:14:57,711	WARNING util.py:214 -- The `start_trial` operation took 0.593 s, which may be a performance bottleneck.
2023-11-03 21:14:58,274	WARNING util.py:214 -- The `start_trial` operation took 0.552 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 21:15:57,928 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2428106) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 21:16:58,057 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2428130) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 21:17:58,245 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2428157) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 21:18:58,437 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2428178) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 21:21:55,732	WARNING util.py:214 -- The `on_step_end` operation took 0.544 s, which may be a performance bottleneck.
2023-11-03 21:21:58,200	WARNING util.py:214 -- The `start_trial` operation took 0.523 s, which may be a performance bottleneck.
2023-11-03 21:21:58,868	WARNING util.py:214 -- The `start_trial` operation took 0.569 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 21:23:00,559 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2428361) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 21:24:00,722 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2428382) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-03 21:00:44 (running for 02:24:17.39)
Memory usage on this node: 28.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 718/1000000 (32 RUNNING, 686 TERMINATED)


== Status ==
Current time: 2023-11-03 21:04:19 (running for 02:27:52.01)
Memory usage on this node: 28.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 718/1000000 (32 RUNNING, 686 TERMINATED)


== Status ==
Current time: 2023-11-03 21:04:25 (running for 02:27:57.86)
Memory usage on this node: 28.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 723/1000000 (32 RUNNING, 691 TERMINATED)


== Status ==
Current time: 2023-11-03 21:08:10 (running for 02:31:42.86)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 723/1000000 (32 RUNNING, 691 TERMINATED)


== Status ==
Current time: 2023-11-03 21:08:16 (running for 02:31:48.49)
Memory usage on this node: 28.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 728/1000000 (31 RUNNING, 697 TERMINATED)


== Status ==
Current time: 2023-11-03 21:11:01 (running for 02:34:34.22)
Memory usage on this node: 28.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 729/1000000 (1 PENDING, 30 RUNNING, 698 TERMINATED)


== Status ==
Current time: 2023-11-03 21:11:09 (running for 02:34:42.05)
Memory usage on this node: 28.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 731/1000000 (32 RUNNING, 699 TERMINATED)


== Status ==
Current time: 2023-11-03 21:14:54 (running for 02:38:27.05)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 731/1000000 (32 RUNNING, 699 TERMINATED)


== Status ==
Current time: 2023-11-03 21:15:00 (running for 02:38:32.43)
Memory usage on this node: 28.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 734/1000000 (32 RUNNING, 702 TERMINATED)


== Status ==
Current time: 2023-11-03 21:21:55 (running for 02:45:28.34)
Memory usage on this node: 29.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 734/1000000 (32 RUNNING, 702 TERMINATED)


2023-11-03 21:26:59,397	WARNING util.py:214 -- The `on_step_end` operation took 0.611 s, which may be a performance bottleneck.
2023-11-03 21:27:02,635	WARNING util.py:214 -- The `start_trial` operation took 0.651 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 21:28:02,222 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2428539) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 21:31:01,869	WARNING util.py:214 -- The `on_step_end` operation took 0.754 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 21:32:04,901 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2428793) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 21:33:05,080 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2428813) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 21:34:05,250 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2428845) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 21:36:54,994	WARNING util.py:214 -- The `on_step_end` operation took 0.723 s, which may be a performance bottleneck.
2023-11-03 21:36:56,597	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.829 s, which may be a performance bottleneck.
2023-11-03 21:36:56,598	WARNING util.py:214 -- The `process_trial_result` operation took 0.829 s, which may be a performance bottleneck.
2023-11-03 21:36:56,598	WARNING util.py:214 -- Processing trial results took 0.829 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 21:36:56,598	WARNING util.py:214 -- The `process_trial_result` operation took 0.829 s, which may be a performance bottleneck.
2023-11-03 21:36:58,867	WARNING util.py:214 -- The `start_trial` operation took 0.553 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 21:37:59,110 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2429081) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 21:43:16,098	WARNING util.py:214 -- The `on_step_end` operation took 0.777 s, which may be a performance bottleneck.
2023-11-03 21:43:16,921	WARNING util.py:214 -- The `start_trial` operation took 0.605 s, which may be a performance bottleneck.
2023-11-03 21:43:17,528	WARNING util.py:214 -- The `start_trial` operation took 0.593 s, which may be a performance bottleneck.
2023-11-03 21:43:18,867	WARNING util.py:214 -- The `start_trial` operation took 0.631 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 21:22:05 (running for 02:45:38.30)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 738/1000000 (32 RUNNING, 706 TERMINATED)


== Status ==
Current time: 2023-11-03 21:26:59 (running for 02:50:32.10)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 738/1000000 (32 RUNNING, 706 TERMINATED)


== Status ==
Current time: 2023-11-03 21:27:09 (running for 02:50:41.58)
Memory usage on this node: 29.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 741/1000000 (32 RUNNING, 709 TERMINATED)


== Status ==
Current time: 2023-11-03 21:31:01 (running for 02:54:34.29)
Memory usage on this node: 30.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 741/1000000 (32 RUNNING, 709 TERMINATED)


== Status ==
Current time: 2023-11-03 21:31:10 (running for 02:54:42.59)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 743/1000000 (32 RUNNING, 711 TERMINATED)


== Status ==
Current time: 2023-11-03 21:36:54 (running for 03:00:27.42)
Memory usage on this node: 30.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 743/1000000 (32 RUNNING, 711 TERMINATED)


== Status ==
Current time: 2023-11-03 21:37:04 (running for 03:00:36.82)
Memory usage on this node: 29.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 747/1000000 (32 RUNNING, 715 TERMINATED)


== Status ==
Current time: 2023-11-03 21:40:31 (running for 03:04:03.47)
Memory usage on this node: 30.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 747/1000000 (32 RUNNING, 715 TERMINATED)


== Status ==
Current time: 2023-11-03 21:40:36 (running for 03:04:09.11)
Memory usage on this node: 29.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 752/1000000 (31 RUNNING, 721 TERMINATED)


== Status ==
Current time: 2023-11-03 21:43:16 (running for 03:06:48.54)
Memory usage on this node: 29.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 753/1000000 (1 PENDING, 30 RUNNING, 722 TERMINATED)


2023-11-03 21:46:15,145	WARNING util.py:214 -- The `on_step_end` operation took 0.776 s, which may be a performance bottleneck.
2023-11-03 21:46:18,242	WARNING util.py:214 -- The `start_trial` operation took 0.547 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 21:47:19,837 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2429583) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 21:49:59,086	WARNING util.py:214 -- The `on_step_end` operation took 0.628 s, which may be a performance bottleneck.
2023-11-03 21:50:02,565	WARNING util.py:214 -- The `start_trial` operation took 0.507 s, which may be a performance bottleneck.
2023-11-03 21:50:03,573	WARNING util.py:214 -- The `start_trial` operation took 0.573 s, which may be a performance bottleneck.
2023-11-03 21:50:04,648	WARNING util.py:214 -- The `on_step_end` operation took 0.528 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 21:51:02,237 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2429735) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 21:53:52,649	WARNING util.py:214 -- The `on_step_end` operation took 0.783 s, which may be a performance bottleneck.
2023-11-03 21:53:53,704	WARNING util.py:214 -- The `start_trial` operation took 0.666 s, which may be a performance bottleneck.
2023-11-03 21:53:56,557	WARNING util.py:214 -- The `start_trial` operation took 0.582 s, which may be a performance bottleneck.
2023-11-03 21:53:57,897	WARNING util.py:214 -- The `start_trial` operation took 0.590 s, which may be a performance bottleneck.
2023-11-03 21:53:58,578	WARNING util.py:214 -- The `on_step_end` operation took 0.681 s, which may be a performance bottleneck.
2023-11-03 21:56:42,024	WARNING util.py:214 -- The `on_step_end` operation took 0.572 s, which may be a performance bottleneck.
2023-11-03 21:56:42,958	WARNING util.py:214 -- The `start_trial` operation took 0.546 s, which may be a performance bottleneck.
2023-11-03 21:56:45,909	WARNING util.py:214 -- The `start_trial` operation took 0.519 s, which may be a performance bottleneck.
2023-11-03 21:56:46,885	WARNING util.py:214 -- The `start_trial` operation took 0.540 s, which may be a performance bottleneck.
2023-11-03 21:56:47,531	WARNING util.py:214 -- The `start_trial` operation took 0.638 s, which may be a performance bottleneck.
2023-11-03 21:59:34,034	WARNING util.py:214 -- The `start_trial` operation took 0.629 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 21:43:26 (running for 03:06:58.49)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 758/1000000 (32 RUNNING, 726 TERMINATED)


== Status ==
Current time: 2023-11-03 21:46:15 (running for 03:09:47.57)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 758/1000000 (32 RUNNING, 726 TERMINATED)


== Status ==
Current time: 2023-11-03 21:46:24 (running for 03:09:57.25)
Memory usage on this node: 29.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 762/1000000 (32 RUNNING, 730 TERMINATED)


== Status ==
Current time: 2023-11-03 21:49:59 (running for 03:13:31.77)
Memory usage on this node: 29.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 762/1000000 (32 RUNNING, 730 TERMINATED)


== Status ==
Current time: 2023-11-03 21:50:04 (running for 03:13:37.07)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 766/1000000 (31 RUNNING, 735 TERMINATED)


== Status ==
Current time: 2023-11-03 21:53:52 (running for 03:17:25.07)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 767/1000000 (1 PENDING, 31 RUNNING, 735 TERMINATED)


== Status ==
Current time: 2023-11-03 21:53:58 (running for 03:17:31.05)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 771/1000000 (31 RUNNING, 740 TERMINATED)


== Status ==
Current time: 2023-11-03 21:56:42 (running for 03:20:14.45)
Memory usage on this node: 29.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 772/1000000 (1 PENDING, 31 RUNNING, 740 TERMINATED)


== Status ==
Current time: 2023-11-03 21:56:48 (running for 03:20:20.43)
Memory usage on this node: 29.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 777/1000000 (32 RUNNING, 745 TERMINATED)


== Status ==
Current time: 2023-11-03 21:59:31 (running for 03:23:04.07)
Memory usage on this node: 29.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 777/1000000 (31 RUNNING, 746 TERMINATED)


2023-11-03 22:02:39,307	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 16.262 s, which may be a performance bottleneck.
2023-11-03 22:02:39,307	WARNING util.py:214 -- The `process_trial_result` operation took 16.263 s, which may be a performance bottleneck.
2023-11-03 22:02:39,307	WARNING util.py:214 -- Processing trial results took 16.263 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-03 22:02:39,307	WARNING util.py:214 -- The `process_trial_result` operation took 16.263 s, which may be a performance bottleneck.
2023-11-03 22:02:44,545	WARNING util.py:214 -- The `start_trial` operation took 0.579 s, which may be a performance bottleneck.
2023-11-03 22:02:45,328	WARNING util.py:214 -- The `on_step_end` operation took 0.567 s, which may be a performance bottleneck.
2023-11-03 22:05:31,610	WARNING util.py:214 -- The `on_step_end` operation took 0.697 s, which may be a performance bottleneck.
2023-11-03 22:05:33,161	WARNING util.py:214 -- The `start_trial` operation took 0.660 s, which may be a performance bottleneck.
2023-11-03 22:05:34,980	WARNING util.py:214 -- The `start_trial` operation took 0.569 s, which may be a performance bottleneck.
2023-11-03 22:08:30,767	WARNING util.py:214 -- The `on_step_end` operation took 0.731 s, which may be a performance bottleneck.
2023-11-03 22:10:40,604	WARNING util.py:214 -- The `on_step_end` operation took 0.556 s, which may be a performance bottleneck.
2023-11-03 22:10:46,610	WARNING util.py:214 -- The `on_step_end` operation took 0.636 s, which may be a performance bottleneck.
2023-11-03 22:10:49,587	WARNING util.py:214 -- The `start_trial` operation took 0.829 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 22:11:51,496 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2430863) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 22:14:43,927	WARNING util.py:214 -- The `on_step_end` operation took 0.703 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 21:59:40 (running for 03:23:13.30)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 780/1000000 (32 RUNNING, 748 TERMINATED)


== Status ==
Current time: 2023-11-03 22:02:22 (running for 03:25:54.51)
Memory usage on this node: 29.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 780/1000000 (32 RUNNING, 748 TERMINATED)


== Status ==
Current time: 2023-11-03 22:02:39 (running for 03:26:11.98)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 780/1000000 (32 RUNNING, 748 TERMINATED)


== Status ==
Current time: 2023-11-03 22:02:45 (running for 03:26:17.75)
Memory usage on this node: 28.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 787/1000000 (1 PENDING, 31 RUNNING, 755 TERMINATED)


== Status ==
Current time: 2023-11-03 22:05:31 (running for 03:29:04.03)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 787/1000000 (1 PENDING, 31 RUNNING, 755 TERMINATED)


== Status ==
Current time: 2023-11-03 22:05:37 (running for 03:29:09.53)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 792/1000000 (31 RUNNING, 761 TERMINATED)


== Status ==
Current time: 2023-11-03 22:08:30 (running for 03:32:03.19)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 793/1000000 (32 RUNNING, 761 TERMINATED)


== Status ==
Current time: 2023-11-03 22:10:40 (running for 03:34:13.03)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 793/1000000 (31 RUNNING, 762 TERMINATED)


== Status ==
Current time: 2023-11-03 22:10:46 (running for 03:34:19.07)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 799/1000000 (31 RUNNING, 768 TERMINATED)


== Status ==
Current time: 2023-11-03 22:10:52 (running for 03:34:24.62)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 805/1000000 (32 RUNNING, 773 TERMINATED)


2023-11-03 22:14:49,246	WARNING util.py:214 -- The `start_trial` operation took 0.532 s, which may be a performance bottleneck.
2023-11-03 22:17:37,769	WARNING util.py:214 -- The `on_step_end` operation took 0.621 s, which may be a performance bottleneck.
2023-11-03 22:17:42,351	WARNING util.py:214 -- The `start_trial` operation took 0.555 s, which may be a performance bottleneck.
2023-11-03 22:17:43,659	WARNING util.py:214 -- The `on_step_end` operation took 0.573 s, which may be a performance bottleneck.
2023-11-03 22:20:09,585	WARNING util.py:214 -- The `on_step_end` operation took 0.514 s, which may be a performance bottleneck.
2023-11-03 22:20:14,398	WARNING util.py:214 -- The `start_trial` operation took 0.578 s, which may be a performance bottleneck.
2023-11-03 22:20:15,390	WARNING util.py:214 -- The `on_step_end` operation took 0.655 s, which may be a performance bottleneck.
2023-11-03 22:22:45,521	WARNING util.py:214 -- The `on_step_end` operation took 0.517 s, which may be a performance bottleneck.
2023-11-03 22:22:49,190	WARNING util.py:214 -- The `start_trial` operation took 0.652 s, which may be a performance bottleneck.
2023-11-03 22:22:51,488	WARNING util.py:214 -- The `on_step_end` operation took 0.507 s, which may be a performance bottleneck.
2023-11-03 22:25:14,014	WARNING util.py:214 -- The `on_step_end` operation took 0.578 s, which may be a performance bottleneck.
2023-11-03 22:25:19,821	WARNING util.py:214 -- The `on_step_end` operation took 0.641 s, which may be a performance bottleneck.
2023-11-03 22:27:58,583	WARNING util.py:214 -- The `on_step_end` operation took 0.632 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 22:14:44 (running for 03:38:16.51)
Memory usage on this node: 29.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 805/1000000 (32 RUNNING, 773 TERMINATED)


== Status ==
Current time: 2023-11-03 22:14:49 (running for 03:38:22.14)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 810/1000000 (32 RUNNING, 778 TERMINATED)


== Status ==
Current time: 2023-11-03 22:17:37 (running for 03:41:10.31)
Memory usage on this node: 30.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 810/1000000 (32 RUNNING, 778 TERMINATED)


== Status ==
Current time: 2023-11-03 22:17:43 (running for 03:41:16.08)
Memory usage on this node: 29.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 815/1000000 (32 RUNNING, 783 TERMINATED)


== Status ==
Current time: 2023-11-03 22:20:09 (running for 03:43:42.01)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 815/1000000 (31 RUNNING, 784 TERMINATED)


== Status ==
Current time: 2023-11-03 22:20:15 (running for 03:43:47.81)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 821/1000000 (32 RUNNING, 789 TERMINATED)


== Status ==
Current time: 2023-11-03 22:22:45 (running for 03:46:17.94)
Memory usage on this node: 29.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 821/1000000 (32 RUNNING, 789 TERMINATED)


== Status ==
Current time: 2023-11-03 22:22:51 (running for 03:46:24.01)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 826/1000000 (32 RUNNING, 794 TERMINATED)


== Status ==
Current time: 2023-11-03 22:25:14 (running for 03:48:46.48)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 826/1000000 (32 RUNNING, 794 TERMINATED)


== Status ==
Current time: 2023-11-03 22:25:20 (running for 03:48:52.43)
Memory usage on this node: 28.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 833/1000000 (31 RUNNING, 802 TERMINATED)


2023-11-03 22:28:03,049	WARNING util.py:214 -- The `start_trial` operation took 0.528 s, which may be a performance bottleneck.
2023-11-03 22:28:04,404	WARNING util.py:214 -- The `on_step_end` operation took 0.638 s, which may be a performance bottleneck.
2023-11-03 22:30:33,974	WARNING util.py:214 -- The `start_trial` operation took 0.656 s, which may be a performance bottleneck.
2023-11-03 22:30:35,233	WARNING util.py:214 -- The `start_trial` operation took 0.527 s, which may be a performance bottleneck.
2023-11-03 22:30:37,754	WARNING util.py:214 -- The `start_trial` operation took 0.572 s, which may be a performance bottleneck.
2023-11-03 22:30:38,705	WARNING util.py:214 -- The `on_step_end` operation took 0.770 s, which may be a performance bottleneck.
2023-11-03 22:33:06,203	WARNING util.py:214 -- The `on_step_end` operation took 0.715 s, which may be a performance bottleneck.
2023-11-03 22:35:25,506	WARNING util.py:214 -- The `on_step_end` operation took 0.666 s, which may be a performance bottleneck.
2023-11-03 22:35:29,804	WARNING util.py:214 -- The `start_trial` operation took 0.543 s, which may be a performance bottleneck.
2023-11-03 22:35:30,960	WARNING util.py:214 -- The `start_trial` operation took 0.600 s, which may be a performance bottleneck.
2023-11-03 22:35:31,535	WARNING util.py:214 -- The `on_step_end` operation took 0.575 s, which may be a performance bottleneck.
2023-11-03 22:38:17,899	WARNING util.py:214 -- The `on_step_end` operation took 0.592 s, which may be a performance bottleneck.
2023-11-03 22:38:24,143	WARNING util.py:214 -- The `on_step_end` operation took 0.998 s, which may be a performance bottleneck.
2023-11-03 22:38:27,496	WARNING util.py:214 -- The `start_trial` operation took 0.564 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 22:39:27,198 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2432485) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 22:42:03,723	WARNING util.py:214 -- The `on_step_end` operation took 0.827 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 22:27:58 (running for 03:51:31.01)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 834/1000000 (1 PENDING, 31 RUNNING, 802 TERMINATED)


== Status ==
Current time: 2023-11-03 22:28:04 (running for 03:51:36.99)
Memory usage on this node: 29.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 840/1000000 (1 PENDING, 30 RUNNING, 809 TERMINATED)


== Status ==
Current time: 2023-11-03 22:30:32 (running for 03:54:05.30)
Memory usage on this node: 29.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 840/1000000 (31 RUNNING, 809 TERMINATED)


== Status ==
Current time: 2023-11-03 22:30:38 (running for 03:54:11.27)
Memory usage on this node: 28.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 846/1000000 (1 PENDING, 31 RUNNING, 814 TERMINATED)


== Status ==
Current time: 2023-11-03 22:33:06 (running for 03:56:38.77)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 846/1000000 (32 RUNNING, 814 TERMINATED)


== Status ==
Current time: 2023-11-03 22:35:25 (running for 03:58:57.93)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 846/1000000 (31 RUNNING, 815 TERMINATED)


== Status ==
Current time: 2023-11-03 22:35:31 (running for 03:59:04.11)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 852/1000000 (32 RUNNING, 820 TERMINATED)


== Status ==
Current time: 2023-11-03 22:38:17 (running for 04:01:50.32)
Memory usage on this node: 28.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 852/1000000 (31 RUNNING, 821 TERMINATED)


== Status ==
Current time: 2023-11-03 22:38:24 (running for 04:01:56.57)
Memory usage on this node: 29.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 857/1000000 (1 PENDING, 30 RUNNING, 826 TERMINATED)


== Status ==
Current time: 2023-11-03 22:38:34 (running for 04:02:06.49)
Memory usage on this node: 28.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 860/1000000 (32 RUNNING, 828 TERMINATED)


2023-11-03 22:42:06,028	WARNING util.py:214 -- The `start_trial` operation took 0.545 s, which may be a performance bottleneck.
2023-11-03 22:42:07,201	WARNING util.py:214 -- The `start_trial` operation took 0.555 s, which may be a performance bottleneck.
2023-11-03 22:42:10,088	WARNING util.py:214 -- The `on_step_end` operation took 0.977 s, which may be a performance bottleneck.
2023-11-03 22:44:50,032	WARNING util.py:214 -- The `on_step_end` operation took 0.726 s, which may be a performance bottleneck.
2023-11-03 22:47:03,967	WARNING util.py:214 -- The `on_step_end` operation took 0.717 s, which may be a performance bottleneck.
2023-11-03 22:47:09,999	WARNING util.py:214 -- The `on_step_end` operation took 0.570 s, which may be a performance bottleneck.
2023-11-03 22:49:08,593	WARNING util.py:214 -- The `on_step_end` operation took 0.512 s, which may be a performance bottleneck.
2023-11-03 22:49:14,440	WARNING util.py:214 -- The `on_step_end` operation took 0.801 s, which may be a performance bottleneck.
2023-11-03 22:53:39,797	WARNING util.py:214 -- The `start_trial` operation took 0.510 s, which may be a performance bottleneck.
2023-11-03 22:53:40,984	WARNING util.py:214 -- The `start_trial` operation took 0.599 s, which may be a performance bottleneck.
2023-11-03 22:53:45,204	WARNING util.py:214 -- The `on_step_end` operation took 0.880 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 22:42:03 (running for 04:05:36.15)
Memory usage on this node: 29.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 860/1000000 (32 RUNNING, 828 TERMINATED)


== Status ==
Current time: 2023-11-03 22:42:10 (running for 04:05:42.53)
Memory usage on this node: 28.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 864/1000000 (1 PENDING, 31 RUNNING, 832 TERMINATED)


== Status ==
Current time: 2023-11-03 22:44:50 (running for 04:08:22.45)
Memory usage on this node: 28.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 864/1000000 (32 RUNNING, 832 TERMINATED)


== Status ==
Current time: 2023-11-03 22:47:04 (running for 04:10:36.45)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 864/1000000 (32 RUNNING, 832 TERMINATED)


== Status ==
Current time: 2023-11-03 22:47:10 (running for 04:10:42.43)
Memory usage on this node: 28.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 868/1000000 (32 RUNNING, 836 TERMINATED)


== Status ==
Current time: 2023-11-03 22:49:08 (running for 04:12:41.02)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 868/1000000 (31 RUNNING, 837 TERMINATED)


== Status ==
Current time: 2023-11-03 22:49:14 (running for 04:12:46.86)
Memory usage on this node: 28.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 874/1000000 (31 RUNNING, 843 TERMINATED)


== Status ==
Current time: 2023-11-03 22:51:22 (running for 04:14:54.81)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 875/1000000 (1 PENDING, 31 RUNNING, 843 TERMINATED)


== Status ==
Current time: 2023-11-03 22:51:28 (running for 04:15:00.78)
Memory usage on this node: 28.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 881/1000000 (31 RUNNING, 850 TERMINATED)


== Status ==
Current time: 2023-11-03 22:53:38 (running for 04:17:11.21)
Memory usage on this node: 29.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 882/1000000 (1 PENDING, 31 RUNNING, 850 TERMINATED)


2023-11-03 22:56:01,794	WARNING util.py:214 -- The `on_step_end` operation took 0.880 s, which may be a performance bottleneck.
2023-11-03 22:56:06,089	WARNING util.py:214 -- The `start_trial` operation took 0.636 s, which may be a performance bottleneck.
2023-11-03 22:56:07,086	WARNING util.py:214 -- The `start_trial` operation took 0.514 s, which may be a performance bottleneck.
2023-11-03 22:56:07,795	WARNING util.py:214 -- The `on_step_end` operation took 0.709 s, which may be a performance bottleneck.
2023-11-03 22:58:42,187	WARNING util.py:214 -- The `on_step_end` operation took 0.903 s, which may be a performance bottleneck.
2023-11-03 22:58:47,077	WARNING util.py:214 -- The `start_trial` operation took 0.700 s, which may be a performance bottleneck.
2023-11-03 22:58:48,212	WARNING util.py:214 -- The `on_step_end` operation took 0.583 s, which may be a performance bottleneck.
2023-11-03 23:01:37,987	WARNING util.py:214 -- The `on_step_end` operation took 0.743 s, which may be a performance bottleneck.
2023-11-03 23:04:01,785	WARNING util.py:214 -- The `on_step_end` operation took 0.790 s, which may be a performance bottleneck.
2023-11-03 23:04:02,961	WARNING util.py:214 -- The `start_trial` operation took 0.561 s, which may be a performance bottleneck.
2023-11-03 23:04:05,189	WARNING util.py:214 -- The `start_trial` operation took 0.576 s, which may be a performance bottleneck.
2023-11-03 23:04:06,845	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
2023-11-03 23:06:25,053	WARNING util.py:214 -- The `on_step_end` operation took 0.776 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 22:53:45 (running for 04:17:17.63)
Memory usage on this node: 28.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 887/1000000 (1 PENDING, 31 RUNNING, 855 TERMINATED)


== Status ==
Current time: 2023-11-03 22:55:55 (running for 04:19:28.05)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 887/1000000 (1 PENDING, 31 RUNNING, 855 TERMINATED)


== Status ==
Current time: 2023-11-03 22:56:01 (running for 04:19:34.39)
Memory usage on this node: 29.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 892/1000000 (1 PENDING, 31 RUNNING, 860 TERMINATED)


== Status ==
Current time: 2023-11-03 22:56:07 (running for 04:19:40.22)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 897/1000000 (31 RUNNING, 866 TERMINATED)


== Status ==
Current time: 2023-11-03 22:58:42 (running for 04:22:14.66)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 898/1000000 (1 PENDING, 31 RUNNING, 866 TERMINATED)


== Status ==
Current time: 2023-11-03 22:58:48 (running for 04:22:20.84)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 902/1000000 (31 RUNNING, 871 TERMINATED)


== Status ==
Current time: 2023-11-03 23:01:32 (running for 04:25:04.47)
Memory usage on this node: 30.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 903/1000000 (1 PENDING, 31 RUNNING, 871 TERMINATED)


== Status ==
Current time: 2023-11-03 23:01:38 (running for 04:25:10.63)
Memory usage on this node: 29.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 908/1000000 (1 PENDING, 30 RUNNING, 877 TERMINATED)


== Status ==
Current time: 2023-11-03 23:04:01 (running for 04:27:34.29)
Memory usage on this node: 30.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 908/1000000 (31 RUNNING, 877 TERMINATED)


== Status ==
Current time: 2023-11-03 23:04:07 (running for 04:27:39.47)
Memory usage on this node: 29.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 913/1000000 (32 RUNNING, 881 TERMINATED)


2023-11-03 23:06:28,329	WARNING util.py:214 -- The `start_trial` operation took 0.513 s, which may be a performance bottleneck.
2023-11-03 23:06:31,287	WARNING util.py:214 -- The `on_step_end` operation took 1.129 s, which may be a performance bottleneck.
2023-11-03 23:09:00,123	WARNING util.py:214 -- The `start_trial` operation took 0.515 s, which may be a performance bottleneck.
2023-11-03 23:09:07,209	WARNING util.py:214 -- The `on_step_end` operation took 0.933 s, which may be a performance bottleneck.
2023-11-03 23:09:10,277	WARNING util.py:214 -- The `start_trial` operation took 0.598 s, which may be a performance bottleneck.
2023-11-03 23:09:10,822	WARNING util.py:214 -- The `start_trial` operation took 0.533 s, which may be a performance bottleneck.
2023-11-03 23:09:13,145	WARNING util.py:214 -- The `on_step_end` operation took 0.729 s, which may be a performance bottleneck.
2023-11-03 23:12:01,534	WARNING util.py:214 -- The `on_step_end` operation took 0.680 s, which may be a performance bottleneck.
2023-11-03 23:14:08,288	WARNING util.py:214 -- The `on_step_end` operation took 0.517 s, which may be a performance bottleneck.
2023-11-03 23:14:14,245	WARNING util.py:214 -- The `on_step_end` operation took 0.612 s, which may be a performance bottleneck.
2023-11-03 23:14:15,676	WARNING util.py:214 -- The `start_trial` operation took 0.603 s, which may be a performance bottleneck.
2023-11-03 23:14:17,756	WARNING util.py:214 -- The `start_trial` operation took 0.525 s, which may be a performance bottleneck.
2023-11-03 23:14:20,528	WARNING util.py:214 -- The `on_step_end` operation took 0.815 s, which may be a performance bottleneck.
2023-11-03 23:17:12,462	WARNING util.py:214 -- The `on_step_end` operation took 0.850 s, which may be a performance bottleneck.
2023-11-03 23:17:14,582	WARNING util.py:214 -- The `start_trial` operation took 0.642 s, which may be a performance bottleneck.
2023-11-03 23:17:20,817	WARNING util.py:214 -- The `on_step_end` operation took 0.606 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 23:06:25 (running for 04:29:57.48)
Memory usage on this node: 30.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 913/1000000 (32 RUNNING, 881 TERMINATED)


== Status ==
Current time: 2023-11-03 23:06:31 (running for 04:30:03.71)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 919/1000000 (1 PENDING, 30 RUNNING, 888 TERMINATED)


== Status ==
Current time: 2023-11-03 23:09:07 (running for 04:32:39.79)
Memory usage on this node: 29.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 919/1000000 (31 RUNNING, 888 TERMINATED)


== Status ==
Current time: 2023-11-03 23:09:13 (running for 04:32:45.78)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 924/1000000 (31 RUNNING, 893 TERMINATED)


== Status ==
Current time: 2023-11-03 23:12:01 (running for 04:35:34.17)
Memory usage on this node: 30.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 925/1000000 (32 RUNNING, 893 TERMINATED)


== Status ==
Current time: 2023-11-03 23:13:59 (running for 04:37:32.21)
Memory usage on this node: 30.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: 79085ade with val_loss=478.0047958063571 and parameters={'n_estimators': 2052, 'max_depth': 5, 'min_child_weight': 0.08242316688132471, 'learning_rate': 0.012404498689673485, 'subsample': 0.9229646981077315, 'colsample_bylevel': 0.5947528261434792, 'colsample_bytree': 0.4221357079532695, 'reg_alpha': 0.12824835606043783, 'reg_lambda': 0.172579055511457, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 925/1000000 (32 RUNNING, 893 TERMINATED)


== Status ==
Current time: 2023-11-03 23:14:08 (running for 04:37:40.85)
Memory usage on this node: 30.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 926/1000000 (1 PENDING, 30 RUNNING, 895 TERMINATED)


== Status ==
Current time: 2023-11-03 23:14:14 (running for 04:37:46.67)
Memory usage on this node: 29.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 933/1000000 (31 RUNNING, 902 TERMINATED)


== Status ==
Current time: 2023-11-03 23:14:20 (running for 04:37:52.95)
Memory usage on this node: 29.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 939/1000000 (32 RUNNING, 907 TERMINATED)


== Status ==
Current time: 2023-11-03 23:17:12 (running for 04:40:44.88)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 939/1000000 (32 RUNNING, 907 TERMINATED)


2023-11-03 23:20:13,800	WARNING util.py:214 -- The `on_step_end` operation took 0.800 s, which may be a performance bottleneck.
2023-11-03 23:20:16,117	WARNING util.py:214 -- The `start_trial` operation took 0.575 s, which may be a performance bottleneck.
2023-11-03 23:20:22,182	WARNING util.py:214 -- The `on_step_end` operation took 0.561 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 23:21:16,416 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2435057) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 23:22:16,606 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2435077) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 23:25:25,499	WARNING util.py:214 -- The `on_step_end` operation took 0.778 s, which may be a performance bottleneck.
2023-11-03 23:25:27,744	WARNING util.py:214 -- The `start_trial` operation took 0.541 s, which may be a performance bottleneck.
2023-11-03 23:25:28,338	WARNING util.py:214 -- The `start_trial` operation took 0.585 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 23:26:28,003 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2435223) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 23:27:28,229 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2435254) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 23:30:30,247	WARNING util.py:214 -- The `on_step_end` operation took 0.884 s, which may be a performance bottleneck.
2023-11-03 23:30:34,221	WARNING util.py:214 -- The `start_trial` operation took 0.531 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 23:31:33,902 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2435465) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 23:32:34,114 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2435488) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 23:35:35,890	WARNING util.py:214 -- The `on_step_end` operation took 0.931 s, which may be a performance bottleneck.
2023-11-03 23:35:38,310	WARNING util.py:214 -- The `start_trial` operation took 0.634 s, which may be a performance bottleneck.
2023-11-03 23:35:41,822	WARNING util.py:214 -- The `start_trial` operation took 2.561 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 23:36:38,504 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2435634) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 23:36:39,536 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2435636) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 23:39:36,562	WARNING util.py:214 -- The `on_step_end` operation took 1.082 s, which may be a performance bottleneck.
2023-11-03 23:39:39,050	WARNING util.py:214 -- The `start_trial` operation took 0.540 s, which may be a performance bottleneck.
2023-11-03 23:39:39,568	WARNING util.py:214 -- The `start_trial` operation took 0.507 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 23:40:39,281 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2435873) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 23:41:39,507 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2435894) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 23:42:39,690 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2435911) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-03 23:17:20 (running for 04:40:53.24)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 941/1000000 (32 RUNNING, 909 TERMINATED)


== Status ==
Current time: 2023-11-03 23:20:13 (running for 04:43:46.40)
Memory usage on this node: 30.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 941/1000000 (32 RUNNING, 909 TERMINATED)


== Status ==
Current time: 2023-11-03 23:20:22 (running for 04:43:54.61)
Memory usage on this node: 29.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 943/1000000 (32 RUNNING, 911 TERMINATED)


== Status ==
Current time: 2023-11-03 23:25:25 (running for 04:48:57.92)
Memory usage on this node: 31.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 943/1000000 (32 RUNNING, 911 TERMINATED)


== Status ==
Current time: 2023-11-03 23:25:35 (running for 04:49:07.49)
Memory usage on this node: 30.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 946/1000000 (32 RUNNING, 914 TERMINATED)


== Status ==
Current time: 2023-11-03 23:30:30 (running for 04:54:02.88)
Memory usage on this node: 32.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 946/1000000 (32 RUNNING, 914 TERMINATED)


== Status ==
Current time: 2023-11-03 23:30:39 (running for 04:54:12.10)
Memory usage on this node: 31.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 949/1000000 (32 RUNNING, 917 TERMINATED)


== Status ==
Current time: 2023-11-03 23:35:35 (running for 04:59:08.31)
Memory usage on this node: 32.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 949/1000000 (32 RUNNING, 917 TERMINATED)


== Status ==
Current time: 2023-11-03 23:35:42 (running for 04:59:14.80)
Memory usage on this node: 31.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 952/1000000 (32 RUNNING, 920 TERMINATED)


== Status ==
Current time: 2023-11-03 23:39:36 (running for 05:03:08.99)
Memory usage on this node: 32.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 952/1000000 (32 RUNNING, 920 TERMINATED)


2023-11-03 23:45:38,316	WARNING util.py:214 -- The `on_step_end` operation took 0.762 s, which may be a performance bottleneck.
2023-11-03 23:45:40,782	WARNING util.py:214 -- The `start_trial` operation took 0.523 s, which may be a performance bottleneck.
2023-11-03 23:45:42,386	WARNING util.py:214 -- The `start_trial` operation took 0.527 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 23:46:40,987 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2436147) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 23:46:43,320 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2436155) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 23:47:41,208 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2436176) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 23:48:41,365 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2436195) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 23:51:41,609	WARNING util.py:214 -- The `on_step_end` operation took 0.805 s, which may be a performance bottleneck.
2023-11-03 23:51:44,689	WARNING util.py:214 -- The `start_trial` operation took 0.643 s, which may be a performance bottleneck.
2023-11-03 23:51:45,297	WARNING util.py:214 -- The `start_trial` operation took 0.591 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 23:52:44,858 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2436334) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 23:53:45,023 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2436362) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 23:54:45,198 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2436383) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-03 23:57:52,531	WARNING util.py:214 -- The `on_step_end` operation took 1.098 s, which may be a performance bottleneck.
2023-11-03 23:57:56,212	WARNING util.py:214 -- The `start_trial` operation took 0.509 s, which may be a performance bottleneck.
2023-11-03 23:58:01,774	WARNING util.py:214 -- The `on_step_end` operation took 0.560 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-03 23:58:55,873 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2436619) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-03 23:59:56,034 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2436643) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 00:00:56,226 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2436767) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 00:03:54,352	WARNING util.py:214 -- The `on_step_end` operation took 0.855 s, which may be a performance bottleneck.
2023-11-04 00:03:58,758	WARNING util.py:214 -- The `start_trial` operation took 0.578 s, which may be a performance bottleneck.
2023-11-04 00:03:59,361	WARNING util.py:214 -- The `start_trial` operation took 0.518 s, which may be a performance bottleneck.
2023-11-04 00:04:00,014	WARNING util.py:214 -- The `on_step_end` operation took 0.653 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 00:04:56,344 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2436877) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 00:07:51,511	WARNING util.py:214 -- The `on_step_end` operation took 0.736 s, which may be a performance bottleneck.
2023-11-04 00:07:55,107	WARNING util.py:214 -- The `start_trial` operation took 0.520 s, which may be a performance bottleneck.
2023-11-04 00:07:55,956	WARNING util.py:214 -- The `start_trial` operation took 0.792 s, which may be a performance bottleneck.
2023-11-04 00:07:57,423	WARNING util.py:214 -- The `on_step_end` operation took 0.651 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-03 23:39:44 (running for 05:03:17.25)
Memory usage on this node: 32.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 954/1000000 (32 RUNNING, 922 TERMINATED)


== Status ==
Current time: 2023-11-03 23:45:38 (running for 05:09:10.94)
Memory usage on this node: 32.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 954/1000000 (32 RUNNING, 922 TERMINATED)


== Status ==
Current time: 2023-11-03 23:45:43 (running for 05:09:16.32)
Memory usage on this node: 31.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 958/1000000 (32 RUNNING, 926 TERMINATED)


== Status ==
Current time: 2023-11-03 23:51:41 (running for 05:15:14.12)
Memory usage on this node: 33.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 958/1000000 (32 RUNNING, 926 TERMINATED)


== Status ==
Current time: 2023-11-03 23:51:50 (running for 05:15:23.14)
Memory usage on this node: 32.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 961/1000000 (32 RUNNING, 929 TERMINATED)


== Status ==
Current time: 2023-11-03 23:57:52 (running for 05:21:25.02)
Memory usage on this node: 33.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 961/1000000 (32 RUNNING, 929 TERMINATED)


== Status ==
Current time: 2023-11-03 23:58:01 (running for 05:21:34.20)
Memory usage on this node: 32.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 964/1000000 (32 RUNNING, 932 TERMINATED)


== Status ==
Current time: 2023-11-04 00:03:54 (running for 05:27:26.83)
Memory usage on this node: 33.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 964/1000000 (32 RUNNING, 932 TERMINATED)


== Status ==
Current time: 2023-11-04 00:04:00 (running for 05:27:32.51)
Memory usage on this node: 32.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 968/1000000 (31 RUNNING, 937 TERMINATED)


== Status ==
Current time: 2023-11-04 00:07:51 (running for 05:31:23.93)
Memory usage on this node: 32.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 969/1000000 (1 PENDING, 31 RUNNING, 937 TERMINATED)


2023-11-04 00:10:59,052	WARNING util.py:214 -- The `on_step_end` operation took 1.052 s, which may be a performance bottleneck.
2023-11-04 00:11:00,366	WARNING util.py:214 -- The `start_trial` operation took 0.856 s, which may be a performance bottleneck.
2023-11-04 00:11:01,576	WARNING util.py:214 -- The `start_trial` operation took 0.551 s, which may be a performance bottleneck.
2023-11-04 00:11:02,117	WARNING util.py:214 -- The `start_trial` operation took 0.521 s, which may be a performance bottleneck.
2023-11-04 00:13:55,951	WARNING util.py:214 -- The `on_step_end` operation took 0.662 s, which may be a performance bottleneck.
2023-11-04 00:13:58,383	WARNING util.py:214 -- The `start_trial` operation took 0.705 s, which may be a performance bottleneck.
2023-11-04 00:13:59,362	WARNING util.py:214 -- The `start_trial` operation took 0.527 s, which may be a performance bottleneck.
2023-11-04 00:14:01,959	WARNING util.py:214 -- The `on_step_end` operation took 0.683 s, which may be a performance bottleneck.
2023-11-04 00:16:54,479	WARNING util.py:214 -- The `on_step_end` operation took 0.824 s, which may be a performance bottleneck.
2023-11-04 00:16:57,460	WARNING util.py:214 -- The `start_trial` operation took 0.600 s, which may be a performance bottleneck.
2023-11-04 00:16:58,126	WARNING util.py:214 -- The `start_trial` operation took 0.653 s, which may be a performance bottleneck.
2023-11-04 00:17:00,390	WARNING util.py:214 -- The `on_step_end` operation took 0.789 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 00:17:57,702 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2437625) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 00:20:35,741	WARNING util.py:214 -- The `on_step_end` operation took 0.765 s, which may be a performance bottleneck.
2023-11-04 00:20:37,639	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.581 s, which may be a performance bottleneck.
2023-11-04 00:20:37,639	WARNING util.py:214 -- The `process_trial_result` operation took 0.581 s, which may be a performance bottleneck.
2023-11-04 00:20:37,639	WARNING util.py:214 -- Processing trial results took 0.581 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-04 00:20:37,639	WARNING util.py:214 -- The `process_trial_result` operation took 0.581 s, which may be a performance bottleneck.
2023-11-04 00:20:38,810	WARNING util.py:214 -- The `start_trial` operation took 0.539 s, which may be a performance bottleneck.
2023-11-04 00:20:41,711	WARNING util.py:214 -- The `on_step_end` operation took 0.800 s, which may be a performance bottleneck.
2023-11-04 00:20:46,383	WARNING util.py:214 -- The `start_trial` operation took 0.690 s, which may be a performance bottleneck.
2023-11-04 00:20:47,741	WARNING util.py:214 -- The `on_step_end` operation took 1.017 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 00:21:45,941 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2437811) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 00:24:21,953	WARNING util.py:214 -- The `on_step_end` operation took 0.590 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 00:07:57 (running for 05:31:29.85)
Memory usage on this node: 31.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 973/1000000 (31 RUNNING, 942 TERMINATED)


== Status ==
Current time: 2023-11-04 00:10:59 (running for 05:34:31.47)
Memory usage on this node: 32.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 974/1000000 (1 PENDING, 31 RUNNING, 942 TERMINATED)


== Status ==
Current time: 2023-11-04 00:11:07 (running for 05:34:40.02)
Memory usage on this node: 32.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 976/1000000 (32 RUNNING, 944 TERMINATED)


== Status ==
Current time: 2023-11-04 00:13:55 (running for 05:37:28.37)
Memory usage on this node: 33.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 976/1000000 (32 RUNNING, 944 TERMINATED)


== Status ==
Current time: 2023-11-04 00:14:02 (running for 05:37:34.49)
Memory usage on this node: 32.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 981/1000000 (32 RUNNING, 949 TERMINATED)


== Status ==
Current time: 2023-11-04 00:16:54 (running for 05:40:26.90)
Memory usage on this node: 33.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 981/1000000 (32 RUNNING, 949 TERMINATED)


== Status ==
Current time: 2023-11-04 00:17:00 (running for 05:40:33.04)
Memory usage on this node: 32.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 985/1000000 (32 RUNNING, 953 TERMINATED)


== Status ==
Current time: 2023-11-04 00:20:35 (running for 05:44:08.33)
Memory usage on this node: 33.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 985/1000000 (32 RUNNING, 953 TERMINATED)


== Status ==
Current time: 2023-11-04 00:20:41 (running for 05:44:14.18)
Memory usage on this node: 32.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 989/1000000 (31 RUNNING, 958 TERMINATED)


== Status ==
Current time: 2023-11-04 00:20:47 (running for 05:44:20.38)
Memory usage on this node: 33.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 992/1000000 (32 RUNNING, 960 TERMINATED)


2023-11-04 00:24:25,042	WARNING util.py:214 -- The `start_trial` operation took 0.518 s, which may be a performance bottleneck.
2023-11-04 00:24:26,827	WARNING util.py:214 -- The `start_trial` operation took 0.531 s, which may be a performance bottleneck.
2023-11-04 00:24:28,349	WARNING util.py:214 -- The `on_step_end` operation took 0.902 s, which may be a performance bottleneck.
2023-11-04 00:26:44,623	WARNING util.py:214 -- The `on_step_end` operation took 0.524 s, which may be a performance bottleneck.
2023-11-04 00:26:49,597	WARNING util.py:214 -- The `start_trial` operation took 0.849 s, which may be a performance bottleneck.
2023-11-04 00:26:50,142	WARNING util.py:214 -- The `on_step_end` operation took 0.512 s, which may be a performance bottleneck.
2023-11-04 00:29:06,306	WARNING util.py:214 -- The `on_step_end` operation took 0.582 s, which may be a performance bottleneck.
2023-11-04 00:29:09,207	WARNING util.py:214 -- The `start_trial` operation took 0.649 s, which may be a performance bottleneck.
2023-11-04 00:29:12,258	WARNING util.py:214 -- The `on_step_end` operation took 0.795 s, which may be a performance bottleneck.
2023-11-04 00:29:14,652	WARNING util.py:214 -- The `start_trial` operation took 0.550 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 00:30:17,839 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2438300) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 00:31:18,024 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2438324) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 00:33:58,118	WARNING util.py:214 -- The `on_step_end` operation took 0.758 s, which may be a performance bottleneck.
2023-11-04 00:34:03,929	WARNING util.py:214 -- The `on_step_end` operation took 0.795 s, which may be a performance bottleneck.
2023-11-04 00:36:34,647	WARNING util.py:214 -- The `on_step_end` operation took 0.826 s, which may be a performance bottleneck.
2023-11-04 00:36:40,971	WARNING util.py:214 -- The `on_step_end` operation took 0.953 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 00:24:22 (running for 05:47:54.48)
Memory usage on this node: 33.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 992/1000000 (32 RUNNING, 960 TERMINATED)


== Status ==
Current time: 2023-11-04 00:24:28 (running for 05:48:00.77)
Memory usage on this node: 32.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 995/1000000 (1 PENDING, 31 RUNNING, 963 TERMINATED)


== Status ==
Current time: 2023-11-04 00:26:44 (running for 05:50:17.15)
Memory usage on this node: 32.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 995/1000000 (1 PENDING, 31 RUNNING, 963 TERMINATED)


== Status ==
Current time: 2023-11-04 00:26:50 (running for 05:50:22.62)
Memory usage on this node: 32.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 999/1000000 (31 RUNNING, 968 TERMINATED)


== Status ==
Current time: 2023-11-04 00:29:06 (running for 05:52:38.86)
Memory usage on this node: 33.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1000/1000000 (1 PENDING, 31 RUNNING, 968 TERMINATED)


== Status ==
Current time: 2023-11-04 00:29:12 (running for 05:52:44.70)
Memory usage on this node: 33.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1005/1000000 (31 RUNNING, 974 TERMINATED)


== Status ==
Current time: 2023-11-04 00:29:18 (running for 05:52:50.73)
Memory usage on this node: 33.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1011/1000000 (32 RUNNING, 979 TERMINATED)


== Status ==
Current time: 2023-11-04 00:33:58 (running for 05:57:30.54)
Memory usage on this node: 33.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1011/1000000 (32 RUNNING, 979 TERMINATED)


== Status ==
Current time: 2023-11-04 00:34:03 (running for 05:57:36.35)
Memory usage on this node: 33.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1015/1000000 (32 RUNNING, 983 TERMINATED)


== Status ==
Current time: 2023-11-04 00:36:34 (running for 06:00:07.15)
Memory usage on this node: 33.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1015/1000000 (31 RUNNING, 984 TERMINATED)


2023-11-04 00:39:21,888	WARNING util.py:214 -- The `on_step_end` operation took 0.887 s, which may be a performance bottleneck.
2023-11-04 00:41:39,027	WARNING util.py:214 -- The `on_step_end` operation took 0.517 s, which may be a performance bottleneck.
2023-11-04 00:41:43,197	WARNING util.py:214 -- The `start_trial` operation took 0.541 s, which may be a performance bottleneck.
2023-11-04 00:43:54,531	WARNING util.py:214 -- The `on_step_end` operation took 0.710 s, which may be a performance bottleneck.
2023-11-04 00:43:56,452	WARNING util.py:214 -- The `start_trial` operation took 0.535 s, which may be a performance bottleneck.
2023-11-04 00:44:00,691	WARNING util.py:214 -- The `on_step_end` operation took 0.968 s, which may be a performance bottleneck.
2023-11-04 00:46:15,156	WARNING util.py:214 -- The `on_step_end` operation took 0.758 s, which may be a performance bottleneck.
2023-11-04 00:46:17,599	WARNING util.py:214 -- The `start_trial` operation took 0.691 s, which may be a performance bottleneck.
2023-11-04 00:46:20,991	WARNING util.py:214 -- The `on_step_end` operation took 0.785 s, which may be a performance bottleneck.
2023-11-04 00:48:56,131	WARNING util.py:214 -- The `on_step_end` operation took 0.797 s, which may be a performance bottleneck.
2023-11-04 00:49:00,641	WARNING util.py:214 -- The `start_trial` operation took 0.547 s, which may be a performance bottleneck.
2023-11-04 00:49:02,194	WARNING util.py:214 -- The `on_step_end` operation took 0.786 s, which may be a performance bottleneck.
2023-11-04 00:51:15,026	WARNING util.py:214 -- The `on_step_end` operation took 0.827 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 00:36:41 (running for 06:00:13.44)
Memory usage on this node: 32.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1021/1000000 (31 RUNNING, 990 TERMINATED)


== Status ==
Current time: 2023-11-04 00:39:22 (running for 06:02:54.52)
Memory usage on this node: 33.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1022/1000000 (32 RUNNING, 990 TERMINATED)


== Status ==
Current time: 2023-11-04 00:41:39 (running for 06:05:11.55)
Memory usage on this node: 33.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1022/1000000 (32 RUNNING, 990 TERMINATED)


== Status ==
Current time: 2023-11-04 00:41:44 (running for 06:05:17.20)
Memory usage on this node: 32.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1026/1000000 (1 PENDING, 30 RUNNING, 995 TERMINATED)


== Status ==
Current time: 2023-11-04 00:43:54 (running for 06:07:26.96)
Memory usage on this node: 33.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1026/1000000 (31 RUNNING, 995 TERMINATED)


== Status ==
Current time: 2023-11-04 00:44:00 (running for 06:07:33.11)
Memory usage on this node: 32.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1032/1000000 (1 PENDING, 30 RUNNING, 1001 TERMINATED)


== Status ==
Current time: 2023-11-04 00:46:15 (running for 06:09:47.58)
Memory usage on this node: 32.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1032/1000000 (31 RUNNING, 1001 TERMINATED)


== Status ==
Current time: 2023-11-04 00:46:21 (running for 06:09:53.55)
Memory usage on this node: 32.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1038/1000000 (1 PENDING, 31 RUNNING, 1006 TERMINATED)


== Status ==
Current time: 2023-11-04 00:48:56 (running for 06:12:28.57)
Memory usage on this node: 32.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1038/1000000 (1 PENDING, 31 RUNNING, 1006 TERMINATED)


== Status ==
Current time: 2023-11-04 00:49:02 (running for 06:12:34.62)
Memory usage on this node: 31.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1042/1000000 (31 RUNNING, 1011 TERMINATED)


2023-11-04 00:51:15,961	WARNING util.py:214 -- The `start_trial` operation took 0.505 s, which may be a performance bottleneck.
2023-11-04 00:51:16,781	WARNING util.py:214 -- The `start_trial` operation took 0.507 s, which may be a performance bottleneck.
2023-11-04 00:51:20,236	WARNING util.py:214 -- The `start_trial` operation took 0.613 s, which may be a performance bottleneck.
2023-11-04 00:51:21,022	WARNING util.py:214 -- The `on_step_end` operation took 0.785 s, which may be a performance bottleneck.
2023-11-04 00:53:57,997	WARNING util.py:214 -- The `on_step_end` operation took 0.947 s, which may be a performance bottleneck.
2023-11-04 00:56:09,129	WARNING util.py:214 -- The `on_step_end` operation took 0.576 s, which may be a performance bottleneck.
2023-11-04 00:56:15,533	WARNING util.py:214 -- The `on_step_end` operation took 1.197 s, which may be a performance bottleneck.
2023-11-04 00:58:50,523	WARNING util.py:214 -- The `on_step_end` operation took 0.880 s, which may be a performance bottleneck.
2023-11-04 00:58:56,733	WARNING util.py:214 -- The `on_step_end` operation took 0.884 s, which may be a performance bottleneck.
2023-11-04 01:01:58,246	WARNING util.py:214 -- The `on_step_end` operation took 1.196 s, which may be a performance bottleneck.
2023-11-04 01:01:59,421	WARNING util.py:214 -- The `start_trial` operation took 0.627 s, which may be a performance bottleneck.
2023-11-04 01:02:00,579	WARNING util.py:214 -- The `start_trial` operation took 0.501 s, which may be a performance bottleneck.
2023-11-04 01:02:01,218	WARNING util.py:214 -- The `start_trial` operation took 0.501 s, which may be a performance bottleneck.
2023-11-04 01:02:02,034	WARNING util.py:214 -- The `start_trial` operation took 0.753 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 01:02:59,175 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2440044) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 01:05:34,888	WARNING util.py:214 -- The `on_step_end` operation took 0.878 s, which may be a performance bottleneck.
2023-11-04 01:05:40,166	WARNING util.py:214 -- The `start_trial` operation took 0.506 s, which may be a performance bottleneck.
2023-11-04 01:05:41,069	WARNING util.py:214 -- The `on_step_end` operation took 0.903 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 00:51:15 (running for 06:14:47.45)
Memory usage on this node: 32.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1043/1000000 (1 PENDING, 30 RUNNING, 1012 TERMINATED)


== Status ==
Current time: 2023-11-04 00:51:21 (running for 06:14:53.49)
Memory usage on this node: 32.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1048/1000000 (31 RUNNING, 1017 TERMINATED)


== Status ==
Current time: 2023-11-04 00:53:57 (running for 06:17:30.42)
Memory usage on this node: 32.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1049/1000000 (32 RUNNING, 1017 TERMINATED)


== Status ==
Current time: 2023-11-04 00:56:09 (running for 06:19:41.72)
Memory usage on this node: 32.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1049/1000000 (31 RUNNING, 1018 TERMINATED)


== Status ==
Current time: 2023-11-04 00:56:15 (running for 06:19:48.18)
Memory usage on this node: 32.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1055/1000000 (1 PENDING, 30 RUNNING, 1024 TERMINATED)


== Status ==
Current time: 2023-11-04 00:58:50 (running for 06:22:23.18)
Memory usage on this node: 32.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1055/1000000 (31 RUNNING, 1024 TERMINATED)


== Status ==
Current time: 2023-11-04 00:58:56 (running for 06:22:29.19)
Memory usage on this node: 32.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1060/1000000 (31 RUNNING, 1029 TERMINATED)


== Status ==
Current time: 2023-11-04 01:01:58 (running for 06:25:30.67)
Memory usage on this node: 33.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1061/1000000 (1 PENDING, 31 RUNNING, 1029 TERMINATED)


== Status ==
Current time: 2023-11-04 01:02:07 (running for 06:25:39.93)
Memory usage on this node: 32.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1064/1000000 (32 RUNNING, 1032 TERMINATED)


== Status ==
Current time: 2023-11-04 01:05:34 (running for 06:29:07.31)
Memory usage on this node: 33.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1064/1000000 (32 RUNNING, 1032 TERMINATED)


2023-11-04 01:05:42,919	WARNING util.py:214 -- The `start_trial` operation took 0.598 s, which may be a performance bottleneck.
2023-11-04 01:05:49,246	WARNING util.py:214 -- The `on_step_end` operation took 0.717 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 01:06:43,322 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2440309) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 01:07:43,487 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2440330) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 01:08:43,657 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2440347) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 01:11:34,429	WARNING util.py:214 -- The `on_step_end` operation took 0.882 s, which may be a performance bottleneck.
2023-11-04 01:11:39,403	WARNING util.py:214 -- The `start_trial` operation took 0.515 s, which may be a performance bottleneck.
2023-11-04 01:11:39,971	WARNING util.py:214 -- The `start_trial` operation took 0.559 s, which may be a performance bottleneck.
2023-11-04 01:11:40,890	WARNING util.py:214 -- The `on_step_end` operation took 0.918 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 01:12:40,309 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2440509) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 01:15:21,896	WARNING util.py:214 -- The `on_step_end` operation took 0.930 s, which may be a performance bottleneck.
2023-11-04 01:15:25,720	WARNING util.py:214 -- The `start_trial` operation took 0.600 s, which may be a performance bottleneck.
2023-11-04 01:15:26,774	WARNING util.py:214 -- The `start_trial` operation took 0.565 s, which may be a performance bottleneck.
2023-11-04 01:15:27,964	WARNING util.py:214 -- The `on_step_end` operation took 0.757 s, which may be a performance bottleneck.
2023-11-04 01:18:16,487	WARNING util.py:214 -- The `on_step_end` operation took 0.937 s, which may be a performance bottleneck.
2023-11-04 01:18:18,917	WARNING util.py:214 -- The `start_trial` operation took 0.520 s, which may be a performance bottleneck.
2023-11-04 01:18:19,487	WARNING util.py:214 -- The `start_trial` operation took 0.559 s, which may be a performance bottleneck.
2023-11-04 01:18:21,368	WARNING util.py:214 -- The `start_trial` operation took 0.510 s, which may be a performance bottleneck.
2023-11-04 01:18:21,992	WARNING util.py:214 -- The `start_trial` operation took 0.548 s, which may be a performance bottleneck.
2023-11-04 01:18:22,830	WARNING util.py:214 -- The `on_step_end` operation took 0.837 s, which may be a performance bottleneck.
2023-11-04 01:21:06,469	WARNING util.py:214 -- The `on_step_end` operation took 0.893 s, which may be a performance bottleneck.
2023-11-04 01:21:09,524	WARNING util.py:214 -- The `start_trial` operation took 0.601 s, which may be a performance bottleneck.
2023-11-04 01:21:11,267	WARNING util.py:214 -- The `start_trial` operation took 0.595 s, which may be a performance bottleneck.
2023-11-04 01:21:12,753	WARNING util.py:214 -- The `on_step_end` operation took 1.099 s, which may be a performance bottleneck.
2023-11-04 01:24:00,308	WARNING util.py:214 -- The `on_step_end` operation took 1.128 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 01:05:41 (running for 06:29:13.49)
Memory usage on this node: 31.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1069/1000000 (31 RUNNING, 1038 TERMINATED)


== Status ==
Current time: 2023-11-04 01:05:49 (running for 06:29:21.67)
Memory usage on this node: 32.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1071/1000000 (32 RUNNING, 1039 TERMINATED)


== Status ==
Current time: 2023-11-04 01:11:34 (running for 06:35:06.85)
Memory usage on this node: 32.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1071/1000000 (32 RUNNING, 1039 TERMINATED)


== Status ==
Current time: 2023-11-04 01:11:41 (running for 06:35:13.57)
Memory usage on this node: 32.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1076/1000000 (32 RUNNING, 1044 TERMINATED)


== Status ==
Current time: 2023-11-04 01:15:21 (running for 06:38:54.39)
Memory usage on this node: 32.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1076/1000000 (32 RUNNING, 1044 TERMINATED)


== Status ==
Current time: 2023-11-04 01:15:27 (running for 06:39:00.39)
Memory usage on this node: 31.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1081/1000000 (32 RUNNING, 1049 TERMINATED)


== Status ==
Current time: 2023-11-04 01:18:16 (running for 06:41:48.91)
Memory usage on this node: 32.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1081/1000000 (32 RUNNING, 1049 TERMINATED)


== Status ==
Current time: 2023-11-04 01:18:22 (running for 06:41:55.25)
Memory usage on this node: 30.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1086/1000000 (32 RUNNING, 1054 TERMINATED)


== Status ==
Current time: 2023-11-04 01:21:06 (running for 06:44:38.92)
Memory usage on this node: 31.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1086/1000000 (32 RUNNING, 1054 TERMINATED)


== Status ==
Current time: 2023-11-04 01:21:12 (running for 06:44:45.38)
Memory usage on this node: 30.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1091/1000000 (1 PENDING, 31 RUNNING, 1059 TERMINATED)


2023-11-04 01:26:26,365	WARNING util.py:214 -- The `start_trial` operation took 0.508 s, which may be a performance bottleneck.
2023-11-04 01:26:27,271	WARNING util.py:214 -- The `start_trial` operation took 0.585 s, which may be a performance bottleneck.
2023-11-04 01:26:28,822	WARNING util.py:214 -- The `on_step_end` operation took 1.018 s, which may be a performance bottleneck.
2023-11-04 01:29:21,366	WARNING util.py:214 -- The `on_step_end` operation took 0.945 s, which may be a performance bottleneck.
2023-11-04 01:31:48,336	WARNING util.py:214 -- The `start_trial` operation took 0.515 s, which may be a performance bottleneck.
2023-11-04 01:31:50,769	WARNING util.py:214 -- The `on_step_end` operation took 1.150 s, which may be a performance bottleneck.
2023-11-04 01:31:52,061	WARNING util.py:214 -- The `start_trial` operation took 0.545 s, which may be a performance bottleneck.
2023-11-04 01:31:52,816	WARNING util.py:214 -- The `start_trial` operation took 0.551 s, which may be a performance bottleneck.
2023-11-04 01:31:58,496	WARNING util.py:214 -- The `on_step_end` operation took 0.677 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 01:32:52,496 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2441500) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 01:35:40,194	WARNING util.py:214 -- The `on_step_end` operation took 0.919 s, which may be a performance bottleneck.
2023-11-04 01:35:42,945	WARNING util.py:214 -- The `start_trial` operation took 0.642 s, which may be a performance bottleneck.
2023-11-04 01:35:46,250	WARNING util.py:214 -- The `on_step_end` operation took 0.925 s, which may be a performance bottleneck.
2023-11-04 01:38:26,805	WARNING util.py:214 -- The `on_step_end` operation took 1.081 s, which may be a performance bottleneck.
2023-11-04 01:38:29,330	WARNING util.py:214 -- The `start_trial` operation took 0.664 s, which may be a performance bottleneck.
2023-11-04 01:38:31,401	WARNING util.py:214 -- The `start_trial` operation took 0.587 s, which may be a performance bottleneck.
2023-11-04 01:38:32,890	WARNING util.py:214 -- The `on_step_end` operation took 0.933 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 01:39:29,043 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2441797) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 01:39:31,699 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2441808) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 01:40:29,227 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2441879) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 01:40:31,887 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2441887) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-04 01:24:00 (running for 06:47:32.73)
Memory usage on this node: 30.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1091/1000000 (32 RUNNING, 1059 TERMINATED)


== Status ==
Current time: 2023-11-04 01:26:22 (running for 06:49:55.40)
Memory usage on this node: 31.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1091/1000000 (32 RUNNING, 1059 TERMINATED)


== Status ==
Current time: 2023-11-04 01:26:28 (running for 06:50:01.24)
Memory usage on this node: 30.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1096/1000000 (1 PENDING, 31 RUNNING, 1064 TERMINATED)


== Status ==
Current time: 2023-11-04 01:29:21 (running for 06:52:53.86)
Memory usage on this node: 30.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1096/1000000 (32 RUNNING, 1064 TERMINATED)


== Status ==
Current time: 2023-11-04 01:31:44 (running for 06:55:16.89)
Memory usage on this node: 31.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1096/1000000 (32 RUNNING, 1064 TERMINATED)


== Status ==
Current time: 2023-11-04 01:31:50 (running for 06:55:23.19)
Memory usage on this node: 31.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1102/1000000 (1 PENDING, 30 RUNNING, 1071 TERMINATED)


== Status ==
Current time: 2023-11-04 01:31:58 (running for 06:55:30.92)
Memory usage on this node: 31.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1103/1000000 (32 RUNNING, 1071 TERMINATED)


== Status ==
Current time: 2023-11-04 01:35:40 (running for 06:59:12.62)
Memory usage on this node: 31.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1103/1000000 (32 RUNNING, 1071 TERMINATED)


== Status ==
Current time: 2023-11-04 01:35:46 (running for 06:59:18.67)
Memory usage on this node: 30.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1107/1000000 (32 RUNNING, 1075 TERMINATED)


== Status ==
Current time: 2023-11-04 01:38:26 (running for 07:01:59.37)
Memory usage on this node: 30.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1107/1000000 (31 RUNNING, 1076 TERMINATED)


2023-11-04 01:43:21,657	WARNING util.py:214 -- The `on_step_end` operation took 1.022 s, which may be a performance bottleneck.
2023-11-04 01:43:24,374	WARNING util.py:214 -- The `start_trial` operation took 0.545 s, which may be a performance bottleneck.
2023-11-04 01:43:24,956	WARNING util.py:214 -- The `start_trial` operation took 0.572 s, which may be a performance bottleneck.
2023-11-04 01:43:26,781	WARNING util.py:214 -- The `start_trial` operation took 0.708 s, which may be a performance bottleneck.
2023-11-04 01:43:27,748	WARNING util.py:214 -- The `on_step_end` operation took 0.966 s, which may be a performance bottleneck.
2023-11-04 01:46:06,706	WARNING util.py:214 -- The `on_step_end` operation took 0.706 s, which may be a performance bottleneck.
2023-11-04 01:46:09,207	WARNING util.py:214 -- The `start_trial` operation took 0.524 s, which may be a performance bottleneck.
2023-11-04 01:46:20,071	WARNING util.py:214 -- The `on_step_end` operation took 1.131 s, which may be a performance bottleneck.
2023-11-04 01:46:21,537	WARNING util.py:214 -- The `start_trial` operation took 0.626 s, which may be a performance bottleneck.
2023-11-04 01:46:24,377	WARNING util.py:214 -- The `start_trial` operation took 0.737 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 01:47:21,162 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2442261) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 01:48:21,356 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2442308) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 01:51:06,616	WARNING util.py:214 -- The `on_step_end` operation took 0.965 s, which may be a performance bottleneck.
2023-11-04 01:51:09,387	WARNING util.py:214 -- The `start_trial` operation took 0.516 s, which may be a performance bottleneck.
2023-11-04 01:51:10,812	WARNING util.py:214 -- The `start_trial` operation took 0.516 s, which may be a performance bottleneck.
2023-11-04 01:51:11,401	WARNING util.py:214 -- The `start_trial` operation took 0.581 s, which may be a performance bottleneck.
2023-11-04 01:51:12,701	WARNING util.py:214 -- The `on_step_end` operation took 1.015 s, which may be a performance bottleneck.
2023-11-04 01:54:09,646	WARNING util.py:214 -- The `on_step_end` operation took 1.052 s, which may be a performance bottleneck.
2023-11-04 01:54:18,544	WARNING util.py:214 -- The `on_step_end` operation took 0.795 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 01:55:12,672 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2442691) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 01:58:16,398	WARNING util.py:214 -- The `on_step_end` operation took 1.210 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 01:38:32 (running for 07:02:05.31)
Memory usage on this node: 30.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1112/1000000 (32 RUNNING, 1080 TERMINATED)


== Status ==
Current time: 2023-11-04 01:43:21 (running for 07:06:54.08)
Memory usage on this node: 31.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1112/1000000 (32 RUNNING, 1080 TERMINATED)


== Status ==
Current time: 2023-11-04 01:43:27 (running for 07:07:00.38)
Memory usage on this node: 31.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1116/1000000 (32 RUNNING, 1084 TERMINATED)


== Status ==
Current time: 2023-11-04 01:46:06 (running for 07:09:39.20)
Memory usage on this node: 31.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1116/1000000 (32 RUNNING, 1084 TERMINATED)


== Status ==
Current time: 2023-11-04 01:46:20 (running for 07:09:52.53)
Memory usage on this node: 30.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1117/1000000 (31 RUNNING, 1086 TERMINATED)


== Status ==
Current time: 2023-11-04 01:46:29 (running for 07:10:02.27)
Memory usage on this node: 30.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1121/1000000 (32 RUNNING, 1089 TERMINATED)


== Status ==
Current time: 2023-11-04 01:51:06 (running for 07:14:39.19)
Memory usage on this node: 31.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1121/1000000 (32 RUNNING, 1089 TERMINATED)


== Status ==
Current time: 2023-11-04 01:51:12 (running for 07:14:45.28)
Memory usage on this node: 30.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1126/1000000 (1 PENDING, 31 RUNNING, 1094 TERMINATED)


== Status ==
Current time: 2023-11-04 01:54:09 (running for 07:17:42.07)
Memory usage on this node: 29.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1126/1000000 (1 PENDING, 31 RUNNING, 1094 TERMINATED)


== Status ==
Current time: 2023-11-04 01:54:18 (running for 07:17:50.97)
Memory usage on this node: 30.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1129/1000000 (32 RUNNING, 1097 TERMINATED)


2023-11-04 01:58:19,650	WARNING util.py:214 -- The `start_trial` operation took 0.670 s, which may be a performance bottleneck.
2023-11-04 01:58:20,884	WARNING util.py:214 -- The `start_trial` operation took 0.587 s, which may be a performance bottleneck.
2023-11-04 01:58:26,984	WARNING util.py:214 -- The `on_step_end` operation took 0.594 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 01:59:19,278 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2442800) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 02:02:09,782	WARNING util.py:214 -- The `on_step_end` operation took 0.975 s, which may be a performance bottleneck.
2023-11-04 02:02:16,484	WARNING util.py:214 -- The `on_step_end` operation took 0.869 s, which may be a performance bottleneck.
2023-11-04 02:05:10,103	WARNING util.py:214 -- The `on_step_end` operation took 1.123 s, which may be a performance bottleneck.
2023-11-04 02:05:12,643	WARNING util.py:214 -- The `start_trial` operation took 0.523 s, which may be a performance bottleneck.
2023-11-04 02:05:13,179	WARNING util.py:214 -- The `start_trial` operation took 0.525 s, which may be a performance bottleneck.
2023-11-04 02:05:20,257	WARNING util.py:214 -- The `on_step_end` operation took 0.520 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 02:06:12,876 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2443224) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 02:09:04,111	WARNING util.py:214 -- The `on_step_end` operation took 1.234 s, which may be a performance bottleneck.
2023-11-04 02:09:07,503	WARNING util.py:214 -- The `start_trial` operation took 0.590 s, which may be a performance bottleneck.
2023-11-04 02:09:09,754	WARNING util.py:214 -- The `on_step_end` operation took 0.626 s, which may be a performance bottleneck.
2023-11-04 02:12:09,087	WARNING util.py:214 -- The `on_step_end` operation took 1.153 s, which may be a performance bottleneck.
2023-11-04 02:12:12,854	WARNING util.py:214 -- The `start_trial` operation took 0.531 s, which may be a performance bottleneck.
2023-11-04 02:12:13,582	WARNING util.py:214 -- The `start_trial` operation took 0.505 s, which may be a performance bottleneck.
2023-11-04 02:12:19,239	WARNING util.py:214 -- The `on_step_end` operation took 0.654 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 02:13:11,509 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2443533) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 02:15:49,328	WARNING util.py:214 -- The `on_step_end` operation took 0.921 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 01:58:16 (running for 07:21:48.90)
Memory usage on this node: 30.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1129/1000000 (32 RUNNING, 1097 TERMINATED)


== Status ==
Current time: 2023-11-04 01:58:27 (running for 07:21:59.63)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1133/1000000 (32 RUNNING, 1101 TERMINATED)


== Status ==
Current time: 2023-11-04 02:02:09 (running for 07:25:42.33)
Memory usage on this node: 30.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1133/1000000 (32 RUNNING, 1101 TERMINATED)


== Status ==
Current time: 2023-11-04 02:02:16 (running for 07:25:48.91)
Memory usage on this node: 29.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1138/1000000 (32 RUNNING, 1106 TERMINATED)


== Status ==
Current time: 2023-11-04 02:05:10 (running for 07:28:42.66)
Memory usage on this node: 30.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1138/1000000 (32 RUNNING, 1106 TERMINATED)


== Status ==
Current time: 2023-11-04 02:05:20 (running for 07:28:52.86)
Memory usage on this node: 29.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1141/1000000 (32 RUNNING, 1109 TERMINATED)


== Status ==
Current time: 2023-11-04 02:09:04 (running for 07:32:36.53)
Memory usage on this node: 30.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1141/1000000 (32 RUNNING, 1109 TERMINATED)


== Status ==
Current time: 2023-11-04 02:09:09 (running for 07:32:42.18)
Memory usage on this node: 29.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1145/1000000 (32 RUNNING, 1113 TERMINATED)


== Status ==
Current time: 2023-11-04 02:12:09 (running for 07:35:41.62)
Memory usage on this node: 30.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1145/1000000 (32 RUNNING, 1113 TERMINATED)


== Status ==
Current time: 2023-11-04 02:12:19 (running for 07:35:51.72)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1148/1000000 (32 RUNNING, 1116 TERMINATED)


2023-11-04 02:15:53,690	WARNING util.py:214 -- The `start_trial` operation took 0.504 s, which may be a performance bottleneck.
2023-11-04 02:15:54,208	WARNING util.py:214 -- The `start_trial` operation took 0.510 s, which may be a performance bottleneck.
2023-11-04 02:15:55,681	WARNING util.py:214 -- The `on_step_end` operation took 0.957 s, which may be a performance bottleneck.
2023-11-04 02:18:38,095	WARNING util.py:214 -- The `on_step_end` operation took 1.052 s, which may be a performance bottleneck.
2023-11-04 02:18:40,812	WARNING util.py:214 -- The `start_trial` operation took 0.869 s, which may be a performance bottleneck.
2023-11-04 02:18:42,743	WARNING util.py:214 -- The `start_trial` operation took 0.599 s, which may be a performance bottleneck.
2023-11-04 02:18:44,879	WARNING util.py:214 -- The `on_step_end` operation took 0.762 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 02:19:40,164 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2443887) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 02:22:32,394	WARNING util.py:214 -- The `on_step_end` operation took 1.061 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 02:23:34,991 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2444142) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 02:23:37,015 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2444147) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 02:24:35,157 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2444181) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 02:27:13,246	WARNING util.py:214 -- The `on_step_end` operation took 0.973 s, which may be a performance bottleneck.
2023-11-04 02:27:16,932	WARNING util.py:214 -- The `start_trial` operation took 0.766 s, which may be a performance bottleneck.
2023-11-04 02:27:18,323	WARNING util.py:214 -- The `start_trial` operation took 0.527 s, which may be a performance bottleneck.
2023-11-04 02:27:19,186	WARNING util.py:214 -- The `on_step_end` operation took 0.863 s, which may be a performance bottleneck.
2023-11-04 02:30:04,633	WARNING util.py:214 -- The `on_step_end` operation took 1.022 s, which may be a performance bottleneck.
2023-11-04 02:32:24,029	WARNING util.py:214 -- The `on_step_end` operation took 0.781 s, which may be a performance bottleneck.
2023-11-04 02:32:26,194	WARNING util.py:214 -- The `start_trial` operation took 0.632 s, which may be a performance bottleneck.
2023-11-04 02:32:27,319	WARNING util.py:214 -- The `start_trial` operation took 0.535 s, which may be a performance bottleneck.
2023-11-04 02:32:30,414	WARNING util.py:214 -- The `on_step_end` operation took 1.224 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 02:15:49 (running for 07:39:21.90)
Memory usage on this node: 30.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1148/1000000 (32 RUNNING, 1116 TERMINATED)


== Status ==
Current time: 2023-11-04 02:15:55 (running for 07:39:28.10)
Memory usage on this node: 29.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1153/1000000 (1 PENDING, 30 RUNNING, 1122 TERMINATED)


== Status ==
Current time: 2023-11-04 02:18:38 (running for 07:42:10.52)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1153/1000000 (31 RUNNING, 1122 TERMINATED)


== Status ==
Current time: 2023-11-04 02:18:45 (running for 07:42:17.54)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1159/1000000 (32 RUNNING, 1127 TERMINATED)


== Status ==
Current time: 2023-11-04 02:22:32 (running for 07:46:04.82)
Memory usage on this node: 29.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1159/1000000 (32 RUNNING, 1127 TERMINATED)


== Status ==
Current time: 2023-11-04 02:22:42 (running for 07:46:14.95)
Memory usage on this node: 29.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1162/1000000 (32 RUNNING, 1130 TERMINATED)


== Status ==
Current time: 2023-11-04 02:27:13 (running for 07:50:45.67)
Memory usage on this node: 29.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1162/1000000 (32 RUNNING, 1130 TERMINATED)


== Status ==
Current time: 2023-11-04 02:27:19 (running for 07:50:51.77)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1166/1000000 (31 RUNNING, 1135 TERMINATED)


== Status ==
Current time: 2023-11-04 02:30:04 (running for 07:53:37.11)
Memory usage on this node: 29.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1167/1000000 (32 RUNNING, 1135 TERMINATED)


== Status ==
Current time: 2023-11-04 02:32:24 (running for 07:55:56.45)
Memory usage on this node: 30.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1167/1000000 (32 RUNNING, 1135 TERMINATED)


2023-11-04 02:35:00,439	WARNING util.py:214 -- The `on_step_end` operation took 1.047 s, which may be a performance bottleneck.
2023-11-04 02:35:04,795	WARNING util.py:214 -- The `start_trial` operation took 0.583 s, which may be a performance bottleneck.
2023-11-04 02:35:06,691	WARNING util.py:214 -- The `on_step_end` operation took 1.213 s, which may be a performance bottleneck.
2023-11-04 02:38:12,834	WARNING util.py:214 -- The `on_step_end` operation took 1.320 s, which may be a performance bottleneck.
2023-11-04 02:38:16,323	WARNING util.py:214 -- The `start_trial` operation took 0.574 s, which may be a performance bottleneck.
2023-11-04 02:38:23,497	WARNING util.py:214 -- The `on_step_end` operation took 0.740 s, which may be a performance bottleneck.
2023-11-04 02:41:08,867	WARNING util.py:214 -- The `on_step_end` operation took 1.077 s, which may be a performance bottleneck.
2023-11-04 02:41:11,507	WARNING util.py:214 -- The `start_trial` operation took 0.511 s, which may be a performance bottleneck.
2023-11-04 02:41:13,934	WARNING util.py:214 -- The `start_trial` operation took 0.613 s, which may be a performance bottleneck.
2023-11-04 02:41:15,006	WARNING util.py:214 -- The `on_step_end` operation took 1.072 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 02:42:11,773 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2445138) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 02:43:11,992 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2445169) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 02:46:15,604	WARNING util.py:214 -- The `on_step_end` operation took 1.008 s, which may be a performance bottleneck.
2023-11-04 02:48:52,604	WARNING util.py:214 -- The `on_step_end` operation took 0.764 s, which may be a performance bottleneck.
2023-11-04 02:48:58,022	WARNING util.py:214 -- The `start_trial` operation took 0.517 s, which may be a performance bottleneck.
2023-11-04 02:48:59,252	WARNING util.py:214 -- The `on_step_end` operation took 1.230 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 02:49:55,663 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2445395) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 02:52:37,810	WARNING util.py:214 -- The `start_trial` operation took 0.504 s, which may be a performance bottleneck.
2023-11-04 02:53:06,797	WARNING util.py:214 -- The `on_step_end` operation took 0.512 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 02:32:30 (running for 07:56:02.90)
Memory usage on this node: 29.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1172/1000000 (1 PENDING, 30 RUNNING, 1141 TERMINATED)


== Status ==
Current time: 2023-11-04 02:35:00 (running for 07:58:32.86)
Memory usage on this node: 29.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1172/1000000 (31 RUNNING, 1141 TERMINATED)


== Status ==
Current time: 2023-11-04 02:35:06 (running for 07:58:39.13)
Memory usage on this node: 30.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1177/1000000 (32 RUNNING, 1145 TERMINATED)


== Status ==
Current time: 2023-11-04 02:38:13 (running for 08:01:45.45)
Memory usage on this node: 30.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1177/1000000 (32 RUNNING, 1145 TERMINATED)


== Status ==
Current time: 2023-11-04 02:38:23 (running for 08:01:55.92)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1180/1000000 (32 RUNNING, 1148 TERMINATED)


== Status ==
Current time: 2023-11-04 02:41:08 (running for 08:04:41.38)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1180/1000000 (32 RUNNING, 1148 TERMINATED)


== Status ==
Current time: 2023-11-04 02:41:15 (running for 08:04:47.59)
Memory usage on this node: 29.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1184/1000000 (31 RUNNING, 1153 TERMINATED)


== Status ==
Current time: 2023-11-04 02:46:15 (running for 08:09:48.25)
Memory usage on this node: 30.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1185/1000000 (32 RUNNING, 1153 TERMINATED)


== Status ==
Current time: 2023-11-04 02:48:52 (running for 08:12:25.03)
Memory usage on this node: 30.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1185/1000000 (32 RUNNING, 1153 TERMINATED)


== Status ==
Current time: 2023-11-04 02:48:59 (running for 08:12:31.67)
Memory usage on this node: 29.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1189/1000000 (31 RUNNING, 1158 TERMINATED)


2023-11-04 02:55:21,816	WARNING util.py:214 -- The `on_step_end` operation took 0.683 s, which may be a performance bottleneck.
2023-11-04 02:55:27,749	WARNING util.py:214 -- The `on_step_end` operation took 0.932 s, which may be a performance bottleneck.
2023-11-04 02:58:06,835	WARNING util.py:214 -- The `on_step_end` operation took 0.638 s, which may be a performance bottleneck.
2023-11-04 02:58:09,624	WARNING util.py:214 -- The `start_trial` operation took 0.517 s, which may be a performance bottleneck.
2023-11-04 02:58:12,919	WARNING util.py:214 -- The `on_step_end` operation took 1.081 s, which may be a performance bottleneck.
2023-11-04 03:01:00,667	WARNING util.py:214 -- The `on_step_end` operation took 0.817 s, which may be a performance bottleneck.
2023-11-04 03:03:41,281	WARNING util.py:214 -- The `on_step_end` operation took 0.908 s, which may be a performance bottleneck.
2023-11-04 03:03:47,620	WARNING util.py:214 -- The `on_step_end` operation took 1.294 s, which may be a performance bottleneck.
2023-11-04 03:06:10,391	WARNING util.py:214 -- The `on_step_end` operation took 0.629 s, which may be a performance bottleneck.
2023-11-04 03:06:11,763	WARNING util.py:214 -- The `start_trial` operation took 0.582 s, which may be a performance bottleneck.
2023-11-04 03:06:13,019	WARNING util.py:214 -- The `start_trial` operation took 0.601 s, which may be a performance bottleneck.
2023-11-04 03:06:15,456	WARNING util.py:214 -- The `start_trial` operation took 0.586 s, which may be a performance bottleneck.
2023-11-04 03:06:16,526	WARNING util.py:214 -- The `on_step_end` operation took 1.070 s, which may be a performance bottleneck.
2023-11-04 03:08:52,438	WARNING util.py:214 -- The `on_step_end` operation took 1.033 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 02:53:06 (running for 08:16:39.22)
Memory usage on this node: 30.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1190/1000000 (32 RUNNING, 1158 TERMINATED)


== Status ==
Current time: 2023-11-04 02:55:22 (running for 08:18:54.44)
Memory usage on this node: 30.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1190/1000000 (32 RUNNING, 1158 TERMINATED)


== Status ==
Current time: 2023-11-04 02:55:27 (running for 08:19:00.37)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1194/1000000 (32 RUNNING, 1162 TERMINATED)


== Status ==
Current time: 2023-11-04 02:58:06 (running for 08:21:39.26)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1194/1000000 (32 RUNNING, 1162 TERMINATED)


== Status ==
Current time: 2023-11-04 02:58:12 (running for 08:21:45.37)
Memory usage on this node: 28.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1198/1000000 (31 RUNNING, 1167 TERMINATED)


== Status ==
Current time: 2023-11-04 03:01:00 (running for 08:24:33.09)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1199/1000000 (32 RUNNING, 1167 TERMINATED)


== Status ==
Current time: 2023-11-04 03:03:41 (running for 08:27:13.70)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1199/1000000 (32 RUNNING, 1167 TERMINATED)


== Status ==
Current time: 2023-11-04 03:03:47 (running for 08:27:20.04)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1203/1000000 (1 PENDING, 30 RUNNING, 1172 TERMINATED)


== Status ==
Current time: 2023-11-04 03:06:10 (running for 08:29:42.96)
Memory usage on this node: 29.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1203/1000000 (31 RUNNING, 1172 TERMINATED)


== Status ==
Current time: 2023-11-04 03:06:16 (running for 08:29:49.08)
Memory usage on this node: 27.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1208/1000000 (31 RUNNING, 1177 TERMINATED)


2023-11-04 03:11:16,287	WARNING util.py:214 -- The `on_step_end` operation took 0.833 s, which may be a performance bottleneck.
2023-11-04 03:11:19,296	WARNING util.py:214 -- The `start_trial` operation took 0.516 s, which may be a performance bottleneck.
2023-11-04 03:11:22,823	WARNING util.py:214 -- The `on_step_end` operation took 1.104 s, which may be a performance bottleneck.
2023-11-04 03:14:13,866	WARNING util.py:214 -- The `on_step_end` operation took 1.089 s, which may be a performance bottleneck.
2023-11-04 03:14:18,619	WARNING util.py:214 -- The `start_trial` operation took 0.503 s, which may be a performance bottleneck.
2023-11-04 03:14:19,322	WARNING util.py:214 -- The `start_trial` operation took 0.583 s, which may be a performance bottleneck.
2023-11-04 03:14:20,287	WARNING util.py:214 -- The `on_step_end` operation took 0.966 s, which may be a performance bottleneck.
2023-11-04 03:16:59,092	WARNING util.py:214 -- The `on_step_end` operation took 0.837 s, which may be a performance bottleneck.
2023-11-04 03:17:00,356	WARNING util.py:214 -- The `start_trial` operation took 0.575 s, which may be a performance bottleneck.
2023-11-04 03:17:11,391	WARNING util.py:214 -- The `on_step_end` operation took 1.212 s, which may be a performance bottleneck.
2023-11-04 03:19:39,133	WARNING util.py:214 -- The `on_step_end` operation took 0.698 s, which may be a performance bottleneck.
2023-11-04 03:19:43,584	WARNING util.py:214 -- The `start_trial` operation took 0.547 s, which may be a performance bottleneck.
2023-11-04 03:19:45,443	WARNING util.py:214 -- The `on_step_end` operation took 0.975 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 03:20:44,335 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2447061) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 03:23:29,014	WARNING util.py:214 -- The `on_step_end` operation took 1.083 s, which may be a performance bottleneck.
2023-11-04 03:23:33,824	WARNING util.py:214 -- The `start_trial` operation took 0.526 s, which may be a performance bottleneck.
2023-11-04 03:23:34,466	WARNING util.py:214 -- The `start_trial` operation took 0.505 s, which may be a performance bottleneck.
2023-11-04 03:23:35,667	WARNING util.py:214 -- The `on_step_end` operation took 1.201 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 03:08:52 (running for 08:32:24.92)
Memory usage on this node: 27.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1209/1000000 (32 RUNNING, 1177 TERMINATED)


== Status ==
Current time: 2023-11-04 03:11:16 (running for 08:34:48.71)
Memory usage on this node: 28.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1209/1000000 (32 RUNNING, 1177 TERMINATED)


== Status ==
Current time: 2023-11-04 03:11:22 (running for 08:34:55.25)
Memory usage on this node: 27.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1214/1000000 (31 RUNNING, 1183 TERMINATED)


== Status ==
Current time: 2023-11-04 03:14:13 (running for 08:37:46.29)
Memory usage on this node: 28.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1215/1000000 (1 PENDING, 31 RUNNING, 1183 TERMINATED)


== Status ==
Current time: 2023-11-04 03:14:20 (running for 08:37:52.88)
Memory usage on this node: 27.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1219/1000000 (31 RUNNING, 1188 TERMINATED)


== Status ==
Current time: 2023-11-04 03:16:59 (running for 08:40:31.51)
Memory usage on this node: 28.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1220/1000000 (1 PENDING, 31 RUNNING, 1188 TERMINATED)


== Status ==
Current time: 2023-11-04 03:17:11 (running for 08:40:43.81)
Memory usage on this node: 28.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1220/1000000 (32 RUNNING, 1188 TERMINATED)


== Status ==
Current time: 2023-11-04 03:19:39 (running for 08:43:11.61)
Memory usage on this node: 28.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1220/1000000 (32 RUNNING, 1188 TERMINATED)


== Status ==
Current time: 2023-11-04 03:19:45 (running for 08:43:18.05)
Memory usage on this node: 28.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1226/1000000 (32 RUNNING, 1194 TERMINATED)


== Status ==
Current time: 2023-11-04 03:23:29 (running for 08:47:01.59)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1226/1000000 (32 RUNNING, 1194 TERMINATED)


2023-11-04 03:26:25,280	WARNING util.py:214 -- The `on_step_end` operation took 1.012 s, which may be a performance bottleneck.
2023-11-04 03:26:28,819	WARNING util.py:214 -- The `start_trial` operation took 0.519 s, which may be a performance bottleneck.
2023-11-04 03:26:29,631	WARNING util.py:214 -- The `start_trial` operation took 0.534 s, which may be a performance bottleneck.
2023-11-04 03:26:31,995	WARNING util.py:214 -- The `on_step_end` operation took 1.063 s, which may be a performance bottleneck.
2023-11-04 03:29:14,267	WARNING util.py:214 -- The `on_step_end` operation took 0.546 s, which may be a performance bottleneck.
2023-11-04 03:32:17,189	WARNING util.py:214 -- The `on_step_end` operation took 1.294 s, which may be a performance bottleneck.
2023-11-04 03:32:19,940	WARNING util.py:214 -- The `start_trial` operation took 0.598 s, which may be a performance bottleneck.
2023-11-04 03:32:21,165	WARNING util.py:214 -- The `start_trial` operation took 0.503 s, which may be a performance bottleneck.
2023-11-04 03:32:26,899	WARNING util.py:214 -- The `on_step_end` operation took 0.732 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 03:33:20,858 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2447603) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 03:34:21,053 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2447625) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 03:37:26,624	WARNING util.py:214 -- The `on_step_end` operation took 1.090 s, which may be a performance bottleneck.
2023-11-04 03:37:31,902	WARNING util.py:214 -- The `start_trial` operation took 0.767 s, which may be a performance bottleneck.
2023-11-04 03:37:32,857	WARNING util.py:214 -- The `on_step_end` operation took 0.955 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 03:38:29,197 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2447783) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 03:38:31,557 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2447793) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 03:41:23,796	WARNING util.py:214 -- The `on_step_end` operation took 1.422 s, which may be a performance bottleneck.
2023-11-04 03:41:26,682	WARNING util.py:214 -- The `start_trial` operation took 0.504 s, which may be a performance bottleneck.
2023-11-04 03:41:27,545	WARNING util.py:214 -- The `start_trial` operation took 0.659 s, which may be a performance bottleneck.
2023-11-04 03:41:29,719	WARNING util.py:214 -- The `on_step_end` operation took 0.579 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 03:42:27,112 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2448001) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 03:43:27,316 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2448031) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 03:44:27,516 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2448071) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 03:47:16,580	WARNING util.py:214 -- The `on_step_end` operation took 1.122 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 03:23:35 (running for 08:47:08.11)
Memory usage on this node: 28.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1230/1000000 (31 RUNNING, 1199 TERMINATED)


== Status ==
Current time: 2023-11-04 03:26:25 (running for 08:49:57.83)
Memory usage on this node: 28.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1231/1000000 (1 PENDING, 31 RUNNING, 1199 TERMINATED)


== Status ==
Current time: 2023-11-04 03:26:31 (running for 08:50:04.42)
Memory usage on this node: 27.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1236/1000000 (1 PENDING, 31 RUNNING, 1204 TERMINATED)


== Status ==
Current time: 2023-11-04 03:29:14 (running for 08:52:46.78)
Memory usage on this node: 28.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1236/1000000 (32 RUNNING, 1204 TERMINATED)


== Status ==
Current time: 2023-11-04 03:32:17 (running for 08:55:49.61)
Memory usage on this node: 28.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1236/1000000 (32 RUNNING, 1204 TERMINATED)


== Status ==
Current time: 2023-11-04 03:32:26 (running for 08:55:59.32)
Memory usage on this node: 28.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1239/1000000 (32 RUNNING, 1207 TERMINATED)


== Status ==
Current time: 2023-11-04 03:37:26 (running for 09:00:59.29)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1239/1000000 (32 RUNNING, 1207 TERMINATED)


== Status ==
Current time: 2023-11-04 03:37:32 (running for 09:01:05.28)
Memory usage on this node: 28.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1243/1000000 (32 RUNNING, 1211 TERMINATED)


== Status ==
Current time: 2023-11-04 03:41:23 (running for 09:04:56.22)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1243/1000000 (32 RUNNING, 1211 TERMINATED)


== Status ==
Current time: 2023-11-04 03:41:29 (running for 09:05:02.14)
Memory usage on this node: 28.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1247/1000000 (32 RUNNING, 1215 TERMINATED)


2023-11-04 03:47:20,011	WARNING util.py:214 -- The `start_trial` operation took 0.544 s, which may be a performance bottleneck.
2023-11-04 03:47:21,591	WARNING util.py:214 -- The `start_trial` operation took 0.550 s, which may be a performance bottleneck.
2023-11-04 03:47:22,552	WARNING util.py:214 -- The `on_step_end` operation took 0.962 s, which may be a performance bottleneck.
2023-11-04 03:49:53,992	WARNING util.py:214 -- The `on_step_end` operation took 0.770 s, which may be a performance bottleneck.
2023-11-04 03:49:56,697	WARNING util.py:214 -- The `start_trial` operation took 0.505 s, which may be a performance bottleneck.
2023-11-04 03:49:58,286	WARNING util.py:214 -- The `start_trial` operation took 0.509 s, which may be a performance bottleneck.
2023-11-04 03:50:10,120	WARNING util.py:214 -- The `on_step_end` operation took 1.449 s, which may be a performance bottleneck.
2023-11-04 03:50:11,737	WARNING util.py:214 -- The `start_trial` operation took 0.588 s, which may be a performance bottleneck.
2023-11-04 03:50:13,121	WARNING util.py:214 -- The `start_trial` operation took 0.535 s, which may be a performance bottleneck.
2023-11-04 03:50:19,578	WARNING util.py:214 -- The `on_step_end` operation took 0.741 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 03:51:11,377 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2448450) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 03:51:13,716 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2448455) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 03:54:14,493	WARNING util.py:214 -- The `on_step_end` operation took 1.305 s, which may be a performance bottleneck.
2023-11-04 03:54:17,725	WARNING util.py:214 -- The `start_trial` operation took 0.530 s, which may be a performance bottleneck.
2023-11-04 03:54:23,457	WARNING util.py:214 -- The `on_step_end` operation took 0.728 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 03:55:17,416 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2448651) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 03:56:17,647 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2448671) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 03:59:20,750	WARNING util.py:214 -- The `on_step_end` operation took 1.229 s, which may be a performance bottleneck.
2023-11-04 03:59:24,356	WARNING util.py:214 -- The `start_trial` operation took 0.503 s, which may be a performance bottleneck.
2023-11-04 03:59:30,998	WARNING util.py:214 -- The `on_step_end` operation took 0.577 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 04:00:25,287 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2448852) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 04:01:25,466 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2448876) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 04:02:25,611 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2448893) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 04:05:17,317	WARNING util.py:214 -- The `on_step_end` operation took 1.078 s, which may be a performance bottleneck.
2023-11-04 04:05:23,597	WARNING util.py:214 -- The `on_step_end` operation took 1.201 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 03:47:16 (running for 09:10:49.00)
Memory usage on this node: 28.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1247/1000000 (32 RUNNING, 1215 TERMINATED)


== Status ==
Current time: 2023-11-04 03:47:22 (running for 09:10:54.98)
Memory usage on this node: 27.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1251/1000000 (32 RUNNING, 1219 TERMINATED)


== Status ==
Current time: 2023-11-04 03:49:53 (running for 09:13:26.42)
Memory usage on this node: 27.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1251/1000000 (31 RUNNING, 1220 TERMINATED)


== Status ==
Current time: 2023-11-04 03:50:10 (running for 09:13:42.54)
Memory usage on this node: 28.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1255/1000000 (31 RUNNING, 1224 TERMINATED)


== Status ==
Current time: 2023-11-04 03:50:19 (running for 09:13:52.00)
Memory usage on this node: 27.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1258/1000000 (32 RUNNING, 1226 TERMINATED)


== Status ==
Current time: 2023-11-04 03:54:14 (running for 09:17:46.92)
Memory usage on this node: 28.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1258/1000000 (32 RUNNING, 1226 TERMINATED)


== Status ==
Current time: 2023-11-04 03:54:23 (running for 09:17:56.13)
Memory usage on this node: 28.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1260/1000000 (32 RUNNING, 1228 TERMINATED)


== Status ==
Current time: 2023-11-04 03:59:20 (running for 09:22:53.17)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1260/1000000 (32 RUNNING, 1228 TERMINATED)


== Status ==
Current time: 2023-11-04 03:59:30 (running for 09:23:03.42)
Memory usage on this node: 29.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1263/1000000 (32 RUNNING, 1231 TERMINATED)


== Status ==
Current time: 2023-11-04 04:05:17 (running for 09:28:49.94)
Memory usage on this node: 30.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1263/1000000 (32 RUNNING, 1231 TERMINATED)


2023-11-04 04:05:25,812	WARNING util.py:214 -- The `start_trial` operation took 0.529 s, which may be a performance bottleneck.
2023-11-04 04:05:27,432	WARNING util.py:214 -- The `start_trial` operation took 0.565 s, which may be a performance bottleneck.
2023-11-04 04:05:28,693	WARNING util.py:214 -- The `start_trial` operation took 0.702 s, which may be a performance bottleneck.
2023-11-04 04:05:29,959	WARNING util.py:214 -- The `on_step_end` operation took 1.265 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 04:06:28,245 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2449083) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 04:09:14,491	WARNING util.py:214 -- The `on_step_end` operation took 1.042 s, which may be a performance bottleneck.
2023-11-04 04:09:18,524	WARNING util.py:214 -- The `start_trial` operation took 0.677 s, which may be a performance bottleneck.
2023-11-04 04:09:21,547	WARNING util.py:214 -- The `on_step_end` operation took 1.450 s, which may be a performance bottleneck.
2023-11-04 04:11:52,680	WARNING util.py:214 -- The `on_step_end` operation took 0.733 s, which may be a performance bottleneck.
2023-11-04 04:14:26,575	WARNING util.py:214 -- The `on_step_end` operation took 0.921 s, which may be a performance bottleneck.
2023-11-04 04:14:32,468	WARNING util.py:214 -- The `on_step_end` operation took 0.879 s, which may be a performance bottleneck.
2023-11-04 04:16:40,869	WARNING util.py:214 -- The `on_step_end` operation took 0.774 s, which may be a performance bottleneck.
2023-11-04 04:16:42,125	WARNING util.py:214 -- The `start_trial` operation took 0.544 s, which may be a performance bottleneck.
2023-11-04 04:16:46,777	WARNING util.py:214 -- The `on_step_end` operation took 0.790 s, which may be a performance bottleneck.
2023-11-04 04:18:48,558	WARNING util.py:214 -- The `on_step_end` operation took 0.745 s, which may be a performance bottleneck.
2023-11-04 04:18:49,506	WARNING util.py:214 -- The `start_trial` operation took 0.530 s, which may be a performance bottleneck.
2023-11-04 04:18:54,758	WARNING util.py:214 -- The `on_step_end` operation took 1.025 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 04:05:23 (running for 09:28:56.02)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1265/1000000 (31 RUNNING, 1234 TERMINATED)


== Status ==
Current time: 2023-11-04 04:05:29 (running for 09:29:02.38)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1268/1000000 (32 RUNNING, 1236 TERMINATED)


== Status ==
Current time: 2023-11-04 04:09:14 (running for 09:32:46.91)
Memory usage on this node: 30.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1268/1000000 (32 RUNNING, 1236 TERMINATED)


== Status ==
Current time: 2023-11-04 04:09:21 (running for 09:32:54.01)
Memory usage on this node: 29.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1271/1000000 (1 PENDING, 31 RUNNING, 1239 TERMINATED)


== Status ==
Current time: 2023-11-04 04:11:52 (running for 09:35:25.10)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1271/1000000 (32 RUNNING, 1239 TERMINATED)


== Status ==
Current time: 2023-11-04 04:14:26 (running for 09:37:59.00)
Memory usage on this node: 30.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1271/1000000 (32 RUNNING, 1239 TERMINATED)


== Status ==
Current time: 2023-11-04 04:14:32 (running for 09:38:05.13)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1275/1000000 (31 RUNNING, 1244 TERMINATED)


== Status ==
Current time: 2023-11-04 04:16:40 (running for 09:40:13.29)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1276/1000000 (1 PENDING, 31 RUNNING, 1244 TERMINATED)


== Status ==
Current time: 2023-11-04 04:16:46 (running for 09:40:19.20)
Memory usage on this node: 30.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1281/1000000 (31 RUNNING, 1250 TERMINATED)


== Status ==
Current time: 2023-11-04 04:18:48 (running for 09:42:21.07)
Memory usage on this node: 30.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1282/1000000 (1 PENDING, 30 RUNNING, 1251 TERMINATED)


2023-11-04 04:20:39,264	WARNING util.py:214 -- The `on_step_end` operation took 0.684 s, which may be a performance bottleneck.
2023-11-04 04:20:45,682	WARNING util.py:214 -- The `on_step_end` operation took 1.037 s, which may be a performance bottleneck.
2023-11-04 04:22:43,145	WARNING util.py:214 -- The `on_step_end` operation took 0.818 s, which may be a performance bottleneck.
2023-11-04 04:22:49,403	WARNING util.py:214 -- The `on_step_end` operation took 0.939 s, which may be a performance bottleneck.
2023-11-04 04:24:53,478	WARNING util.py:214 -- The `on_step_end` operation took 0.790 s, which may be a performance bottleneck.
2023-11-04 04:24:58,683	WARNING util.py:214 -- The `start_trial` operation took 0.520 s, which may be a performance bottleneck.
2023-11-04 04:24:59,631	WARNING util.py:214 -- The `on_step_end` operation took 0.948 s, which may be a performance bottleneck.
2023-11-04 04:25:02,167	WARNING util.py:214 -- The `start_trial` operation took 0.533 s, which may be a performance bottleneck.
2023-11-04 04:25:03,983	WARNING util.py:214 -- The `start_trial` operation took 0.570 s, which may be a performance bottleneck.
2023-11-04 04:25:04,784	WARNING util.py:214 -- The `start_trial` operation took 0.569 s, which may be a performance bottleneck.
2023-11-04 04:25:05,650	WARNING util.py:214 -- The `on_step_end` operation took 0.866 s, which may be a performance bottleneck.
2023-11-04 04:27:15,553	WARNING util.py:214 -- The `on_step_end` operation took 0.916 s, which may be a performance bottleneck.
2023-11-04 04:27:21,617	WARNING util.py:214 -- The `on_step_end` operation took 1.031 s, which may be a performance bottleneck.
2023-11-04 04:29:07,922	WARNING util.py:214 -- The `on_step_end` operation took 0.537 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 04:18:54 (running for 09:42:27.20)
Memory usage on this node: 29.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1288/1000000 (31 RUNNING, 1257 TERMINATED)


== Status ==
Current time: 2023-11-04 04:20:39 (running for 09:44:11.69)
Memory usage on this node: 30.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1289/1000000 (1 PENDING, 31 RUNNING, 1257 TERMINATED)


== Status ==
Current time: 2023-11-04 04:20:45 (running for 09:44:18.16)
Memory usage on this node: 29.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1294/1000000 (1 PENDING, 30 RUNNING, 1263 TERMINATED)


== Status ==
Current time: 2023-11-04 04:22:43 (running for 09:46:15.57)
Memory usage on this node: 30.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1294/1000000 (31 RUNNING, 1263 TERMINATED)


== Status ==
Current time: 2023-11-04 04:22:49 (running for 09:46:21.83)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1300/1000000 (31 RUNNING, 1269 TERMINATED)


== Status ==
Current time: 2023-11-04 04:24:53 (running for 09:48:25.90)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1301/1000000 (1 PENDING, 31 RUNNING, 1269 TERMINATED)


== Status ==
Current time: 2023-11-04 04:24:59 (running for 09:48:32.05)
Memory usage on this node: 30.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1306/1000000 (31 RUNNING, 1275 TERMINATED)


== Status ==
Current time: 2023-11-04 04:25:05 (running for 09:48:38.17)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1312/1000000 (31 RUNNING, 1281 TERMINATED)


== Status ==
Current time: 2023-11-04 04:27:15 (running for 09:50:47.98)
Memory usage on this node: 30.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1313/1000000 (1 PENDING, 31 RUNNING, 1281 TERMINATED)


== Status ==
Current time: 2023-11-04 04:27:21 (running for 09:50:54.04)
Memory usage on this node: 29.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1318/1000000 (1 PENDING, 30 RUNNING, 1287 TERMINATED)


2023-11-04 04:29:09,565	WARNING util.py:214 -- The `start_trial` operation took 0.551 s, which may be a performance bottleneck.
2023-11-04 04:29:14,169	WARNING util.py:214 -- The `on_step_end` operation took 0.837 s, which may be a performance bottleneck.
2023-11-04 04:30:57,505	WARNING util.py:214 -- The `on_step_end` operation took 0.778 s, which may be a performance bottleneck.
2023-11-04 04:32:24,660	WARNING util.py:214 -- The `on_step_end` operation took 0.572 s, which may be a performance bottleneck.
2023-11-04 04:34:05,220	WARNING util.py:214 -- The `on_step_end` operation took 0.819 s, which may be a performance bottleneck.
2023-11-04 04:34:09,543	WARNING util.py:214 -- The `start_trial` operation took 0.529 s, which may be a performance bottleneck.
2023-11-04 04:34:11,002	WARNING util.py:214 -- The `on_step_end` operation took 0.684 s, which may be a performance bottleneck.
2023-11-04 04:35:59,795	WARNING util.py:214 -- The `start_trial` operation took 0.536 s, which may be a performance bottleneck.
2023-11-04 04:36:00,385	WARNING util.py:214 -- The `on_step_end` operation took 0.590 s, which may be a performance bottleneck.
2023-11-04 04:37:54,951	WARNING util.py:214 -- The `on_step_end` operation took 0.799 s, which may be a performance bottleneck.
2023-11-04 04:37:59,752	WARNING util.py:214 -- The `start_trial` operation took 0.564 s, which may be a performance bottleneck.
2023-11-04 04:38:01,124	WARNING util.py:214 -- The `on_step_end` operation took 0.757 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 04:29:08 (running for 09:52:40.52)
Memory usage on this node: 30.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1318/1000000 (31 RUNNING, 1287 TERMINATED)


== Status ==
Current time: 2023-11-04 04:29:14 (running for 09:52:46.64)
Memory usage on this node: 29.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1324/1000000 (31 RUNNING, 1293 TERMINATED)


== Status ==
Current time: 2023-11-04 04:30:57 (running for 09:54:29.93)
Memory usage on this node: 29.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1325/1000000 (32 RUNNING, 1293 TERMINATED)


== Status ==
Current time: 2023-11-04 04:32:18 (running for 09:55:51.15)
Memory usage on this node: 30.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1325/1000000 (32 RUNNING, 1293 TERMINATED)


== Status ==
Current time: 2023-11-04 04:32:24 (running for 09:55:57.12)
Memory usage on this node: 28.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1332/1000000 (31 RUNNING, 1301 TERMINATED)


== Status ==
Current time: 2023-11-04 04:34:05 (running for 09:57:37.74)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1333/1000000 (1 PENDING, 31 RUNNING, 1301 TERMINATED)


== Status ==
Current time: 2023-11-04 04:34:11 (running for 09:57:43.47)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1341/1000000 (32 RUNNING, 1309 TERMINATED)


== Status ==
Current time: 2023-11-04 04:35:54 (running for 09:59:27.05)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1341/1000000 (32 RUNNING, 1309 TERMINATED)


== Status ==
Current time: 2023-11-04 04:36:00 (running for 09:59:32.82)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1347/1000000 (31 RUNNING, 1316 TERMINATED)


== Status ==
Current time: 2023-11-04 04:37:54 (running for 10:01:27.37)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1348/1000000 (1 PENDING, 30 RUNNING, 1317 TERMINATED)


2023-11-04 04:40:09,372	WARNING util.py:214 -- The `on_step_end` operation took 0.938 s, which may be a performance bottleneck.
2023-11-04 04:40:15,657	WARNING util.py:214 -- The `on_step_end` operation took 1.251 s, which may be a performance bottleneck.
2023-11-04 04:42:46,564	WARNING util.py:214 -- The `on_step_end` operation took 1.018 s, which may be a performance bottleneck.
2023-11-04 04:42:48,020	WARNING util.py:214 -- The `start_trial` operation took 0.520 s, which may be a performance bottleneck.
2023-11-04 04:42:48,599	WARNING util.py:214 -- The `start_trial` operation took 0.532 s, which may be a performance bottleneck.
2023-11-04 04:42:51,498	WARNING util.py:214 -- The `start_trial` operation took 0.563 s, which may be a performance bottleneck.
2023-11-04 04:42:53,065	WARNING util.py:214 -- The `on_step_end` operation took 1.476 s, which may be a performance bottleneck.
2023-11-04 04:45:23,610	WARNING util.py:214 -- The `on_step_end` operation took 0.710 s, which may be a performance bottleneck.
2023-11-04 04:45:25,712	WARNING util.py:214 -- The `start_trial` operation took 0.538 s, which may be a performance bottleneck.
2023-11-04 04:45:28,479	WARNING util.py:214 -- The `start_trial` operation took 0.671 s, which may be a performance bottleneck.
2023-11-04 04:45:30,446	WARNING util.py:214 -- The `on_step_end` operation took 1.617 s, which may be a performance bottleneck.
2023-11-04 04:48:14,055	WARNING util.py:214 -- The `on_step_end` operation took 0.750 s, which may be a performance bottleneck.
2023-11-04 04:48:20,158	WARNING util.py:214 -- The `on_step_end` operation took 1.032 s, which may be a performance bottleneck.
2023-11-04 04:48:22,228	WARNING util.py:214 -- The `start_trial` operation took 0.524 s, which may be a performance bottleneck.
2023-11-04 04:48:25,731	WARNING util.py:214 -- The `start_trial` operation took 0.812 s, which may be a performance bottleneck.
2023-11-04 04:48:27,001	WARNING util.py:214 -- The `on_step_end` operation took 1.270 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 04:49:25,124 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2452300) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 04:50:25,354 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2452420) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 04:53:17,425	WARNING util.py:214 -- The `on_step_end` operation took 1.189 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 04:38:01 (running for 10:01:33.57)
Memory usage on this node: 28.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1355/1000000 (31 RUNNING, 1324 TERMINATED)


== Status ==
Current time: 2023-11-04 04:40:09 (running for 10:03:41.79)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1356/1000000 (1 PENDING, 31 RUNNING, 1324 TERMINATED)


== Status ==
Current time: 2023-11-04 04:40:15 (running for 10:03:48.26)
Memory usage on this node: 28.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1361/1000000 (1 PENDING, 31 RUNNING, 1329 TERMINATED)


== Status ==
Current time: 2023-11-04 04:42:46 (running for 10:06:19.08)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1361/1000000 (1 PENDING, 31 RUNNING, 1329 TERMINATED)


== Status ==
Current time: 2023-11-04 04:42:53 (running for 10:06:25.49)
Memory usage on this node: 28.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1367/1000000 (1 PENDING, 30 RUNNING, 1336 TERMINATED)


== Status ==
Current time: 2023-11-04 04:45:23 (running for 10:08:56.09)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1367/1000000 (31 RUNNING, 1336 TERMINATED)


== Status ==
Current time: 2023-11-04 04:45:30 (running for 10:09:03.00)
Memory usage on this node: 28.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1373/1000000 (1 PENDING, 30 RUNNING, 1342 TERMINATED)


== Status ==
Current time: 2023-11-04 04:48:14 (running for 10:11:46.62)
Memory usage on this node: 29.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1373/1000000 (31 RUNNING, 1342 TERMINATED)


== Status ==
Current time: 2023-11-04 04:48:20 (running for 10:11:52.78)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1378/1000000 (1 PENDING, 31 RUNNING, 1346 TERMINATED)


== Status ==
Current time: 2023-11-04 04:48:27 (running for 10:11:59.67)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1383/1000000 (32 RUNNING, 1351 TERMINATED)


2023-11-04 04:53:20,317	WARNING util.py:214 -- The `start_trial` operation took 0.562 s, which may be a performance bottleneck.
2023-11-04 04:53:24,261	WARNING util.py:214 -- The `on_step_end` operation took 1.152 s, which may be a performance bottleneck.
2023-11-04 04:53:27,218	WARNING util.py:214 -- The `start_trial` operation took 0.614 s, which may be a performance bottleneck.
2023-11-04 04:53:28,574	WARNING util.py:214 -- The `start_trial` operation took 0.539 s, which may be a performance bottleneck.
2023-11-04 04:53:29,212	WARNING util.py:214 -- The `start_trial` operation took 0.557 s, which may be a performance bottleneck.
2023-11-04 04:53:30,969	WARNING util.py:214 -- The `on_step_end` operation took 1.530 s, which may be a performance bottleneck.
2023-11-04 04:53:32,313	WARNING util.py:214 -- The `start_trial` operation took 0.660 s, which may be a performance bottleneck.
2023-11-04 04:53:32,865	WARNING util.py:214 -- The `start_trial` operation took 0.541 s, which may be a performance bottleneck.
2023-11-04 04:53:33,895	WARNING util.py:214 -- The `start_trial` operation took 0.549 s, which may be a performance bottleneck.
2023-11-04 04:53:39,901	WARNING util.py:214 -- The `on_step_end` operation took 1.003 s, which may be a performance bottleneck.
2023-11-04 04:56:06,372	WARNING util.py:214 -- The `on_step_end` operation took 0.664 s, which may be a performance bottleneck.
2023-11-04 04:56:11,535	WARNING util.py:214 -- The `start_trial` operation took 0.643 s, which may be a performance bottleneck.
2023-11-04 04:56:12,724	WARNING util.py:214 -- The `on_step_end` operation took 1.189 s, which may be a performance bottleneck.
2023-11-04 04:58:09,101	WARNING util.py:214 -- The `on_step_end` operation took 0.620 s, which may be a performance bottleneck.
2023-11-04 04:58:12,101	WARNING util.py:214 -- The `start_trial` operation took 0.522 s, which may be a performance bottleneck.
2023-11-04 04:58:15,245	WARNING util.py:214 -- The `on_step_end` operation took 1.106 s, which may be a performance bottleneck.
2023-11-04 05:00:12,502	WARNING util.py:214 -- The `on_step_end` operation took 1.129 s, which may be a performance bottleneck.
2023-11-04 05:00:17,775	WARNING util.py:214 -- The `start_trial` operation took 0.586 s, which may be a performance bottleneck.
2023-11-04 05:00:18,625	WARNING util.py:214 -- The `on_step_end` operation took 0.850 s, which may be a performance bottleneck.
2023-11-04 05:02:38,827	WARNING util.py:214 -- The `on_step_end` operation took 1.039 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 04:53:17 (running for 10:16:49.85)
Memory usage on this node: 29.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1383/1000000 (32 RUNNING, 1351 TERMINATED)


== Status ==
Current time: 2023-11-04 04:53:24 (running for 10:16:56.78)
Memory usage on this node: 29.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1387/1000000 (1 PENDING, 31 RUNNING, 1355 TERMINATED)


== Status ==
Current time: 2023-11-04 04:53:31 (running for 10:17:03.44)
Memory usage on this node: 29.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1391/1000000 (1 PENDING, 30 RUNNING, 1360 TERMINATED)


== Status ==
Current time: 2023-11-04 04:53:39 (running for 10:17:12.32)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1393/1000000 (32 RUNNING, 1361 TERMINATED)


== Status ==
Current time: 2023-11-04 04:56:06 (running for 10:19:38.91)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1393/1000000 (32 RUNNING, 1361 TERMINATED)


== Status ==
Current time: 2023-11-04 04:56:12 (running for 10:19:45.15)
Memory usage on this node: 28.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1397/1000000 (32 RUNNING, 1365 TERMINATED)


== Status ==
Current time: 2023-11-04 04:58:09 (running for 10:21:41.52)
Memory usage on this node: 29.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1397/1000000 (32 RUNNING, 1365 TERMINATED)


== Status ==
Current time: 2023-11-04 04:58:15 (running for 10:21:47.67)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1400/1000000 (31 RUNNING, 1369 TERMINATED)


== Status ==
Current time: 2023-11-04 05:00:12 (running for 10:23:44.93)
Memory usage on this node: 29.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1401/1000000 (1 PENDING, 31 RUNNING, 1369 TERMINATED)


== Status ==
Current time: 2023-11-04 05:00:18 (running for 10:23:51.26)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1405/1000000 (32 RUNNING, 1373 TERMINATED)


2023-11-04 05:02:43,012	WARNING util.py:214 -- The `start_trial` operation took 0.530 s, which may be a performance bottleneck.
2023-11-04 05:02:43,756	WARNING util.py:214 -- The `start_trial` operation took 0.576 s, which may be a performance bottleneck.
2023-11-04 05:02:45,233	WARNING util.py:214 -- The `on_step_end` operation took 1.361 s, which may be a performance bottleneck.
2023-11-04 05:04:45,971	WARNING util.py:214 -- The `on_step_end` operation took 0.799 s, which may be a performance bottleneck.
2023-11-04 05:04:52,185	WARNING util.py:214 -- The `on_step_end` operation took 1.034 s, which may be a performance bottleneck.
2023-11-04 05:06:57,640	WARNING util.py:214 -- The `on_step_end` operation took 0.907 s, which may be a performance bottleneck.
2023-11-04 05:07:03,785	WARNING util.py:214 -- The `on_step_end` operation took 1.098 s, which may be a performance bottleneck.
2023-11-04 05:09:04,348	WARNING util.py:214 -- The `on_step_end` operation took 0.563 s, which may be a performance bottleneck.
2023-11-04 05:09:07,553	WARNING util.py:214 -- The `start_trial` operation took 0.649 s, which may be a performance bottleneck.
2023-11-04 05:09:10,389	WARNING util.py:214 -- The `on_step_end` operation took 0.955 s, which may be a performance bottleneck.
2023-11-04 05:11:15,463	WARNING util.py:214 -- The `on_step_end` operation took 0.949 s, which may be a performance bottleneck.
2023-11-04 05:11:21,943	WARNING util.py:214 -- The `on_step_end` operation took 1.312 s, which may be a performance bottleneck.
2023-11-04 05:11:24,520	WARNING util.py:214 -- The `start_trial` operation took 0.523 s, which may be a performance bottleneck.
2023-11-04 05:11:26,834	WARNING util.py:214 -- The `start_trial` operation took 0.572 s, which may be a performance bottleneck.
2023-11-04 05:11:29,171	WARNING util.py:214 -- The `on_step_end` operation took 1.654 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 05:02:38 (running for 10:26:11.25)
Memory usage on this node: 29.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1405/1000000 (32 RUNNING, 1373 TERMINATED)


== Status ==
Current time: 2023-11-04 05:02:45 (running for 10:26:17.72)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1410/1000000 (31 RUNNING, 1379 TERMINATED)


== Status ==
Current time: 2023-11-04 05:04:45 (running for 10:28:18.39)
Memory usage on this node: 29.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1411/1000000 (1 PENDING, 31 RUNNING, 1379 TERMINATED)


== Status ==
Current time: 2023-11-04 05:04:52 (running for 10:28:24.61)
Memory usage on this node: 28.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1416/1000000 (1 PENDING, 31 RUNNING, 1384 TERMINATED)


== Status ==
Current time: 2023-11-04 05:06:57 (running for 10:30:30.06)
Memory usage on this node: 29.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1416/1000000 (1 PENDING, 31 RUNNING, 1384 TERMINATED)


== Status ==
Current time: 2023-11-04 05:07:03 (running for 10:30:36.39)
Memory usage on this node: 28.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1422/1000000 (1 PENDING, 30 RUNNING, 1391 TERMINATED)


== Status ==
Current time: 2023-11-04 05:09:04 (running for 10:32:36.91)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1422/1000000 (31 RUNNING, 1391 TERMINATED)


== Status ==
Current time: 2023-11-04 05:09:10 (running for 10:32:42.93)
Memory usage on this node: 28.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1426/1000000 (31 RUNNING, 1395 TERMINATED)


== Status ==
Current time: 2023-11-04 05:11:15 (running for 10:34:47.96)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1427/1000000 (1 PENDING, 31 RUNNING, 1395 TERMINATED)


== Status ==
Current time: 2023-11-04 05:11:22 (running for 10:34:54.53)
Memory usage on this node: 29.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1432/1000000 (1 PENDING, 30 RUNNING, 1401 TERMINATED)


2023-11-04 05:11:31,452	WARNING util.py:214 -- The `start_trial` operation took 0.770 s, which may be a performance bottleneck.
2023-11-04 05:11:38,791	WARNING util.py:214 -- The `on_step_end` operation took 1.075 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 05:12:30,952 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2453696) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 05:12:32,664 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2453702) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 05:15:11,574	WARNING util.py:214 -- The `on_step_end` operation took 1.312 s, which may be a performance bottleneck.
2023-11-04 05:15:15,973	WARNING util.py:214 -- The `start_trial` operation took 0.509 s, which may be a performance bottleneck.
2023-11-04 05:15:18,063	WARNING util.py:214 -- The `on_step_end` operation took 1.330 s, which may be a performance bottleneck.
2023-11-04 05:15:19,452	WARNING util.py:214 -- The `start_trial` operation took 0.820 s, which may be a performance bottleneck.
2023-11-04 05:15:21,083	WARNING util.py:214 -- The `start_trial` operation took 0.505 s, which may be a performance bottleneck.
2023-11-04 05:15:22,017	WARNING util.py:214 -- The `start_trial` operation took 0.513 s, which may be a performance bottleneck.
2023-11-04 05:15:24,752	WARNING util.py:214 -- The `on_step_end` operation took 1.492 s, which may be a performance bottleneck.
2023-11-04 05:18:02,529	WARNING util.py:214 -- The `on_step_end` operation took 0.860 s, which may be a performance bottleneck.
2023-11-04 05:18:09,361	WARNING util.py:214 -- The `on_step_end` operation took 1.424 s, which may be a performance bottleneck.
2023-11-04 05:20:54,525	WARNING util.py:214 -- The `on_step_end` operation took 1.037 s, which may be a performance bottleneck.
2023-11-04 05:22:38,457	WARNING util.py:214 -- The `on_step_end` operation took 0.732 s, which may be a performance bottleneck.
2023-11-04 05:22:44,911	WARNING util.py:214 -- The `on_step_end` operation took 1.049 s, which may be a performance bottleneck.
2023-11-04 05:22:51,397	WARNING util.py:214 -- The `on_step_end` operation took 1.138 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 05:11:29 (running for 10:35:01.70)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1437/1000000 (1 PENDING, 30 RUNNING, 1406 TERMINATED)


== Status ==
Current time: 2023-11-04 05:11:38 (running for 10:35:11.31)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1439/1000000 (32 RUNNING, 1407 TERMINATED)


== Status ==
Current time: 2023-11-04 05:15:11 (running for 10:38:44.18)
Memory usage on this node: 29.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1439/1000000 (32 RUNNING, 1407 TERMINATED)


== Status ==
Current time: 2023-11-04 05:15:18 (running for 10:38:50.56)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1444/1000000 (1 PENDING, 31 RUNNING, 1412 TERMINATED)


== Status ==
Current time: 2023-11-04 05:15:24 (running for 10:38:57.17)
Memory usage on this node: 28.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1448/1000000 (32 RUNNING, 1416 TERMINATED)


== Status ==
Current time: 2023-11-04 05:18:02 (running for 10:41:34.95)
Memory usage on this node: 29.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1448/1000000 (32 RUNNING, 1416 TERMINATED)


== Status ==
Current time: 2023-11-04 05:18:09 (running for 10:41:41.86)
Memory usage on this node: 28.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1451/1000000 (31 RUNNING, 1420 TERMINATED)


== Status ==
Current time: 2023-11-04 05:20:54 (running for 10:44:27.05)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1452/1000000 (32 RUNNING, 1420 TERMINATED)


== Status ==
Current time: 2023-11-04 05:22:38 (running for 10:46:10.88)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1452/1000000 (32 RUNNING, 1420 TERMINATED)


== Status ==
Current time: 2023-11-04 05:22:45 (running for 10:46:17.49)
Memory usage on this node: 28.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1457/1000000 (1 PENDING, 31 RUNNING, 1425 TERMINATED)


2023-11-04 05:25:22,470	WARNING util.py:214 -- The `on_step_end` operation took 1.250 s, which may be a performance bottleneck.
2023-11-04 05:25:29,333	WARNING util.py:214 -- The `on_step_end` operation took 1.682 s, which may be a performance bottleneck.
2023-11-04 05:27:48,329	WARNING util.py:214 -- The `on_step_end` operation took 0.741 s, which may be a performance bottleneck.
2023-11-04 05:27:51,626	WARNING util.py:214 -- The `start_trial` operation took 0.612 s, which may be a performance bottleneck.
2023-11-04 05:27:52,724	WARNING util.py:214 -- The `start_trial` operation took 0.684 s, which may be a performance bottleneck.
2023-11-04 05:27:53,905	WARNING util.py:214 -- The `start_trial` operation took 0.636 s, which may be a performance bottleneck.
2023-11-04 05:27:55,251	WARNING util.py:214 -- The `on_step_end` operation took 1.345 s, which may be a performance bottleneck.
2023-11-04 05:30:45,510	WARNING util.py:214 -- The `on_step_end` operation took 1.437 s, which may be a performance bottleneck.
2023-11-04 05:30:50,738	WARNING util.py:214 -- The `start_trial` operation took 0.574 s, which may be a performance bottleneck.
2023-11-04 05:30:51,830	WARNING util.py:214 -- The `on_step_end` operation took 1.093 s, which may be a performance bottleneck.
2023-11-04 05:33:19,273	WARNING util.py:214 -- The `on_step_end` operation took 0.948 s, which may be a performance bottleneck.
2023-11-04 05:33:24,481	WARNING util.py:214 -- The `start_trial` operation took 0.619 s, which may be a performance bottleneck.
2023-11-04 05:33:25,531	WARNING util.py:214 -- The `on_step_end` operation took 1.050 s, which may be a performance bottleneck.
2023-11-04 05:35:55,006	WARNING util.py:214 -- The `on_step_end` operation took 0.834 s, which may be a performance bottleneck.
2023-11-04 05:35:56,296	WARNING util.py:214 -- The `start_trial` operation took 0.601 s, which may be a performance bottleneck.
2023-11-04 05:35:59,002	WARNING util.py:214 -- The `start_trial` operation took 0.585 s, which may be a performance bottleneck.
2023-11-04 05:36:00,363	WARNING util.py:214 -- The `start_trial` operation took 0.554 s, which may be a performance bottleneck.
2023-11-04 05:36:01,785	WARNING util.py:214 -- The `on_step_end` operation took 1.422 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 05:22:51 (running for 10:46:23.92)
Memory usage on this node: 28.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1462/1000000 (31 RUNNING, 1431 TERMINATED)


== Status ==
Current time: 2023-11-04 05:25:22 (running for 10:48:55.10)
Memory usage on this node: 28.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1463/1000000 (1 PENDING, 31 RUNNING, 1431 TERMINATED)


== Status ==
Current time: 2023-11-04 05:25:29 (running for 10:49:01.95)
Memory usage on this node: 28.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1468/1000000 (1 PENDING, 30 RUNNING, 1437 TERMINATED)


== Status ==
Current time: 2023-11-04 05:27:48 (running for 10:51:20.86)
Memory usage on this node: 28.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1468/1000000 (31 RUNNING, 1437 TERMINATED)


== Status ==
Current time: 2023-11-04 05:27:55 (running for 10:51:27.70)
Memory usage on this node: 27.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1473/1000000 (32 RUNNING, 1441 TERMINATED)


== Status ==
Current time: 2023-11-04 05:30:45 (running for 10:54:18.02)
Memory usage on this node: 27.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1473/1000000 (31 RUNNING, 1442 TERMINATED)


== Status ==
Current time: 2023-11-04 05:30:52 (running for 10:54:24.49)
Memory usage on this node: 27.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1478/1000000 (32 RUNNING, 1446 TERMINATED)


== Status ==
Current time: 2023-11-04 05:33:19 (running for 10:56:51.70)
Memory usage on this node: 27.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1478/1000000 (32 RUNNING, 1446 TERMINATED)


== Status ==
Current time: 2023-11-04 05:33:25 (running for 10:56:57.95)
Memory usage on this node: 27.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1482/1000000 (31 RUNNING, 1451 TERMINATED)


== Status ==
Current time: 2023-11-04 05:35:55 (running for 10:59:27.59)
Memory usage on this node: 27.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1483/1000000 (1 PENDING, 31 RUNNING, 1451 TERMINATED)


2023-11-04 05:38:27,876	WARNING util.py:214 -- The `on_step_end` operation took 0.995 s, which may be a performance bottleneck.
2023-11-04 05:38:31,025	WARNING util.py:214 -- The `start_trial` operation took 0.690 s, which may be a performance bottleneck.
2023-11-04 05:38:34,274	WARNING util.py:214 -- The `on_step_end` operation took 1.385 s, which may be a performance bottleneck.
2023-11-04 05:41:00,347	WARNING util.py:214 -- The `on_step_end` operation took 1.365 s, which may be a performance bottleneck.
2023-11-04 05:41:07,040	WARNING util.py:214 -- The `on_step_end` operation took 1.622 s, which may be a performance bottleneck.
2023-11-04 05:43:17,402	WARNING util.py:214 -- The `on_step_end` operation took 0.682 s, which may be a performance bottleneck.
2023-11-04 05:43:23,378	WARNING util.py:214 -- The `on_step_end` operation took 0.958 s, which may be a performance bottleneck.
2023-11-04 05:45:22,657	WARNING util.py:214 -- The `on_step_end` operation took 1.270 s, which may be a performance bottleneck.
2023-11-04 05:45:28,061	WARNING util.py:214 -- The `start_trial` operation took 0.538 s, which may be a performance bottleneck.
2023-11-04 05:45:29,389	WARNING util.py:214 -- The `on_step_end` operation took 1.328 s, which may be a performance bottleneck.
2023-11-04 05:45:33,476	WARNING util.py:214 -- The `start_trial` operation took 0.519 s, which may be a performance bottleneck.
2023-11-04 05:45:34,210	WARNING util.py:214 -- The `start_trial` operation took 0.523 s, which may be a performance bottleneck.
2023-11-04 05:45:36,117	WARNING util.py:214 -- The `on_step_end` operation took 1.402 s, which may be a performance bottleneck.
2023-11-04 05:48:16,824	WARNING util.py:214 -- The `on_step_end` operation took 1.121 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 05:36:01 (running for 10:59:34.21)
Memory usage on this node: 27.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1488/1000000 (32 RUNNING, 1456 TERMINATED)


== Status ==
Current time: 2023-11-04 05:38:27 (running for 11:02:00.30)
Memory usage on this node: 28.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1488/1000000 (32 RUNNING, 1456 TERMINATED)


== Status ==
Current time: 2023-11-04 05:38:34 (running for 11:02:06.70)
Memory usage on this node: 27.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1493/1000000 (32 RUNNING, 1461 TERMINATED)


== Status ==
Current time: 2023-11-04 05:41:00 (running for 11:04:32.77)
Memory usage on this node: 27.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1493/1000000 (32 RUNNING, 1461 TERMINATED)


== Status ==
Current time: 2023-11-04 05:41:07 (running for 11:04:39.46)
Memory usage on this node: 26.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1498/1000000 (1 PENDING, 30 RUNNING, 1467 TERMINATED)


== Status ==
Current time: 2023-11-04 05:43:17 (running for 11:06:49.92)
Memory usage on this node: 27.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1498/1000000 (31 RUNNING, 1467 TERMINATED)


== Status ==
Current time: 2023-11-04 05:43:23 (running for 11:06:55.95)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1501/1000000 (31 RUNNING, 1470 TERMINATED)


== Status ==
Current time: 2023-11-04 05:45:22 (running for 11:08:55.08)
Memory usage on this node: 26.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1502/1000000 (1 PENDING, 30 RUNNING, 1471 TERMINATED)


== Status ==
Current time: 2023-11-04 05:45:29 (running for 11:09:01.81)
Memory usage on this node: 26.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1508/1000000 (31 RUNNING, 1477 TERMINATED)


== Status ==
Current time: 2023-11-04 05:45:36 (running for 11:09:08.54)
Memory usage on this node: 26.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1513/1000000 (32 RUNNING, 1481 TERMINATED)


2023-11-04 05:48:33,444	WARNING util.py:214 -- The `on_step_end` operation took 1.618 s, which may be a performance bottleneck.
2023-11-04 05:48:35,913	WARNING util.py:214 -- The `start_trial` operation took 0.586 s, which may be a performance bottleneck.
2023-11-04 05:48:37,857	WARNING util.py:214 -- The `start_trial` operation took 0.570 s, which may be a performance bottleneck.
2023-11-04 05:48:39,920	WARNING util.py:214 -- The `on_step_end` operation took 1.351 s, which may be a performance bottleneck.
2023-11-04 05:50:54,563	WARNING util.py:214 -- The `on_step_end` operation took 1.123 s, which may be a performance bottleneck.
2023-11-04 05:51:01,328	WARNING util.py:214 -- The `on_step_end` operation took 1.437 s, which may be a performance bottleneck.
2023-11-04 05:53:39,096	WARNING util.py:214 -- The `on_step_end` operation took 1.330 s, which may be a performance bottleneck.
2023-11-04 05:53:45,703	WARNING util.py:214 -- The `on_step_end` operation took 1.235 s, which may be a performance bottleneck.
2023-11-04 05:56:30,108	WARNING util.py:214 -- The `on_step_end` operation took 1.622 s, which may be a performance bottleneck.
2023-11-04 05:56:33,623	WARNING util.py:214 -- The `start_trial` operation took 0.665 s, which may be a performance bottleneck.
2023-11-04 05:56:36,600	WARNING util.py:214 -- The `on_step_end` operation took 1.424 s, which may be a performance bottleneck.
2023-11-04 05:59:24,421	WARNING util.py:214 -- The `on_step_end` operation took 1.400 s, which may be a performance bottleneck.
2023-11-04 05:59:29,838	WARNING util.py:214 -- The `start_trial` operation took 0.636 s, which may be a performance bottleneck.
2023-11-04 05:59:31,109	WARNING util.py:214 -- The `on_step_end` operation took 1.271 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 05:48:16 (running for 11:11:49.26)
Memory usage on this node: 27.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1513/1000000 (32 RUNNING, 1481 TERMINATED)


== Status ==
Current time: 2023-11-04 05:48:33 (running for 11:12:06.03)
Memory usage on this node: 27.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1513/1000000 (32 RUNNING, 1481 TERMINATED)


== Status ==
Current time: 2023-11-04 05:48:39 (running for 11:12:12.34)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1517/1000000 (1 PENDING, 31 RUNNING, 1485 TERMINATED)


== Status ==
Current time: 2023-11-04 05:50:54 (running for 11:14:26.99)
Memory usage on this node: 26.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1517/1000000 (1 PENDING, 31 RUNNING, 1485 TERMINATED)


== Status ==
Current time: 2023-11-04 05:51:01 (running for 11:14:33.89)
Memory usage on this node: 26.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1521/1000000 (1 PENDING, 30 RUNNING, 1490 TERMINATED)


== Status ==
Current time: 2023-11-04 05:53:39 (running for 11:17:11.77)
Memory usage on this node: 26.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1521/1000000 (31 RUNNING, 1490 TERMINATED)


== Status ==
Current time: 2023-11-04 05:53:45 (running for 11:17:18.30)
Memory usage on this node: 26.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1524/1000000 (31 RUNNING, 1493 TERMINATED)


== Status ==
Current time: 2023-11-04 05:56:30 (running for 11:20:02.53)
Memory usage on this node: 27.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1525/1000000 (1 PENDING, 31 RUNNING, 1493 TERMINATED)


== Status ==
Current time: 2023-11-04 05:56:36 (running for 11:20:09.11)
Memory usage on this node: 27.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1527/1000000 (1 PENDING, 31 RUNNING, 1495 TERMINATED)


== Status ==
Current time: 2023-11-04 05:59:24 (running for 11:22:56.97)
Memory usage on this node: 27.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1527/1000000 (1 PENDING, 31 RUNNING, 1495 TERMINATED)


2023-11-04 06:02:17,339	WARNING util.py:214 -- The `on_step_end` operation took 1.309 s, which may be a performance bottleneck.
2023-11-04 06:02:20,709	WARNING util.py:214 -- The `start_trial` operation took 0.546 s, which may be a performance bottleneck.
2023-11-04 06:02:24,903	WARNING util.py:214 -- The `on_step_end` operation took 1.745 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 06:03:20,380 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2456713) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 06:04:20,516 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2456732) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 06:07:21,950	WARNING util.py:214 -- The `on_step_end` operation took 1.553 s, which may be a performance bottleneck.
2023-11-04 06:07:27,086	WARNING util.py:214 -- The `start_trial` operation took 0.546 s, which may be a performance bottleneck.
2023-11-04 06:07:28,358	WARNING util.py:214 -- The `on_step_end` operation took 1.272 s, which may be a performance bottleneck.
2023-11-04 06:10:02,405	WARNING util.py:214 -- The `on_step_end` operation took 1.036 s, which may be a performance bottleneck.
2023-11-04 06:10:04,761	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
2023-11-04 06:10:05,391	WARNING util.py:214 -- The `start_trial` operation took 0.532 s, which may be a performance bottleneck.
2023-11-04 06:10:07,098	WARNING util.py:214 -- The `start_trial` operation took 0.540 s, which may be a performance bottleneck.
2023-11-04 06:10:07,703	WARNING util.py:214 -- The `start_trial` operation took 0.583 s, which may be a performance bottleneck.
2023-11-04 06:10:09,151	WARNING util.py:214 -- The `on_step_end` operation took 1.448 s, which may be a performance bottleneck.
2023-11-04 06:13:25,302	WARNING util.py:214 -- The `on_step_end` operation took 21.181 s, which may be a performance bottleneck.
2023-11-04 06:13:26,725	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.589 s, which may be a performance bottleneck.
2023-11-04 06:13:26,726	WARNING util.py:214 -- The `process_trial_result` operation took 0.589 s, which may be a performance bottleneck.
2023-11-04 06:13:26,726	WARNING util.py:214 -- Processing trial results took 0.589 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-04 06:13:26,726	WARNING util.py:214 -- The `process_trial_result` operation took 0.590 s, which may be a performance bottleneck.
2023-11-04 06:13:32,162	WARNING util.py:214 -- The `on_step_end` operation took 1.632 s, which may be a performance bottleneck.
2023-11-04 06:13:33,570	WARNING util.py:214 -- The `start_trial` operation took 0.663 s, which may be a performance bottleneck.
2023-11-04 06:13:34,300	WARNING util.py:214 -- The `start_trial` operation took 0.686 s, which may be a performance bottleneck.
2023-11-04 06:13:40,373	WARNING util.py:214 -- The `on_step_end` operation took 1.071 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 06:14:33,920 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2457195) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 06:15:34,020 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2457311) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 06:18:24,068	WARNING util.py:214 -- The `on_step_end` operation took 1.266 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 05:59:31 (running for 11:23:03.53)
Memory usage on this node: 27.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1530/1000000 (32 RUNNING, 1498 TERMINATED)


== Status ==
Current time: 2023-11-04 06:02:17 (running for 11:25:49.86)
Memory usage on this node: 28.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1530/1000000 (32 RUNNING, 1498 TERMINATED)


== Status ==
Current time: 2023-11-04 06:02:24 (running for 11:25:57.33)
Memory usage on this node: 27.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1533/1000000 (1 PENDING, 30 RUNNING, 1502 TERMINATED)


== Status ==
Current time: 2023-11-04 06:07:22 (running for 11:30:54.51)
Memory usage on this node: 27.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1533/1000000 (31 RUNNING, 1502 TERMINATED)


== Status ==
Current time: 2023-11-04 06:07:28 (running for 11:31:00.78)
Memory usage on this node: 27.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1535/1000000 (32 RUNNING, 1503 TERMINATED)


== Status ==
Current time: 2023-11-04 06:10:02 (running for 11:33:35.05)
Memory usage on this node: 27.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1535/1000000 (31 RUNNING, 1504 TERMINATED)


== Status ==
Current time: 2023-11-04 06:10:09 (running for 11:33:41.57)
Memory usage on this node: 28.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1540/1000000 (32 RUNNING, 1508 TERMINATED)


== Status ==
Current time: 2023-11-04 06:13:25 (running for 11:36:57.72)
Memory usage on this node: 28.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1540/1000000 (32 RUNNING, 1508 TERMINATED)


== Status ==
Current time: 2023-11-04 06:13:32 (running for 11:37:04.59)
Memory usage on this node: 28.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1545/1000000 (1 PENDING, 30 RUNNING, 1514 TERMINATED)


== Status ==
Current time: 2023-11-04 06:13:40 (running for 11:37:12.96)
Memory usage on this node: 28.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1546/1000000 (32 RUNNING, 1514 TERMINATED)


2023-11-04 06:18:28,600	WARNING util.py:214 -- The `start_trial` operation took 0.542 s, which may be a performance bottleneck.
2023-11-04 06:18:30,706	WARNING util.py:214 -- The `on_step_end` operation took 1.356 s, which may be a performance bottleneck.
2023-11-04 06:21:06,618	WARNING util.py:214 -- The `on_step_end` operation took 0.943 s, which may be a performance bottleneck.
2023-11-04 06:21:08,083	WARNING util.py:214 -- The `start_trial` operation took 0.555 s, which may be a performance bottleneck.
2023-11-04 06:21:13,125	WARNING util.py:214 -- The `on_step_end` operation took 1.451 s, which may be a performance bottleneck.
2023-11-04 06:23:46,571	WARNING util.py:214 -- The `on_step_end` operation took 1.603 s, which may be a performance bottleneck.
2023-11-04 06:23:48,368	WARNING util.py:214 -- The `start_trial` operation took 0.551 s, which may be a performance bottleneck.
2023-11-04 06:23:49,171	WARNING util.py:214 -- The `start_trial` operation took 0.581 s, which may be a performance bottleneck.
2023-11-04 06:23:50,324	WARNING util.py:214 -- The `start_trial` operation took 0.568 s, which may be a performance bottleneck.
2023-11-04 06:23:52,336	WARNING util.py:214 -- The `start_trial` operation took 0.748 s, which may be a performance bottleneck.
2023-11-04 06:23:54,000	WARNING util.py:214 -- The `on_step_end` operation took 1.664 s, which may be a performance bottleneck.
2023-11-04 06:26:41,371	WARNING util.py:214 -- The `on_step_end` operation took 0.964 s, which may be a performance bottleneck.
2023-11-04 06:26:45,234	WARNING util.py:214 -- The `start_trial` operation took 0.544 s, which may be a performance bottleneck.
2023-11-04 06:26:46,584	WARNING util.py:214 -- The `start_trial` operation took 0.589 s, which may be a performance bottleneck.
2023-11-04 06:26:48,339	WARNING util.py:214 -- The `on_step_end` operation took 1.755 s, which may be a performance bottleneck.
2023-11-04 06:29:54,185	WARNING util.py:214 -- The `on_step_end` operation took 1.670 s, which may be a performance bottleneck.
2023-11-04 06:29:57,717	WARNING util.py:214 -- The `start_trial` operation took 0.601 s, which may be a performance bottleneck.
2023-11-04 06:30:04,894	WARNING util.py:214 -- The `on_step_end` operation took 0.944 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 06:30:57,414 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2458184) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 06:30:58,796 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2458186) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 06:34:08,630	WARNING util.py:214 -- The `on_step_end` operation took 1.878 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 06:18:24 (running for 11:41:56.49)
Memory usage on this node: 29.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1546/1000000 (32 RUNNING, 1514 TERMINATED)


== Status ==
Current time: 2023-11-04 06:18:30 (running for 11:42:03.31)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1551/1000000 (1 PENDING, 30 RUNNING, 1520 TERMINATED)


== Status ==
Current time: 2023-11-04 06:21:06 (running for 11:44:39.05)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1551/1000000 (31 RUNNING, 1520 TERMINATED)


== Status ==
Current time: 2023-11-04 06:21:13 (running for 11:44:45.69)
Memory usage on this node: 28.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1556/1000000 (1 PENDING, 31 RUNNING, 1524 TERMINATED)


== Status ==
Current time: 2023-11-04 06:23:46 (running for 11:47:18.99)
Memory usage on this node: 29.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1556/1000000 (1 PENDING, 31 RUNNING, 1524 TERMINATED)


== Status ==
Current time: 2023-11-04 06:23:54 (running for 11:47:26.50)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1560/1000000 (32 RUNNING, 1528 TERMINATED)


== Status ==
Current time: 2023-11-04 06:26:41 (running for 11:50:13.79)
Memory usage on this node: 29.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1560/1000000 (32 RUNNING, 1528 TERMINATED)


== Status ==
Current time: 2023-11-04 06:26:48 (running for 11:50:20.76)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1562/1000000 (32 RUNNING, 1530 TERMINATED)


== Status ==
Current time: 2023-11-04 06:29:54 (running for 11:53:26.61)
Memory usage on this node: 29.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1562/1000000 (31 RUNNING, 1531 TERMINATED)


== Status ==
Current time: 2023-11-04 06:30:05 (running for 11:53:37.49)
Memory usage on this node: 29.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1565/1000000 (32 RUNNING, 1533 TERMINATED)


2023-11-04 06:34:11,059	WARNING util.py:214 -- The `start_trial` operation took 0.671 s, which may be a performance bottleneck.
2023-11-04 06:34:17,460	WARNING util.py:214 -- The `on_step_end` operation took 1.398 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 06:35:10,607 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2458446) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 06:36:10,839 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2458463) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 06:37:11,001 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2458480) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 06:40:08,202	WARNING util.py:214 -- The `on_step_end` operation took 1.592 s, which may be a performance bottleneck.
2023-11-04 06:40:12,560	WARNING util.py:214 -- The `start_trial` operation took 0.597 s, which may be a performance bottleneck.
2023-11-04 06:40:13,338	WARNING util.py:214 -- The `start_trial` operation took 0.573 s, which may be a performance bottleneck.
2023-11-04 06:40:14,693	WARNING util.py:214 -- The `on_step_end` operation took 1.355 s, which may be a performance bottleneck.
2023-11-04 06:43:02,898	WARNING util.py:214 -- The `on_step_end` operation took 1.209 s, which may be a performance bottleneck.
2023-11-04 06:45:53,409	WARNING util.py:214 -- The `on_step_end` operation took 1.391 s, which may be a performance bottleneck.
2023-11-04 06:45:56,546	WARNING util.py:214 -- The `start_trial` operation took 0.609 s, which may be a performance bottleneck.
2023-11-04 06:45:58,943	WARNING util.py:214 -- The `start_trial` operation took 0.627 s, which may be a performance bottleneck.
2023-11-04 06:46:00,257	WARNING util.py:214 -- The `on_step_end` operation took 1.314 s, which may be a performance bottleneck.
2023-11-04 06:48:43,523	WARNING util.py:214 -- The `on_step_end` operation took 1.368 s, which may be a performance bottleneck.
2023-11-04 06:48:45,663	WARNING util.py:214 -- The `start_trial` operation took 0.520 s, which may be a performance bottleneck.
2023-11-04 06:48:50,408	WARNING util.py:214 -- The `on_step_end` operation took 1.588 s, which may be a performance bottleneck.
2023-11-04 06:51:49,618	WARNING util.py:214 -- The `on_step_end` operation took 1.486 s, which may be a performance bottleneck.
2023-11-04 06:51:52,671	WARNING util.py:214 -- The `start_trial` operation took 0.573 s, which may be a performance bottleneck.
2023-11-04 06:51:53,264	WARNING util.py:214 -- The `start_trial` operation took 0.579 s, which may be a performance bottleneck.
2023-11-04 06:51:54,474	WARNING util.py:214 -- The `start_trial` operation took 0.537 s, which may be a performance bottleneck.
2023-11-04 06:51:55,165	WARNING util.py:214 -- The `start_trial` operation took 0.673 s, which may be a performance bottleneck.
2023-11-04 06:51:56,693	WARNING util.py:214 -- The `on_step_end` operation took 1.528 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 06:52:52,959 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2459209) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 06:52:54,851 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2459220) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-04 06:34:08 (running for 11:57:41.05)
Memory usage on this node: 30.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1565/1000000 (32 RUNNING, 1533 TERMINATED)


== Status ==
Current time: 2023-11-04 06:34:17 (running for 11:57:49.88)
Memory usage on this node: 30.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1566/1000000 (32 RUNNING, 1534 TERMINATED)


== Status ==
Current time: 2023-11-04 06:40:08 (running for 12:03:40.63)
Memory usage on this node: 31.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1566/1000000 (32 RUNNING, 1534 TERMINATED)


== Status ==
Current time: 2023-11-04 06:40:14 (running for 12:03:47.34)
Memory usage on this node: 29.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1569/1000000 (31 RUNNING, 1538 TERMINATED)


== Status ==
Current time: 2023-11-04 06:43:03 (running for 12:06:35.50)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1570/1000000 (32 RUNNING, 1538 TERMINATED)


== Status ==
Current time: 2023-11-04 06:45:53 (running for 12:09:25.90)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1570/1000000 (32 RUNNING, 1538 TERMINATED)


== Status ==
Current time: 2023-11-04 06:46:00 (running for 12:09:32.79)
Memory usage on this node: 29.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1574/1000000 (32 RUNNING, 1542 TERMINATED)


== Status ==
Current time: 2023-11-04 06:48:43 (running for 12:12:15.95)
Memory usage on this node: 29.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1574/1000000 (31 RUNNING, 1543 TERMINATED)


== Status ==
Current time: 2023-11-04 06:48:50 (running for 12:12:22.83)
Memory usage on this node: 29.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1579/1000000 (1 PENDING, 31 RUNNING, 1547 TERMINATED)


== Status ==
Current time: 2023-11-04 06:51:49 (running for 12:15:22.23)
Memory usage on this node: 30.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1579/1000000 (1 PENDING, 31 RUNNING, 1547 TERMINATED)


2023-11-04 06:55:54,777	WARNING util.py:214 -- The `on_step_end` operation took 1.983 s, which may be a performance bottleneck.
2023-11-04 06:55:57,577	WARNING util.py:214 -- The `start_trial` operation took 0.549 s, which may be a performance bottleneck.
2023-11-04 06:55:58,742	WARNING util.py:214 -- The `start_trial` operation took 0.604 s, which may be a performance bottleneck.
2023-11-04 06:56:01,775	WARNING util.py:214 -- The `on_step_end` operation took 1.471 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 06:57:00,245 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2459483) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 06:58:00,458 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2459504) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 07:01:08,480	WARNING util.py:214 -- The `on_step_end` operation took 1.908 s, which may be a performance bottleneck.
2023-11-04 07:01:15,205	WARNING util.py:214 -- The `on_step_end` operation took 1.505 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 07:02:13,409 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2459682) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 07:03:13,570 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2459702) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 07:06:15,235	WARNING util.py:214 -- The `on_step_end` operation took 1.460 s, which may be a performance bottleneck.
2023-11-04 07:06:18,404	WARNING util.py:214 -- The `callbacks.on_trial_result` operation took 0.533 s, which may be a performance bottleneck.
2023-11-04 07:06:18,404	WARNING util.py:214 -- The `process_trial_result` operation took 0.534 s, which may be a performance bottleneck.
2023-11-04 07:06:18,404	WARNING util.py:214 -- Processing trial results took 0.534 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.
2023-11-04 07:06:18,404	WARNING util.py:214 -- The `process_trial_result` operation took 0.534 s, which may be a performance bottleneck.
2023-11-04 07:06:22,910	WARNING util.py:214 -- The `on_step_end` operation took 1.807 s, which may be a performance bottleneck.
2023-11-04 07:08:40,379	WARNING util.py:214 -- The `on_step_end` operation took 0.962 s, which may be a performance bottleneck.
2023-11-04 07:08:47,451	WARNING util.py:214 -- The `on_step_end` operation took 1.765 s, which may be a performance bottleneck.
2023-11-04 07:11:30,026	WARNING util.py:214 -- The `on_step_end` operation took 1.272 s, which may be a performance bottleneck.
2023-11-04 07:13:36,483	WARNING util.py:214 -- The `on_step_end` operation took 0.963 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 06:51:56 (running for 12:15:29.12)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1583/1000000 (32 RUNNING, 1551 TERMINATED)


== Status ==
Current time: 2023-11-04 06:55:54 (running for 12:19:27.20)
Memory usage on this node: 31.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1583/1000000 (32 RUNNING, 1551 TERMINATED)


== Status ==
Current time: 2023-11-04 06:56:01 (running for 12:19:34.20)
Memory usage on this node: 31.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1586/1000000 (32 RUNNING, 1554 TERMINATED)


== Status ==
Current time: 2023-11-04 07:01:08 (running for 12:24:40.90)
Memory usage on this node: 31.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1586/1000000 (32 RUNNING, 1554 TERMINATED)


== Status ==
Current time: 2023-11-04 07:01:15 (running for 12:24:47.82)
Memory usage on this node: 31.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1588/1000000 (32 RUNNING, 1556 TERMINATED)


== Status ==
Current time: 2023-11-04 07:06:15 (running for 12:29:47.66)
Memory usage on this node: 31.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1588/1000000 (32 RUNNING, 1556 TERMINATED)


== Status ==
Current time: 2023-11-04 07:06:22 (running for 12:29:55.33)
Memory usage on this node: 31.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1590/1000000 (1 PENDING, 30 RUNNING, 1559 TERMINATED)


== Status ==
Current time: 2023-11-04 07:08:40 (running for 12:32:12.80)
Memory usage on this node: 31.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1590/1000000 (31 RUNNING, 1559 TERMINATED)


== Status ==
Current time: 2023-11-04 07:08:47 (running for 12:32:19.96)
Memory usage on this node: 30.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1593/1000000 (1 PENDING, 31 RUNNING, 1561 TERMINATED)


== Status ==
Current time: 2023-11-04 07:11:30 (running for 12:35:02.45)
Memory usage on this node: 31.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1593/1000000 (32 RUNNING, 1561 TERMINATED)


2023-11-04 07:13:42,940	WARNING util.py:214 -- The `on_step_end` operation took 1.208 s, which may be a performance bottleneck.
2023-11-04 07:13:46,904	WARNING util.py:214 -- The `start_trial` operation took 0.561 s, which may be a performance bottleneck.
2023-11-04 07:13:48,349	WARNING util.py:214 -- The `start_trial` operation took 0.639 s, which may be a performance bottleneck.
2023-11-04 07:13:49,768	WARNING util.py:214 -- The `on_step_end` operation took 1.418 s, which may be a performance bottleneck.
2023-11-04 07:13:51,926	WARNING util.py:214 -- The `start_trial` operation took 0.524 s, which may be a performance bottleneck.
2023-11-04 07:13:53,478	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
2023-11-04 07:13:59,653	WARNING util.py:214 -- The `on_step_end` operation took 1.171 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 07:14:53,208 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2460213) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 07:15:53,409 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2460290) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 07:16:53,604 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2460307) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 07:19:58,517	WARNING util.py:214 -- The `on_step_end` operation took 1.681 s, which may be a performance bottleneck.
2023-11-04 07:20:01,492	WARNING util.py:214 -- The `start_trial` operation took 0.572 s, which may be a performance bottleneck.
2023-11-04 07:20:03,933	WARNING util.py:214 -- The `start_trial` operation took 0.591 s, which may be a performance bottleneck.
2023-11-04 07:20:05,731	WARNING util.py:214 -- The `on_step_end` operation took 1.578 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 07:21:01,728 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2460544) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 07:22:01,935 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2460574) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 07:23:02,079 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2460616) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 07:26:01,935	WARNING util.py:214 -- The `on_step_end` operation took 1.208 s, which may be a performance bottleneck.
2023-11-04 07:26:06,556	WARNING util.py:214 -- The `start_trial` operation took 0.509 s, which may be a performance bottleneck.
2023-11-04 07:26:08,475	WARNING util.py:214 -- The `on_step_end` operation took 1.413 s, which may be a performance bottleneck.
2023-11-04 07:28:35,237	WARNING util.py:214 -- The `on_step_end` operation took 1.118 s, which may be a performance bottleneck.
2023-11-04 07:28:42,056	WARNING util.py:214 -- The `on_step_end` operation took 1.641 s, which may be a performance bottleneck.
2023-11-04 07:28:49,223	WARNING util.py:214 -- The `on_step_end` operation took 2.083 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 07:13:36 (running for 12:37:08.91)
Memory usage on this node: 31.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1593/1000000 (32 RUNNING, 1561 TERMINATED)


== Status ==
Current time: 2023-11-04 07:13:42 (running for 12:37:15.36)
Memory usage on this node: 31.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1596/1000000 (1 PENDING, 31 RUNNING, 1564 TERMINATED)


== Status ==
Current time: 2023-11-04 07:13:49 (running for 12:37:22.32)
Memory usage on this node: 31.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1600/1000000 (31 RUNNING, 1569 TERMINATED)


== Status ==
Current time: 2023-11-04 07:13:59 (running for 12:37:32.08)
Memory usage on this node: 31.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1602/1000000 (32 RUNNING, 1570 TERMINATED)


== Status ==
Current time: 2023-11-04 07:19:58 (running for 12:43:30.94)
Memory usage on this node: 32.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1602/1000000 (32 RUNNING, 1570 TERMINATED)


== Status ==
Current time: 2023-11-04 07:20:05 (running for 12:43:38.15)
Memory usage on this node: 31.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1606/1000000 (32 RUNNING, 1574 TERMINATED)


== Status ==
Current time: 2023-11-04 07:26:01 (running for 12:49:34.36)
Memory usage on this node: 31.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1606/1000000 (32 RUNNING, 1574 TERMINATED)


== Status ==
Current time: 2023-11-04 07:26:08 (running for 12:49:40.90)
Memory usage on this node: 31.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1609/1000000 (32 RUNNING, 1577 TERMINATED)


== Status ==
Current time: 2023-11-04 07:28:35 (running for 12:52:07.66)
Memory usage on this node: 31.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1609/1000000 (32 RUNNING, 1577 TERMINATED)


== Status ==
Current time: 2023-11-04 07:28:42 (running for 12:52:14.55)
Memory usage on this node: 31.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1612/1000000 (1 PENDING, 31 RUNNING, 1580 TERMINATED)


2023-11-04 07:31:41,482	WARNING util.py:214 -- The `on_step_end` operation took 1.647 s, which may be a performance bottleneck.
2023-11-04 07:31:43,000	WARNING util.py:214 -- The `start_trial` operation took 0.669 s, which may be a performance bottleneck.
2023-11-04 07:31:44,672	WARNING util.py:214 -- The `start_trial` operation took 0.604 s, which may be a performance bottleneck.
2023-11-04 07:31:48,530	WARNING util.py:214 -- The `on_step_end` operation took 1.890 s, which may be a performance bottleneck.
2023-11-04 07:34:25,605	WARNING util.py:214 -- The `on_step_end` operation took 0.917 s, which may be a performance bottleneck.
2023-11-04 07:34:27,250	WARNING util.py:214 -- The `start_trial` operation took 0.584 s, which may be a performance bottleneck.
2023-11-04 07:34:28,840	WARNING util.py:214 -- The `start_trial` operation took 0.647 s, which may be a performance bottleneck.
2023-11-04 07:34:29,762	WARNING util.py:214 -- The `start_trial` operation took 0.556 s, which may be a performance bottleneck.
2023-11-04 07:34:36,029	WARNING util.py:214 -- The `on_step_end` operation took 1.265 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 07:35:26,931 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2461193) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 07:38:33,989	WARNING util.py:214 -- The `on_step_end` operation took 1.707 s, which may be a performance bottleneck.
2023-11-04 07:38:37,115	WARNING util.py:214 -- The `start_trial` operation took 0.623 s, which may be a performance bottleneck.
2023-11-04 07:38:37,678	WARNING util.py:214 -- The `start_trial` operation took 0.550 s, which may be a performance bottleneck.
2023-11-04 07:38:43,982	WARNING util.py:214 -- The `on_step_end` operation took 1.301 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 07:39:37,371 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2461372) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 07:40:37,485 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2461514) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 07:43:47,750	WARNING util.py:214 -- The `on_step_end` operation took 1.734 s, which may be a performance bottleneck.
2023-11-04 07:43:50,926	WARNING util.py:214 -- The `start_trial` operation took 0.551 s, which may be a performance bottleneck.
2023-11-04 07:43:51,819	WARNING util.py:214 -- The `start_trial` operation took 0.877 s, which may be a performance bottleneck.
2023-11-04 07:43:54,489	WARNING util.py:214 -- The `on_step_end` operation took 1.602 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 07:44:51,373 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2461621) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 07:44:52,677 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2461627) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 07:47:56,548	WARNING util.py:214 -- The `on_step_end` operation took 1.724 s, which may be a performance bottleneck.
2023-11-04 07:47:59,380	WARNING util.py:214 -- The `start_trial` operation took 0.553 s, which may be a performance bottleneck.
2023-11-04 07:48:06,136	WARNING util.py:214 -- The `on_step_end` operation took 1.287 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 07:48:59,636 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2461767) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 07:49:59,844 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2461787) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 07:51:00,017 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2461928) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-04 07:28:49 (running for 12:52:21.65)
Memory usage on this node: 31.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1615/1000000 (31 RUNNING, 1584 TERMINATED)


== Status ==
Current time: 2023-11-04 07:31:41 (running for 12:55:13.98)
Memory usage on this node: 31.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1616/1000000 (1 PENDING, 31 RUNNING, 1584 TERMINATED)


== Status ==
Current time: 2023-11-04 07:31:48 (running for 12:55:21.06)
Memory usage on this node: 30.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1619/1000000 (1 PENDING, 30 RUNNING, 1588 TERMINATED)


== Status ==
Current time: 2023-11-04 07:34:25 (running for 12:57:58.03)
Memory usage on this node: 31.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1619/1000000 (31 RUNNING, 1588 TERMINATED)


== Status ==
Current time: 2023-11-04 07:34:36 (running for 12:58:08.58)
Memory usage on this node: 30.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1622/1000000 (32 RUNNING, 1590 TERMINATED)


== Status ==
Current time: 2023-11-04 07:38:34 (running for 13:02:06.50)
Memory usage on this node: 31.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1622/1000000 (32 RUNNING, 1590 TERMINATED)


== Status ==
Current time: 2023-11-04 07:38:43 (running for 13:02:16.40)
Memory usage on this node: 30.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1624/1000000 (32 RUNNING, 1592 TERMINATED)


== Status ==
Current time: 2023-11-04 07:43:47 (running for 13:07:20.17)
Memory usage on this node: 31.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1624/1000000 (32 RUNNING, 1592 TERMINATED)


== Status ==
Current time: 2023-11-04 07:43:54 (running for 13:07:26.91)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1627/1000000 (32 RUNNING, 1595 TERMINATED)


== Status ==
Current time: 2023-11-04 07:47:56 (running for 13:11:28.97)
Memory usage on this node: 30.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1627/1000000 (32 RUNNING, 1595 TERMINATED)


2023-11-04 07:53:55,605	WARNING util.py:214 -- The `on_step_end` operation took 1.287 s, which may be a performance bottleneck.
2023-11-04 07:53:59,675	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
2023-11-04 07:54:00,288	WARNING util.py:214 -- The `start_trial` operation took 0.522 s, which may be a performance bottleneck.
2023-11-04 07:54:02,724	WARNING util.py:214 -- The `on_step_end` operation took 1.655 s, which may be a performance bottleneck.
2023-11-04 07:54:04,730	WARNING util.py:214 -- The `start_trial` operation took 0.600 s, which may be a performance bottleneck.
2023-11-04 07:54:12,354	WARNING util.py:214 -- The `on_step_end` operation took 1.301 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 07:55:05,897 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2462063) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 07:56:06,000 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2462203) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 07:57:06,155 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2462221) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 07:58:06,332 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2462255) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 08:00:53,245	WARNING util.py:214 -- The `on_step_end` operation took 1.425 s, which may be a performance bottleneck.
2023-11-04 08:00:59,895	WARNING util.py:214 -- The `on_step_end` operation took 1.396 s, which may be a performance bottleneck.
2023-11-04 08:01:04,549	WARNING util.py:214 -- The `start_trial` operation took 0.508 s, which may be a performance bottleneck.
2023-11-04 08:01:06,611	WARNING util.py:214 -- The `start_trial` operation took 0.526 s, which may be a performance bottleneck.
2023-11-04 08:01:08,202	WARNING util.py:214 -- The `on_step_end` operation took 1.591 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 08:02:04,265 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2462430) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 08:05:00,526	WARNING util.py:214 -- The `on_step_end` operation took 1.717 s, which may be a performance bottleneck.
2023-11-04 08:05:03,946	WARNING util.py:214 -- The `start_trial` operation took 0.530 s, which may be a performance bottleneck.
2023-11-04 08:05:04,576	WARNING util.py:214 -- The `start_trial` operation took 0.622 s, which may be a performance bottleneck.
2023-11-04 08:05:05,501	WARNING util.py:214 -- The `start_trial` operation took 0.523 s, which may be a performance bottleneck.
2023-11-04 08:05:06,206	WARNING util.py:214 -- The `start_trial` operation took 0.584 s, which may be a performance bottleneck.
2023-11-04 08:05:07,861	WARNING util.py:214 -- The `on_step_end` operation took 1.655 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 08:06:04,208 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2462649) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 08:06:05,810 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2462653) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 08:08:54,935	WARNING util.py:214 -- The `on_step_end` operation took 1.366 s, which may be a performance bottleneck.
2023-11-04 08:09:10,591	WARNING util.py:214 -- The `on_step_end` operation took 1.345 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 07:48:06 (running for 13:11:38.61)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1629/1000000 (32 RUNNING, 1597 TERMINATED)


== Status ==
Current time: 2023-11-04 07:53:55 (running for 13:17:28.14)
Memory usage on this node: 30.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1629/1000000 (32 RUNNING, 1597 TERMINATED)


== Status ==
Current time: 2023-11-04 07:54:02 (running for 13:17:35.15)
Memory usage on this node: 30.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1633/1000000 (31 RUNNING, 1602 TERMINATED)


== Status ==
Current time: 2023-11-04 07:54:12 (running for 13:17:44.78)
Memory usage on this node: 30.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1636/1000000 (32 RUNNING, 1604 TERMINATED)


== Status ==
Current time: 2023-11-04 08:00:53 (running for 13:24:25.77)
Memory usage on this node: 31.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1636/1000000 (32 RUNNING, 1604 TERMINATED)


== Status ==
Current time: 2023-11-04 08:00:59 (running for 13:24:32.32)
Memory usage on this node: 31.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1639/1000000 (31 RUNNING, 1608 TERMINATED)


== Status ==
Current time: 2023-11-04 08:01:08 (running for 13:24:40.62)
Memory usage on this node: 31.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1643/1000000 (32 RUNNING, 1611 TERMINATED)


== Status ==
Current time: 2023-11-04 08:05:00 (running for 13:28:33.07)
Memory usage on this node: 31.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1643/1000000 (32 RUNNING, 1611 TERMINATED)


== Status ==
Current time: 2023-11-04 08:05:08 (running for 13:28:40.48)
Memory usage on this node: 31.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1647/1000000 (32 RUNNING, 1615 TERMINATED)


== Status ==
Current time: 2023-11-04 08:08:54 (running for 13:32:27.38)
Memory usage on this node: 32.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1647/1000000 (32 RUNNING, 1615 TERMINATED)


2023-11-04 08:09:13,655	WARNING util.py:214 -- The `start_trial` operation took 0.594 s, which may be a performance bottleneck.
2023-11-04 08:09:14,459	WARNING util.py:214 -- The `start_trial` operation took 0.503 s, which may be a performance bottleneck.
2023-11-04 08:09:15,079	WARNING util.py:214 -- The `start_trial` operation took 0.601 s, which may be a performance bottleneck.
2023-11-04 08:09:21,427	WARNING util.py:214 -- The `on_step_end` operation took 1.345 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 08:10:14,744 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2462911) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 08:13:37,892	WARNING util.py:214 -- The `on_step_end` operation took 24.169 s, which may be a performance bottleneck.
2023-11-04 08:13:52,970	WARNING util.py:214 -- The `on_step_end` operation took 1.226 s, which may be a performance bottleneck.
2023-11-04 08:13:55,748	WARNING util.py:214 -- The `start_trial` operation took 0.552 s, which may be a performance bottleneck.
2023-11-04 08:13:56,269	WARNING util.py:214 -- The `start_trial` operation took 0.512 s, which may be a performance bottleneck.
2023-11-04 08:14:02,446	WARNING util.py:214 -- The `on_step_end` operation took 1.174 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 08:14:55,959 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2463029) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 08:15:56,094 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2463090) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 08:18:56,785	WARNING util.py:214 -- The `on_step_end` operation took 1.641 s, which may be a performance bottleneck.
2023-11-04 08:19:01,944	WARNING util.py:214 -- The `start_trial` operation took 0.571 s, which may be a performance bottleneck.
2023-11-04 08:19:03,685	WARNING util.py:214 -- The `on_step_end` operation took 1.741 s, which may be a performance bottleneck.
2023-11-04 08:19:13,967	WARNING util.py:214 -- The `on_step_end` operation took 1.298 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 08:20:05,984 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2463213) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 08:20:07,805 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2463304) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 08:21:06,190 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2463324) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 08:21:07,967 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2463326) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 08:22:06,353 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2463387) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 08:22:08,198 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2463405) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 08:24:53,395	WARNING util.py:214 -- The `on_step_end` operation took 1.627 s, which may be a performance bottleneck.
2023-11-04 08:25:00,231	WARNING util.py:214 -- The `on_step_end` operation took 1.803 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 08:25:58,159 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2463599) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 08:26:58,292 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2463625) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 08:30:06,660	WARNING util.py:214 -- The `on_step_end` operation took 1.493 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 08:09:10 (running for 13:32:43.18)
Memory usage on this node: 32.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1647/1000000 (32 RUNNING, 1615 TERMINATED)


== Status ==
Current time: 2023-11-04 08:09:21 (running for 13:32:53.92)
Memory usage on this node: 31.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1650/1000000 (32 RUNNING, 1618 TERMINATED)


== Status ==
Current time: 2023-11-04 08:13:37 (running for 13:37:10.31)
Memory usage on this node: 32.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1650/1000000 (32 RUNNING, 1618 TERMINATED)


== Status ==
Current time: 2023-11-04 08:13:53 (running for 13:37:25.57)
Memory usage on this node: 32.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1650/1000000 (32 RUNNING, 1618 TERMINATED)


== Status ==
Current time: 2023-11-04 08:14:02 (running for 13:37:35.10)
Memory usage on this node: 31.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1652/1000000 (32 RUNNING, 1620 TERMINATED)


== Status ==
Current time: 2023-11-04 08:18:56 (running for 13:42:29.41)
Memory usage on this node: 32.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1652/1000000 (32 RUNNING, 1620 TERMINATED)


== Status ==
Current time: 2023-11-04 08:19:03 (running for 13:42:36.13)
Memory usage on this node: 31.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1655/1000000 (31 RUNNING, 1624 TERMINATED)


== Status ==
Current time: 2023-11-04 08:19:14 (running for 13:42:46.44)
Memory usage on this node: 31.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1657/1000000 (32 RUNNING, 1625 TERMINATED)


== Status ==
Current time: 2023-11-04 08:24:53 (running for 13:48:25.82)
Memory usage on this node: 31.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1657/1000000 (32 RUNNING, 1625 TERMINATED)


== Status ==
Current time: 2023-11-04 08:25:00 (running for 13:48:32.75)
Memory usage on this node: 31.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1661/1000000 (32 RUNNING, 1629 TERMINATED)


2023-11-04 08:30:10,595	WARNING util.py:214 -- The `start_trial` operation took 0.571 s, which may be a performance bottleneck.
2023-11-04 08:30:11,187	WARNING util.py:214 -- The `start_trial` operation took 0.576 s, which may be a performance bottleneck.
2023-11-04 08:30:13,809	WARNING util.py:214 -- The `on_step_end` operation took 1.892 s, which may be a performance bottleneck.
2023-11-04 08:32:49,879	WARNING util.py:214 -- The `on_step_end` operation took 1.100 s, which may be a performance bottleneck.
2023-11-04 08:35:24,221	WARNING util.py:214 -- The `on_step_end` operation took 1.385 s, which may be a performance bottleneck.
2023-11-04 08:35:26,921	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
2023-11-04 08:35:30,804	WARNING util.py:214 -- The `on_step_end` operation took 1.382 s, which may be a performance bottleneck.
2023-11-04 08:37:48,548	WARNING util.py:214 -- The `on_step_end` operation took 0.862 s, which may be a performance bottleneck.
2023-11-04 08:37:50,953	WARNING util.py:214 -- The `start_trial` operation took 0.508 s, which may be a performance bottleneck.
2023-11-04 08:37:55,192	WARNING util.py:214 -- The `on_step_end` operation took 1.435 s, which may be a performance bottleneck.
2023-11-04 08:40:22,860	WARNING util.py:214 -- The `on_step_end` operation took 1.423 s, which may be a performance bottleneck.
2023-11-04 08:40:27,341	WARNING util.py:214 -- The `start_trial` operation took 0.579 s, which may be a performance bottleneck.
2023-11-04 08:40:29,463	WARNING util.py:214 -- The `on_step_end` operation took 1.600 s, which may be a performance bottleneck.
2023-11-04 08:43:04,917	WARNING util.py:214 -- The `on_step_end` operation took 0.851 s, which may be a performance bottleneck.
2023-11-04 08:43:06,807	WARNING util.py:214 -- The `start_trial` operation took 0.579 s, which may be a performance bottleneck.
2023-11-04 08:43:07,337	WARNING util.py:214 -- The `start_trial` operation took 0.523 s, which may be a performance bottleneck.
2023-11-04 08:43:09,165	WARNING util.py:214 -- The `start_trial` operation took 0.531 s, which may be a performance bottleneck.
2023-11-04 08:43:09,787	WARNING util.py:214 -- The `start_trial` operation took 0.596 s, which may be a performance bottleneck.
2023-11-04 08:43:11,527	WARNING util.py:214 -- The `on_step_end` operation took 1.740 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 08:44:07,009 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2464497) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 08:44:09,452 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2464506) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 08:45:07,211 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2464579) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 08:45:09,681 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2464597) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 08:46:07,435 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2464617) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-04 08:30:06 (running for 13:53:39.08)
Memory usage on this node: 32.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1661/1000000 (31 RUNNING, 1630 TERMINATED)


== Status ==
Current time: 2023-11-04 08:30:13 (running for 13:53:46.37)
Memory usage on this node: 30.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1665/1000000 (1 PENDING, 31 RUNNING, 1633 TERMINATED)


== Status ==
Current time: 2023-11-04 08:32:49 (running for 13:56:22.34)
Memory usage on this node: 30.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1665/1000000 (32 RUNNING, 1633 TERMINATED)


== Status ==
Current time: 2023-11-04 08:35:24 (running for 13:58:56.78)
Memory usage on this node: 31.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1665/1000000 (32 RUNNING, 1633 TERMINATED)


== Status ==
Current time: 2023-11-04 08:35:30 (running for 13:59:03.23)
Memory usage on this node: 29.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1669/1000000 (1 PENDING, 30 RUNNING, 1638 TERMINATED)


== Status ==
Current time: 2023-11-04 08:37:48 (running for 14:01:21.13)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1669/1000000 (31 RUNNING, 1638 TERMINATED)


== Status ==
Current time: 2023-11-04 08:37:55 (running for 14:01:27.66)
Memory usage on this node: 29.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1673/1000000 (32 RUNNING, 1641 TERMINATED)


== Status ==
Current time: 2023-11-04 08:40:22 (running for 14:03:55.28)
Memory usage on this node: 30.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1673/1000000 (32 RUNNING, 1641 TERMINATED)


== Status ==
Current time: 2023-11-04 08:40:29 (running for 14:04:02.04)
Memory usage on this node: 29.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1677/1000000 (1 PENDING, 30 RUNNING, 1646 TERMINATED)


== Status ==
Current time: 2023-11-04 08:43:04 (running for 14:06:37.36)
Memory usage on this node: 30.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1677/1000000 (31 RUNNING, 1646 TERMINATED)


2023-11-04 08:49:09,013	WARNING util.py:214 -- The `on_step_end` operation took 1.744 s, which may be a performance bottleneck.
2023-11-04 08:49:11,926	WARNING util.py:214 -- The `start_trial` operation took 0.513 s, which may be a performance bottleneck.
2023-11-04 08:49:18,827	WARNING util.py:214 -- The `on_step_end` operation took 1.293 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 08:50:12,419 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2464835) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 08:53:09,398	WARNING util.py:214 -- The `on_step_end` operation took 1.424 s, which may be a performance bottleneck.
2023-11-04 08:53:12,517	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
2023-11-04 08:53:13,158	WARNING util.py:214 -- The `start_trial` operation took 0.521 s, which may be a performance bottleneck.
2023-11-04 08:53:16,780	WARNING util.py:214 -- The `on_step_end` operation took 1.361 s, which may be a performance bottleneck.
2023-11-04 08:56:11,828	WARNING util.py:214 -- The `on_step_end` operation took 1.987 s, which may be a performance bottleneck.
2023-11-04 08:56:15,491	WARNING util.py:214 -- The `start_trial` operation took 0.556 s, which may be a performance bottleneck.
2023-11-04 08:56:22,898	WARNING util.py:214 -- The `on_step_end` operation took 1.350 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 08:57:15,220 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2465116) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 08:57:16,434 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2465118) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 08:58:16,607 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2465141) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 09:01:29,658	WARNING util.py:214 -- The `on_step_end` operation took 1.641 s, which may be a performance bottleneck.
2023-11-04 09:01:32,789	WARNING util.py:214 -- The `start_trial` operation took 0.710 s, which may be a performance bottleneck.
2023-11-04 09:01:34,531	WARNING util.py:214 -- The `start_trial` operation took 0.532 s, which may be a performance bottleneck.
2023-11-04 09:01:40,655	WARNING util.py:214 -- The `on_step_end` operation took 1.122 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 09:02:32,335 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2465411) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:02:34,331 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2465414) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 09:05:25,543	WARNING util.py:214 -- The `on_step_end` operation took 1.366 s, which may be a performance bottleneck.
2023-11-04 09:05:34,521	WARNING util.py:214 -- The `on_step_end` operation took 1.515 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 09:06:27,931 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2465569) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:07:28,101 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2465586) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-04 08:43:11 (running for 14:06:43.95)
Memory usage on this node: 29.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1682/1000000 (32 RUNNING, 1650 TERMINATED)


== Status ==
Current time: 2023-11-04 08:49:09 (running for 14:12:41.44)
Memory usage on this node: 30.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1682/1000000 (32 RUNNING, 1650 TERMINATED)


== Status ==
Current time: 2023-11-04 08:49:18 (running for 14:12:51.41)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1684/1000000 (32 RUNNING, 1652 TERMINATED)


== Status ==
Current time: 2023-11-04 08:53:09 (running for 14:16:41.82)
Memory usage on this node: 30.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1684/1000000 (32 RUNNING, 1652 TERMINATED)


== Status ==
Current time: 2023-11-04 08:53:16 (running for 14:16:49.37)
Memory usage on this node: 30.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1687/1000000 (32 RUNNING, 1655 TERMINATED)


== Status ==
Current time: 2023-11-04 08:56:11 (running for 14:19:44.32)
Memory usage on this node: 31.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1687/1000000 (32 RUNNING, 1655 TERMINATED)


== Status ==
Current time: 2023-11-04 08:56:23 (running for 14:19:55.46)
Memory usage on this node: 30.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1690/1000000 (32 RUNNING, 1658 TERMINATED)


== Status ==
Current time: 2023-11-04 09:01:29 (running for 14:25:02.30)
Memory usage on this node: 31.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1690/1000000 (32 RUNNING, 1658 TERMINATED)


== Status ==
Current time: 2023-11-04 09:01:40 (running for 14:25:13.08)
Memory usage on this node: 30.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1692/1000000 (32 RUNNING, 1660 TERMINATED)


== Status ==
Current time: 2023-11-04 09:05:25 (running for 14:28:57.97)
Memory usage on this node: 32.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1692/1000000 (32 RUNNING, 1660 TERMINATED)


2023-11-04 09:10:28,417	WARNING util.py:214 -- The `on_step_end` operation took 1.696 s, which may be a performance bottleneck.
2023-11-04 09:10:35,086	WARNING util.py:214 -- The `on_step_end` operation took 1.614 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 09:11:32,844 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2465813) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 09:14:44,954	WARNING util.py:214 -- The `on_step_end` operation took 1.987 s, which may be a performance bottleneck.
2023-11-04 09:14:47,097	WARNING util.py:214 -- The `start_trial` operation took 0.631 s, which may be a performance bottleneck.
2023-11-04 09:14:53,495	WARNING util.py:214 -- The `on_step_end` operation took 1.395 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 09:15:46,760 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2465938) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:16:46,930 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2465955) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 09:19:53,285	WARNING util.py:214 -- The `on_step_end` operation took 1.657 s, which may be a performance bottleneck.
2023-11-04 09:19:56,352	WARNING util.py:214 -- The `start_trial` operation took 0.538 s, which may be a performance bottleneck.
2023-11-04 09:20:04,297	WARNING util.py:214 -- The `on_step_end` operation took 1.231 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 09:20:56,083 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2466178) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:20:57,894 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2466183) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:21:56,240 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2466203) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 09:25:01,361	WARNING util.py:214 -- The `on_step_end` operation took 1.777 s, which may be a performance bottleneck.
2023-11-04 09:25:10,940	WARNING util.py:214 -- The `on_step_end` operation took 1.397 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 09:26:04,503 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2466444) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:27:04,749 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2466461) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:28:04,919 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2466479) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 09:31:11,027	WARNING util.py:214 -- The `on_step_end` operation took 1.715 s, which may be a performance bottleneck.
2023-11-04 09:31:14,021	WARNING util.py:214 -- The `start_trial` operation took 0.546 s, which may be a performance bottleneck.
2023-11-04 09:31:14,711	WARNING util.py:214 -- The `start_trial` operation took 0.679 s, which may be a performance bottleneck.
2023-11-04 09:31:15,790	WARNING util.py:214 -- The `start_trial` operation took 0.519 s, which may be a performance bottleneck.
2023-11-04 09:31:18,201	WARNING util.py:214 -- The `on_step_end` operation took 1.281 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 09:32:14,317 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2466710) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:33:14,500 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2466737) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:34:14,607 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2466781) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:35:14,793 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2466840) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:36:14,963 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2466861) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:37:15,115 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2466878) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:38:15,226 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2466896) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:39:15,401 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2466914) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-04 09:05:34 (running for 14:29:06.94)
Memory usage on this node: 32.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1693/1000000 (32 RUNNING, 1661 TERMINATED)


== Status ==
Current time: 2023-11-04 09:10:28 (running for 14:34:01.00)
Memory usage on this node: 32.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1693/1000000 (32 RUNNING, 1661 TERMINATED)


== Status ==
Current time: 2023-11-04 09:10:35 (running for 14:34:07.64)
Memory usage on this node: 31.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1697/1000000 (1 PENDING, 30 RUNNING, 1666 TERMINATED)


== Status ==
Current time: 2023-11-04 09:14:45 (running for 14:38:17.58)
Memory usage on this node: 32.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1697/1000000 (31 RUNNING, 1666 TERMINATED)


== Status ==
Current time: 2023-11-04 09:14:53 (running for 14:38:25.95)
Memory usage on this node: 32.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1698/1000000 (32 RUNNING, 1666 TERMINATED)


== Status ==
Current time: 2023-11-04 09:19:53 (running for 14:43:25.96)
Memory usage on this node: 33.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1698/1000000 (32 RUNNING, 1666 TERMINATED)


== Status ==
Current time: 2023-11-04 09:20:04 (running for 14:43:36.97)
Memory usage on this node: 32.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1701/1000000 (32 RUNNING, 1669 TERMINATED)


== Status ==
Current time: 2023-11-04 09:25:01 (running for 14:48:33.78)
Memory usage on this node: 33.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1701/1000000 (32 RUNNING, 1669 TERMINATED)


== Status ==
Current time: 2023-11-04 09:25:10 (running for 14:48:43.39)
Memory usage on this node: 33.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1702/1000000 (32 RUNNING, 1670 TERMINATED)


== Status ==
Current time: 2023-11-04 09:31:11 (running for 14:54:43.45)
Memory usage on this node: 34.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1702/1000000 (32 RUNNING, 1670 TERMINATED)


2023-11-04 09:42:26,287	WARNING util.py:214 -- The `on_step_end` operation took 1.662 s, which may be a performance bottleneck.
2023-11-04 09:42:29,492	WARNING util.py:214 -- The `start_trial` operation took 0.505 s, which may be a performance bottleneck.
2023-11-04 09:42:30,018	WARNING util.py:214 -- The `start_trial` operation took 0.516 s, which may be a performance bottleneck.
2023-11-04 09:42:31,746	WARNING util.py:214 -- The `start_trial` operation took 0.589 s, which may be a performance bottleneck.
2023-11-04 09:42:33,549	WARNING util.py:214 -- The `on_step_end` operation took 1.802 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 09:43:29,738 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2467105) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:43:31,438 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2467112) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 09:46:23,562	WARNING util.py:214 -- The `on_step_end` operation took 1.451 s, which may be a performance bottleneck.
2023-11-04 09:46:27,583	WARNING util.py:214 -- The `start_trial` operation took 0.503 s, which may be a performance bottleneck.
2023-11-04 09:46:28,225	WARNING util.py:214 -- The `start_trial` operation took 0.633 s, which may be a performance bottleneck.
2023-11-04 09:46:30,819	WARNING util.py:214 -- The `on_step_end` operation took 2.178 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 09:47:27,814 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2467287) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:48:27,973 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2467312) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:49:28,162 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2467331) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:50:28,390 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2467431) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:51:28,555 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2467451) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 09:54:43,416	WARNING util.py:214 -- The `on_step_end` operation took 1.940 s, which may be a performance bottleneck.
2023-11-04 09:54:44,997	WARNING util.py:214 -- The `start_trial` operation took 0.708 s, which may be a performance bottleneck.
2023-11-04 09:54:53,042	WARNING util.py:214 -- The `on_step_end` operation took 1.178 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 09:55:44,761 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2467606) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:55:46,729 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2467609) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 09:58:31,736	WARNING util.py:214 -- The `on_step_end` operation took 1.102 s, which may be a performance bottleneck.
2023-11-04 09:58:34,630	WARNING util.py:214 -- The `start_trial` operation took 0.531 s, which may be a performance bottleneck.
2023-11-04 09:58:42,536	WARNING util.py:214 -- The `on_step_end` operation took 1.201 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 09:59:34,883 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2467755) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 09:59:36,133 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2467757) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 10:02:36,413	WARNING util.py:214 -- The `on_step_end` operation took 1.999 s, which may be a performance bottleneck.
2023-11-04 10:02:39,682	WARNING util.py:214 -- The `start_trial` operation took 0.509 s, which may be a performance bottleneck.
2023-11-04 10:02:40,243	WARNING util.py:214 -- The `start_trial` operation took 0.508 s, which may be a performance bottleneck.
2023-11-04 10:02:43,024	WARNING util.py:214 -- The `on_step_end` operation took 1.514 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 10:03:39,876 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2467989) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:03:41,391 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2467991) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:04:40,037 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2468012) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:05:40,204 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2468085) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-04 09:31:18 (running for 14:54:50.62)
Memory usage on this node: 33.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1706/1000000 (32 RUNNING, 1674 TERMINATED)


== Status ==
Current time: 2023-11-04 09:42:26 (running for 15:05:58.71)
Memory usage on this node: 34.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1706/1000000 (32 RUNNING, 1674 TERMINATED)


== Status ==
Current time: 2023-11-04 09:42:33 (running for 15:06:06.11)
Memory usage on this node: 33.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1710/1000000 (32 RUNNING, 1678 TERMINATED)


== Status ==
Current time: 2023-11-04 09:46:23 (running for 15:09:56.15)
Memory usage on this node: 34.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1710/1000000 (32 RUNNING, 1678 TERMINATED)


== Status ==
Current time: 2023-11-04 09:46:30 (running for 15:10:03.35)
Memory usage on this node: 32.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1713/1000000 (31 RUNNING, 1682 TERMINATED)


== Status ==
Current time: 2023-11-04 09:54:43 (running for 15:18:15.93)
Memory usage on this node: 33.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1714/1000000 (1 PENDING, 31 RUNNING, 1682 TERMINATED)


== Status ==
Current time: 2023-11-04 09:54:53 (running for 15:18:25.52)
Memory usage on this node: 33.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1715/1000000 (32 RUNNING, 1683 TERMINATED)


== Status ==
Current time: 2023-11-04 09:58:31 (running for 15:22:04.22)
Memory usage on this node: 34.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1715/1000000 (32 RUNNING, 1683 TERMINATED)


== Status ==
Current time: 2023-11-04 09:58:42 (running for 15:22:15.13)
Memory usage on this node: 32.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1718/1000000 (32 RUNNING, 1686 TERMINATED)


== Status ==
Current time: 2023-11-04 10:02:36 (running for 15:26:08.88)
Memory usage on this node: 32.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1718/1000000 (32 RUNNING, 1686 TERMINATED)


2023-11-04 10:08:59,275	WARNING util.py:214 -- The `on_step_end` operation took 1.776 s, which may be a performance bottleneck.
2023-11-04 10:09:08,503	WARNING util.py:214 -- The `on_step_end` operation took 1.207 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 10:10:02,133 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2468222) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:11:02,315 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2468321) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 10:14:03,950	WARNING util.py:214 -- The `on_step_end` operation took 1.671 s, which may be a performance bottleneck.
2023-11-04 10:14:09,407	WARNING util.py:214 -- The `start_trial` operation took 0.503 s, which may be a performance bottleneck.
2023-11-04 10:14:11,122	WARNING util.py:214 -- The `on_step_end` operation took 1.715 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 10:15:09,106 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2468486) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 10:18:22,292	WARNING util.py:214 -- The `on_step_end` operation took 1.765 s, which may be a performance bottleneck.
2023-11-04 10:18:24,942	WARNING util.py:214 -- The `start_trial` operation took 0.628 s, which may be a performance bottleneck.
2023-11-04 10:18:33,200	WARNING util.py:214 -- The `on_step_end` operation took 1.458 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 10:19:24,620 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2468596) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:20:24,811 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2468723) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:21:24,960 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2468770) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:22:25,098 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2468792) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 10:25:27,956	WARNING util.py:214 -- The `on_step_end` operation took 1.558 s, which may be a performance bottleneck.
2023-11-04 10:25:30,911	WARNING util.py:214 -- The `start_trial` operation took 0.507 s, which may be a performance bottleneck.
2023-11-04 10:25:32,007	WARNING util.py:214 -- The `start_trial` operation took 0.588 s, which may be a performance bottleneck.
2023-11-04 10:25:32,602	WARNING util.py:214 -- The `start_trial` operation took 0.585 s, which may be a performance bottleneck.
2023-11-04 10:25:34,897	WARNING util.py:214 -- The `on_step_end` operation took 1.871 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 10:26:32,288 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2468986) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:27:32,450 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469010) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:28:32,607 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469028) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:29:32,722 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469046) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:30:32,907 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469115) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 10:34:06,189	WARNING util.py:214 -- The `on_step_end` operation took 1.983 s, which may be a performance bottleneck.
2023-11-04 10:34:08,245	WARNING util.py:214 -- The `start_trial` operation took 0.548 s, which may be a performance bottleneck.
2023-11-04 10:34:09,298	WARNING util.py:214 -- The `start_trial` operation took 0.630 s, which may be a performance bottleneck.
2023-11-04 10:34:15,480	WARNING util.py:214 -- The `on_step_end` operation took 1.179 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 10:35:07,980 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469300) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:36:08,150 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469339) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-04 10:02:43 (running for 15:26:15.45)
Memory usage on this node: 32.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1721/1000000 (32 RUNNING, 1689 TERMINATED)


== Status ==
Current time: 2023-11-04 10:08:59 (running for 15:32:32.00)
Memory usage on this node: 32.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1721/1000000 (32 RUNNING, 1689 TERMINATED)


== Status ==
Current time: 2023-11-04 10:09:08 (running for 15:32:41.04)
Memory usage on this node: 32.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1722/1000000 (32 RUNNING, 1690 TERMINATED)


== Status ==
Current time: 2023-11-04 10:14:04 (running for 15:37:36.49)
Memory usage on this node: 32.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1722/1000000 (32 RUNNING, 1690 TERMINATED)


== Status ==
Current time: 2023-11-04 10:14:11 (running for 15:37:43.60)
Memory usage on this node: 32.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1726/1000000 (32 RUNNING, 1694 TERMINATED)


== Status ==
Current time: 2023-11-04 10:18:22 (running for 15:41:54.94)
Memory usage on this node: 33.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1726/1000000 (32 RUNNING, 1694 TERMINATED)


== Status ==
Current time: 2023-11-04 10:18:33 (running for 15:42:05.62)
Memory usage on this node: 32.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1729/1000000 (32 RUNNING, 1697 TERMINATED)


== Status ==
Current time: 2023-11-04 10:25:28 (running for 15:49:00.70)
Memory usage on this node: 34.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1729/1000000 (32 RUNNING, 1697 TERMINATED)


== Status ==
Current time: 2023-11-04 10:25:35 (running for 15:49:07.59)
Memory usage on this node: 32.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1732/1000000 (31 RUNNING, 1701 TERMINATED)


== Status ==
Current time: 2023-11-04 10:34:06 (running for 15:57:38.82)
Memory usage on this node: 33.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1733/1000000 (1 PENDING, 31 RUNNING, 1701 TERMINATED)


2023-11-04 10:39:17,475	WARNING util.py:214 -- The `on_step_end` operation took 1.708 s, which may be a performance bottleneck.
2023-11-04 10:39:20,440	WARNING util.py:214 -- The `start_trial` operation took 0.534 s, which may be a performance bottleneck.
2023-11-04 10:39:22,134	WARNING util.py:214 -- The `start_trial` operation took 0.623 s, which may be a performance bottleneck.
2023-11-04 10:39:28,722	WARNING util.py:214 -- The `on_step_end` operation took 1.585 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 10:40:21,740 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469529) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:41:21,896 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469553) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:42:22,091 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469570) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:43:22,344 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469587) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 10:46:32,798	WARNING util.py:214 -- The `on_step_end` operation took 2.033 s, which may be a performance bottleneck.
2023-11-04 10:46:36,214	WARNING util.py:214 -- The `start_trial` operation took 0.570 s, which may be a performance bottleneck.
2023-11-04 10:46:42,578	WARNING util.py:214 -- The `on_step_end` operation took 1.362 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 10:47:35,883 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469768) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:48:36,038 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469789) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:49:36,209 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469807) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:50:36,408 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469876) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:51:36,574 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469894) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:52:36,740 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469911) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:53:36,851 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469938) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:54:37,037 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2469955) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:55:37,264 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470047) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 10:58:39,897	WARNING util.py:214 -- The `on_step_end` operation took 1.894 s, which may be a performance bottleneck.
2023-11-04 10:58:43,433	WARNING util.py:214 -- The `start_trial` operation took 0.541 s, which may be a performance bottleneck.
2023-11-04 10:58:43,993	WARNING util.py:214 -- The `start_trial` operation took 0.552 s, which may be a performance bottleneck.
2023-11-04 10:58:47,209	WARNING util.py:214 -- The `on_step_end` operation took 1.548 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 10:59:43,602 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470156) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 10:59:45,502 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470158) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:00:43,777 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470228) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:00:45,667 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470230) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:01:43,937 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470248) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:01:45,840 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470250) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 11:04:56,204	WARNING util.py:214 -- The `on_step_end` operation took 2.180 s, which may be a performance bottleneck.
2023-11-04 11:05:06,068	WARNING util.py:214 -- The `on_step_end` operation took 1.587 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 11:05:59,380 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470488) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:06:59,550 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470505) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:07:59,703 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470523) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:08:59,859 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470541) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:10:00,003 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470558) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:11:00,205 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470646) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:12:00,427 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470664) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:13:00,619 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470681) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:14:00,819 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470697) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:15:00,965 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470717) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 11:18:14,924	WARNING util.py:214 -- The `on_step_end` operation took 1.627 s, which may be a performance bottleneck.
2023-11-04 11:18:17,899	WARNING util.py:214 -- The `start_trial` operation took 0.618 s, which may be a performance bottleneck.
2023-11-04 11:18:24,811	WARNING util.py:214 -- The `on_step_end` operation took 1.228 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 11:19:18,531 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470886) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:20:18,782 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470977) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:21:18,973 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2470995) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:22:19,172 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471012) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:23:19,349 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471030) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:24:19,504 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471048) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:25:19,620 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471124) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:26:19,778 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471141) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:27:19,971 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471158) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:28:20,162 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471176) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:29:20,326 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471197) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:30:20,500 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471281) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:31:20,649 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471301) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:32:20,824 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471318) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-04 10:34:15 (running for 15:57:47.90)
Memory usage on this node: 33.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1734/1000000 (32 RUNNING, 1702 TERMINATED)


== Status ==
Current time: 2023-11-04 10:39:17 (running for 16:02:50.07)
Memory usage on this node: 34.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1734/1000000 (32 RUNNING, 1702 TERMINATED)


== Status ==
Current time: 2023-11-04 10:39:28 (running for 16:03:01.16)
Memory usage on this node: 34.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1737/1000000 (32 RUNNING, 1705 TERMINATED)


== Status ==
Current time: 2023-11-04 10:46:32 (running for 16:10:05.22)
Memory usage on this node: 36.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1737/1000000 (32 RUNNING, 1705 TERMINATED)


== Status ==
Current time: 2023-11-04 10:46:42 (running for 16:10:15.00)
Memory usage on this node: 35.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1739/1000000 (32 RUNNING, 1707 TERMINATED)


== Status ==
Current time: 2023-11-04 10:58:40 (running for 16:22:12.59)
Memory usage on this node: 38.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1739/1000000 (32 RUNNING, 1707 TERMINATED)


== Status ==
Current time: 2023-11-04 10:58:47 (running for 16:22:19.73)
Memory usage on this node: 37.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1742/1000000 (32 RUNNING, 1710 TERMINATED)


== Status ==
Current time: 2023-11-04 11:04:56 (running for 16:28:28.72)
Memory usage on this node: 38.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1742/1000000 (32 RUNNING, 1710 TERMINATED)


== Status ==
Current time: 2023-11-04 11:05:06 (running for 16:28:38.49)
Memory usage on this node: 38.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1743/1000000 (32 RUNNING, 1711 TERMINATED)


== Status ==
Current time: 2023-11-04 11:18:14 (running for 16:41:47.35)
Memory usage on this node: 39.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1743/1000000 (32 RUNNING, 1711 TERMINATED)


2023-11-04 11:35:27,482	WARNING util.py:214 -- The `on_step_end` operation took 1.968 s, which may be a performance bottleneck.
2023-11-04 11:35:30,201	WARNING util.py:214 -- The `start_trial` operation took 0.516 s, which may be a performance bottleneck.
2023-11-04 11:35:31,474	WARNING util.py:214 -- The `start_trial` operation took 0.553 s, which may be a performance bottleneck.
2023-11-04 11:35:34,301	WARNING util.py:214 -- The `on_step_end` operation took 1.280 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 11:36:29,904 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471479) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:37:30,058 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471501) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 11:40:52,900	WARNING util.py:214 -- The `on_step_end` operation took 1.729 s, which may be a performance bottleneck.
2023-11-04 11:41:02,387	WARNING util.py:214 -- The `on_step_end` operation took 1.422 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 11:41:56,258 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471797) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:42:56,432 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471813) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:43:56,591 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471847) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:44:56,772 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471862) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:45:56,960 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471929) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:46:57,154 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471946) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:47:57,320 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2471964) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 11:50:51,021	WARNING util.py:214 -- The `on_step_end` operation took 1.386 s, which may be a performance bottleneck.
2023-11-04 11:50:56,296	WARNING util.py:214 -- The `start_trial` operation took 0.611 s, which may be a performance bottleneck.
2023-11-04 11:50:57,826	WARNING util.py:214 -- The `on_step_end` operation took 1.529 s, which may be a performance bottleneck.
2023-11-04 11:51:00,838	WARNING util.py:214 -- The `start_trial` operation took 0.542 s, which may be a performance bottleneck.
2023-11-04 11:51:01,395	WARNING util.py:214 -- The `start_trial` operation took 0.520 s, which may be a performance bottleneck.
2023-11-04 11:51:08,007	WARNING util.py:214 -- The `on_step_end` operation took 1.608 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 11:52:01,132 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472181) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:53:01,274 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472211) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:54:01,412 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472228) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 11:55:01,603 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472243) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 11:58:17,489	WARNING util.py:214 -- The `on_step_end` operation took 1.979 s, which may be a performance bottleneck.
2023-11-04 11:58:20,508	WARNING util.py:214 -- The `start_trial` operation took 0.501 s, which may be a performance bottleneck.
2023-11-04 11:58:28,287	WARNING util.py:214 -- The `on_step_end` operation took 1.421 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 11:59:21,694 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472474) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:00:21,879 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472519) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:01:22,104 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472537) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:02:22,299 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472555) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:03:22,456 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472572) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:04:22,648 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472592) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:05:22,806 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472710) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:06:22,992 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472727) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:07:23,183 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472744) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:08:23,380 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472763) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:09:23,536 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472780) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 12:12:37,915	WARNING util.py:214 -- The `on_step_end` operation took 1.750 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 11:18:24 (running for 16:41:57.23)
Memory usage on this node: 38.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1745/1000000 (32 RUNNING, 1713 TERMINATED)


== Status ==
Current time: 2023-11-04 11:35:27 (running for 16:58:59.95)
Memory usage on this node: 39.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1745/1000000 (32 RUNNING, 1713 TERMINATED)


== Status ==
Current time: 2023-11-04 11:35:34 (running for 16:59:06.85)
Memory usage on this node: 38.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1748/1000000 (32 RUNNING, 1716 TERMINATED)


== Status ==
Current time: 2023-11-04 11:40:53 (running for 17:04:25.54)
Memory usage on this node: 39.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1748/1000000 (32 RUNNING, 1716 TERMINATED)


== Status ==
Current time: 2023-11-04 11:41:02 (running for 17:04:34.81)
Memory usage on this node: 38.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1749/1000000 (32 RUNNING, 1717 TERMINATED)


== Status ==
Current time: 2023-11-04 11:50:51 (running for 17:14:23.44)
Memory usage on this node: 38.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1749/1000000 (32 RUNNING, 1717 TERMINATED)


== Status ==
Current time: 2023-11-04 11:50:57 (running for 17:14:30.25)
Memory usage on this node: 38.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1752/1000000 (31 RUNNING, 1721 TERMINATED)


== Status ==
Current time: 2023-11-04 11:51:08 (running for 17:14:40.43)
Memory usage on this node: 38.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1755/1000000 (32 RUNNING, 1723 TERMINATED)


== Status ==
Current time: 2023-11-04 11:58:17 (running for 17:21:49.91)
Memory usage on this node: 39.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1755/1000000 (32 RUNNING, 1723 TERMINATED)


== Status ==
Current time: 2023-11-04 11:58:28 (running for 17:22:00.71)
Memory usage on this node: 38.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1757/1000000 (32 RUNNING, 1725 TERMINATED)


2023-11-04 12:12:48,012	WARNING util.py:214 -- The `on_step_end` operation took 1.299 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 12:13:41,695 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472939) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:14:41,829 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2472959) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:15:42,046 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473050) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:16:42,252 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473070) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:17:42,437 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473088) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:18:42,574 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473108) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:19:42,725 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473127) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 12:22:51,938	WARNING util.py:214 -- The `on_step_end` operation took 1.679 s, which may be a performance bottleneck.
2023-11-04 12:22:54,912	WARNING util.py:214 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.
2023-11-04 12:23:02,142	WARNING util.py:214 -- The `on_step_end` operation took 1.566 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 12:23:55,503 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473287) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:24:55,672 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473304) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:25:55,860 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473398) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:26:56,049 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473415) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:27:56,233 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473433) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:28:56,418 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473467) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:29:56,614 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473484) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:30:56,798 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473554) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 12:34:11,532	WARNING util.py:214 -- The `on_step_end` operation took 1.539 s, which may be a performance bottleneck.
2023-11-04 12:34:15,708	WARNING util.py:214 -- The `start_trial` operation took 0.503 s, which may be a performance bottleneck.
2023-11-04 12:34:16,432	WARNING util.py:214 -- The `start_trial` operation took 0.548 s, which may be a performance bottleneck.
2023-11-04 12:34:18,623	WARNING util.py:214 -- The `on_step_end` operation took 1.932 s, which may be a performance bottleneck.
2023-11-04 12:34:20,227	WARNING util.py:214 -- The `start_trial` operation took 0.656 s, which may be a performance bottleneck.
2023-11-04 12:34:27,492	WARNING util.py:214 -- The `on_step_end` operation took 1.343 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 12:35:21,105 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473756) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:36:21,254 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473776) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:37:21,417 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473793) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:38:21,572 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2473822) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 12:41:22,955	WARNING util.py:214 -- The `on_step_end` operation took 1.667 s, which may be a performance bottleneck.
2023-11-04 12:41:27,152	WARNING util.py:214 -- The `start_trial` operation took 0.577 s, which may be a performance bottleneck.
2023-11-04 12:41:29,828	WARNING util.py:214 -- The `on_step_end` operation took 1.497 s, which may be a performance bottleneck.
2023-11-04 12:44:25,268	WARNING util.py:214 -- The `on_step_end` operation took 1.549 s, which may be a performance bottleneck.
2023-11-04 12:44:28,129	WARNING util.py:214 -- The `start_trial` operation took 0.597 s, which may be a performance bottleneck.
2023-11-04 12:44:35,164	WARNING util.py:214 -- The `on_step_end` operation took 1.426 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 12:45:28,658 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2474170) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:46:28,941 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2474190) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:47:29,132 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2474207) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:48:29,329 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2474225) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:49:29,462 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2474244) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:50:29,662 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2474316) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:51:29,892 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2474334) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-04 12:12:37 (running for 17:36:10.34)
Memory usage on this node: 39.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1757/1000000 (32 RUNNING, 1725 TERMINATED)


== Status ==
Current time: 2023-11-04 12:12:48 (running for 17:36:20.69)
Memory usage on this node: 38.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1759/1000000 (32 RUNNING, 1727 TERMINATED)


== Status ==
Current time: 2023-11-04 12:22:52 (running for 17:46:24.51)
Memory usage on this node: 39.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1759/1000000 (32 RUNNING, 1727 TERMINATED)


== Status ==
Current time: 2023-11-04 12:23:02 (running for 17:46:34.57)
Memory usage on this node: 38.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1761/1000000 (32 RUNNING, 1729 TERMINATED)


== Status ==
Current time: 2023-11-04 12:34:11 (running for 17:57:43.95)
Memory usage on this node: 39.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1761/1000000 (32 RUNNING, 1729 TERMINATED)


== Status ==
Current time: 2023-11-04 12:34:18 (running for 17:57:51.05)
Memory usage on this node: 38.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 120.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1765/1000000 (1 PENDING, 30 RUNNING, 1734 TERMINATED)


== Status ==
Current time: 2023-11-04 12:34:27 (running for 17:58:00.02)
Memory usage on this node: 38.1/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1766/1000000 (32 RUNNING, 1734 TERMINATED)


== Status ==
Current time: 2023-11-04 12:41:23 (running for 18:04:55.44)
Memory usage on this node: 38.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1766/1000000 (32 RUNNING, 1734 TERMINATED)


== Status ==
Current time: 2023-11-04 12:41:30 (running for 18:05:02.45)
Memory usage on this node: 37.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1769/1000000 (32 RUNNING, 1737 TERMINATED)


== Status ==
Current time: 2023-11-04 12:44:25 (running for 18:07:57.69)
Memory usage on this node: 39.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1769/1000000 (32 RUNNING, 1737 TERMINATED)


2023-11-04 12:54:42,636	WARNING util.py:214 -- The `on_step_end` operation took 1.526 s, which may be a performance bottleneck.
2023-11-04 12:54:46,249	WARNING util.py:214 -- The `start_trial` operation took 0.574 s, which may be a performance bottleneck.
2023-11-04 12:54:48,314	WARNING util.py:214 -- The `start_trial` operation took 0.652 s, which may be a performance bottleneck.
2023-11-04 12:54:50,416	WARNING util.py:214 -- The `on_step_end` operation took 1.995 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 12:55:45,890 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2474520) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 12:58:26,973	WARNING util.py:214 -- The `on_step_end` operation took 1.353 s, which may be a performance bottleneck.
2023-11-04 12:58:30,066	WARNING util.py:214 -- The `start_trial` operation took 0.521 s, which may be a performance bottleneck.
2023-11-04 12:58:30,693	WARNING util.py:214 -- The `start_trial` operation took 0.616 s, which may be a performance bottleneck.
2023-11-04 12:58:38,359	WARNING util.py:214 -- The `on_step_end` operation took 1.508 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 12:59:30,345 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2474663) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 12:59:31,822 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2474665) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:00:30,527 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2474750) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:00:31,951 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2474755) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:01:30,667 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2474789) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:01:32,150 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2474791) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:02:30,839 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2474808) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:02:32,345 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2474810) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 13:05:52,274	WARNING util.py:214 -- The `on_step_end` operation took 2.157 s, which may be a performance bottleneck.
2023-11-04 13:05:59,633	WARNING util.py:214 -- The `on_step_end` operation took 1.208 s, which may be a performance bottleneck.
2023-11-04 13:06:07,104	WARNING util.py:214 -- The `on_step_end` operation took 1.283 s, which may be a performance bottleneck.
2023-11-04 13:06:14,762	WARNING util.py:214 -- The `on_step_end` operation took 1.487 s, which may be a performance bottleneck.
2023-11-04 13:06:22,413	WARNING util.py:214 -- The `on_step_end` operation took 1.458 s, which may be a performance bottleneck.
2023-11-04 13:06:30,364	WARNING util.py:214 -- The `on_step_end` operation took 1.544 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 12:44:35 (running for 18:08:07.59)
Memory usage on this node: 37.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1771/1000000 (32 RUNNING, 1739 TERMINATED)


== Status ==
Current time: 2023-11-04 12:54:42 (running for 18:18:15.06)
Memory usage on this node: 38.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1771/1000000 (32 RUNNING, 1739 TERMINATED)


== Status ==
Current time: 2023-11-04 12:54:50 (running for 18:18:22.86)
Memory usage on this node: 36.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1775/1000000 (32 RUNNING, 1743 TERMINATED)


== Status ==
Current time: 2023-11-04 12:58:27 (running for 18:21:59.59)
Memory usage on this node: 37.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1775/1000000 (32 RUNNING, 1743 TERMINATED)


== Status ==
Current time: 2023-11-04 12:58:38 (running for 18:22:10.89)
Memory usage on this node: 37.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1778/1000000 (32 RUNNING, 1746 TERMINATED)


== Status ==
Current time: 2023-11-04 13:05:52 (running for 18:29:24.70)
Memory usage on this node: 38.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1778/1000000 (32 RUNNING, 1746 TERMINATED)


== Status ==
Current time: 2023-11-04 13:05:59 (running for 18:29:32.31)
Memory usage on this node: 37.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1778/1000000 (32 RUNNING, 1746 TERMINATED)


== Status ==
Current time: 2023-11-04 13:06:07 (running for 18:29:39.65)
Memory usage on this node: 37.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1778/1000000 (32 RUNNING, 1746 TERMINATED)


== Status ==
Current time: 2023-11-04 13:06:14 (running for 18:29:47.19)
Memory usage on this node: 37.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1778/1000000 (32 RUNNING, 1746 TERMINATED)


== Status ==
Current time: 2023-11-04 13:06:22 (running for 18:29:55.13)
Memory usage on this node: 37.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1778/1000000 (32 RUNNING, 1746 TERMINATED)


2023-11-04 13:06:38,060	WARNING util.py:214 -- The `on_step_end` operation took 1.493 s, which may be a performance bottleneck.
2023-11-04 13:06:45,657	WARNING util.py:214 -- The `on_step_end` operation took 1.471 s, which may be a performance bottleneck.
2023-11-04 13:06:53,248	WARNING util.py:214 -- The `on_step_end` operation took 1.408 s, which may be a performance bottleneck.
2023-11-04 13:07:01,009	WARNING util.py:214 -- The `on_step_end` operation took 1.717 s, which may be a performance bottleneck.
2023-11-04 13:07:08,710	WARNING util.py:214 -- The `on_step_end` operation took 1.465 s, which may be a performance bottleneck.
2023-11-04 13:07:18,923	WARNING util.py:214 -- The `on_step_end` operation took 1.432 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 13:08:12,351 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2475029) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:09:12,508 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2475048) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:10:12,697 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2475131) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:11:12,895 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2475151) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:12:13,091 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2475168) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 13:15:24,502	WARNING util.py:214 -- The `on_step_end` operation took 1.983 s, which may be a performance bottleneck.
2023-11-04 13:15:27,222	WARNING util.py:214 -- The `start_trial` operation took 0.501 s, which may be a performance bottleneck.
2023-11-04 13:15:27,963	WARNING util.py:214 -- The `start_trial` operation took 0.732 s, which may be a performance bottleneck.
2023-11-04 13:15:29,765	WARNING util.py:214 -- The `start_trial` operation took 0.529 s, which may be a performance bottleneck.
2023-11-04 13:15:31,627	WARNING util.py:214 -- The `on_step_end` operation took 1.862 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 13:16:27,594 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2475335) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:17:27,746 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2475362) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:18:27,937 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2475386) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 13:21:37,663	WARNING util.py:214 -- The `on_step_end` operation took 1.556 s, which may be a performance bottleneck.
2023-11-04 13:21:39,237	WARNING util.py:214 -- The `start_trial` operation took 0.647 s, which may be a performance bottleneck.
2023-11-04 13:21:47,168	WARNING util.py:214 -- The `on_step_end` operation took 1.255 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 13:22:38,919 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2475553) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:22:40,881 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2475556) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:23:39,115 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2475573) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:23:41,628 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2475576) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:24:39,331 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2475594) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-04 13:06:30 (running for 18:30:02.79)
Memory usage on this node: 37.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1778/1000000 (32 RUNNING, 1746 TERMINATED)


== Status ==
Current time: 2023-11-04 13:06:38 (running for 18:30:10.55)
Memory usage on this node: 37.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1778/1000000 (32 RUNNING, 1746 TERMINATED)


== Status ==
Current time: 2023-11-04 13:06:45 (running for 18:30:18.27)
Memory usage on this node: 38.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1778/1000000 (32 RUNNING, 1746 TERMINATED)


== Status ==
Current time: 2023-11-04 13:06:53 (running for 18:30:25.67)
Memory usage on this node: 37.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1778/1000000 (32 RUNNING, 1746 TERMINATED)


== Status ==
Current time: 2023-11-04 13:07:01 (running for 18:30:33.59)
Memory usage on this node: 37.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1778/1000000 (32 RUNNING, 1746 TERMINATED)


== Status ==
Current time: 2023-11-04 13:07:08 (running for 18:30:41.40)
Memory usage on this node: 37.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1778/1000000 (32 RUNNING, 1746 TERMINATED)


== Status ==
Current time: 2023-11-04 13:07:19 (running for 18:30:51.53)
Memory usage on this node: 37.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1779/1000000 (32 RUNNING, 1747 TERMINATED)


== Status ==
Current time: 2023-11-04 13:15:24 (running for 18:38:56.92)
Memory usage on this node: 38.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1779/1000000 (32 RUNNING, 1747 TERMINATED)


== Status ==
Current time: 2023-11-04 13:15:31 (running for 18:39:04.18)
Memory usage on this node: 37.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1782/1000000 (31 RUNNING, 1751 TERMINATED)


== Status ==
Current time: 2023-11-04 13:21:37 (running for 18:45:10.09)
Memory usage on this node: 40.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1783/1000000 (1 PENDING, 31 RUNNING, 1751 TERMINATED)


2023-11-04 13:27:49,644	WARNING util.py:214 -- The `on_step_end` operation took 1.996 s, which may be a performance bottleneck.
2023-11-04 13:27:53,487	WARNING util.py:214 -- The `start_trial` operation took 0.737 s, which may be a performance bottleneck.
2023-11-04 13:27:56,153	WARNING util.py:214 -- The `on_step_end` operation took 1.374 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 13:28:54,730 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2475813) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:29:54,938 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2475858) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 13:33:12,434	WARNING util.py:214 -- The `on_step_end` operation took 1.833 s, which may be a performance bottleneck.
2023-11-04 13:33:22,579	WARNING util.py:214 -- The `on_step_end` operation took 1.346 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 13:34:16,183 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2476069) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:35:16,390 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2476202) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:36:16,537 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2476219) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:37:16,752 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2476236) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:38:16,928 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2476257) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:39:17,089 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2476275) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:40:17,254 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2476414) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:41:17,425 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2476432) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:42:17,616 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2476449) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 13:45:29,994	WARNING util.py:214 -- The `on_step_end` operation took 2.029 s, which may be a performance bottleneck.
2023-11-04 13:45:34,115	WARNING util.py:214 -- The `start_trial` operation took 0.664 s, which may be a performance bottleneck.
2023-11-04 13:45:40,979	WARNING util.py:214 -- The `on_step_end` operation took 1.381 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 13:46:34,364 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2476674) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:47:34,530 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2476697) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:48:34,690 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2476716) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:49:34,855 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2476734) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:50:35,057 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2476854) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 13:51:35,222 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2476872) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 13:54:40,664	WARNING util.py:214 -- The `on_step_end` operation took 1.771 s, which may be a performance bottleneck.
2023-11-04 13:54:44,994	WARNING util.py:214 -- The `start_trial` operation took 0.606 s, which may be a performance bottleneck.
2023-11-04 13:54:45,604	WARNING util.py:214 -- The `start_trial` operation took 0.600 s, which may be a performance bottleneck.
2023-11-04 13:54:47,815	WARNING util.py:214 -- The `on_step_end` operation took 2.094 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 13:55:45,202 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2477024) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 13:58:31,231	WARNING util.py:214 -- The `on_step_end` operation took 1.634 s, which may be a performance bottleneck.
2023-11-04 13:58:32,699	WARNING util.py:214 -- The `start_trial` operation took 0.677 s, which may be a performance bottleneck.
2023-11-04 13:58:48,341	WARNING util.py:214 -- The `on_step_end` operation took 1.642 s, which may be a performance bottleneck.
== Status ==
Current time: 2023-11-04 13:21:47 (running for 18:45:19.75)
Memory usage on this node: 39.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1784/1000000 (32 RUNNING, 1752 TERMINATED)


== Status ==
Current time: 2023-11-04 13:27:49 (running for 18:51:22.07)
Memory usage on this node: 40.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1784/1000000 (32 RUNNING, 1752 TERMINATED)


== Status ==
Current time: 2023-11-04 13:27:56 (running for 18:51:28.58)
Memory usage on this node: 38.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1787/1000000 (32 RUNNING, 1755 TERMINATED)


== Status ==
Current time: 2023-11-04 13:33:12 (running for 18:56:45.04)
Memory usage on this node: 39.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1787/1000000 (32 RUNNING, 1755 TERMINATED)


== Status ==
Current time: 2023-11-04 13:33:22 (running for 18:56:55.00)
Memory usage on this node: 38.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1789/1000000 (32 RUNNING, 1757 TERMINATED)


== Status ==
Current time: 2023-11-04 13:45:30 (running for 19:09:02.64)
Memory usage on this node: 40.5/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1789/1000000 (32 RUNNING, 1757 TERMINATED)


== Status ==
Current time: 2023-11-04 13:45:41 (running for 19:09:13.50)
Memory usage on this node: 40.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1792/1000000 (32 RUNNING, 1760 TERMINATED)


== Status ==
Current time: 2023-11-04 13:54:40 (running for 19:18:13.22)
Memory usage on this node: 40.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1792/1000000 (32 RUNNING, 1760 TERMINATED)


== Status ==
Current time: 2023-11-04 13:54:48 (running for 19:18:20.47)
Memory usage on this node: 39.4/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1795/1000000 (31 RUNNING, 1764 TERMINATED)


== Status ==
Current time: 2023-11-04 13:58:31 (running for 19:22:03.65)
Memory usage on this node: 39.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 124.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1796/1000000 (1 PENDING, 31 RUNNING, 1764 TERMINATED)


2023-11-04 14:01:23,189	WARNING util.py:214 -- The `on_step_end` operation took 1.340 s, which may be a performance bottleneck.
2023-11-04 14:01:25,740	WARNING util.py:214 -- The `start_trial` operation took 0.574 s, which may be a performance bottleneck.
2023-11-04 14:01:26,320	WARNING util.py:214 -- The `start_trial` operation took 0.571 s, which may be a performance bottleneck.
2023-11-04 14:01:30,560	WARNING util.py:214 -- The `on_step_end` operation took 2.062 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 14:02:26,026 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2477298) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 14:02:28,337 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2477306) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 14:05:26,093	WARNING util.py:214 -- The `on_step_end` operation took 1.584 s, which may be a performance bottleneck.
2023-11-04 14:05:35,054	WARNING util.py:214 -- The `on_step_end` operation took 1.298 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 14:06:28,670 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2477528) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 14:07:28,872 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2477647) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 14:10:52,289	WARNING util.py:214 -- The `on_step_end` operation took 2.021 s, which may be a performance bottleneck.
2023-11-04 14:11:01,899	WARNING util.py:214 -- The `on_step_end` operation took 1.615 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 14:11:55,166 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2477852) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 14:12:55,357 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2477869) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 14:13:55,497 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2477886) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 14:14:55,645 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2477904) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 14:15:55,829 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2477958) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 14:16:55,961 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2477975) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 14:17:56,168 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2477995) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 14:18:56,346 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2478016) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 14:19:56,521 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2478034) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 14:23:11,389	WARNING util.py:214 -- The `on_step_end` operation took 2.197 s, which may be a performance bottleneck.
2023-11-04 14:23:14,352	WARNING util.py:214 -- The `start_trial` operation took 0.596 s, which may be a performance bottleneck.
2023-11-04 14:23:22,078	WARNING util.py:214 -- The `on_step_end` operation took 1.531 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 14:24:15,399 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2478234) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 14:25:15,584 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2478377) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 14:26:15,747 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2478394) have not registered within the timeout. The process is still alive, probably it's hanging during start.
2023-11-04 14:29:33,514	WARNING util.py:214 -- The `on_step_end` operation took 2.017 s, which may be a performance bottleneck.
2023-11-04 14:29:43,291	WARNING util.py:214 -- The `on_step_end` operation took 1.530 s, which may be a performance bottleneck.
[2m[33m(raylet)[0m [2023-11-04 14:30:36,657 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2478517) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 14:31:36,861 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2478535) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 14:32:37,044 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2478552) have not registered within the timeout. The process is still alive, probably it's hanging during start.
[2m[33m(raylet)[0m [2023-11-04 14:33:37,234 E 488902 488902] (raylet) worker_pool.cc:502: Some workers of the worker process(2478569) have not registered within the timeout. The process is still alive, probably it's hanging during start.
== Status ==
Current time: 2023-11-04 13:58:48 (running for 19:22:20.95)
Memory usage on this node: 39.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1796/1000000 (32 RUNNING, 1764 TERMINATED)


== Status ==
Current time: 2023-11-04 14:01:23 (running for 19:24:55.81)
Memory usage on this node: 39.9/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1796/1000000 (32 RUNNING, 1764 TERMINATED)


== Status ==
Current time: 2023-11-04 14:01:30 (running for 19:25:02.98)
Memory usage on this node: 38.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1800/1000000 (32 RUNNING, 1768 TERMINATED)


== Status ==
Current time: 2023-11-04 14:05:26 (running for 19:28:58.71)
Memory usage on this node: 40.0/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1800/1000000 (32 RUNNING, 1768 TERMINATED)


== Status ==
Current time: 2023-11-04 14:05:35 (running for 19:29:07.77)
Memory usage on this node: 39.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1801/1000000 (32 RUNNING, 1769 TERMINATED)


== Status ==
Current time: 2023-11-04 14:10:52 (running for 19:34:24.94)
Memory usage on this node: 39.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1801/1000000 (32 RUNNING, 1769 TERMINATED)


== Status ==
Current time: 2023-11-04 14:11:01 (running for 19:34:34.40)
Memory usage on this node: 38.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1802/1000000 (32 RUNNING, 1770 TERMINATED)


== Status ==
Current time: 2023-11-04 14:23:11 (running for 19:46:43.90)
Memory usage on this node: 39.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1802/1000000 (32 RUNNING, 1770 TERMINATED)


== Status ==
Current time: 2023-11-04 14:23:22 (running for 19:46:54.50)
Memory usage on this node: 39.3/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1804/1000000 (32 RUNNING, 1772 TERMINATED)


== Status ==
Current time: 2023-11-04 14:29:33 (running for 19:53:06.19)
Memory usage on this node: 40.7/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1804/1000000 (32 RUNNING, 1772 TERMINATED)


2023-11-04 14:36:40,861	INFO stopper.py:363 -- Reached timeout of 71999.82826375961 seconds. Stopping all trials.
2023-11-04 14:40:48,178	WARNING util.py:214 -- The `on_step_end` operation took 1.501 s, which may be a performance bottleneck.
2023-11-04 16:19:06,769	INFO tune.py:747 -- Total run time: 78159.27 seconds (72261.52 seconds for the tuning loop).
== Status ==
Current time: 2023-11-04 14:29:43 (running for 19:53:15.71)
Memory usage on this node: 39.8/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 128.0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1805/1000000 (32 RUNNING, 1773 TERMINATED)


== Status ==
Current time: 2023-11-04 14:40:48 (running for 20:04:20.75)
Memory usage on this node: 38.2/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1805/1000000 (1805 TERMINATED)


== Status ==
Current time: 2023-11-04 14:41:02 (running for 20:04:34.99)
Memory usage on this node: 38.6/995.5 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/128 CPUs, 0/0 GPUs, 0.0/795.17 GiB heap, 0.0/186.26 GiB objects
Current best trial: d02a2334 with val_loss=477.9336681063475 and parameters={'n_estimators': 5686, 'max_depth': 6, 'min_child_weight': 0.061424699278297426, 'learning_rate': 0.002642725415312793, 'subsample': 0.8805524271612375, 'colsample_bylevel': 0.8311030749720376, 'colsample_bytree': 0.2291156259805124, 'reg_alpha': 0.01723212586279316, 'reg_lambda': 0.7407486688086379, 'learner': 'xgb_limitdepth'}
Result logdir: /home/e/e1124485/ray_results/train_2023-11-03_18-36-27
Number of trials: 1805/1000000 (1805 TERMINATED)


[flaml.automl.logger: 11-04 16:19:34] {2493} INFO - selected model: None
[flaml.automl.logger: 11-04 16:20:03] {2627} INFO - retrain xgb_limitdepth for 29.0s
[flaml.automl.logger: 11-04 16:20:03] {2630} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[],
             colsample_bylevel=0.8311030749720376, colsample_bynode=None,
             colsample_bytree=0.2291156259805124, device=None,
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.002642725415312793, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=6, max_leaves=None,
             min_child_weight=0.061424699278297426, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=5686,
             n_jobs=4, num_parallel_tree=None, random_state=None, ...)
[flaml.automl.logger: 11-04 16:20:03] {1930} INFO - fit succeeded
[flaml.automl.logger: 11-04 16:20:03] {1931} INFO - Time taken to find the best model: 16590.49664926529
/home/e/e1124485/CS5228/trial7/ensemble7.py:75: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  KNN_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:86: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  predict_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:75: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  KNN_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:86: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  predict_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:75: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  KNN_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:86: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  predict_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:75: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  KNN_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:86: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  predict_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:75: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  KNN_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:86: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  predict_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:75: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  KNN_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:86: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  predict_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:75: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  KNN_X['latitude'] *= 2
/home/e/e1124485/CS5228/trial7/ensemble7.py:86: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  predict_X['latitude'] *= 2
